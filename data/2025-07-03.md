<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 88]
- [eess.SY](#eess.SY) [Total: 14]
- [cs.SD](#cs.SD) [Total: 4]
- [cs.NE](#cs.NE) [Total: 4]
- [cs.RO](#cs.RO) [Total: 28]
- [cs.HC](#cs.HC) [Total: 14]
- [cs.GR](#cs.GR) [Total: 3]
- [cs.GT](#cs.GT) [Total: 3]
- [cs.LG](#cs.LG) [Total: 86]
- [cs.MA](#cs.MA) [Total: 4]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Geometry-aware 4D Video Generation for Robot Manipulation](https://arxiv.org/abs/2507.01099)
*Zeyi Liu,Shuang Li,Eric Cousineau,Siyuan Feng,Benjamin Burchfiel,Shuran Song*

Main category: cs.CV

TL;DR: 提出了一种4D视频生成模型，通过跨视角点图对齐监督，实现多视角3D一致性，提升机器人对复杂环境的理解和预测能力。


<details>
  <summary>Details</summary>
Motivation: 增强机器人在复杂环境中的规划和交互能力，解决现有视频生成模型在时间连贯性和几何一致性上的不足。

Method: 使用跨视角点图对齐监督训练模型，学习共享3D场景表示，仅需RGB-D观测即可预测未来视频序列。

Result: 在模拟和真实机器人数据集上，生成更稳定且空间对齐的视频预测，并能恢复机器人末端执行器轨迹。

Conclusion: 该方法支持机器人操作和适应新视角，为动态场景建模提供了有效解决方案。

Abstract: Understanding and predicting the dynamics of the physical world can enhance a
robot's ability to plan and interact effectively in complex environments. While
recent video generation models have shown strong potential in modeling dynamic
scenes, generating videos that are both temporally coherent and geometrically
consistent across camera views remains a significant challenge. To address
this, we propose a 4D video generation model that enforces multi-view 3D
consistency of videos by supervising the model with cross-view pointmap
alignment during training. This geometric supervision enables the model to
learn a shared 3D representation of the scene, allowing it to predict future
video sequences from novel viewpoints based solely on the given RGB-D
observations, without requiring camera poses as inputs. Compared to existing
baselines, our method produces more visually stable and spatially aligned
predictions across multiple simulated and real-world robotic datasets. We
further show that the predicted 4D videos can be used to recover robot
end-effector trajectories using an off-the-shelf 6DoF pose tracker, supporting
robust robot manipulation and generalization to novel camera viewpoints.

</details>


### [2] [Landslide Detection and Mapping Using Deep Learning Across Multi-Source Satellite Data and Geographic Regions](https://arxiv.org/abs/2507.01123)
*Rahul A. Burange,Harsh K. Shinde,Omkar Mutyalwar*

Main category: cs.CV

TL;DR: 该研究提出了一种结合多源卫星影像和深度学习模型的方法，用于提高滑坡识别和预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 滑坡对基础设施、经济和人类生命构成严重威胁，需要准确检测和预测。

Method: 利用Sentinel-2多光谱数据和ALOS PALSAR生成的坡度及数字高程模型（DEM）层，结合多种地理空间分析技术，评估地形特征、植被覆盖和降雨对检测精度的影响。同时，评估了U-Net、DeepLabV3+和Res-Net等深度学习分割模型的性能。

Result: 研究结果为开发可靠的早期预警系统、改进灾害风险管理和可持续土地利用规划提供了有价值的见解。

Conclusion: 深度学习与多源遥感数据结合在构建稳健、可扩展和可迁移的滑坡预测模型中具有巨大潜力。

Abstract: Landslides pose severe threats to infrastructure, economies, and human lives,
necessitating accurate detection and predictive mapping across diverse
geographic regions. With advancements in deep learning and remote sensing,
automated landslide detection has become increasingly effective. This study
presents a comprehensive approach integrating multi-source satellite imagery
and deep learning models to enhance landslide identification and prediction. We
leverage Sentinel-2 multispectral data and ALOS PALSAR-derived slope and
Digital Elevation Model (DEM) layers to capture critical environmental features
influencing landslide occurrences. Various geospatial analysis techniques are
employed to assess the impact of terra in characteristics, vegetation cover,
and rainfall on detection accuracy. Additionally, we evaluate the performance
of multiple stateof-the-art deep learning segmentation models, including U-Net,
DeepLabV3+, and Res-Net, to determine their effectiveness in landslide
detection. The proposed framework contributes to the development of reliable
early warning systems, improved disaster risk management, and sustainable
land-use planning. Our findings provide valuable insights into the potential of
deep learning and multi-source remote sensing in creating robust, scalable, and
transferable landslide prediction models.

</details>


### [3] [cp_measure: API-first feature extraction for image-based profiling workflows](https://arxiv.org/abs/2507.01163)
*Alán F. Muñoz,Tim Treis,Alexandr A. Kalinin,Shatavisha Dasgupta,Fabian Theis,Anne E. Carpenter,Shantanu Singh*

Main category: cs.CV

TL;DR: cp_measure是一个Python库，将CellProfiler的核心测量功能模块化，便于程序化特征提取，支持机器学习工作流。


<details>
  <summary>Details</summary>
Motivation: 当前工具如CellProfiler在自动化、可重复分析方面存在障碍，阻碍了机器学习工作流。

Method: 开发cp_measure库，提取CellProfiler的核心测量功能，设计为模块化、API优先的工具。

Result: cp_measure特征与CellProfiler特征高度一致，并能无缝集成Python生态系统。

Conclusion: cp_measure支持可重复、自动化的图像分析流程，适用于计算生物学中的机器学习应用。

Abstract: Biological image analysis has traditionally focused on measuring specific
visual properties of interest for cells or other entities. A complementary
paradigm gaining increasing traction is image-based profiling - quantifying
many distinct visual features to form comprehensive profiles which may reveal
hidden patterns in cellular states, drug responses, and disease mechanisms.
While current tools like CellProfiler can generate these feature sets, they
pose significant barriers to automated and reproducible analyses, hindering
machine learning workflows. Here we introduce cp_measure, a Python library that
extracts CellProfiler's core measurement capabilities into a modular, API-first
tool designed for programmatic feature extraction. We demonstrate that
cp_measure features retain high fidelity with CellProfiler features while
enabling seamless integration with the scientific Python ecosystem. Through
applications to 3D astrocyte imaging and spatial transcriptomics, we showcase
how cp_measure enables reproducible, automated image-based profiling pipelines
that scale effectively for machine learning applications in computational
biology.

</details>


### [4] [Rapid Salient Object Detection with Difference Convolutional Neural Networks](https://arxiv.org/abs/2507.01182)
*Zhuo Su,Li Liu,Matthias Müller,Jiehua Zhang,Diana Wofk,Ming-Ming Cheng,Matti Pietikäinen*

Main category: cs.CV

TL;DR: 提出了一种高效网络设计，结合传统显著目标检测（SOD）方法和现代CNN，通过像素差异卷积（PDCs）和差异卷积重参数化（DCR）策略，显著提升资源受限设备上的实时性能。


<details>
  <summary>Details</summary>
Motivation: 现有SOD模型计算成本高，难以在资源受限设备上实现实时性能。

Method: 结合传统SOD方法和CNN，使用PDCs编码特征对比，并通过DCR策略嵌入标准卷积以减少计算量。针对视频SOD，引入时空差异卷积（STDC）。

Result: 模型SDNet和STDNet在效率和准确性上取得显著提升，在Jetson Orin设备上分别以46 FPS和150 FPS运行，速度和准确性均优于其他轻量级模型。

Conclusion: 提出的方法在资源受限设备上实现了高效的实时SOD，为轻量级模型设计提供了新思路。

Abstract: This paper addresses the challenge of deploying salient object detection
(SOD) on resource-constrained devices with real-time performance. While recent
advances in deep neural networks have improved SOD, existing top-leading models
are computationally expensive. We propose an efficient network design that
combines traditional wisdom on SOD and the representation power of modern CNNs.
Like biologically-inspired classical SOD methods relying on computing contrast
cues to determine saliency of image regions, our model leverages Pixel
Difference Convolutions (PDCs) to encode the feature contrasts. Differently,
PDCs are incorporated in a CNN architecture so that the valuable contrast cues
are extracted from rich feature maps. For efficiency, we introduce a difference
convolution reparameterization (DCR) strategy that embeds PDCs into standard
convolutions, eliminating computation and parameters at inference.
Additionally, we introduce SpatioTemporal Difference Convolution (STDC) for
video SOD, enhancing the standard 3D convolution with spatiotemporal contrast
capture. Our models, SDNet for image SOD and STDNet for video SOD, achieve
significant improvements in efficiency-accuracy trade-offs. On a Jetson Orin
device, our models with $<$ 1M parameters operate at 46 FPS and 150 FPS on
streamed images and videos, surpassing the second-best lightweight models in
our experiments by more than $2\times$ and $3\times$ in speed with superior
accuracy. Code will be available at https://github.com/hellozhuo/stdnet.git.

</details>


### [5] [Robust Brain Tumor Segmentation with Incomplete MRI Modalities Using Hölder Divergence and Mutual Information-Enhanced Knowledge Transfer](https://arxiv.org/abs/2507.01254)
*Runze Cheng,Xihang Qiu,Ming Li,Ye Zhang,Chun Li,Fei Yu*

Main category: cs.CV

TL;DR: 提出了一种基于单模态并行处理的鲁棒框架，用于处理多模态MRI中缺失模态的脑肿瘤分割问题。


<details>
  <summary>Details</summary>
Motivation: 多模态MRI在脑肿瘤分割中至关重要，但传统方法在模态缺失时表现不佳。

Method: 利用Holder散度和互信息，动态调整网络参数，保持模态特异性特征。

Result: 在BraTS 2018和2020数据集上表现优于现有方法。

Conclusion: 该框架在模态缺失情况下仍能实现高精度分割。

Abstract: Multimodal MRI provides critical complementary information for accurate brain
tumor segmentation. However, conventional methods struggle when certain
modalities are missing due to issues such as image quality, protocol
inconsistencies, patient allergies, or financial constraints. To address this,
we propose a robust single-modality parallel processing framework that achieves
high segmentation accuracy even with incomplete modalities. Leveraging Holder
divergence and mutual information, our model maintains modality-specific
features while dynamically adjusting network parameters based on the available
inputs. By using these divergence- and information-based loss functions, the
framework effectively quantifies discrepancies between predictions and
ground-truth labels, resulting in consistently accurate segmentation. Extensive
evaluations on the BraTS 2018 and BraTS 2020 datasets demonstrate superior
performance over existing methods in handling missing modalities.

</details>


### [6] [AIGVE-MACS: Unified Multi-Aspect Commenting and Scoring Model for AI-Generated Video Evaluation](https://arxiv.org/abs/2507.01255)
*Xiao Liu,Jiawei Zhang*

Main category: cs.CV

TL;DR: 论文提出AIGVE-MACS模型，用于AI生成视频的多方面评估，提供分数和语言反馈，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成视频评估指标缺乏解释性，难以与人类评价对齐，亟需改进。

Method: 结合AIGVE-BENCH 2基准和Vision-Language模型，采用加权损失和动态帧采样策略。

Result: AIGVE-MACS在评分相关性和评论质量上表现最优，质量提升53.5%。

Conclusion: AIGVE-MACS为AI生成视频评估提供了全面、人类对齐的新范式。

Abstract: The rapid advancement of AI-generated video models has created a pressing
need for robust and interpretable evaluation frameworks. Existing metrics are
limited to producing numerical scores without explanatory comments, resulting
in low interpretability and human evaluation alignment. To address those
challenges, we introduce AIGVE-MACS, a unified model for AI-Generated Video
Evaluation(AIGVE), which can provide not only numerical scores but also
multi-aspect language comment feedback in evaluating these generated videos.
Central to our approach is AIGVE-BENCH 2, a large-scale benchmark comprising
2,500 AI-generated videos and 22,500 human-annotated detailed comments and
numerical scores across nine critical evaluation aspects. Leveraging
AIGVE-BENCH 2, AIGVE-MACS incorporates recent Vision-Language Models with a
novel token-wise weighted loss and a dynamic frame sampling strategy to better
align with human evaluators. Comprehensive experiments across supervised and
zero-shot benchmarks demonstrate that AIGVE-MACS achieves state-of-the-art
performance in both scoring correlation and comment quality, significantly
outperforming prior baselines including GPT-4o and VideoScore. In addition, we
further showcase a multi-agent refinement framework where feedback from
AIGVE-MACS drives iterative improvements in video generation, leading to 53.5%
quality enhancement. This work establishes a new paradigm for comprehensive,
human-aligned evaluation of AI-generated videos. We release the AIGVE-BENCH 2
and AIGVE-MACS at https://huggingface.co/xiaoliux/AIGVE-MACS.

</details>


### [7] [Advancements in Weed Mapping: A Systematic Review](https://arxiv.org/abs/2507.01269)
*Mohammad Jahanbakht,Alex Olsen,Ross Marchant,Emilie Fillols,Mostafa Rahimi Azghadi*

Main category: cs.CV

TL;DR: 本文综述了杂草测绘的最新方法，填补了从数据获取到处理技术的文献空白，为精准管理提供支持。


<details>
  <summary>Details</summary>
Motivation: 杂草测绘对精准管理至关重要，但缺乏全面的文献综述，限制了该领域的进展。

Method: 系统分析了数据获取（传感器与平台技术）、数据处理（标注与建模）和测绘技术（时空分析与决策工具）。

Result: 综述提供了杂草测绘领域的全面理解，为未来研究和发展高效、可扩展的可持续杂草管理系统奠定基础。

Conclusion: 本文填补了杂草测绘领域的文献空白，为精准管理和可持续发展提供了重要参考。

Abstract: Weed mapping plays a critical role in precision management by providing
accurate and timely data on weed distribution, enabling targeted control and
reduced herbicide use. This minimizes environmental impacts, supports
sustainable land management, and improves outcomes across agricultural and
natural environments. Recent advances in weed mapping leverage ground-vehicle
Red Green Blue (RGB) cameras, satellite and drone-based remote sensing combined
with sensors such as spectral, Near Infra-Red (NIR), and thermal cameras. The
resulting data are processed using advanced techniques including big data
analytics and machine learning, significantly improving the spatial and
temporal resolution of weed maps and enabling site-specific management
decisions. Despite a growing body of research in this domain, there is a lack
of comprehensive literature reviews specifically focused on weed mapping. In
particular, the absence of a structured analysis spanning the entire mapping
pipeline, from data acquisition to processing techniques and mapping tools,
limits progress in the field. This review addresses these gaps by
systematically examining state-of-the-art methods in data acquisition (sensor
and platform technologies), data processing (including annotation and
modelling), and mapping techniques (such as spatiotemporal analysis and
decision support tools). Following PRISMA guidelines, we critically evaluate
and synthesize key findings from the literature to provide a holistic
understanding of the weed mapping landscape. This review serves as a
foundational reference to guide future research and support the development of
efficient, scalable, and sustainable weed management systems.

</details>


### [8] [DiffusionLight-Turbo: Accelerated Light Probes for Free via Single-Pass Chrome Ball Inpainting](https://arxiv.org/abs/2507.01305)
*Worameth Chinchuthakun,Pakkapon Phongthawee,Amit Raj,Varun Jampani,Pramook Khungurn,Supasorn Suwajanakorn*

Main category: cs.CV

TL;DR: 论文提出了一种通过将任务重构为铬球修复问题，利用预训练扩散模型从单张低动态范围图像估计光照的技术。通过迭代修复生成稳定的低频光照先验，并结合曝光LoRA生成高动态范围光探针。进一步提出快速版本DiffusionLight-Turbo，显著提升效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖有限的高动态范围全景数据集，泛化能力不足。扩散模型在修复任务中易生成不一致内容且难以直接生成高动态范围铬球。

Method: 提出DiffusionLight，通过迭代修复生成中值铬球作为稳定光照先验；结合曝光LoRA生成多曝光图像并合并为高动态范围光探针。进一步开发DiffusionLight-Turbo，通过训练Turbo LoRA直接预测迭代结果，大幅提升速度。

Result: 实验表明，该方法能生成高质量光照估计，泛化能力强于现有方法。DiffusionLight-Turbo在保持质量的同时将运行时间从30分钟缩短至30秒。

Conclusion: 该方法通过创新的迭代修复和LoRA技术，有效解决了光照估计中的泛化和效率问题，适用于多样化场景。

Abstract: We introduce a simple yet effective technique for estimating lighting from a
single low-dynamic-range (LDR) image by reframing the task as a chrome ball
inpainting problem. This approach leverages a pre-trained diffusion model,
Stable Diffusion XL, to overcome the generalization failures of existing
methods that rely on limited HDR panorama datasets. While conceptually simple,
the task remains challenging because diffusion models often insert incorrect or
inconsistent content and cannot readily generate chrome balls in HDR format.
Our analysis reveals that the inpainting process is highly sensitive to the
initial noise in the diffusion process, occasionally resulting in unrealistic
outputs. To address this, we first introduce DiffusionLight, which uses
iterative inpainting to compute a median chrome ball from multiple outputs to
serve as a stable, low-frequency lighting prior that guides the generation of a
high-quality final result. To generate high-dynamic-range (HDR) light probes,
an Exposure LoRA is fine-tuned to create LDR images at multiple exposure
values, which are then merged. While effective, DiffusionLight is
time-intensive, requiring approximately 30 minutes per estimation. To reduce
this overhead, we introduce DiffusionLight-Turbo, which reduces the runtime to
about 30 seconds with minimal quality loss. This 60x speedup is achieved by
training a Turbo LoRA to directly predict the averaged chrome balls from the
iterative process. Inference is further streamlined into a single denoising
pass using a LoRA swapping technique. Experimental results that show our method
produces convincing light estimates across diverse settings and demonstrates
superior generalization to in-the-wild scenarios. Our code is available at
https://diffusionlight.github.io/turbo

</details>


### [9] [Frequency Domain-Based Diffusion Model for Unpaired Image Dehazing](https://arxiv.org/abs/2507.01275)
*Chengxu Liu,Lu Qi,Jinshan Pan,Xueming Qian,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: 提出了一种基于频域的扩散模型（FD-Diffusion）用于无配对图像去雾，通过振幅残差编码器和相位校正模块提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有对比学习方法引入无关内容且忽略频域特性，导致去雾效果不佳。

Method: 利用扩散模型在频域重建振幅谱，设计振幅残差编码器（ARE）补偿振幅差异，相位校正模块（PCM）优化相位谱。

Result: 在合成和真实数据集上优于现有方法。

Conclusion: FD-Diffusion通过频域建模和残差补偿显著提升无配对去雾效果。

Abstract: Unpaired image dehazing has attracted increasing attention due to its
flexible data requirements during model training. Dominant methods based on
contrastive learning not only introduce haze-unrelated content information, but
also ignore haze-specific properties in the frequency domain (\ie,~haze-related
degradation is mainly manifested in the amplitude spectrum). To address these
issues, we propose a novel frequency domain-based diffusion model, named \ours,
for fully exploiting the beneficial knowledge in unpaired clear data. In
particular, inspired by the strong generative ability shown by Diffusion Models
(DMs), we tackle the dehazing task from the perspective of frequency domain
reconstruction and perform the DMs to yield the amplitude spectrum consistent
with the distribution of clear images. To implement it, we propose an Amplitude
Residual Encoder (ARE) to extract the amplitude residuals, which effectively
compensates for the amplitude gap from the hazy to clear domains, as well as
provide supervision for the DMs training. In addition, we propose a Phase
Correction Module (PCM) to eliminate artifacts by further refining the phase
spectrum during dehazing with a simple attention mechanism. Experimental
results demonstrate that our \ours outperforms other state-of-the-art methods
on both synthetic and real-world datasets.

</details>


### [10] [Tile and Slide : A New Framework for Scaling NeRF from Local to Global 3D Earth Observation](https://arxiv.org/abs/2507.01631)
*Camille Billouard,Dawa Derksen,Alexandre Constantin,Bruno Vallet*

Main category: cs.CV

TL;DR: Snake-NeRF是一种扩展到大场景的NeRF框架，通过分块处理和优化策略，解决了传统NeRF内存占用高的问题。


<details>
  <summary>Details</summary>
Motivation: 现有NeRF方法因内存限制仅适用于小场景，无法处理大尺度卫星图像。

Method: 提出Snake-NeRF框架，采用分块处理、图像重叠裁剪和3D瓦片策略，避免边缘误差。

Result: 实验表明，该方法在单GPU上线性时间处理大卫星图像，且质量无损失。

Conclusion: Snake-NeRF成功扩展了NeRF的应用范围，适用于大场景3D重建。

Abstract: Neural Radiance Fields (NeRF) have recently emerged as a paradigm for 3D
reconstruction from multiview satellite imagery. However, state-of-the-art NeRF
methods are typically constrained to small scenes due to the memory footprint
during training, which we study in this paper. Previous work on large-scale
NeRFs palliate this by dividing the scene into NeRFs. This paper introduces
Snake-NeRF, a framework that scales to large scenes. Our out-of-core method
eliminates the need to load all images and networks simultaneously, and
operates on a single device. We achieve this by dividing the region of interest
into NeRFs that 3D tile without overlap. Importantly, we crop the images with
overlap to ensure each NeRFs is trained with all the necessary pixels. We
introduce a novel $2\times 2$ 3D tile progression strategy and segmented
sampler, which together prevent 3D reconstruction errors along the tile edges.
Our experiments conclude that large satellite images can effectively be
processed with linear time complexity, on a single GPU, and without compromise
in quality.

</details>


### [11] [Learning an Ensemble Token from Task-driven Priors in Facial Analysis](https://arxiv.org/abs/2507.01290)
*Sunyong Seo,Semin Kim,Jongha Lee*

Main category: cs.CV

TL;DR: ET-Fuser是一种新颖的方法，通过利用基于预训练模型的任务先验的注意力机制，学习集成令牌，以改进面部分析任务中的特征表示。


<details>
  <summary>Details</summary>
Motivation: 现有方法在单任务学习中缺乏统一的特征表示，ET-Fuser旨在解决这一问题。

Method: 提出了一种基于自注意力机制的集成令牌学习方法，利用预训练编码器的共享信息。

Result: 在多种面部分析任务中表现出显著的特征表示改进。

Conclusion: ET-Fuser高效且计算成本低，为面部分析任务提供了统一的特征表示方法。

Abstract: Facial analysis exhibits task-specific feature variations. While
Convolutional Neural Networks (CNNs) have enabled the fine-grained
representation of spatial information, Vision Transformers (ViTs) have
facilitated the representation of semantic information at the patch level.
Although the generalization of conventional methodologies has advanced visual
interpretability, there remains paucity of research that preserves the unified
feature representation on single task learning during the training process. In
this work, we introduce ET-Fuser, a novel methodology for learning ensemble
token by leveraging attention mechanisms based on task priors derived from
pre-trained models for facial analysis. Specifically, we propose a robust prior
unification learning method that generates a ensemble token within a
self-attention mechanism, which shares the mutual information along the
pre-trained encoders. This ensemble token approach offers high efficiency with
negligible computational cost. Our results show improvements across a variety
of facial analysis, with statistically significant enhancements observed in the
feature representations.

</details>


### [12] [Physics-informed Ground Reaction Dynamics from Human Motion Capture](https://arxiv.org/abs/2507.01340)
*Cuong Le,Huy-Phuong Le,Duc Le,Minh-Thien Duong,Van-Binh Nguyen,My-Ha Le*

Main category: cs.CV

TL;DR: 提出了一种基于物理约束和运动捕捉数据的新方法，用于估计地面反作用力，无需依赖实验室专用设备。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖实验室专用设备（如力板）收集地面反作用力，限制了动态学习的应用范围。

Method: 结合欧拉积分方案和PD算法，从运动捕捉数据中计算地面反作用力，并通过物理约束改进深度学习模型。

Result: 在GroundLink数据集上测试，优于基线模型，提高了地面反作用力估计精度和模拟根轨迹精度。

Conclusion: 该方法通过物理约束和运动捕捉数据，实现了无需力板的高精度地面反作用力估计。

Abstract: Body dynamics are crucial information for the analysis of human motions in
important research fields, ranging from biomechanics, sports science to
computer vision and graphics. Modern approaches collect the body dynamics,
external reactive force specifically, via force plates, synchronizing with
human motion capture data, and learn to estimate the dynamics from a black-box
deep learning model. Being specialized devices, force plates can only be
installed in laboratory setups, imposing a significant limitation on the
learning of human dynamics. To this end, we propose a novel method for
estimating human ground reaction dynamics directly from the more reliable
motion capture data with physics laws and computational simulation as
constrains. We introduce a highly accurate and robust method for computing
ground reaction forces from motion capture data using Euler's integration
scheme and PD algorithm. The physics-based reactive forces are used to inform
the learning model about the physics-informed motion dynamics thus improving
the estimation accuracy. The proposed approach was tested on the GroundLink
dataset, outperforming the baseline model on: 1) the ground reaction force
estimation accuracy compared to the force plates measurement; and 2) our
simulated root trajectory precision. The implementation code is available at
https://github.com/cuongle1206/Phys-GRD

</details>


### [13] [Learning Camera-Agnostic White-Balance Preferences](https://arxiv.org/abs/2507.01342)
*Luxi Zhao,Mahmoud Afifi,Michael S. Brown*

Main category: cs.CV

TL;DR: 论文提出了一种轻量级方法，通过学习后照明估计映射，将中性白平衡转换为美学偏好，实现跨相机的一致性。


<details>
  <summary>Details</summary>
Motivation: 商业自动白平衡（AWB）系统通常追求美学偏好而非中性校正，且现有学习型方法难以跨相机泛化。

Method: 提出学习一个后照明估计映射，将中性白平衡转换为美学偏好，适用于不同相机传感器。

Result: 模型仅含约500参数，运行速度快（0.024毫秒），在771张智能手机图像上表现优异。

Conclusion: 该方法在保持兼容性的同时，实现了跨相机的美学一致性，计算开销极小。

Abstract: The image signal processor (ISP) pipeline in modern cameras consists of
several modules that transform raw sensor data into visually pleasing images in
a display color space. Among these, the auto white balance (AWB) module is
essential for compensating for scene illumination. However, commercial AWB
systems often strive to compute aesthetic white-balance preferences rather than
accurate neutral color correction. While learning-based methods have improved
AWB accuracy, they typically struggle to generalize across different camera
sensors -- an issue for smartphones with multiple cameras. Recent work has
explored cross-camera AWB, but most methods remain focused on achieving neutral
white balance. In contrast, this paper is the first to address aesthetic
consistency by learning a post-illuminant-estimation mapping that transforms
neutral illuminant corrections into aesthetically preferred corrections in a
camera-agnostic space. Once trained, our mapping can be applied after any
neutral AWB module to enable consistent and stylized color rendering across
unseen cameras. Our proposed model is lightweight -- containing only $\sim$500
parameters -- and runs in just 0.024 milliseconds on a typical flagship mobile
CPU. Evaluated on a dataset of 771 smartphone images from three different
cameras, our method achieves state-of-the-art performance while remaining fully
compatible with existing cross-camera AWB techniques, introducing minimal
computational and memory overhead.

</details>


### [14] [Learning from Random Subspace Exploration: Generalized Test-Time Augmentation with Self-supervised Distillation](https://arxiv.org/abs/2507.01347)
*Andrei Jelea,Ahmed Nabil Belbachir,Marius Leordeanu*

Main category: cs.CV

TL;DR: GTTA是一种通用的测试时间增强方法，适用于多种视觉和非视觉任务，通过PCA子空间扰动和自监督学习提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有测试时间增强方法缺乏通用性，GTTA旨在提供一种适用于多种任务的通用解决方案。

Method: GTTA通过随机扰动PCA子空间投影生成鲁棒集成，并引入自监督学习阶段降低计算成本。

Result: GTTA在多种任务和数据集上验证了其通用性和有效性，包括特定任务如低能见度水下视频中的鲑鱼分割。

Conclusion: GTTA是一种高效且通用的测试时间增强方法，显著提升模型性能且不增加计算成本。

Abstract: We introduce Generalized Test-Time Augmentation (GTTA), a highly effective
method for improving the performance of a trained model, which unlike other
existing Test-Time Augmentation approaches from the literature is general
enough to be used off-the-shelf for many vision and non-vision tasks, such as
classification, regression, image segmentation and object detection. By
applying a new general data transformation, that randomly perturbs multiple
times the PCA subspace projection of a test input, GTTA forms robust ensembles
at test time in which, due to sound statistical properties, the structural and
systematic noises in the initial input data is filtered out and final estimator
errors are reduced. Different from other existing methods, we also propose a
final self-supervised learning stage in which the ensemble output, acting as an
unsupervised teacher, is used to train the initial single student model, thus
reducing significantly the test time computational cost, at no loss in
accuracy. Our tests and comparisons to strong TTA approaches and SoTA models on
various vision and non-vision well-known datasets and tasks, such as image
classification and segmentation, speech recognition and house price prediction,
validate the generality of the proposed GTTA. Furthermore, we also prove its
effectiveness on the more specific real-world task of salmon segmentation and
detection in low-visibility underwater videos, for which we introduce
DeepSalmon, the largest dataset of its kind in the literature.

</details>


### [15] [Long-Tailed Distribution-Aware Router For Mixture-of-Experts in Large Vision-Language Model](https://arxiv.org/abs/2507.01351)
*Chaoxiang Cai,Longrong Yang,Kaibing Chen,Fan Yang,Xi Li*

Main category: cs.CV

TL;DR: 提出了一种长尾分布感知路由器（LTDR），用于视觉语言混合专家模型（MoE），解决了模态间分布差异和视觉尾部令牌激活问题。


<details>
  <summary>Details</summary>
Motivation: 现有MoE框架忽视了视觉和语言模态间的分布差异，导致路由策略不匹配。

Method: 提出LTDR，针对语言和视觉的不同分布设计路由策略，并通过过采样增强视觉尾部令牌的专家激活。

Result: 在多个基准测试中验证了方法的有效性。

Conclusion: LTDR显著提升了视觉语言MoE模型的性能，解决了现有框架的局限性。

Abstract: The mixture-of-experts (MoE), which replaces dense models with sparse
architectures, has gained attention in large vision-language models (LVLMs) for
achieving comparable performance with fewer activated parameters. Existing MoE
frameworks for LVLMs focus on token-to-expert routing (TER), encouraging
different experts to specialize in processing distinct tokens. However, these
frameworks often rely on the load balancing mechanism, overlooking the inherent
distributional differences between vision and language. To this end, we propose
a Long-Tailed Distribution-aware Router (LTDR) for vision-language TER,
tackling two challenges: (1) Distribution-aware router for modality-specific
routing. We observe that language TER follows a uniform distribution, whereas
vision TER exhibits a long-tailed distribution. This discrepancy necessitates
distinct routing strategies tailored to each modality. (2) Enhancing expert
activation for vision tail tokens. Recognizing the importance of vision tail
tokens, we introduce an oversampling-like strategy by increasing the number of
activated experts for these tokens. Experiments on extensive benchmarks
validate the effectiveness of our approach.

</details>


### [16] [3D Gaussian Splatting Driven Multi-View Robust Physical Adversarial Camouflage Generation](https://arxiv.org/abs/2507.01367)
*Tianrui Lou,Xiaojun Jia,Siyuan Liang,Jiawei Liang,Ming Zhang,Yanjun Xiao,Xiaochun Cao*

Main category: cs.CV

TL;DR: 论文提出了一种基于3D高斯散射（3DGS）的物理攻击框架PGA，解决了现有伪装攻击方法在多视角和复杂环境中的鲁棒性问题。


<details>
  <summary>Details</summary>
Motivation: 现有物理对抗攻击方法依赖目标对象的网格先验和模拟器构建的虚拟环境，耗时且与真实世界存在差异，导致对抗效果和鲁棒性不足。

Method: 利用3DGS快速精确重建和逼真渲染能力，通过防止高斯间的相互和自遮挡，以及采用min-max优化调整每个视角的背景，增强多视角鲁棒性和对抗效果。

Result: 实验验证了PGA的有效性和优越性。

Conclusion: PGA框架显著提升了物理对抗攻击在多视角和复杂环境中的鲁棒性和对抗效果。

Abstract: Physical adversarial attack methods expose the vulnerabilities of deep neural
networks and pose a significant threat to safety-critical scenarios such as
autonomous driving. Camouflage-based physical attack is a more promising
approach compared to the patch-based attack, offering stronger adversarial
effectiveness in complex physical environments. However, most prior work relies
on mesh priors of the target object and virtual environments constructed by
simulators, which are time-consuming to obtain and inevitably differ from the
real world. Moreover, due to the limitations of the backgrounds in training
images, previous methods often fail to produce multi-view robust adversarial
camouflage and tend to fall into sub-optimal solutions. Due to these reasons,
prior work lacks adversarial effectiveness and robustness across diverse
viewpoints and physical environments. We propose a physical attack framework
based on 3D Gaussian Splatting (3DGS), named PGA, which provides rapid and
precise reconstruction with few images, along with photo-realistic rendering
capabilities. Our framework further enhances cross-view robustness and
adversarial effectiveness by preventing mutual and self-occlusion among
Gaussians and employing a min-max optimization approach that adjusts the
imaging background of each viewpoint, helping the algorithm filter out
non-robust adversarial features. Extensive experiments validate the
effectiveness and superiority of PGA. Our code is available
at:https://github.com/TRLou/PGA.

</details>


### [17] [Activation Reward Models for Few-Shot Model Alignment](https://arxiv.org/abs/2507.01368)
*Tianning Chai,Chancharik Mitra,Brandon Huang,Gautam Rajendrakumar Gare,Zhiqiu Lin,Assaf Arbelle,Leonid Karlinsky,Rogerio Feris,Trevor Darrell,Deva Ramanan,Roei Herzig*

Main category: cs.CV

TL;DR: 提出了一种名为Activation RMs的新方法，通过激活导向构建奖励信号，无需额外微调，在少样本奖励建模中表现优于现有方法，并在防止奖励攻击行为上效果显著。


<details>
  <summary>Details</summary>
Motivation: 传统奖励建模难以适应新偏好，需依赖大规模数据集和单独奖励模型，限制了灵活性和效率。

Method: Activation RMs利用激活导向技术，通过少量监督构建奖励信号，无需额外模型微调。

Result: 在标准奖励建模基准测试中优于现有少样本方法，并在新提出的PreferenceHack基准上表现优异，甚至超越GPT-4o。

Conclusion: Activation RMs为少样本奖励建模提供了高效且安全的解决方案，适用于安全关键应用。

Abstract: Aligning Large Language Models (LLMs) and Large Multimodal Models (LMMs) to
human preferences is a central challenge in improving the quality of the
models' generative outputs for real-world applications. A common approach is to
use reward modeling to encode preferences, enabling alignment via post-training
using reinforcement learning. However, traditional reward modeling is not
easily adaptable to new preferences because it requires a separate reward
model, commonly trained on large preference datasets. To address this, we
introduce Activation Reward Models (Activation RMs) -- a novel few-shot reward
modeling method that leverages activation steering to construct well-aligned
reward signals using minimal supervision and no additional model finetuning.
Activation RMs outperform existing few-shot reward modeling approaches such as
LLM-as-a-judge with in-context learning, voting-based scoring, and token
probability scoring on standard reward modeling benchmarks. Furthermore, we
demonstrate the effectiveness of Activation RMs in mitigating reward hacking
behaviors, highlighting their utility for safety-critical applications. Toward
this end, we propose PreferenceHack, a novel few-shot setting benchmark, the
first to test reward models on reward hacking in a paired preference format.
Finally, we show that Activation RM achieves state-of-the-art performance on
this benchmark, surpassing even GPT-4o.

</details>


### [18] [Active Measurement: Efficient Estimation at Scale](https://arxiv.org/abs/2507.01372)
*Max Hamilton,Jinlin Lai,Wenlong Zhao,Subhransu Maji,Daniel Sheldon*

Main category: cs.CV

TL;DR: 提出了一种名为“主动测量”的人机协作AI框架，用于科学测量，通过重要性采样和AI模型迭代优化，提高测量精度并减少人力需求。


<details>
  <summary>Details</summary>
Motivation: 当前AI在科学发现中的应用缺乏准确性和统计保证，需要一种更高效且可靠的方法。

Method: 结合AI模型预测和重要性采样的人类标注，通过迭代优化模型并计算无偏蒙特卡洛估计。

Result: 主动测量在多个测量任务中降低了估计误差，即使AI模型不完美也能提供精确估计。

Conclusion: 主动测量框架为科学测量提供了一种高效且可靠的方法，显著减少了人力需求并提高了精度。

Abstract: AI has the potential to transform scientific discovery by analyzing vast
datasets with little human effort. However, current workflows often do not
provide the accuracy or statistical guarantees that are needed. We introduce
active measurement, a human-in-the-loop AI framework for scientific
measurement. An AI model is used to predict measurements for individual units,
which are then sampled for human labeling using importance sampling. With each
new set of human labels, the AI model is improved and an unbiased Monte Carlo
estimate of the total measurement is refined. Active measurement can provide
precise estimates even with an imperfect AI model, and requires little human
effort when the AI model is very accurate. We derive novel estimators,
weighting schemes, and confidence intervals, and show that active measurement
reduces estimation error compared to alternatives in several measurement tasks.

</details>


### [19] [MUG: Pseudo Labeling Augmented Audio-Visual Mamba Network for Audio-Visual Video Parsing](https://arxiv.org/abs/2507.01384)
*Langyu Wang,Bingke Zhu,Yingying Chen,Yiyuan Zhang,Ming Tang,Jinqiao Wang*

Main category: cs.CV

TL;DR: 提出了一种基于伪标签增强的音频-视觉Mamba网络（MUG），用于提升弱监督音频-视觉视频解析任务中的段级和事件级预测性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在弱监督条件下难以同时优化段级和事件级预测，且模型架构存在不足。

Method: 通过伪标签增强生成新数据，并采用音频-视觉Mamba网络进行特征处理和交互，以提升模型解析能力。

Result: 在LLP数据集上，MUG在所有指标上均优于现有方法，如视觉段级和音频段级指标分别提升2.1%和1.2%。

Conclusion: MUG通过伪标签增强和Mamba网络设计，显著提升了弱监督音频-视觉视频解析的性能。

Abstract: The weakly-supervised audio-visual video parsing (AVVP) aims to predict all
modality-specific events and locate their temporal boundaries. Despite
significant progress, due to the limitations of the weakly-supervised and the
deficiencies of the model architecture, existing methods are lacking in
simultaneously improving both the segment-level prediction and the event-level
prediction. In this work, we propose a audio-visual Mamba network with pseudo
labeling aUGmentation (MUG) for emphasising the uniqueness of each segment and
excluding the noise interference from the alternate modalities. Specifically,
we annotate some of the pseudo-labels based on previous work. Using unimodal
pseudo-labels, we perform cross-modal random combinations to generate new data,
which can enhance the model's ability to parse various segment-level event
combinations. For feature processing and interaction, we employ a audio-visual
mamba network. The AV-Mamba enhances the ability to perceive different segments
and excludes additional modal noise while sharing similar modal information.
Our extensive experiments demonstrate that MUG improves state-of-the-art
results on LLP dataset in all metrics (e.g,, gains of 2.1% and 1.2% in terms of
visual Segment-level and audio Segment-level metrics). Our code is available at
https://github.com/WangLY136/MUG.

</details>


### [20] [FixTalk: Taming Identity Leakage for High-Quality Talking Head Generation in Extreme Cases](https://arxiv.org/abs/2507.01390)
*Shuai Tan,Bill Gong,Bin Ji,Ye Pan*

Main category: cs.CV

TL;DR: FixTalk框架通过EMI和EDI分别解决身份泄漏和渲染伪影问题，提升说话头生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在极端情况下存在身份泄漏和渲染伪影问题，影响生成质量。

Method: 提出EMI解耦身份信息与运动特征，EDI利用泄漏的身份信息补充细节。

Result: 实验表明FixTalk有效减少身份泄漏和伪影，性能优于现有方法。

Conclusion: FixTalk为高质量说话头生成提供了有效解决方案。

Abstract: Talking head generation is gaining significant importance across various
domains, with a growing demand for high-quality rendering. However, existing
methods often suffer from identity leakage (IL) and rendering artifacts (RA),
particularly in extreme cases. Through an in-depth analysis of previous
approaches, we identify two key insights: (1) IL arises from identity
information embedded within motion features, and (2) this identity information
can be leveraged to address RA. Building on these findings, this paper
introduces FixTalk, a novel framework designed to simultaneously resolve both
issues for high-quality talking head generation. Firstly, we propose an
Enhanced Motion Indicator (EMI) to effectively decouple identity information
from motion features, mitigating the impact of IL on generated talking heads.
To address RA, we introduce an Enhanced Detail Indicator (EDI), which utilizes
the leaked identity information to supplement missing details, thus fixing the
artifacts. Extensive experiments demonstrate that FixTalk effectively mitigates
IL and RA, achieving superior performance compared to state-of-the-art methods.

</details>


### [21] [Coherent Online Road Topology Estimation and Reasoning with Standard-Definition Maps](https://arxiv.org/abs/2507.01397)
*Khanh Son Pham,Christian Witte,Jens Behley,Johannes Betz,Cyrill Stachniss*

Main category: cs.CV

TL;DR: 提出了一种利用标准地图（SD）信息预测车道段及其拓扑和道路边界的方法，通过混合编码和去噪技术提升性能，实验表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决高精地图（HD）在线构建的挑战，尤其是道路拓扑的高复杂性建模问题。

Method: 利用SD地图信息，设计混合车道段编码和去噪技术的网络架构，结合历史帧保证时间一致性。

Result: 实验表明，该方法大幅优于现有方法，验证了建模方案的有效性。

Conclusion: 通过结合先验信息和去噪技术，实现了高效且一致的HD地图在线构建。

Abstract: Most autonomous cars rely on the availability of high-definition (HD) maps.
Current research aims to address this constraint by directly predicting HD map
elements from onboard sensors and reasoning about the relationships between the
predicted map and traffic elements. Despite recent advancements, the coherent
online construction of HD maps remains a challenging endeavor, as it
necessitates modeling the high complexity of road topologies in a unified and
consistent manner. To address this challenge, we propose a coherent approach to
predict lane segments and their corresponding topology, as well as road
boundaries, all by leveraging prior map information represented by commonly
available standard-definition (SD) maps. We propose a network architecture,
which leverages hybrid lane segment encodings comprising prior information and
denoising techniques to enhance training stability and performance.
Furthermore, we facilitate past frames for temporal consistency. Our
experimental evaluation demonstrates that our approach outperforms previous
methods by a large margin, highlighting the benefits of our modeling scheme.

</details>


### [22] [Medical-Knowledge Driven Multiple Instance Learning for Classifying Severe Abdominal Anomalies on Prenatal Ultrasound](https://arxiv.org/abs/2507.01401)
*Huanwen Liang,Jingxian Xu,Yuanji Zhang,Yuhao Huang,Yuhan Zhang,Xin Yang,Ran Li,Xuedong Deng,Yanjun Liu,Guowei Tao,Yun Wu,Sheng Zhao,Xinru Gao,Dong Ni*

Main category: cs.CV

TL;DR: 本文提出了一种基于多实例学习（MIL）的方法，用于胎儿腹部异常的产前超声分类，无需标准平面定位。方法包括混合注意力专家模块（MoAE）、医学知识驱动的特征选择模块（MFS）和基于提示的原型学习（PPL），在大规模数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 胎儿腹部畸形是严重的先天性异常，需要准确诊断以指导妊娠管理并降低死亡率。尽管AI在医学诊断中显示出潜力，但其在产前腹部异常中的应用仍有限。现有研究多关注图像级分类，而较少关注病例级诊断。

Method: 提出了一种基于MIL的病例级分类方法，包括MoAE模块（加权不同平面的注意力头）、MFS模块（医学知识驱动的特征选择）和PPL模块（增强MFS）。

Result: 在包含2,419个病例、24,748张图像和6个类别的大规模数据集上验证，该方法优于现有技术。

Conclusion: 该方法为产前超声中的胎儿腹部异常分类提供了高效且无需标准平面定位的解决方案，具有实际应用潜力。

Abstract: Fetal abdominal malformations are serious congenital anomalies that require
accurate diagnosis to guide pregnancy management and reduce mortality. Although
AI has demonstrated significant potential in medical diagnosis, its application
to prenatal abdominal anomalies remains limited. Most existing studies focus on
image-level classification and rely on standard plane localization, placing
less emphasis on case-level diagnosis. In this paper, we develop a case-level
multiple instance learning (MIL)-based method, free of standard plane
localization, for classifying fetal abdominal anomalies in prenatal ultrasound.
Our contribution is three-fold. First, we adopt a mixture-of-attention-experts
module (MoAE) to weight different attention heads for various planes. Secondly,
we propose a medical-knowledge-driven feature selection module (MFS) to align
image features with medical knowledge, performing self-supervised image token
selection at the case-level. Finally, we propose a prompt-based prototype
learning (PPL) to enhance the MFS. Extensively validated on a large prenatal
abdominal ultrasound dataset containing 2,419 cases, with a total of 24,748
images and 6 categories, our proposed method outperforms the state-of-the-art
competitors. Codes are available at:https://github.com/LL-AC/AAcls.

</details>


### [23] [CaptionSmiths: Flexibly Controlling Language Pattern in Image Captioning](https://arxiv.org/abs/2507.01409)
*Kuniaki Saito,Donghyun Kim,Kwanyong Park,Atsushi Hashimoto,Yoshitaka Ushiku*

Main category: cs.CV

TL;DR: 提出了一种名为CaptionSmiths的新方法，通过量化标题的长度、描述性和独特性，实现单模型灵活控制生成标题的语言模式。


<details>
  <summary>Details</summary>
Motivation: 现有图像标题生成模型难以精细控制生成标题的属性，如描述性和长度，限制了其多样化应用。

Method: 量化标题的三个属性（长度、描述性、单词独特性）为连续标量值，并通过端点向量插值实现条件控制。

Result: 模型能平滑调整标题属性，词汇对齐优于基线，例如长度控制误差减少506%。

Conclusion: CaptionSmiths为图像标题生成提供了灵活且高效的语言模式控制方法。

Abstract: An image captioning model flexibly switching its language pattern, e.g.,
descriptiveness and length, should be useful since it can be applied to diverse
applications. However, despite the dramatic improvement in generative
vision-language models, fine-grained control over the properties of generated
captions is not easy due to two reasons: (i) existing models are not given the
properties as a condition during training and (ii) existing models cannot
smoothly transition its language pattern from one state to the other. Given
this challenge, we propose a new approach, CaptionSmiths, to acquire a single
captioning model that can handle diverse language patterns. First, our approach
quantifies three properties of each caption, length, descriptiveness, and
uniqueness of a word, as continuous scalar values, without human annotation.
Given the values, we represent the conditioning via interpolation between two
endpoint vectors corresponding to the extreme states, e.g., one for a very
short caption and one for a very long caption. Empirical results demonstrate
that the resulting model can smoothly change the properties of the output
captions and show higher lexical alignment than baselines. For instance,
CaptionSmiths reduces the error in controlling caption length by 506\% despite
better lexical alignment. Code will be available on
https://github.com/omron-sinicx/captionsmiths.

</details>


### [24] [Gradient Short-Circuit: Efficient Out-of-Distribution Detection via Feature Intervention](https://arxiv.org/abs/2507.01417)
*Jiawei Gu,Ziyue Qiao,Zechao Li*

Main category: cs.CV

TL;DR: 论文提出了一种基于梯度方向的OOD检测方法，通过短路异常梯度提升检测效果，同时保持ID分类性能。


<details>
  <summary>Details</summary>
Motivation: 在开放环境中，OOD检测对深度学习模型的安全部署至关重要。观察到ID样本和OOD样本在梯度方向上存在显著差异，激发了该方法的研究。

Method: 提出了一种推理阶段的技术，通过短路异常梯度来抑制OOD样本的置信度，同时引入局部一阶近似以避免二次前向传播的开销。

Result: 在标准OOD基准测试中，该方法表现出显著改进，且计算轻量，适用于实际应用。

Conclusion: 该方法为实际应用中的鲁棒OOD检测提供了一种实用且高效的解决方案。

Abstract: Out-of-Distribution (OOD) detection is critical for safely deploying deep
models in open-world environments, where inputs may lie outside the training
distribution. During inference on a model trained exclusively with
In-Distribution (ID) data, we observe a salient gradient phenomenon: around an
ID sample, the local gradient directions for "enhancing" that sample's
predicted class remain relatively consistent, whereas OOD samples--unseen in
training--exhibit disorganized or conflicting gradient directions in the same
neighborhood. Motivated by this observation, we propose an inference-stage
technique to short-circuit those feature coordinates that spurious gradients
exploit to inflate OOD confidence, while leaving ID classification largely
intact. To circumvent the expense of recomputing the logits after this gradient
short-circuit, we further introduce a local first-order approximation that
accurately captures the post-modification outputs without a second forward
pass. Experiments on standard OOD benchmarks show our approach yields
substantial improvements. Moreover, the method is lightweight and requires
minimal changes to the standard inference pipeline, offering a practical path
toward robust OOD detection in real-world applications.

</details>


### [25] [DocShaDiffusion: Diffusion Model in Latent Space for Document Image Shadow Removal](https://arxiv.org/abs/2507.01422)
*Wenjie Liu,Bingshu Wang,Ze Wang,C. L. Philip Chen*

Main category: cs.CV

TL;DR: 本文提出了一种名为DocShaDiffusion的潜在空间扩散模型，用于文档图像阴影去除，并设计了阴影软掩模生成模块（SSGM）和阴影掩模引导扩散模块（SMGDM）以解决彩色阴影问题。此外，还提出了阴影鲁棒感知特征损失和大规模合成数据集SDCSRD。实验验证了方法的优越性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常仅处理恒定颜色背景的阴影，忽略了彩色阴影问题，限制了文档图像增强的效果。

Method: 1. 设计潜在空间扩散模型DocShaDiffusion；2. 提出SSGM生成精确阴影掩模；3. 提出SMGDM引导扩散与去噪；4. 引入阴影鲁棒感知特征损失；5. 构建合成数据集SDCSRD。

Result: 在三个公共数据集上的实验表明，该方法优于现有技术。

Conclusion: DocShaDiffusion通过潜在空间建模和彩色阴影处理，显著提升了文档图像阴影去除的效果。

Abstract: Document shadow removal is a crucial task in the field of document image
enhancement. However, existing methods tend to remove shadows with constant
color background and ignore color shadows. In this paper, we first design a
diffusion model in latent space for document image shadow removal, called
DocShaDiffusion. It translates shadow images from pixel space to latent space,
enabling the model to more easily capture essential features. To address the
issue of color shadows, we design a shadow soft-mask generation module (SSGM).
It is able to produce accurate shadow mask and add noise into shadow regions
specially. Guided by the shadow mask, a shadow mask-aware guided diffusion
module (SMGDM) is proposed to remove shadows from document images by
supervising the diffusion and denoising process. We also propose a
shadow-robust perceptual feature loss to preserve details and structures in
document images. Moreover, we develop a large-scale synthetic document color
shadow removal dataset (SDCSRD). It simulates the distribution of realistic
color shadows and provides powerful supports for the training of models.
Experiments on three public datasets validate the proposed method's superiority
over state-of-the-art. Our code and dataset will be publicly available.

</details>


### [26] [DiffMark: Diffusion-based Robust Watermark Against Deepfakes](https://arxiv.org/abs/2507.01428)
*Chen Sun,Haiyang Sun,Zhiqing Guo,Yunfeng Diao,Liejun Wang,Dan Ma,Gaobo Yang,Keqin Li*

Main category: cs.CV

TL;DR: 论文提出了一种基于扩散模型的鲁棒水印框架DiffMark，用于对抗Deepfake的面部篡改，通过改进训练和采样方案，结合交叉信息融合模块和深度伪造抗性指导，显著提升了水印的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: Deepfake技术对安全和隐私构成严重威胁，现有水印方法在对抗Deepfake篡改时鲁棒性不足。扩散模型在图像生成中的优异表现启发了利用其生成水印图像的研究。

Method: 提出DiffMark框架，通过修改扩散模型的训练和采样方案，结合面部图像和水印作为条件，逐步去噪生成水印图像。引入交叉信息融合模块和深度伪造抗性指导，增强水印鲁棒性。

Result: 实验证明DiffMark在典型Deepfake篡改中表现优异，水印具有高鲁棒性。

Conclusion: DiffMark为对抗Deepfake篡改提供了一种有效的鲁棒水印解决方案，未来可进一步优化和扩展。

Abstract: Deepfakes pose significant security and privacy threats through malicious
facial manipulations. While robust watermarking can aid in authenticity
verification and source tracking, existing methods often lack the sufficient
robustness against Deepfake manipulations. Diffusion models have demonstrated
remarkable performance in image generation, enabling the seamless fusion of
watermark with image during generation. In this study, we propose a novel
robust watermarking framework based on diffusion model, called DiffMark. By
modifying the training and sampling scheme, we take the facial image and
watermark as conditions to guide the diffusion model to progressively denoise
and generate corresponding watermarked image. In the construction of facial
condition, we weight the facial image by a timestep-dependent factor that
gradually reduces the guidance intensity with the decrease of noise, thus
better adapting to the sampling process of diffusion model. To achieve the
fusion of watermark condition, we introduce a cross information fusion (CIF)
module that leverages a learnable embedding table to adaptively extract
watermark features and integrates them with image features via cross-attention.
To enhance the robustness of the watermark against Deepfake manipulations, we
integrate a frozen autoencoder during training phase to simulate Deepfake
manipulations. Additionally, we introduce Deepfake-resistant guidance that
employs specific Deepfake model to adversarially guide the diffusion sampling
process to generate more robust watermarked images. Experimental results
demonstrate the effectiveness of the proposed DiffMark on typical Deepfakes.
Our code will be available at https://github.com/vpsg-research/DiffMark.

</details>


### [27] [TurboReg: TurboClique for Robust and Efficient Point Cloud Registration](https://arxiv.org/abs/2507.01439)
*Shaocheng Yan,Pengcheng Shi,Zhenjun Zhao,Kaixin Wang,Kuang Cao,Ji Wu,Jiayuan Li*

Main category: cs.CV

TL;DR: TurboReg提出了一种基于轻量级3-clique（TurboClique）和并行化Pivot-Guided Search（PGS）算法的快速鲁棒点云配准方法，显著提升了速度和性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于最大团搜索的方法虽召回率高，但时间复杂度指数级增长，无法满足实时性需求。

Method: 定义TurboClique为高度约束兼容图中的3-clique，结合PGS算法高效搜索高内点率匹配对。

Result: 在3DMatch+FCGF数据集上，TurboReg速度提升208.22倍且召回率更高。

Conclusion: TurboReg在速度和性能上均达到SOTA，适用于实时应用。

Abstract: Robust estimation is essential in correspondence-based Point Cloud
Registration (PCR). Existing methods using maximal clique search in
compatibility graphs achieve high recall but suffer from exponential time
complexity, limiting their use in time-sensitive applications. To address this
challenge, we propose a fast and robust estimator, TurboReg, built upon a novel
lightweight clique, TurboClique, and a highly parallelizable Pivot-Guided
Search (PGS) algorithm. First, we define the TurboClique as a 3-clique within a
highly-constrained compatibility graph. The lightweight nature of the 3-clique
allows for efficient parallel searching, and the highly-constrained
compatibility graph ensures robust spatial consistency for stable
transformation estimation. Next, PGS selects matching pairs with high SC$^2$
scores as pivots, effectively guiding the search toward TurboCliques with
higher inlier ratios. Moreover, the PGS algorithm has linear time complexity
and is significantly more efficient than the maximal clique search with
exponential time complexity. Extensive experiments show that TurboReg achieves
state-of-the-art performance across multiple real-world datasets, with
substantial speed improvements. For example, on the 3DMatch+FCGF dataset,
TurboReg (1K) operates $208.22\times$ faster than 3DMAC while also achieving
higher recall. Our code is accessible at
\href{https://github.com/Laka-3DV/TurboReg}{\texttt{TurboReg}}.

</details>


### [28] [OoDDINO:A Multi-level Framework for Anomaly Segmentation on Complex Road Scenes](https://arxiv.org/abs/2507.01455)
*Yuxing Liu,Ji Zhang,Zhou Xuchuan,Jingzhong Xiao,Huimin Yang,Jiaxin Zhong*

Main category: cs.CV

TL;DR: OoDDINO提出了一种多级异常分割框架，通过粗到细的检测策略解决现有像素级方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视像素间空间相关性且全局阈值策略导致误检或漏检。

Method: 结合不确定性引导的检测模型和像素级分割模型，采用正交约束和动态阈值策略。

Result: 在多个基准数据集上验证了框架的优越性和兼容性。

Conclusion: OoDDINO通过多级策略显著提升了异常分割的准确性和鲁棒性。

Abstract: Anomaly segmentation aims to identify Out-of-Distribution (OoD) anomalous
objects within images. Existing pixel-wise methods typically assign anomaly
scores individually and employ a global thresholding strategy to segment
anomalies. Despite their effectiveness, these approaches encounter significant
challenges in real-world applications: (1) neglecting spatial correlations
among pixels within the same object, resulting in fragmented segmentation; (2)
variabil ity in anomaly score distributions across image regions, causing
global thresholds to either generate false positives in background areas or
miss segments of anomalous objects. In this work, we introduce OoDDINO, a novel
multi-level anomaly segmentation framework designed to address these
limitations through a coarse-to-fine anomaly detection strategy. OoDDINO
combines an uncertainty-guided anomaly detection model with a pixel-level
segmentation model within a two-stage cascade architecture. Initially, we
propose an Orthogonal Uncertainty-Aware Fusion Strategy (OUAFS) that
sequentially integrates multiple uncertainty metrics with visual
representations, employing orthogonal constraints to strengthen the detection
model's capacity for localizing anomalous regions accurately. Subsequently, we
develop an Adaptive Dual-Threshold Network (ADT-Net), which dynamically
generates region-specific thresholds based on object-level detection outputs
and pixel-wise anomaly scores. This approach allows for distinct thresholding
strategies within foreground and background areas, achieving fine-grained
anomaly segmentation. The proposed framework is compatible with other
pixel-wise anomaly detection models, which acts as a plug-in to boost the
performance. Extensive experiments on two benchmark datasets validate our
framework's superiority and compatibility over state-of-the-art methods.

</details>


### [29] [NOCTIS: Novel Object Cyclic Threshold based Instance Segmentation](https://arxiv.org/abs/2507.01463)
*Max Gandyra,Alessandro Santonicola,Michael Beetz*

Main category: cs.CV

TL;DR: NOCTIS是一个无需重新训练即可对未见过的物体进行实例分割的框架，结合了Grounded-SAM 2和DINOv2模型，在BOP 2023挑战中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决计算机视觉中未见物体实例分割的泛化性问题，无需重新训练即可适应各种新物体。

Method: 利用Grounded-SAM 2生成物体提议和分割掩码，DINOv2生成图像嵌入，通过相似性评分和循环阈值过滤匹配物体。

Result: 在BOP 2023挑战的七个核心数据集上，NOCTIS在未见物体分割任务中优于现有RGB和RGB-D方法。

Conclusion: NOCTIS通过结合先进模型和优化匹配策略，实现了对未见物体的高效实例分割，展现了强大的泛化能力。

Abstract: Instance segmentation of novel objects instances in RGB images, given some
example images for each object, is a well known problem in computer vision.
Designing a model general enough to be employed, for all kinds of novel
objects, without (re-) training, has proven to be a difficult task. To handle
this, we propose a simple, yet powerful, framework, called: Novel Object Cyclic
Threshold based Instance Segmentation (NOCTIS). This work stems from and
improves upon previous ones like CNOS, SAM-6D and NIDS-Net; thus, it also
leverages on recent vision foundation models, namely: Grounded-SAM 2 and
DINOv2. It utilises Grounded-SAM 2 to obtain object proposals with precise
bounding boxes and their corresponding segmentation masks; while DINOv2's
zero-shot capabilities are employed to generate the image embeddings. The
quality of those masks, together with their embeddings, is of vital importance
to our approach; as the proposal-object matching is realized by determining an
object matching score based on the similarity of the class embeddings and the
average maximum similarity of the patch embeddings. Differently to SAM-6D,
calculating the latter involves a prior patch filtering based on the distance
between each patch and its corresponding cyclic/roundtrip patch in the image
grid. Furthermore, the average confidence of the proposals' bounding box and
mask is used as an additional weighting factor for the object matching score.
We empirically show that NOCTIS, without further training/fine tuning,
outperforms the best RGB and RGB-D methods on the seven core datasets of the
BOP 2023 challenge for the "Model-based 2D segmentation of unseen objects"
task.

</details>


### [30] [Representation Entanglement for Generation:Training Diffusion Transformers Is Much Easier Than You Think](https://arxiv.org/abs/2507.01467)
*Ge Wu,Shen Zhang,Ruijing Shi,Shanghua Gao,Zhenyuan Chen,Lei Wang,Zhaowei Chen,Hongcheng Gao,Yao Tang,Jian Yang,Ming-Ming Cheng,Xiang Li*

Main category: cs.CV

TL;DR: 论文提出了一种名为REG的方法，通过将低层图像潜在表示与预训练模型的高层类别标记纠缠，显著提升了生成质量和训练效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如REPA）在扩散模型中通过外部视觉表示对齐来缓解训练挑战，但未能充分利用判别性表示的潜力。

Method: 提出REG方法，将低层图像潜在表示与预训练模型的单一高层类别标记纠缠，实现从纯噪声中生成一致的图像-类别对。

Result: 在ImageNet 256×256上，SiT-XL/2 + REG实现了63倍和23倍于SiT-XL/2和SiT-XL/2 + REPA的训练加速，且仅需400K次迭代即可超越4M次迭代的SiT-XL/2 + REPA。

Conclusion: REG方法通过语义知识主动引导图像生成，显著提升了生成质量和训练效率，且推理开销极小。

Abstract: REPA and its variants effectively mitigate training challenges in diffusion
models by incorporating external visual representations from pretrained models,
through alignment between the noisy hidden projections of denoising networks
and foundational clean image representations. We argue that the external
alignment, which is absent during the entire denoising inference process, falls
short of fully harnessing the potential of discriminative representations. In
this work, we propose a straightforward method called Representation
Entanglement for Generation (REG), which entangles low-level image latents with
a single high-level class token from pretrained foundation models for
denoising. REG acquires the capability to produce coherent image-class pairs
directly from pure noise, substantially improving both generation quality and
training efficiency. This is accomplished with negligible additional inference
overhead, requiring only one single additional token for denoising (<0.5\%
increase in FLOPs and latency). The inference process concurrently reconstructs
both image latents and their corresponding global semantics, where the acquired
semantic knowledge actively guides and enhances the image generation process.
On ImageNet 256$\times$256, SiT-XL/2 + REG demonstrates remarkable convergence
acceleration, achieving $\textbf{63}\times$ and $\textbf{23}\times$ faster
training than SiT-XL/2 and SiT-XL/2 + REPA, respectively. More impressively,
SiT-L/2 + REG trained for merely 400K iterations outperforms SiT-XL/2 + REPA
trained for 4M iterations ($\textbf{10}\times$ longer). Code is available at:
https://github.com/Martinser/REG.

</details>


### [31] [Optimizing Methane Detection On Board Satellites: Speed, Accuracy, and Low-Power Solutions for Resource-Constrained Hardware](https://arxiv.org/abs/2507.01472)
*Jonáš Herec,Vít Růžička,Rado Pitoňák*

Main category: cs.CV

TL;DR: 论文提出了一种高效、低功耗的甲烷泄漏检测方法，通过改进现有算法和结合机器学习，显著提升了检测速度和准确性，适合资源有限的星载硬件。


<details>
  <summary>Details</summary>
Motivation: 甲烷是一种强效温室气体，早期检测其泄漏有助于缓解气候变化。现有任务多为手动操作，效率低且易错过重要事件。星载检测因下行速率慢而受限，需高效低功耗算法。

Method: 测试了快速目标检测方法（ACE、CEM），并提出改进算法Mag1c-SAS。结合机器学习模型（U-Net、LinkNet）评估性能，同时提出三种波段选择策略。

Result: Mag1c-SAS和CEM表现优异，分别优化了准确性和速度，比原算法快100倍和230倍。其中一种波段选择策略在减少通道的同时保持准确性。

Conclusion: 研究为星载甲烷检测提供了高效低功耗的解决方案，代码和数据已开源，为未来研究奠定基础。

Abstract: Methane is a potent greenhouse gas, and detecting its leaks early via
hyperspectral satellite imagery can help mitigate climate change. Meanwhile,
many existing missions operate in manual tasking regimes only, thus missing
potential events of interest. To overcome slow downlink rates cost-effectively,
onboard detection is a viable solution. However, traditional methane
enhancement methods are too computationally demanding for resource-limited
onboard hardware. This work accelerates methane detection by focusing on
efficient, low-power algorithms. We test fast target detection methods (ACE,
CEM) that have not been previously used for methane detection and propose a
Mag1c-SAS - a significantly faster variant of the current state-of-the-art
algorithm for methane detection: Mag1c. To explore their true detection
potential, we integrate them with a machine learning model (U-Net, LinkNet).
Our results identify two promising candidates (Mag1c-SAS and CEM), both
acceptably accurate for the detection of strong plumes and computationally
efficient enough for onboard deployment: one optimized more for accuracy, the
other more for speed, achieving up to ~100x and ~230x faster computation than
original Mag1c on resource-limited hardware. Additionally, we propose and
evaluate three band selection strategies. One of them can outperform the method
traditionally used in the field while using fewer channels, leading to even
faster processing without compromising accuracy. This research lays the
foundation for future advancements in onboard methane detection with minimal
hardware requirements, improving timely data delivery. The produced code, data,
and models are open-sourced and can be accessed from
https://github.com/zaitra/methane-filters-benchmark.

</details>


### [32] [Active Control Points-based 6DoF Pose Tracking for Industrial Metal Objects](https://arxiv.org/abs/2507.01478)
*Chentao Shen,Ding Pan,Mingyu Mei,Zaixing He,Xinyue Zhao*

Main category: cs.CV

TL;DR: 提出了一种基于主动控制点的新型6DoF姿态跟踪方法，用于解决工业金属物体因反射特性导致的跟踪难题。


<details>
  <summary>Details</summary>
Motivation: 工业金属物体的姿态跟踪在现实环境中具有挑战性，主要由于其反射特性。

Method: 利用图像控制点主动生成边缘特征进行优化，而非基于6DoF姿态的渲染，并将控制点作为优化变量。引入最优控制点回归方法以提高鲁棒性。

Result: 在数据集评估和实际任务中均表现出色，为工业金属物体的实时跟踪提供了可行方案。

Conclusion: 该方法有效解决了工业金属物体姿态跟踪的难题，代码已开源。

Abstract: Visual pose tracking is playing an increasingly vital role in industrial
contexts in recent years. However, the pose tracking for industrial metal
objects remains a challenging task especially in the real world-environments,
due to the reflection characteristic of metal objects. To address this issue,
we propose a novel 6DoF pose tracking method based on active control points.
The method uses image control points to generate edge feature for optimization
actively instead of 6DoF pose-based rendering, and serve them as optimization
variables. We also introduce an optimal control point regression method to
improve robustness. The proposed tracking method performs effectively in both
dataset evaluation and real world tasks, providing a viable solution for
real-time tracking of industrial metal objects. Our source code is made
publicly available at: https://github.com/tomatoma00/ACPTracking.

</details>


### [33] [What Really Matters for Robust Multi-Sensor HD Map Construction?](https://arxiv.org/abs/2507.01484)
*Xiaoshuai Hao,Yuting Zhao,Yuheng Ji,Luanyuan Dai,Peng Hao,Dingzhe Li,Shuai Cheng,Rong Yin*

Main category: cs.CV

TL;DR: 本文提出了一种增强多模态融合方法鲁棒性的策略，用于高精地图构建，通过数据增强、新型多模态融合模块和模态丢弃训练策略，显著提升了基线方法的鲁棒性，并在NuScenes数据集上达到了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注模型精度，忽视了感知模型的鲁棒性，而鲁棒性对实际应用至关重要。

Method: 提出数据增强、新型多模态融合模块和模态丢弃训练策略。

Result: 在NuScenes数据集上显著提升了基线方法的鲁棒性，并在干净验证集上达到了最先进的性能。

Conclusion: 研究为开发更鲁棒可靠的高精地图构建模型提供了有价值的见解，推动了其在真实自动驾驶场景中的应用。

Abstract: High-definition (HD) map construction methods are crucial for providing
precise and comprehensive static environmental information, which is essential
for autonomous driving systems. While Camera-LiDAR fusion techniques have shown
promising results by integrating data from both modalities, existing approaches
primarily focus on improving model accuracy and often neglect the robustness of
perception models, which is a critical aspect for real-world applications. In
this paper, we explore strategies to enhance the robustness of multi-modal
fusion methods for HD map construction while maintaining high accuracy. We
propose three key components: data augmentation, a novel multi-modal fusion
module, and a modality dropout training strategy. These components are
evaluated on a challenging dataset containing 10 days of NuScenes data. Our
experimental results demonstrate that our proposed methods significantly
enhance the robustness of baseline methods. Furthermore, our approach achieves
state-of-the-art performance on the clean validation set of the NuScenes
dataset. Our findings provide valuable insights for developing more robust and
reliable HD map construction models, advancing their applicability in
real-world autonomous driving scenarios. Project website:
https://robomap-123.github.io.

</details>


### [34] [AVC-DPO: Aligned Video Captioning via Direct Preference Optimization](https://arxiv.org/abs/2507.01492)
*Jiyang Tang,Hengyi Li,Yifan Du,Wayne Xin Zhao*

Main category: cs.CV

TL;DR: AVC-DPO框架通过偏好对齐提升视频MLLMs的标题生成能力，在LOVE@CVPR'25 Workshop中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决视频MLLMs在标题生成中难以根据人类偏好调整焦点的问题。

Method: 设计针对时空动态和空间信息的增强提示，通过偏好感知训练对齐标题。

Result: 在VDC基准测试中取得第一名，表现卓越。

Conclusion: AVC-DPO成功将人类偏好融入视频标题生成，显著提升性能。

Abstract: Although video multimodal large language models (video MLLMs) have achieved
substantial progress in video captioning tasks, it remains challenging to
adjust the focal emphasis of video captions according to human preferences. To
address this limitation, we propose Aligned Video Captioning via Direct
Preference Optimization (AVC-DPO), a post-training framework designed to
enhance captioning capabilities in video MLLMs through preference alignment.
Our approach designs enhanced prompts that specifically target temporal
dynamics and spatial information-two key factors that humans care about when
watching a video-thereby incorporating human-centric preferences. AVC-DPO
leverages the same foundation model's caption generation responses under varied
prompt conditions to conduct preference-aware training and caption alignment.
Using this framework, we have achieved exceptional performance in the
LOVE@CVPR'25 Workshop Track 1A: Video Detailed Captioning Challenge, achieving
first place on the Video Detailed Captioning (VDC) benchmark according to the
VDCSCORE evaluation metric.

</details>


### [35] [Crop Pest Classification Using Deep Learning Techniques: A Review](https://arxiv.org/abs/2507.01494)
*Muhammad Hassam Ejaz,Muhammad Bilal,Usman Habib*

Main category: cs.CV

TL;DR: 综述分析了2018至2025年间37项关于AI害虫分类的研究，探讨了模型架构、数据集及技术挑战，指出当前趋势从CNN转向混合和Transformer模型，但仍面临数据集不平衡等挑战。


<details>
  <summary>Details</summary>
Motivation: 传统害虫监测方法效率低且难以扩展，深度学习为自动化害虫检测提供了高效解决方案。

Method: 综述整理了37项研究，按作物类型、害虫种类、模型架构等分类，分析了CNN、ViT及混合模型的应用。

Result: 研究发现混合和Transformer模型在精度和上下文理解上表现更优，但仍存在数据集不平衡、小害虫检测难等问题。

Conclusion: 综述总结了AI害虫监测的现状、数据集及未来方向，强调需解决技术挑战以实现更广泛应用。

Abstract: Insect pests continue to bring a serious threat to crop yields around the
world, and traditional methods for monitoring them are often slow, manual, and
difficult to scale. In recent years, deep learning has emerged as a powerful
solution, with techniques like convolutional neural networks (CNNs), vision
transformers (ViTs), and hybrid models gaining popularity for automating pest
detection. This review looks at 37 carefully selected studies published between
2018 and 2025, all focused on AI-based pest classification. The selected
research is organized by crop type, pest species, model architecture, dataset
usage, and key technical challenges. The early studies relied heavily on CNNs
but latest work is shifting toward hybrid and transformer-based models that
deliver higher accuracy and better contextual understanding. Still, challenges
like imbalanced datasets, difficulty in detecting small pests, limited
generalizability, and deployment on edge devices remain significant hurdles.
Overall, this review offers a structured overview of the field, highlights
useful datasets, and outlines the key challenges and future directions for
AI-based pest monitoring systems.

</details>


### [36] [ReFlex: Text-Guided Editing of Real Images in Rectified Flow via Mid-Step Feature Extraction and Attention Adaptation](https://arxiv.org/abs/2507.01496)
*Jimyeong Kim,Jungwon Park,Yeji Song,Nojun Kwak,Wonjong Rhee*

Main category: cs.CV

TL;DR: 提出了一种无需训练、无需用户提供掩码的ReFlow实时图像编辑方法，通过分析多模态Transformer块的中间表示，提取关键特征，并利用中步潜在表示提升编辑效果。


<details>
  <summary>Details</summary>
Motivation: 尽管ReFlow在图像质量和文本对齐上优于扩散模型，但其实时图像编辑仍具挑战性。

Method: 分析多模态Transformer块的中间表示，提取三个关键特征；利用中步潜在表示保持结构；调整注意力注入以提升编辑性和目标文本对齐。

Result: 在两个基准测试和九个基线方法上表现优异，用户评估显示用户偏好该方法。

Conclusion: 该方法在无需训练和掩码的情况下，显著提升了ReFlow的实时图像编辑能力。

Abstract: Rectified Flow text-to-image models surpass diffusion models in image quality
and text alignment, but adapting ReFlow for real-image editing remains
challenging. We propose a new real-image editing method for ReFlow by analyzing
the intermediate representations of multimodal transformer blocks and
identifying three key features. To extract these features from real images with
sufficient structural preservation, we leverage mid-step latent, which is
inverted only up to the mid-step. We then adapt attention during injection to
improve editability and enhance alignment to the target text. Our method is
training-free, requires no user-provided mask, and can be applied even without
a source prompt. Extensive experiments on two benchmarks with nine baselines
demonstrate its superior performance over prior methods, further validated by
human evaluations confirming a strong user preference for our approach.

</details>


### [37] [Integrating Traditional and Deep Learning Methods to Detect Tree Crowns in Satellite Images](https://arxiv.org/abs/2507.01502)
*Ozan Durgut,Beril Kallfelz-Sirmacek,Cem Unsalan*

Main category: cs.CV

TL;DR: 论文提出了一种结合传统方法和深度学习的树冠检测新方法，通过规则后处理提高检测的鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 全球变暖、生物多样性丧失和空气污染等问题亟需森林监测，但缺乏自动化监测手段。

Method: 结合传统方法进行特征提取和分割，利用深度学习检测树冠，并通过规则后处理优化结果。

Result: 新方法提高了树冠检测数量，并分析了其优缺点和改进空间。

Conclusion: 规则后处理的方法能有效提升树冠检测的准确性和鲁棒性。

Abstract: Global warming, loss of biodiversity, and air pollution are among the most
significant problems facing Earth. One of the primary challenges in addressing
these issues is the lack of monitoring forests to protect them. To tackle this
problem, it is important to leverage remote sensing and computer vision methods
to automate monitoring applications. Hence, automatic tree crown detection
algorithms emerged based on traditional and deep learning methods. In this
study, we first introduce two different tree crown detection methods based on
these approaches. Then, we form a novel rule-based approach that integrates
these two methods to enhance robustness and accuracy of tree crown detection
results. While traditional methods are employed for feature extraction and
segmentation of forested areas, deep learning methods are used to detect tree
crowns in our method. With the proposed rule-based approach, we post-process
these results, aiming to increase the number of detected tree crowns through
neighboring trees and localized operations. We compare the obtained results
with the proposed method in terms of the number of detected tree crowns and
report the advantages, disadvantages, and areas for improvement of the obtained
outcomes.

</details>


### [38] [Following the Clues: Experiments on Person Re-ID using Cross-Modal Intelligence](https://arxiv.org/abs/2507.01504)
*Robert Aufschläger,Youssef Shoeb,Azarm Nowzad,Michael Heigl,Fabian Bally,Martin Schramm*

Main category: cs.CV

TL;DR: 论文提出了一种跨模态框架cRID，结合视觉语言模型和图注意力网络，用于检测个人可识别信息（PII）并增强行人重识别（Re-ID）性能。


<details>
  <summary>Details</summary>
Motivation: 街景数据作为开放数据对自动驾驶和AI研究至关重要，但其中包含的个人可识别信息（PII）带来隐私风险，需要更高效的检测方法。

Method: cRID框架结合大型视觉语言模型、图注意力网络和表示学习，检测文本可描述的PII线索，并利用可解释特征提升Re-ID性能。

Result: 实验表明，cRID在跨数据集Re-ID任务（如Market-1501到CUHK03-np）中表现优异，验证了其实际应用价值。

Conclusion: cRID框架能有效检测语义上有意义的PII，并在行人重识别任务中表现出色，为隐私保护和AI研究提供了实用工具。

Abstract: The collection and release of street-level recordings as Open Data play a
vital role in advancing autonomous driving systems and AI research. However,
these datasets pose significant privacy risks, particularly for pedestrians,
due to the presence of Personally Identifiable Information (PII) that extends
beyond biometric traits such as faces. In this paper, we present cRID, a novel
cross-modal framework combining Large Vision-Language Models, Graph Attention
Networks, and representation learning to detect textual describable clues of
PII and enhance person re-identification (Re-ID). Our approach focuses on
identifying and leveraging interpretable features, enabling the detection of
semantically meaningful PII beyond low-level appearance cues. We conduct a
systematic evaluation of PII presence in person image datasets. Our experiments
show improved performance in practical cross-dataset Re-ID scenarios, notably
from Market-1501 to CUHK03-np (detected), highlighting the framework's
practical utility. Code is available at https://github.com/RAufschlaeger/cRID.

</details>


### [39] [Mamba Guided Boundary Prior Matters: A New Perspective for Generalized Polyp Segmentation](https://arxiv.org/abs/2507.01509)
*Tapas K. Dutta,Snehashis Majhi,Deepak Ranjan Nayak,Debesh Jha*

Main category: cs.CV

TL;DR: SAM-MaGuP是一种基于Segment Anything Model（SAM）的新方法，通过边界蒸馏模块和1D-2D Mamba适配器，显著提升了息肉分割的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 息肉分割在结肠镜图像中对结直肠癌的早期检测至关重要，但现有方法在弱边界和模糊边界情况下表现不佳，且泛化能力不足。

Method: 结合边界蒸馏模块和1D-2D Mamba适配器，增强SAM模型的特征学习和边界处理能力。

Result: 在五个数据集上的评估显示，SAM-MaGuP在分割准确性和鲁棒性上优于现有方法。

Conclusion: SAM-MaGuP通过创新设计，为息肉分割领域设定了新的基准。

Abstract: Polyp segmentation in colonoscopy images is crucial for early detection and
diagnosis of colorectal cancer. However, this task remains a significant
challenge due to the substantial variations in polyp shape, size, and color, as
well as the high similarity between polyps and surrounding tissues, often
compounded by indistinct boundaries. While existing encoder-decoder CNN and
transformer-based approaches have shown promising results, they struggle with
stable segmentation performance on polyps with weak or blurry boundaries. These
methods exhibit limited abilities to distinguish between polyps and non-polyps
and capture essential boundary cues. Moreover, their generalizability still
falls short of meeting the demands of real-time clinical applications. To
address these limitations, we propose SAM-MaGuP, a groundbreaking approach for
robust polyp segmentation. By incorporating a boundary distillation module and
a 1D-2D Mamba adapter within the Segment Anything Model (SAM), SAM-MaGuP excels
at resolving weak boundary challenges and amplifies feature learning through
enriched global contextual interactions. Extensive evaluations across five
diverse datasets reveal that SAM-MaGuP outperforms state-of-the-art methods,
achieving unmatched segmentation accuracy and robustness. Our key innovations,
a Mamba-guided boundary prior and a 1D-2D Mamba block, set a new benchmark in
the field, pushing the boundaries of polyp segmentation to new heights.

</details>


### [40] [Exploring Pose-based Sign Language Translation: Ablation Studies and Attention Insights](https://arxiv.org/abs/2507.01532)
*Tomas Zelezny,Jakub Straka,Vaclav Javorek,Ondrej Valach,Marek Hruz,Ivan Gruber*

Main category: cs.CV

TL;DR: 本文探讨了基于姿态的数据预处理技术（归一化、插值和增强）对手语翻译（SLT）性能的影响，使用改进的T5编码器-解码器模型，实验表明这些技术能显著提升模型的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过姿态数据预处理技术提升手语翻译系统的性能，特别是在连续无注释翻译场景中。

Method: 采用改进的T5编码器-解码器模型处理姿态表示，并在YouTubeASL和How2Sign数据集上进行消融实验，分析不同预处理策略的影响。

Result: 适当的归一化、插值和增强技术显著提高了模型的翻译准确性和泛化能力，同时发现添加专用寄存器标记可进一步提升性能。

Conclusion: 姿态数据预处理技术对手语翻译性能至关重要，未来可通过优化模型架构和预处理方法进一步提升效果。

Abstract: Sign Language Translation (SLT) has evolved significantly, moving from
isolated recognition approaches to complex, continuous gloss-free translation
systems. This paper explores the impact of pose-based data preprocessing
techniques - normalization, interpolation, and augmentation - on SLT
performance. We employ a transformer-based architecture, adapting a modified T5
encoder-decoder model to process pose representations. Through extensive
ablation studies on YouTubeASL and How2Sign datasets, we analyze how different
preprocessing strategies affect translation accuracy. Our results demonstrate
that appropriate normalization, interpolation, and augmentation techniques can
significantly improve model robustness and generalization abilities.
Additionally, we provide a deep analysis of the model's attentions and reveal
interesting behavior suggesting that adding a dedicated register token can
improve overall model performance. We publish our code on our GitHub
repository, including the preprocessed YouTubeASL data.

</details>


### [41] [What does really matter in image goal navigation?](https://arxiv.org/abs/2507.01667)
*Gianluca Monaci,Philippe Weinzaepfel,Christian Wolf*

Main category: cs.CV

TL;DR: 研究探讨了图像目标导航任务是否可以通过端到端强化学习训练解决，并分析了架构选择和模拟器设置对性能的影响。


<details>
  <summary>Details</summary>
Motivation: 探索图像目标导航任务是否可以通过端到端强化学习训练解决，以简化相对姿态估计的训练过程。

Method: 通过大规模实验研究不同架构选择（如延迟融合、通道堆叠、空间到深度投影和交叉注意力）对导航任务中相对姿态估计器的影响。

Result: 发现模拟器设置会影响性能，但部分能力可迁移到更真实的场景；导航性能与相对姿态估计性能存在相关性。

Conclusion: 端到端强化学习在图像目标导航中具有一定潜力，但需注意模拟器设置的影响和能力的迁移性。

Abstract: Image goal navigation requires two different skills: firstly, core navigation
skills, including the detection of free space and obstacles, and taking
decisions based on an internal representation; and secondly, computing
directional information by comparing visual observations to the goal image.
Current state-of-the-art methods either rely on dedicated image-matching, or
pre-training of computer vision modules on relative pose estimation. In this
paper, we study whether this task can be efficiently solved with end-to-end
training of full agents with RL, as has been claimed by recent work. A positive
answer would have impact beyond Embodied AI and allow training of relative pose
estimation from reward for navigation alone. In a large study we investigate
the effect of architectural choices like late fusion, channel stacking,
space-to-depth projections and cross-attention, and their role in the emergence
of relative pose estimators from navigation training. We show that the success
of recent methods is influenced up to a certain extent by simulator settings,
leading to shortcuts in simulation. However, we also show that these
capabilities can be transferred to more realistic setting, up to some extend.
We also find evidence for correlations between navigation performance and
probed (emerging) relative pose estimation performance, an important sub skill.

</details>


### [42] [TrackingMiM: Efficient Mamba-in-Mamba Serialization for Real-time UAV Object Tracking](https://arxiv.org/abs/2507.01535)
*Bingxi Liu,Calvin Chen,Junhao Li,Guyang Yu,Haoqian Song,Xuchen Liu,Jinqiang Cui,Hong Zhang*

Main category: cs.CV

TL;DR: 论文提出了一种基于Mamba模型的TrackingMiM架构，用于解决ViT在无人机跟踪任务中的二次复杂度问题，实现了高效的长序列建模和实时处理。


<details>
  <summary>Details</summary>
Motivation: Vision Transformer (ViT)在无人机跟踪系统中因二次复杂度问题难以实时处理数据，而Mamba模型的计算效率和长序列建模能力为此提供了潜在解决方案。

Method: 提出TrackingMiM架构，采用嵌套的Mamba扫描机制，独立处理时空一致的图像块标记，并将模板帧编码为查询标记用于跟踪。

Result: 在五个无人机跟踪基准测试中，TrackingMiM实现了最先进的精度和显著更高的速度。

Conclusion: TrackingMiM通过改进的Mamba扫描机制，有效解决了ViT的复杂度问题，为无人机跟踪任务提供了高效且精确的解决方案。

Abstract: The Vision Transformer (ViT) model has long struggled with the challenge of
quadratic complexity, a limitation that becomes especially critical in unmanned
aerial vehicle (UAV) tracking systems, where data must be processed in real
time. In this study, we explore the recently proposed State-Space Model, Mamba,
leveraging its computational efficiency and capability for long-sequence
modeling to effectively process dense image sequences in tracking tasks. First,
we highlight the issue of temporal inconsistency in existing Mamba-based
methods, specifically the failure to account for temporal continuity in the
Mamba scanning mechanism. Secondly, building upon this insight,we propose
TrackingMiM, a Mamba-in-Mamba architecture, a minimal-computation burden model
for handling image sequence of tracking problem. In our framework, the mamba
scan is performed in a nested way while independently process temporal and
spatial coherent patch tokens. While the template frame is encoded as query
token and utilized for tracking in every scan. Extensive experiments conducted
on five UAV tracking benchmarks confirm that the proposed TrackingMiM achieves
state-of-the-art precision while offering noticeable higher speed in UAV
tracking.

</details>


### [43] [A Multi-Centric Anthropomorphic 3D CT Phantom-Based Benchmark Dataset for Harmonization](https://arxiv.org/abs/2507.01539)
*Mohammadreza Amirian,Michael Bach,Oscar Jimenez-del-Toro,Christoph Aberle,Roger Schaer,Vincent Andrearczyk,Jean-Félix Maestrati,Maria Martin Asiain,Kyriakos Flouris,Markus Obmann,Clarisse Dromain,Benoît Dufour,Pierre-Alexandre Alois Poletti,Hendrik von Tengg-Kobligk,Rolf Hügli,Martin Kretzschmar,Hatem Alkadhi,Ender Konukoglu,Henning Müller,Bram Stieltjes,Adrien Depeursinge*

Main category: cs.CV

TL;DR: 该论文提出了一个开源基准数据集，用于促进AI在CT分析中的泛化能力，通过减少数据分布偏移。


<details>
  <summary>Details</summary>
Motivation: AI在医学CT分析中因数据分布偏移（如扫描仪制造商、重建技术或剂量变化）而泛化能力差，需要解决这一问题。

Method: 使用一个包含1378个图像系列的数据集，涵盖不同扫描仪和设置，并提出评估图像和特征稳定性及肝脏组织分类的方法论。

Result: 提供了一个基准数据集和开源代码，支持AI协调技术的发展。

Conclusion: 该数据集和方法论有助于推动AI在医学影像中的泛化能力提升。

Abstract: Artificial intelligence (AI) has introduced numerous opportunities for human
assistance and task automation in medicine. However, it suffers from poor
generalization in the presence of shifts in the data distribution. In the
context of AI-based computed tomography (CT) analysis, significant data
distribution shifts can be caused by changes in scanner manufacturer,
reconstruction technique or dose. AI harmonization techniques can address this
problem by reducing distribution shifts caused by various acquisition settings.
This paper presents an open-source benchmark dataset containing CT scans of an
anthropomorphic phantom acquired with various scanners and settings, which
purpose is to foster the development of AI harmonization techniques. Using a
phantom allows fixing variations attributed to inter- and intra-patient
variations. The dataset includes 1378 image series acquired with 13 scanners
from 4 manufacturers across 8 institutions using a harmonized protocol as well
as several acquisition doses. Additionally, we present a methodology, baseline
results and open-source code to assess image- and feature-level stability and
liver tissue classification, promoting the development of AI harmonization
strategies.

</details>


### [44] [Interpolation-Based Event Visual Data Filtering Algorithms](https://arxiv.org/abs/2507.01557)
*Marcin Kowlaczyk,Tomasz Kryjak*

Main category: cs.CV

TL;DR: 提出了一种基于无限脉冲响应（IIR）滤波器矩阵的方法，可去除事件相机数据中约99%的噪声，同时保留有效信号。


<details>
  <summary>Details</summary>
Motivation: 事件相机数据流中存在显著噪声，影响应用效果。

Method: 提出四种基于IIR滤波器矩阵的算法，并在多个事件数据集上进行比较测试。

Result: 方法在1280x720分辨率传感器上仅需约30KB内存，适合嵌入式设备实现。

Conclusion: 该方法高效去噪且资源占用低，适用于嵌入式系统。

Abstract: The field of neuromorphic vision is developing rapidly, and event cameras are
finding their way into more and more applications. However, the data stream
from these sensors is characterised by significant noise. In this paper, we
propose a method for event data that is capable of removing approximately 99\%
of noise while preserving the majority of the valid signal. We have proposed
four algorithms based on the matrix of infinite impulse response (IIR) filters
method. We compared them on several event datasets that were further modified
by adding artificially generated noise and noise recorded with dynamic vision
sensor. The proposed methods use about 30KB of memory for a sensor with a
resolution of 1280 x 720 and is therefore well suited for implementation in
embedded devices.

</details>


### [45] [A Gift from the Integration of Discriminative and Diffusion-based Generative Learning: Boundary Refinement Remote Sensing Semantic Segmentation](https://arxiv.org/abs/2507.01573)
*Hao Wang,Keyan Hu,Xin Guo,Haifeng Li,Chao Tao*

Main category: cs.CV

TL;DR: 论文提出了一种结合判别学习和扩散生成学习的框架（IDGBR），用于改进遥感语义分割中的边界精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖判别学习，擅长捕捉低频特征但忽视高频特征，而扩散生成模型擅长生成高频细节。结合两者优势以提升分割精度。

Method: IDGBR框架首先生成粗略分割图，再通过条件引导网络和扩散去噪过程细化边界。

Result: 在五个遥感数据集上的实验表明，IDGBR能一致改进不同判别架构的粗糙分割结果。

Conclusion: 结合判别和生成学习的IDGBR框架有效提升了语义分割的边界精度。

Abstract: Remote sensing semantic segmentation must address both what the ground
objects are within an image and where they are located. Consequently,
segmentation models must ensure not only the semantic correctness of
large-scale patches (low-frequency information) but also the precise
localization of boundaries between patches (high-frequency information).
However, most existing approaches rely heavily on discriminative learning,
which excels at capturing low-frequency features, while overlooking its
inherent limitations in learning high-frequency features for semantic
segmentation. Recent studies have revealed that diffusion generative models
excel at generating high-frequency details. Our theoretical analysis confirms
that the diffusion denoising process significantly enhances the model's ability
to learn high-frequency features; however, we also observe that these models
exhibit insufficient semantic inference for low-frequency features when guided
solely by the original image. Therefore, we integrate the strengths of both
discriminative and generative learning, proposing the Integration of
Discriminative and diffusion-based Generative learning for Boundary Refinement
(IDGBR) framework. The framework first generates a coarse segmentation map
using a discriminative backbone model. This map and the original image are fed
into a conditioning guidance network to jointly learn a guidance representation
subsequently leveraged by an iterative denoising diffusion process refining the
coarse segmentation. Extensive experiments across five remote sensing semantic
segmentation datasets (binary and multi-class segmentation) confirm our
framework's capability of consistent boundary refinement for coarse results
from diverse discriminative architectures. The source code will be available at
https://github.com/KeyanHu-git/IDGBR.

</details>


### [46] [SketchColour: Channel Concat Guided DiT-based Sketch-to-Colour Pipeline for 2D Animation](https://arxiv.org/abs/2507.01586)
*Bryan Constantine Sadihin,Michael Hua Wang,Shei Pern Chua,Hang Su*

Main category: cs.CV

TL;DR: SketchColour提出了一种基于扩散变压器（DiT）的2D动画草图到色彩转换方法，显著减少了参数和GPU内存使用，并在SAKUGA数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统2D动画制作需要大量手工绘制和上色，耗时耗力。本文旨在通过自动化技术简化这一过程。

Method: 采用扩散变压器（DiT）架构，通过轻量级通道连接适配器和LoRA微调注入草图信息，避免参数和内存膨胀。

Result: 在SAKUGA数据集上表现优于现有视频上色方法，仅用一半训练数据即可生成时间一致且无显著伪影的动画。

Conclusion: SketchColour为2D动画上色提供了一种高效且高质量的解决方案，显著提升了自动化水平。

Abstract: The production of high-quality 2D animation is highly labor-intensive
process, as animators are currently required to draw and color a large number
of frames by hand. We present SketchColour, the first sketch-to-colour pipeline
for 2D animation built on a diffusion transformer (DiT) backbone. By replacing
the conventional U-Net denoiser with a DiT-style architecture and injecting
sketch information via lightweight channel-concatenation adapters accompanied
with LoRA finetuning, our method natively integrates conditioning without the
parameter and memory bloat of a duplicated ControlNet, greatly reducing
parameter count and GPU memory usage. Evaluated on the SAKUGA dataset,
SketchColour outperforms previous state-of-the-art video colourization methods
across all metrics, despite using only half the training data of competing
models. Our approach produces temporally coherent animations with minimal
artifacts such as colour bleeding or object deformation. Our code is available
at: https://bconstantine.github.io/SketchColour .

</details>


### [47] [Towards Controllable Real Image Denoising with Camera Parameters](https://arxiv.org/abs/2507.01587)
*Youngjin Oh,Junhyeong Kwon,Keuntek Lee,Nam Ik Cho*

Main category: cs.CV

TL;DR: 提出了一种基于相机参数的可控去噪框架，通过ISO、快门速度和F值调整去噪强度。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法缺乏根据噪声水平、相机设置和用户偏好调整去噪强度的灵活性。

Method: 将ISO、快门速度和F值转换为向量，用于控制去噪网络的性能。

Result: 实验表明，该方法为去噪网络增加了可控性并提升了性能。

Conclusion: 该方法成功实现了基于相机参数的自适应去噪，代码已开源。

Abstract: Recent deep learning-based image denoising methods have shown impressive
performance; however, many lack the flexibility to adjust the denoising
strength based on the noise levels, camera settings, and user preferences. In
this paper, we introduce a new controllable denoising framework that adaptively
removes noise from images by utilizing information from camera parameters.
Specifically, we focus on ISO, shutter speed, and F-number, which are closely
related to noise levels. We convert these selected parameters into a vector to
control and enhance the performance of the denoising network. Experimental
results show that our method seamlessly adds controllability to standard
denoising neural networks and improves their performance. Code is available at
https://github.com/OBAKSA/CPADNet.

</details>


### [48] [Autonomous AI Surveillance: Multimodal Deep Learning for Cognitive and Behavioral Monitoring](https://arxiv.org/abs/2507.01590)
*Ameer Hamza,Zuhaib Hussain But,Umar Arif,Samiya,M. Abdullah Asad,Muhammad Naeem*

Main category: cs.CV

TL;DR: 提出了一种多模态课堂监控系统，结合睡意检测、手机使用追踪和人脸识别，提升学生注意力评估精度。


<details>
  <summary>Details</summary>
Motivation: 通过多模态技术实时监测学生行为和参与度，优化课堂管理。

Method: 使用YOLOv8检测手机和睡眠行为，LResNet Occ FC和MTCNN进行人脸识别，集成PHP和ESP32-CAM硬件。

Result: 睡眠检测mAP@50为97.42%，人脸识别准确率86.45%，手机检测mAP@50为85.89%。

Conclusion: 系统实现了高效课堂监控和自动考勤，适用于多样化教育环境。

Abstract: This study presents a novel classroom surveillance system that integrates
multiple modalities, including drowsiness, tracking of mobile phone usage, and
face recognition,to assess student attentiveness with enhanced precision.The
system leverages the YOLOv8 model to detect both mobile phone and sleep
usage,(Ghatge et al., 2024) while facial recognition is achieved through
LResNet Occ FC body tracking using YOLO and MTCNN.(Durai et al., 2024) These
models work in synergy to provide comprehensive, real-time monitoring, offering
insights into student engagement and behavior.(S et al., 2023) The framework is
trained on specialized datasets, such as the RMFD dataset for face recognition
and a Roboflow dataset for mobile phone detection. The extensive evaluation of
the system shows promising results. Sleep detection achieves 97. 42% mAP@50,
face recognition achieves 86. 45% validation accuracy and mobile phone
detection reach 85. 89% mAP@50. The system is implemented within a core PHP web
application and utilizes ESP32-CAM hardware for seamless data capture.(Neto et
al., 2024) This integrated approach not only enhances classroom monitoring, but
also ensures automatic attendance recording via face recognition as students
remain seated in the classroom, offering scalability for diverse educational
environments.(Banada,2025)

</details>


### [49] [DepthSync: Diffusion Guidance-Based Depth Synchronization for Scale- and Geometry-Consistent Video Depth Estimation](https://arxiv.org/abs/2507.01603)
*Yue-Jiang Dong,Wang Zhao,Jiale Xu,Ying Shan,Song-Hai Zhang*

Main category: cs.CV

TL;DR: DepthSync提出了一种无需训练的框架，通过扩散引导实现长视频深度预测的尺度和几何一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理长视频时存在尺度差异和几何不一致问题，主要依赖2D扩散先验而忽略了3D几何结构。

Method: 引入尺度引导和几何引导，协同优化去噪过程，确保跨窗口的尺度同步和窗口内的几何对齐。

Result: 在多个数据集上验证了DepthSync在尺度和几何一致性方面的有效性，尤其适用于长视频。

Conclusion: DepthSync通过结合尺度和几何引导，显著提升了长视频深度预测的一致性和准确性。

Abstract: Diffusion-based video depth estimation methods have achieved remarkable
success with strong generalization ability. However, predicting depth for long
videos remains challenging. Existing methods typically split videos into
overlapping sliding windows, leading to accumulated scale discrepancies across
different windows, particularly as the number of windows increases.
Additionally, these methods rely solely on 2D diffusion priors, overlooking the
inherent 3D geometric structure of video depths, which results in geometrically
inconsistent predictions. In this paper, we propose DepthSync, a novel,
training-free framework using diffusion guidance to achieve scale- and
geometry-consistent depth predictions for long videos. Specifically, we
introduce scale guidance to synchronize the depth scale across windows and
geometry guidance to enforce geometric alignment within windows based on the
inherent 3D constraints in video depths. These two terms work synergistically,
steering the denoising process toward consistent depth predictions. Experiments
on various datasets validate the effectiveness of our method in producing depth
estimates with improved scale and geometry consistency, particularly for long
videos.

</details>


### [50] [Survivability of Backdoor Attacks on Unconstrained Face Recognition Systems](https://arxiv.org/abs/2507.01607)
*Quentin Le Roux,Yannick Teglia,Teddy Furon,Philippe Loubet-Moundi,Eric Bourbao*

Main category: cs.CV

TL;DR: 本文首次系统研究了深度学习人脸识别系统中的后门攻击，展示了两种新型攻击方式，并提出了防护措施。


<details>
  <summary>Details</summary>
Motivation: 深度学习人脸识别系统在现实场景中的安全问题尚未充分研究，尤其是后门攻击的潜在威胁。

Method: 通过探索人脸检测任务中的后门攻击可行性，提出两种新型攻击（人脸生成和关键点偏移），并测试了20种系统配置和15种攻击案例。

Result: 研究表明，单一后门攻击可绕过整个系统功能，且基于大间隔损失的特征提取器也易受攻击。

Conclusion: 研究揭示了人脸识别系统的后门漏洞，并提供了防护建议。

Abstract: The widespread use of deep learning face recognition raises several security
concerns. Although prior works point at existing vulnerabilities, DNN backdoor
attacks against real-life, unconstrained systems dealing with images captured
in the wild remain a blind spot of the literature. This paper conducts the
first system-level study of backdoors in deep learning-based face recognition
systems. This paper yields four contributions by exploring the feasibility of
DNN backdoors on these pipelines in a holistic fashion. We demonstrate for the
first time two backdoor attacks on the face detection task: face generation and
face landmark shift attacks. We then show that face feature extractors trained
with large margin losses also fall victim to backdoor attacks. Combining our
models, we then show using 20 possible pipeline configurations and 15 attack
cases that a single backdoor enables an attacker to bypass the entire function
of a system. Finally, we provide stakeholders with several best practices and
countermeasures.

</details>


### [51] [Perception-Oriented Latent Coding for High-Performance Compressed Domain Semantic Inference](https://arxiv.org/abs/2507.01608)
*Xu Zhang,Ming Lu,Yan Chen,Zhan Ma*

Main category: cs.CV

TL;DR: POLC提出了一种感知导向的潜在编码方法，通过丰富潜在特征的语义内容，提升压缩域语义推理性能，同时减少微调参数。


<details>
  <summary>Details</summary>
Motivation: 传统基于MSE优化的图像编码模型潜在空间语义贫乏，且微调计算成本高。

Method: 引入POLC方法，通过增强潜在特征的语义内容，仅需轻量级适配器进行微调。

Result: POLC在率感知性能上媲美生成式图像编码方法，显著提升视觉任务性能，且微调开销低。

Conclusion: POLC为压缩域语义推理提供了一种高效且高性能的解决方案。

Abstract: In recent years, compressed domain semantic inference has primarily relied on
learned image coding models optimized for mean squared error (MSE). However,
MSE-oriented optimization tends to yield latent spaces with limited semantic
richness, which hinders effective semantic inference in downstream tasks.
Moreover, achieving high performance with these models often requires
fine-tuning the entire vision model, which is computationally intensive,
especially for large models. To address these problems, we introduce
Perception-Oriented Latent Coding (POLC), an approach that enriches the
semantic content of latent features for high-performance compressed domain
semantic inference. With the semantically rich latent space, POLC requires only
a plug-and-play adapter for fine-tuning, significantly reducing the parameter
count compared to previous MSE-oriented methods. Experimental results
demonstrate that POLC achieves rate-perception performance comparable to
state-of-the-art generative image coding methods while markedly enhancing
performance in vision tasks, with minimal fine-tuning overhead. Code is
available at https://github.com/NJUVISION/POLC.

</details>


### [52] [Prompt Guidance and Human Proximal Perception for HOT Prediction with Regional Joint Loss](https://arxiv.org/abs/2507.01630)
*Yuxiao Wang,Yu Lei,Zhenao Wei,Weiying Xue,Xinyu Jiang,Nan Zhuang,Qi Liu*

Main category: cs.CV

TL;DR: P3HOT框架结合提示引导和人类近端感知，通过语义驱动提示和深度感知优化人-物接触检测，提出新损失函数和评估指标，性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 解决现有模型在单一图像类型中过度分割和类别一致性不足的问题。

Method: 结合语义驱动提示和人类近端感知机制，引入区域联合损失（RJLoss）和新评估指标AD-Acc。

Result: 在两个基准数据集上四项指标达到最优，性能显著提升。

Conclusion: P3HOT框架有效优化人-物接触检测任务，性能显著优于现有方法。

Abstract: The task of Human-Object conTact (HOT) detection involves identifying the
specific areas of the human body that are touching objects. Nevertheless,
current models are restricted to just one type of image, often leading to too
much segmentation in areas with little interaction, and struggling to maintain
category consistency within specific regions. To tackle this issue, a HOT
framework, termed \textbf{P3HOT}, is proposed, which blends \textbf{P}rompt
guidance and human \textbf{P}roximal \textbf{P}erception. To begin with, we
utilize a semantic-driven prompt mechanism to direct the network's attention
towards the relevant regions based on the correlation between image and text.
Then a human proximal perception mechanism is employed to dynamically perceive
key depth range around the human, using learnable parameters to effectively
eliminate regions where interactions are not expected. Calculating depth
resolves the uncertainty of the overlap between humans and objects in a 2D
perspective, providing a quasi-3D viewpoint. Moreover, a Regional Joint Loss
(RJLoss) has been created as a new loss to inhibit abnormal categories in the
same area. A new evaluation metric called ``AD-Acc.'' is introduced to address
the shortcomings of existing methods in addressing negative samples.
Comprehensive experimental results demonstrate that our approach achieves
state-of-the-art performance in four metrics across two benchmark datasets.
Specifically, our model achieves an improvement of \textbf{0.7}$\uparrow$,
\textbf{2.0}$\uparrow$, \textbf{1.6}$\uparrow$, and \textbf{11.0}$\uparrow$ in
SC-Acc., mIoU, wIoU, and AD-Acc. metrics, respectively, on the HOT-Annotated
dataset. Code is available at https://github.com/YuxiaoWang-AI/P3HOT.

</details>


### [53] [Depth Anything at Any Condition](https://arxiv.org/abs/2507.01634)
*Boyuan Sun,Modi Jin,Bowen Yin,Qibin Hou*

Main category: cs.CV

TL;DR: DepthAnything-AC是一种基础单目深度估计模型，能够在多样环境条件下工作，通过无监督一致性正则化微调和空间距离约束提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有基础MDE模型在复杂开放世界环境中表现不佳，特别是在光照变化、恶劣天气和传感器失真等条件下。

Method: 提出无监督一致性正则化微调范式，仅需少量未标记数据，并引入空间距离约束以学习补丁级相对关系。

Result: 实验证明模型在多种基准测试（包括恶劣天气、合成失真和通用场景）中具有零样本能力。

Conclusion: DepthAnything-AC在复杂环境条件下表现出色，为单目深度估计提供了更鲁棒的解决方案。

Abstract: We present Depth Anything at Any Condition (DepthAnything-AC), a foundation
monocular depth estimation (MDE) model capable of handling diverse
environmental conditions. Previous foundation MDE models achieve impressive
performance across general scenes but not perform well in complex open-world
environments that involve challenging conditions, such as illumination
variations, adverse weather, and sensor-induced distortions. To overcome the
challenges of data scarcity and the inability of generating high-quality
pseudo-labels from corrupted images, we propose an unsupervised consistency
regularization finetuning paradigm that requires only a relatively small amount
of unlabeled data. Furthermore, we propose the Spatial Distance Constraint to
explicitly enforce the model to learn patch-level relative relationships,
resulting in clearer semantic boundaries and more accurate details.
Experimental results demonstrate the zero-shot capabilities of DepthAnything-AC
across diverse benchmarks, including real-world adverse weather benchmarks,
synthetic corruption benchmarks, and general benchmarks.
  Project Page: https://ghost233lism.github.io/depthanything-AC-page
  Code: https://github.com/HVision-NKU/DepthAnythingAC

</details>


### [54] [SAILViT: Towards Robust and Generalizable Visual Backbones for MLLMs via Gradual Feature Refinement](https://arxiv.org/abs/2507.01643)
*Weijie Yin,Dingkang Yang,Hongyuan Dong,Zijian Kang,Jiacong Wang,Xiao Liang,Chao Feng,Jiao Ran*

Main category: cs.CV

TL;DR: SAILViT是一种逐步特征学习增强的ViT，用于解决ViT与LLM联合训练中的参数冲突和模态语义差距问题，显著提升MLLM在多模态任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有ViT在图像-文本对比学习或自监督机制中表现优异，但难以与LLM直接联合训练，存在参数初始化和模态语义差距问题。

Method: 提出SAILViT，通过逐步特征细化实现粗到细的特征对齐和世界知识注入，适应目标训练需求。

Result: SAILViT在不同参数规模、架构、训练策略和数据规模下表现出强大的鲁棒性和泛化能力，显著提升MLLM在OpenCompass基准上的性能。

Conclusion: SAILViT有效解决了ViT与LLM联合训练的挑战，为复杂多模态交互提供了性能突破。

Abstract: Vision Transformers (ViTs) are essential as foundation backbones in
establishing the visual comprehension capabilities of Multimodal Large Language
Models (MLLMs). Although most ViTs achieve impressive performance through
image-text pair-based contrastive learning or self-supervised mechanisms, they
struggle to engage in connector-based co-training directly with LLMs due to
potential parameter initialization conflicts and modality semantic gaps. To
address the above challenges, this paper proposes SAILViT, a gradual feature
learning-enhanced ViT for facilitating MLLMs to break through performance
bottlenecks in complex multimodal interactions. SAILViT achieves
coarse-to-fine-grained feature alignment and world knowledge infusion with
gradual feature refinement, which better serves target training demands. We
perform thorough empirical analyses to confirm the powerful robustness and
generalizability of SAILViT across different dimensions, including parameter
sizes, model architectures, training strategies, and data scales. Equipped with
SAILViT, existing MLLMs show significant and consistent performance
improvements on the OpenCompass benchmark across extensive downstream tasks.
SAILViT series models are released at
https://huggingface.co/BytedanceDouyinContent.

</details>


### [55] [Autoregressive Image Generation with Linear Complexity: A Spatial-Aware Decay Perspective](https://arxiv.org/abs/2507.01652)
*Yuxin Mao,Zhen Qin,Jinxing Zhou,Hui Deng,Xuyang Shen,Bin Fan,Jing Zhang,Yiran Zhong,Yuchao Dai*

Main category: cs.CV

TL;DR: 论文提出了一种新型注意力机制LASAD，通过保留2D空间关系解决线性注意力在图像生成中的性能问题，并基于此构建了高效的图像生成模型LASADGen。


<details>
  <summary>Details</summary>
Motivation: 传统自回归模型依赖Transformer架构，计算复杂且内存开销大；线性注意力虽能降低复杂度，但会因无法捕捉长程依赖而影响图像生成质量。

Method: 提出LASAD机制，通过基于真实2D空间位置的位置依赖衰减因子保留空间关系，并构建LASADGen模型实现线性复杂度的选择性注意力。

Result: 在ImageNet上的实验表明，LASADGen在图像生成性能和计算效率上达到最优。

Conclusion: LASADGen成功平衡了线性注意力的效率与高质量生成所需的空间理解能力。

Abstract: Autoregressive (AR) models have garnered significant attention in image
generation for their ability to effectively capture both local and global
structures within visual data. However, prevalent AR models predominantly rely
on the transformer architectures, which are beset by quadratic computational
complexity concerning input sequence length and substantial memory overhead due
to the necessity of maintaining key-value caches. Although linear attention
mechanisms have successfully reduced this burden in language models, our
initial experiments reveal that they significantly degrade image generation
quality because of their inability to capture critical long-range dependencies
in visual data. We propose Linear Attention with Spatial-Aware Decay (LASAD), a
novel attention mechanism that explicitly preserves genuine 2D spatial
relationships within the flattened image sequences by computing
position-dependent decay factors based on true 2D spatial location rather than
1D sequence positions. Based on this mechanism, we present LASADGen, an
autoregressive image generator that enables selective attention to relevant
spatial contexts with linear complexity. Experiments on ImageNet show LASADGen
achieves state-of-the-art image generation performance and computational
efficiency, bridging the gap between linear attention's efficiency and spatial
understanding needed for high-quality generation.

</details>


### [56] [RobuSTereo: Robust Zero-Shot Stereo Matching under Adverse Weather](https://arxiv.org/abs/2507.01653)
*Yuran Wang,Yingping Liang,Yutao Hu,Ying Fu*

Main category: cs.CV

TL;DR: RobuSTereo框架通过扩散模拟和稳健特征编码，提升了立体匹配模型在恶劣天气下的零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 基于学习的立体匹配模型在恶劣天气下表现不佳，主要因训练数据稀缺和特征提取困难。

Method: 提出扩散模拟管道生成高质量合成数据，并设计结合ConvNet和去噪Transformer的特征编码器。

Result: 实验表明RobuSTereo显著提升了模型在多种恶劣天气下的鲁棒性和泛化能力。

Conclusion: RobuSTereo有效解决了数据稀缺和特征提取问题，为恶劣天气下的立体匹配提供了可靠解决方案。

Abstract: Learning-based stereo matching models struggle in adverse weather conditions
due to the scarcity of corresponding training data and the challenges in
extracting discriminative features from degraded images. These limitations
significantly hinder zero-shot generalization to out-of-distribution weather
conditions. In this paper, we propose \textbf{RobuSTereo}, a novel framework
that enhances the zero-shot generalization of stereo matching models under
adverse weather by addressing both data scarcity and feature extraction
challenges. First, we introduce a diffusion-based simulation pipeline with a
stereo consistency module, which generates high-quality stereo data tailored
for adverse conditions. By training stereo matching models on our synthetic
datasets, we reduce the domain gap between clean and degraded images,
significantly improving the models' robustness to unseen weather conditions.
The stereo consistency module ensures structural alignment across synthesized
image pairs, preserving geometric integrity and enhancing depth estimation
accuracy. Second, we design a robust feature encoder that combines a
specialized ConvNet with a denoising transformer to extract stable and reliable
features from degraded images. The ConvNet captures fine-grained local
structures, while the denoising transformer refines global representations,
effectively mitigating the impact of noise, low visibility, and weather-induced
distortions. This enables more accurate disparity estimation even under
challenging visual conditions. Extensive experiments demonstrate that
\textbf{RobuSTereo} significantly improves the robustness and generalization of
stereo matching models across diverse adverse weather scenarios.

</details>


### [57] [SPoT: Subpixel Placement of Tokens in Vision Transformers](https://arxiv.org/abs/2507.01654)
*Martine Hjelkrem-Tan,Marius Aasan,Gabriel Y. Arteaga,Adín Ramírez Rivera*

Main category: cs.CV

TL;DR: 提出了一种名为SPoT的新标记化策略，通过连续定位图像中的标记，避免了基于网格的限制，显著提升了性能并减少了推理所需的标记数量。


<details>
  <summary>Details</summary>
Motivation: 标准标记化方法将特征限制在离散的补丁网格中，阻碍了模型在稀疏场景中的潜力，需要妥协。

Method: 提出Subpixel Placement of Tokens (SPoT)，通过连续定位标记，利用oracle-guided搜索优化标记位置。

Result: 显著提升了性能，减少了推理所需的标记数量。

Conclusion: SPoT为ViT架构提供了灵活、高效且可解释的新方向，将稀疏性转化为战略优势。

Abstract: Vision Transformers naturally accommodate sparsity, yet standard tokenization
methods confine features to discrete patch grids. This constraint prevents
models from fully exploiting sparse regimes, forcing awkward compromises. We
propose Subpixel Placement of Tokens (SPoT), a novel tokenization strategy that
positions tokens continuously within images, effectively sidestepping
grid-based limitations. With our proposed oracle-guided search, we uncover
substantial performance gains achievable with ideal subpixel token positioning,
drastically reducing the number of tokens necessary for accurate predictions
during inference. SPoT provides a new direction for flexible, efficient, and
interpretable ViT architectures, redefining sparsity as a strategic advantage
rather than an imposed limitation.

</details>


### [58] [Facial Emotion Learning with Text-Guided Multiview Fusion via Vision-Language Model for 3D/4D Facial Expression Recognition](https://arxiv.org/abs/2507.01673)
*Muzammil Behzad*

Main category: cs.CV

TL;DR: FACET-VLM是一个用于3D/4D面部表情识别的视觉语言框架，通过多视角面部表示学习和自然语言提示的语义引导，实现了高精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 3D/4D面部表情识别在情感计算中具有挑战性，但对人类行为理解、医疗监测和人机交互至关重要。

Method: FACET-VLM包含三个关键组件：跨视角语义聚合（CVSA）、多视角文本引导融合（MTGF）和多视角一致性损失。

Result: 在多个基准测试中达到最先进水平，并成功扩展到4D微表情识别。

Conclusion: FACET-VLM为多模态面部表情识别提供了高效、可扩展的解决方案。

Abstract: Facial expression recognition (FER) in 3D and 4D domains presents a
significant challenge in affective computing due to the complexity of spatial
and temporal facial dynamics. Its success is crucial for advancing applications
in human behavior understanding, healthcare monitoring, and human-computer
interaction. In this work, we propose FACET-VLM, a vision-language framework
for 3D/4D FER that integrates multiview facial representation learning with
semantic guidance from natural language prompts. FACET-VLM introduces three key
components: Cross-View Semantic Aggregation (CVSA) for view-consistent fusion,
Multiview Text-Guided Fusion (MTGF) for semantically aligned facial emotions,
and a multiview consistency loss to enforce structural coherence across views.
Our model achieves state-of-the-art accuracy across multiple benchmarks,
including BU-3DFE, Bosphorus, BU-4DFE, and BP4D-Spontaneous. We further extend
FACET-VLM to 4D micro-expression recognition (MER) on the 4DME dataset,
demonstrating strong performance in capturing subtle, short-lived emotional
cues. The extensive experimental results confirm the effectiveness and
substantial contributions of each individual component within the framework.
Overall, FACET-VLM offers a robust, extensible, and high-performing solution
for multimodal FER in both posed and spontaneous settings.

</details>


### [59] [Component Adaptive Clustering for Generalized Category Discovery](https://arxiv.org/abs/2507.01711)
*Mingfu Yan,Jiancheng Huang,Yifan Liu,Shifeng Chen*

Main category: cs.CV

TL;DR: AdaGCD是一种基于自适应槽注意力的聚类对比学习框架，用于在部分标记数据集中动态分类已知和未知类别的图像，无需预定义类别数量。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖预定义类别数量等刚性假设，难以处理真实数据的复杂性和可变性。

Method: 提出AdaGCD框架，结合自适应槽注意力（AdaSlot），动态确定最佳槽数量，实现灵活聚类。

Result: 在公开和细粒度数据集上的实验验证了AdaGCD的有效性，特别是在利用空间局部信息进行类别发现方面。

Conclusion: AdaGCD通过自适应表示和动态槽分配，显著提升了开放世界场景中的类别发现能力。

Abstract: Generalized Category Discovery (GCD) tackles the challenging problem of
categorizing unlabeled images into both known and novel classes within a
partially labeled dataset, without prior knowledge of the number of unknown
categories. Traditional methods often rely on rigid assumptions, such as
predefining the number of classes, which limits their ability to handle the
inherent variability and complexity of real-world data. To address these
shortcomings, we propose AdaGCD, a cluster-centric contrastive learning
framework that incorporates Adaptive Slot Attention (AdaSlot) into the GCD
framework. AdaSlot dynamically determines the optimal number of slots based on
data complexity, removing the need for predefined slot counts. This adaptive
mechanism facilitates the flexible clustering of unlabeled data into known and
novel categories by dynamically allocating representational capacity. By
integrating adaptive representation with dynamic slot allocation, our method
captures both instance-specific and spatially clustered features, improving
class discovery in open-world scenarios. Extensive experiments on public and
fine-grained datasets validate the effectiveness of our framework, emphasizing
the advantages of leveraging spatial local information for category discovery
in unlabeled image datasets.

</details>


### [60] [Using Wavelet Domain Fingerprints to Improve Source Camera Identification](https://arxiv.org/abs/2507.01712)
*Xinle Tian,Matthew Nunes,Emiko Dupont,Shaunagh Downing,Freddie Lichtenstein,Matt Burns*

Main category: cs.CV

TL;DR: 提出了一种基于小波域的传感器模式噪声（SPN）提取方法，避免了传统方法的逆变换步骤，提高了检测精度和处理速度。


<details>
  <summary>Details</summary>
Motivation: 传统小波去噪方法在提取SPN时需要将指纹构建为图像并进行逆变换，效率较低。

Method: 提出小波域指纹概念，直接在频域进行指纹提取和比较，省去逆变换步骤。

Result: 实验表明，该方法检测精度更高，处理速度显著提升。

Conclusion: 小波域指纹方法简化了流程，提高了效率和准确性。

Abstract: Camera fingerprint detection plays a crucial role in source identification
and image forensics, with wavelet denoising approaches proving to be
particularly effective in extracting sensor pattern noise (SPN). In this
article, we propose a modification to wavelet-based SPN extraction. Rather than
constructing the fingerprint as an image, we introduce the notion of a wavelet
domain fingerprint. This avoids the final inversion step of the denoising
algorithm and allows fingerprint comparisons to be made directly in the wavelet
domain. As such, our modification streamlines the extraction and comparison
process. Experimental results on real-world datasets demonstrate that our
method not only achieves higher detection accuracy but can also significantly
improve processing speed.

</details>


### [61] [Soft Self-labeling and Potts Relaxations for Weakly-Supervised Segmentation](https://arxiv.org/abs/2507.01721)
*Zhongwen Zhang,Yuri Boykov*

Main category: cs.CV

TL;DR: 提出了一种基于软自标记的弱监督分割方法，通过优化CRF/Potts损失的松弛形式，显著提升了基于涂鸦标签的训练效果。


<details>
  <summary>Details</summary>
Motivation: 解决硬伪标签无法表示类别不确定性和错误的问题，提出软自标记方法以提高网络训练效果。

Method: 通过推导辅助损失函数，系统评估标准和新CRF松弛形式（凸和非凸）、邻域系统以及网络预测与软伪标签的连接项，并提出通用的连续子问题求解器。

Result: 软自标记方法在标准架构下显著提升了涂鸦标签训练效果，甚至优于完全像素级监督。

Conclusion: 软自标记方法不仅适用于弱监督分割，还可推广到其他弱监督问题/系统。

Abstract: We consider weakly supervised segmentation where only a fraction of pixels
have ground truth labels (scribbles) and focus on a self-labeling approach
optimizing relaxations of the standard unsupervised CRF/Potts loss on unlabeled
pixels. While WSSS methods can directly optimize such losses via gradient
descent, prior work suggests that higher-order optimization can improve network
training by introducing hidden pseudo-labels and powerful CRF sub-problem
solvers, e.g. graph cut. However, previously used hard pseudo-labels can not
represent class uncertainty or errors, which motivates soft self-labeling. We
derive a principled auxiliary loss and systematically evaluate standard and new
CRF relaxations (convex and non-convex), neighborhood systems, and terms
connecting network predictions with soft pseudo-labels. We also propose a
general continuous sub-problem solver. Using only standard architectures, soft
self-labeling consistently improves scribble-based training and outperforms
significantly more complex specialized WSSS systems. It can outperform full
pixel-precise supervision. Our general ideas apply to other weakly-supervised
problems/systems.

</details>


### [62] [When Does Pruning Benefit Vision Representations?](https://arxiv.org/abs/2507.01722)
*Enrico Cassano,Riccardo Renzulli,Andrea Bragagnolo,Marco Grangetto*

Main category: cs.CV

TL;DR: 该论文研究了剪枝对视觉模型在可解释性、无监督目标发现和与人类感知对齐三个方面的影响，发现稀疏模型在特定条件下表现更优。


<details>
  <summary>Details</summary>
Motivation: 剪枝虽常用于降低深度学习模型复杂度，但其对可解释性和表示学习的影响尚不明确，因此需要深入研究。

Method: 分析不同视觉网络架构在不同稀疏度下对特征归因可解释性方法的影响，并探讨剪枝是否能促进更简洁的结构化表示。

Result: 研究发现稀疏模型在某些条件下（如特定架构和参数规模）表现出更高的可解释性、泛化能力和人类感知对齐。

Conclusion: 剪枝对视觉表示的影响复杂，需进一步研究其适用条件和方法。

Abstract: Pruning is widely used to reduce the complexity of deep learning models, but
its effects on interpretability and representation learning remain poorly
understood. This paper investigates how pruning influences vision models across
three key dimensions: (i) interpretability, (ii) unsupervised object discovery,
and (iii) alignment with human perception. We first analyze different vision
network architectures to examine how varying sparsity levels affect feature
attribution interpretability methods. Additionally, we explore whether pruning
promotes more succinct and structured representations, potentially improving
unsupervised object discovery by discarding redundant information while
preserving essential features. Finally, we assess whether pruning enhances the
alignment between model representations and human perception, investigating
whether sparser models focus on more discriminative features similarly to
humans. Our findings also reveal the presence of sweet spots, where sparse
models exhibit higher interpretability, downstream generalization and human
alignment. However, these spots highly depend on the network architectures and
their size in terms of trainable parameters. Our results suggest a complex
interplay between these three dimensions, highlighting the importance of
investigating when and how pruning benefits vision representations.

</details>


### [63] [ECCV 2024 W-CODA: 1st Workshop on Multimodal Perception and Comprehension of Corner Cases in Autonomous Driving](https://arxiv.org/abs/2507.01735)
*Kai Chen,Ruiyuan Gao,Lanqing Hong,Hang Xu,Xu Jia,Holger Caesar,Dengxin Dai,Bingbing Liu,Dzmitry Tsishkou,Songcen Xu,Chunjing Xu,Qiang Xu,Huchuan Lu,Dit-Yan Yeung*

Main category: cs.CV

TL;DR: 介绍了首届W-CODA研讨会的详情，聚焦于自动驾驶极端场景的下一代解决方案。


<details>
  <summary>Details</summary>
Motivation: 探索前沿多模态感知与理解技术，以解决自动驾驶极端场景问题。

Method: 邀请5位学术界和工业界专家分享最新进展，并举办双轨挑战赛（场景理解与生成）。

Result: 收集研究论文并推动前沿自动驾驶技术与可靠智能体的结合。

Conclusion: W-CODA将持续弥合前沿技术与极端场景下可靠自动驾驶之间的差距。

Abstract: In this paper, we present details of the 1st W-CODA workshop, held in
conjunction with the ECCV 2024. W-CODA aims to explore next-generation
solutions for autonomous driving corner cases, empowered by state-of-the-art
multimodal perception and comprehension techniques. 5 Speakers from both
academia and industry are invited to share their latest progress and opinions.
We collect research papers and hold a dual-track challenge, including both
corner case scene understanding and generation. As the pioneering effort, we
will continuously bridge the gap between frontier autonomous driving techniques
and fully intelligent, reliable self-driving agents robust towards corner
cases.

</details>


### [64] [HOI-Dyn: Learning Interaction Dynamics for Human-Object Motion Diffusion](https://arxiv.org/abs/2507.01737)
*Lin Wu,Zhixiang Chen,Jianglin Lan*

Main category: cs.CV

TL;DR: HOI-Dyn提出了一种新框架，将3D人-物交互（HOI）生成建模为驱动-响应系统，通过轻量级Transformer动态模型预测物体对人物动作的响应，并引入残差动力学损失提升一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法将人物和物体运动独立处理，导致物理上不合理且因果不一致的行为，HOI-Dyn旨在解决这一问题。

Method: 采用驱动-响应系统框架，使用Transformer动态模型预测物体响应，并通过残差动力学损失优化训练。

Result: 实验表明，HOI-Dyn提升了HOI生成质量，并提供了可行的交互质量评估指标。

Conclusion: HOI-Dyn通过动态建模和一致性优化，显著改善了3D人-物交互生成的真实性和效率。

Abstract: Generating realistic 3D human-object interactions (HOIs) remains a
challenging task due to the difficulty of modeling detailed interaction
dynamics. Existing methods treat human and object motions independently,
resulting in physically implausible and causally inconsistent behaviors. In
this work, we present HOI-Dyn, a novel framework that formulates HOI generation
as a driver-responder system, where human actions drive object responses. At
the core of our method is a lightweight transformer-based interaction dynamics
model that explicitly predicts how objects should react to human motion. To
further enforce consistency, we introduce a residual-based dynamics loss that
mitigates the impact of dynamics prediction errors and prevents misleading
optimization signals. The dynamics model is used only during training,
preserving inference efficiency. Through extensive qualitative and quantitative
experiments, we demonstrate that our approach not only enhances the quality of
HOI generation but also establishes a feasible metric for evaluating the
quality of generated interactions.

</details>


### [65] [DeRIS: Decoupling Perception and Cognition for Enhanced Referring Image Segmentation through Loopback Synergy](https://arxiv.org/abs/2507.01738)
*Ming Dai,Wenxuan Cheng,Jiang-jiang Liu,Sen Yang,Wenxiao Cai,Yanpeng Sun,Wankou Yang*

Main category: cs.CV

TL;DR: DeRIS框架将Referring Image Segmentation（RIS）分解为感知和认知两个模块，通过Loopback Synergy机制提升多模态认知能力，并引入数据增强解决长尾分布问题。


<details>
  <summary>Details</summary>
Motivation: 现有RIS框架缺乏对性能瓶颈的系统分析，尤其是多模态认知能力的不足。

Method: 提出DeRIS框架，分解RIS为感知和认知模块，引入Loopback Synergy机制和简单数据增强方法。

Result: DeRIS在精确分割和图像-文本理解方面表现优异，且无需修改即可适应多目标场景。

Conclusion: DeRIS通过模块化分析和机制改进，显著提升了RIS任务的性能与泛化能力。

Abstract: Referring Image Segmentation (RIS) is a challenging task that aims to segment
objects in an image based on natural language expressions. While prior studies
have predominantly concentrated on improving vision-language interactions and
achieving fine-grained localization, a systematic analysis of the fundamental
bottlenecks in existing RIS frameworks remains underexplored. To bridge this
gap, we propose DeRIS, a novel framework that decomposes RIS into two key
components: perception and cognition. This modular decomposition facilitates a
systematic analysis of the primary bottlenecks impeding RIS performance. Our
findings reveal that the predominant limitation lies not in perceptual
deficiencies, but in the insufficient multi-modal cognitive capacity of current
models. To mitigate this, we propose a Loopback Synergy mechanism, which
enhances the synergy between the perception and cognition modules, thereby
enabling precise segmentation while simultaneously improving robust image-text
comprehension. Additionally, we analyze and introduce a simple non-referent
sample conversion data augmentation to address the long-tail distribution issue
related to target existence judgement in general scenarios. Notably, DeRIS
demonstrates inherent adaptability to both non- and multi-referents scenarios
without requiring specialized architectural modifications, enhancing its
general applicability. The codes and models are available at
https://github.com/Dmmm1997/DeRIS.

</details>


### [66] [Calibrated Self-supervised Vision Transformers Improve Intracranial Arterial Calcification Segmentation from Clinical CT Head Scans](https://arxiv.org/abs/2507.01744)
*Benjamin Jin,Grant Mair,Joanna M. Wardlaw,Maria del C. Valdés Hernández*

Main category: cs.CV

TL;DR: 本文研究了基于Vision Transformers (ViTs) 和掩码自编码器 (MAE) 的3D医学图像分割方法，首次将其应用于颅内动脉钙化 (IAC) 分割，并在临床数据上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: ViTs在自然图像领域表现优异，但在3D医学图像分割中应用较少。IAC作为神经血管疾病的生物标志物，其自动化量化对大规模风险评估具有重要意义。

Method: 通过MAE框架进行自监督预训练ViTs，并在IST-3临床试验数据上微调用于IAC分割。研究了低patch大小和插值上采样对性能的影响。

Result: 自监督ViT在Dice分数上比监督nnU-Net基线高3.2分；低patch大小和插值上采样效果更佳；ViT对高切片厚度更具鲁棒性，风险分类提升46%。

Conclusion: ViTs结合MAE在IAC分割中表现优异，具有临床实用价值，代码已开源。

Abstract: Vision Transformers (ViTs) have gained significant popularity in the natural
image domain but have been less successful in 3D medical image segmentation.
Nevertheless, 3D ViTs are particularly interesting for large medical imaging
volumes due to their efficient self-supervised training within the masked
autoencoder (MAE) framework, which enables the use of imaging data without the
need for expensive manual annotations. intracranial arterial calcification
(IAC) is an imaging biomarker visible on routinely acquired CT scans linked to
neurovascular diseases such as stroke and dementia, and automated IAC
quantification could enable their large-scale risk assessment. We pre-train
ViTs with MAE and fine-tune them for IAC segmentation for the first time. To
develop our models, we use highly heterogeneous data from a large clinical
trial, the third International Stroke Trial (IST-3). We evaluate key aspects of
MAE pre-trained ViTs in IAC segmentation, and analyse the clinical
implications. We show: 1) our calibrated self-supervised ViT beats a strong
supervised nnU-Net baseline by 3.2 Dice points, 2) low patch sizes are crucial
for ViTs for IAC segmentation and interpolation upsampling with regular
convolutions is preferable to transposed convolutions for ViT-based models, and
3) our ViTs increase robustness to higher slice thicknesses and improve risk
group classification in a clinical scenario by 46%. Our code is available
online.

</details>


### [67] [SSL4SAR: Self-Supervised Learning for Glacier Calving Front Extraction from SAR Imagery](https://arxiv.org/abs/2507.01747)
*Nora Gourmelon,Marcel Dreier,Martin Mayr,Thorsten Seehaus,Dakota Pyles,Matthias Braun,Andreas Maier,Vincent Christlein*

Main category: cs.CV

TL;DR: 论文提出两种自监督多模态预训练技术和一种混合模型架构，用于从SAR图像中提取冰川崩解前沿位置，显著提升了精度。


<details>
  <summary>Details</summary>
Motivation: 冰川冰量流失加剧，需要更精确的全年监测方法以理解崩解过程，现有基于ImageNet预训练的模型因领域差异表现不佳。

Method: 提出两种自监督多模态预训练技术，利用新数据集SSL4SAR，并设计结合Swin Transformer编码器和残差CNN解码器的混合模型。

Result: 模型在CaFFe基准数据集上平均距离误差为293米，优于之前最佳模型67米；集成模型在多标注研究中误差降至75米，接近人类水平（38米）。

Conclusion: 新技术和模型显著提升了冰川崩解前沿监测的精度，为季节性变化研究提供了可靠工具。

Abstract: Glaciers are losing ice mass at unprecedented rates, increasing the need for
accurate, year-round monitoring to understand frontal ablation, particularly
the factors driving the calving process. Deep learning models can extract
calving front positions from Synthetic Aperture Radar imagery to track seasonal
ice losses at the calving fronts of marine- and lake-terminating glaciers. The
current state-of-the-art model relies on ImageNet-pretrained weights. However,
they are suboptimal due to the domain shift between the natural images in
ImageNet and the specialized characteristics of remote sensing imagery, in
particular for Synthetic Aperture Radar imagery. To address this challenge, we
propose two novel self-supervised multimodal pretraining techniques that
leverage SSL4SAR, a new unlabeled dataset comprising 9,563 Sentinel-1 and 14
Sentinel-2 images of Arctic glaciers, with one optical image per glacier in the
dataset. Additionally, we introduce a novel hybrid model architecture that
combines a Swin Transformer encoder with a residual Convolutional Neural
Network (CNN) decoder. When pretrained on SSL4SAR, this model achieves a mean
distance error of 293 m on the "CAlving Fronts and where to Find thEm" (CaFFe)
benchmark dataset, outperforming the prior best model by 67 m. Evaluating an
ensemble of the proposed model on a multi-annotator study of the benchmark
dataset reveals a mean distance error of 75 m, approaching the human
performance of 38 m. This advancement enables precise monitoring of seasonal
changes in glacier calving fronts.

</details>


### [68] [Rethinking Discrete Tokens: Treating Them as Conditions for Continuous Autoregressive Image Synthesis](https://arxiv.org/abs/2507.01756)
*Peng Zheng,Junke Wang,Yi Chang,Yizhou Yu,Rui Ma,Zuxuan Wu*

Main category: cs.CV

TL;DR: DisCon框架通过将离散标记作为条件信号而非生成目标，解决了连续标记建模的优化挑战，同时避免了量化导致的信息损失，显著提升了图像生成质量。


<details>
  <summary>Details</summary>
Motivation: 解决基于自回归框架的视觉生成模型中量化过程导致的信息丢失问题，同时避免连续标记建模的挑战。

Method: 提出DisCon框架，将离散标记作为条件信号，建模连续表示的条件概率。

Result: 在ImageNet 256×256生成任务上，DisCon的gFID得分为1.38，优于现有自回归方法。

Conclusion: DisCon通过结合离散和连续表示的优势，显著提升了图像生成性能。

Abstract: Recent advances in large language models (LLMs) have spurred interests in
encoding images as discrete tokens and leveraging autoregressive (AR)
frameworks for visual generation. However, the quantization process in AR-based
visual generation models inherently introduces information loss that degrades
image fidelity. To mitigate this limitation, recent studies have explored to
autoregressively predict continuous tokens. Unlike discrete tokens that reside
in a structured and bounded space, continuous representations exist in an
unbounded, high-dimensional space, making density estimation more challenging
and increasing the risk of generating out-of-distribution artifacts. Based on
the above findings, this work introduces DisCon (Discrete-Conditioned
Continuous Autoregressive Model), a novel framework that reinterprets discrete
tokens as conditional signals rather than generation targets. By modeling the
conditional probability of continuous representations conditioned on discrete
tokens, DisCon circumvents the optimization challenges of continuous token
modeling while avoiding the information loss caused by quantization. DisCon
achieves a gFID score of 1.38 on ImageNet 256$\times$256 generation,
outperforming state-of-the-art autoregressive approaches by a clear margin.

</details>


### [69] [Are Vision Transformer Representations Semantically Meaningful? A Case Study in Medical Imaging](https://arxiv.org/abs/2507.01788)
*Montasir Shams,Chashi Mahiul Islam,Shaeke Salman,Phat Tran,Xiuwen Liu*

Main category: cs.CV

TL;DR: Vision transformers (ViTs) 在医学影像任务中表现优异，但其语义表示缺乏意义且易受微小变化影响，导致分类结果不可靠。


<details>
  <summary>Details</summary>
Motivation: 研究ViT在医学影像任务中的语义表示是否具有意义，以及其对微小变化的脆弱性。

Method: 使用基于投影梯度的算法分析ViT的表示。

Result: ViT的表示缺乏语义意义，对微小变化敏感，分类准确率可下降60%以上。

Conclusion: ViT在医学影像分类中的语义表示问题揭示了其在安全关键系统中部署的挑战。

Abstract: Vision transformers (ViTs) have rapidly gained prominence in medical imaging
tasks such as disease classification, segmentation, and detection due to their
superior accuracy compared to conventional deep learning models. However, due
to their size and complex interactions via the self-attention mechanism, they
are not well understood. In particular, it is unclear whether the
representations produced by such models are semantically meaningful. In this
paper, using a projected gradient-based algorithm, we show that their
representations are not semantically meaningful and they are inherently
vulnerable to small changes. Images with imperceptible differences can have
very different representations; on the other hand, images that should belong to
different semantic classes can have nearly identical representations. Such
vulnerability can lead to unreliable classification results; for example,
unnoticeable changes cause the classification accuracy to be reduced by over
60\%. %. To the best of our knowledge, this is the first work to systematically
demonstrate this fundamental lack of semantic meaningfulness in ViT
representations for medical image classification, revealing a critical
challenge for their deployment in safety-critical systems.

</details>


### [70] [Boosting Adversarial Transferability Against Defenses via Multi-Scale Transformation](https://arxiv.org/abs/2507.01791)
*Zihong Guo,Chen Wan,Yayin Zheng,Hailing Kuang,Xiaohai Lu*

Main category: cs.CV

TL;DR: 提出了一种新的分段高斯金字塔（SGP）攻击方法，通过多尺度图像增强对抗样本的可迁移性，显著提高了对黑盒防御模型的攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 对抗样本的可迁移性对深度神经网络构成安全挑战，现有方法通常关注单尺度图像，限制了攻击效果。

Method: 采用高斯滤波和三种下采样方法构建多尺度样本，计算各尺度损失函数的梯度并取平均值以确定对抗扰动。

Result: 实验表明，SGP显著提高了对黑盒防御模型的攻击成功率，平均提升2.3%至32.6%。

Conclusion: SGP是一种高扩展性的输入变换方法，易于与现有对抗攻击结合，有效提升攻击效果。

Abstract: The transferability of adversarial examples poses a significant security
challenge for deep neural networks, which can be attacked without knowing
anything about them. In this paper, we propose a new Segmented Gaussian Pyramid
(SGP) attack method to enhance the transferability, particularly against
defense models. Unlike existing methods that generally focus on single-scale
images, our approach employs Gaussian filtering and three types of downsampling
to construct a series of multi-scale examples. Then, the gradients of the loss
function with respect to each scale are computed, and their average is used to
determine the adversarial perturbations. The proposed SGP can be considered an
input transformation with high extensibility that is easily integrated into
most existing adversarial attacks. Extensive experiments demonstrate that in
contrast to the state-of-the-art methods, SGP significantly enhances attack
success rates against black-box defense models, with average attack success
rates increasing by 2.3% to 32.6%, based only on transferability.

</details>


### [71] [FreeLoRA: Enabling Training-Free LoRA Fusion for Autoregressive Multi-Subject Personalization](https://arxiv.org/abs/2507.01792)
*Peng Zheng,Ye Wang,Rui Ma,Zuxuan Wu*

Main category: cs.CV

TL;DR: FreeLoRA提出了一种无需训练的框架，通过融合多个主题特定的LoRA模块实现多主题个性化图像生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多主题个性化生成中需要复杂调整或联合优化，FreeLoRA旨在简化这一过程。

Method: 采用Full Token Tuning策略训练主题特定LoRA模块，并通过Subject-Aware Inference在推理时激活对应模块。

Result: 实验表明FreeLoRA在主题保真度和提示一致性上表现优异。

Conclusion: FreeLoRA是一种简单且通用的多主题个性化生成框架。

Abstract: Subject-driven image generation plays a crucial role in applications such as
virtual try-on and poster design. Existing approaches typically fine-tune
pretrained generative models or apply LoRA-based adaptations for individual
subjects. However, these methods struggle with multi-subject personalization,
as combining independently adapted modules often requires complex re-tuning or
joint optimization. We present FreeLoRA, a simple and generalizable framework
that enables training-free fusion of subject-specific LoRA modules for
multi-subject personalization. Each LoRA module is adapted on a few images of a
specific subject using a Full Token Tuning strategy, where it is applied across
all tokens in the prompt to encourage weakly supervised token-content
alignment. At inference, we adopt Subject-Aware Inference, activating each
module only on its corresponding subject tokens. This enables training-free
fusion of multiple personalized subjects within a single image, while
mitigating overfitting and mutual interference between subjects. Extensive
experiments show that FreeLoRA achieves strong performance in both subject
fidelity and prompt consistency.

</details>


### [72] [HCNQA: Enhancing 3D VQA with Hierarchical Concentration Narrowing Supervision](https://arxiv.org/abs/2507.01800)
*Shengli Zhou,Jianuo Zhu,Qilin Huang,Fangjing Wang,Yanfu Zhang,Feng Zheng*

Main category: cs.CV

TL;DR: HCNQA提出了一种分层监督方法，通过模仿人类逐步聚焦的过程，确保3D VQA模型发展出合理的推理路径。


<details>
  <summary>Details</summary>
Motivation: 现有基于答案监督的3D VQA模型可能因缺乏对推理路径的监督而产生浅层捷径，且慢思考方法存在欠思考问题。

Method: 采用分层浓度窄化监督方法，通过三个阶段逐步聚焦，监督关键检查点以确保推理路径的合理性。

Result: 实验表明，该方法能有效确保模型发展出合理的推理路径并表现更优。

Conclusion: HCNQA通过分层监督解决了现有方法的不足，提升了3D VQA任务的性能。

Abstract: 3D Visual Question-Answering (3D VQA) is pivotal for models to perceive the
physical world and perform spatial reasoning. Answer-centric supervision is a
commonly used training method for 3D VQA models. Many models that utilize this
strategy have achieved promising results in 3D VQA tasks. However, the
answer-centric approach only supervises the final output of models and allows
models to develop reasoning pathways freely. The absence of supervision on the
reasoning pathway enables the potential for developing superficial shortcuts
through common patterns in question-answer pairs. Moreover, although
slow-thinking methods advance large language models, they suffer from
underthinking. To address these issues, we propose \textbf{HCNQA}, a 3D VQA
model leveraging a hierarchical concentration narrowing supervision method. By
mimicking the human process of gradually focusing from a broad area to specific
objects while searching for answers, our method guides the model to perform
three phases of concentration narrowing through hierarchical supervision. By
supervising key checkpoints on a general reasoning pathway, our method can
ensure the development of a rational and effective reasoning pathway. Extensive
experimental results demonstrate that our method can effectively ensure that
the model develops a rational reasoning pathway and performs better. The code
is available at https://github.com/JianuoZhu/HCNQA.

</details>


### [73] [AMD: Adaptive Momentum and Decoupled Contrastive Learning Framework for Robust Long-Tail Trajectory Prediction](https://arxiv.org/abs/2507.01801)
*Bin Rao,Haicheng Liao,Yanchen Guan,Chengyue Wang,Bonan Wang,Jiaxun Zhang,Zhenning Li*

Main category: cs.CV

TL;DR: 提出了一种自适应动量和解耦对比学习框架（AMD），用于提升自动驾驶中长尾轨迹预测的准确性和多样性。


<details>
  <summary>Details</summary>
Motivation: 解决现有研究在长尾轨迹预测中忽视多样性和不确定性的问题，特别是在复杂和危险场景中的表现。

Method: 结合改进的动量对比学习（MoCo-DT）和解耦对比学习（DCL），设计了四种轨迹随机增强方法和在线迭代聚类策略。

Result: 在nuScenes和ETH/UCY数据集上，AMD在长尾轨迹预测和整体准确性上均表现最优。

Conclusion: AMD框架有效提升了模型对长尾轨迹的识别能力，同时保持了高预测精度。

Abstract: Accurately predicting the future trajectories of traffic agents is essential
in autonomous driving. However, due to the inherent imbalance in trajectory
distributions, tail data in natural datasets often represents more complex and
hazardous scenarios. Existing studies typically rely solely on a base model's
prediction error, without considering the diversity and uncertainty of
long-tail trajectory patterns. We propose an adaptive momentum and decoupled
contrastive learning framework (AMD), which integrates unsupervised and
supervised contrastive learning strategies. By leveraging an improved momentum
contrast learning (MoCo-DT) and decoupled contrastive learning (DCL) module,
our framework enhances the model's ability to recognize rare and complex
trajectories. Additionally, we design four types of trajectory random
augmentation methods and introduce an online iterative clustering strategy,
allowing the model to dynamically update pseudo-labels and better adapt to the
distributional shifts in long-tail data. We propose three different criteria to
define long-tail trajectories and conduct extensive comparative experiments on
the nuScenes and ETH$/$UCY datasets. The results show that AMD not only
achieves optimal performance in long-tail trajectory prediction but also
demonstrates outstanding overall prediction accuracy.

</details>


### [74] [Modulate and Reconstruct: Learning Hyperspectral Imaging from Misaligned Smartphone Views](https://arxiv.org/abs/2507.01835)
*Daniil Reutsky,Daniil Vladimirov,Yasin Mamedov,Georgy Perevozchikov,Nancy Mehta,Egor Ershov,Radu Timofte*

Main category: cs.CV

TL;DR: 提出了一种基于多图像的超光谱重建（MI-HSR）框架，利用配备光谱滤镜的三摄像头智能手机系统，显著提升了重建精度。


<details>
  <summary>Details</summary>
Motivation: 传统单RGB图像方法因光谱信息丢失严重，重建精度受限，需探索多图像方法以提升性能。

Method: 采用三摄像头智能手机系统，其中两个镜头配备精选光谱滤镜，结合理论与实证分析，构建了首个MI-HSR数据集Doomer。

Result: 新方法在基准测试中表现优于现有技术，光谱估计精度提升了30%。

Conclusion: 多视角光谱滤镜结合消费级硬件，可提供更准确、实用的超光谱成像解决方案。

Abstract: Hyperspectral reconstruction (HSR) from RGB images is a fundamentally
ill-posed problem due to severe spectral information loss. Existing approaches
typically rely on a single RGB image, limiting reconstruction accuracy. In this
work, we propose a novel multi-image-to-hyperspectral reconstruction (MI-HSR)
framework that leverages a triple-camera smartphone system, where two lenses
are equipped with carefully selected spectral filters. Our configuration,
grounded in theoretical and empirical analysis, enables richer and more diverse
spectral observations than conventional single-camera setups. To support this
new paradigm, we introduce Doomer, the first dataset for MI-HSR, comprising
aligned images from three smartphone cameras and a hyperspectral reference
camera across diverse scenes. We show that the proposed HSR model achieves
consistent improvements over existing methods on the newly proposed benchmark.
In a nutshell, our setup allows 30% towards more accurately estimated spectra
compared to an ordinary RGB camera. Our findings suggest that multi-view
spectral filtering with commodity hardware can unlock more accurate and
practical hyperspectral imaging solutions.

</details>


### [75] [MobileIE: An Extremely Lightweight and Effective ConvNet for Real-Time Image Enhancement on Mobile Devices](https://arxiv.org/abs/2507.01838)
*Hailong Yan,Ao Li,Xiangtao Zhang,Zhe Liu,Zenglin Shi,Ce Zhu,Le Zhang*

Main category: cs.CV

TL;DR: 提出了一种超轻量级CNN框架，用于移动设备上的实时图像增强，仅需约4K参数，首次实现1100 FPS的实时推理。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习模型在资源受限平台上部署的高计算和内存需求问题。

Method: 结合重参数化和增量权重优化策略，引入特征自变换模块和分层双路径注意力机制，并使用局部方差加权损失优化。

Result: 在多个图像增强任务中实现了速度和性能的最佳平衡，达到1100 FPS的实时推理。

Conclusion: 该框架为移动设备上的实时图像增强提供了高效解决方案，代码已开源。

Abstract: Recent advancements in deep neural networks have driven significant progress
in image enhancement (IE). However, deploying deep learning models on
resource-constrained platforms, such as mobile devices, remains challenging due
to high computation and memory demands. To address these challenges and
facilitate real-time IE on mobile, we introduce an extremely lightweight
Convolutional Neural Network (CNN) framework with around 4K parameters. Our
approach integrates reparameterization with an Incremental Weight Optimization
strategy to ensure efficiency. Additionally, we enhance performance with a
Feature Self-Transform module and a Hierarchical Dual-Path Attention mechanism,
optimized with a Local Variance-Weighted loss. With this efficient framework,
we are the first to achieve real-time IE inference at up to 1,100 frames per
second (FPS) while delivering competitive image quality, achieving the best
trade-off between speed and performance across multiple IE tasks. The code will
be available at https://github.com/AVC2-UESTC/MobileIE.git.

</details>


### [76] [Future Slot Prediction for Unsupervised Object Discovery in Surgical Video](https://arxiv.org/abs/2507.01882)
*Guiqiu Liao,Matjaz Jogan,Marcel Hussing,Edward Zhang,Eric Eaton,Daniel A. Hashimoto*

Main category: cs.CV

TL;DR: 提出动态时序槽变换器（DTST）模块，用于解决手术视频中对象中心表示学习的挑战，并在多个手术数据库中实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界应用（如手术）中的异构场景难以解析为有意义的一组槽，现有方法在手术视频上性能较低。

Method: 提出动态时序槽变换器（DTST）模块，结合时序推理和预测未来最优槽初始化。

Result: 在多个手术数据库中实现最先进性能。

Conclusion: 无监督对象中心方法可应用于现实世界数据，成为医疗应用中的常见工具。

Abstract: Object-centric slot attention is an emerging paradigm for unsupervised
learning of structured, interpretable object-centric representations (slots).
This enables effective reasoning about objects and events at a low
computational cost and is thus applicable to critical healthcare applications,
such as real-time interpretation of surgical video. The heterogeneous scenes in
real-world applications like surgery are, however, difficult to parse into a
meaningful set of slots. Current approaches with an adaptive slot count perform
well on images, but their performance on surgical videos is low. To address
this challenge, we propose a dynamic temporal slot transformer (DTST) module
that is trained both for temporal reasoning and for predicting the optimal
future slot initialization. The model achieves state-of-the-art performance on
multiple surgical databases, demonstrating that unsupervised object-centric
methods can be applied to real-world data and become part of the common arsenal
in healthcare applications.

</details>


### [77] [Self-Reinforcing Prototype Evolution with Dual-Knowledge Cooperation for Semi-Supervised Lifelong Person Re-Identification](https://arxiv.org/abs/2507.01884)
*Kunlun Xu,Fan Zhuo,Jiangmeng Li,Xu Zou,Jiahuan Zhou*

Main category: cs.CV

TL;DR: 该论文提出了SPRED框架，通过动态原型引导的伪标签生成和新旧知识协同净化，解决了半监督终身行人重识别（Semi-LReID）问题。


<details>
  <summary>Details</summary>
Motivation: 现实场景中标注资源有限，现有方法在利用未标注数据时性能下降严重，需要解决噪声知识问题。

Method: 引入可学习的身份原型动态捕捉身份分布，生成高质量伪标签；通过双知识协作方案净化噪声伪标签。

Result: 在Semi-LReID基准测试中达到最先进性能。

Conclusion: SPRED框架通过自增强循环设计，有效提升了未标注数据的利用率和长期学习性能。

Abstract: Current lifelong person re-identification (LReID) methods predominantly rely
on fully labeled data streams. However, in real-world scenarios where
annotation resources are limited, a vast amount of unlabeled data coexists with
scarce labeled samples, leading to the Semi-Supervised LReID (Semi-LReID)
problem where LReID methods suffer severe performance degradation. Existing
LReID methods, even when combined with semi-supervised strategies, suffer from
limited long-term adaptation performance due to struggling with the noisy
knowledge occurring during unlabeled data utilization. In this paper, we
pioneer the investigation of Semi-LReID, introducing a novel Self-Reinforcing
Prototype Evolution with Dual-Knowledge Cooperation framework (SPRED). Our key
innovation lies in establishing a self-reinforcing cycle between dynamic
prototype-guided pseudo-label generation and new-old knowledge collaborative
purification to enhance the utilization of unlabeled data. Specifically,
learnable identity prototypes are introduced to dynamically capture the
identity distributions and generate high-quality pseudo-labels. Then, the
dual-knowledge cooperation scheme integrates current model specialization and
historical model generalization, refining noisy pseudo-labels. Through this
cyclic design, reliable pseudo-labels are progressively mined to improve
current-stage learning and ensure positive knowledge propagation over long-term
learning. Experiments on the established Semi-LReID benchmarks show that our
SPRED achieves state-of-the-art performance. Our source code is available at
https://github.com/zhoujiahuan1991/ICCV2025-SPRED

</details>


### [78] [Reasoning to Edit: Hypothetical Instruction-Based Image Editing with Visual Reasoning](https://arxiv.org/abs/2507.01908)
*Qingdong He,Xueqin Chen,Chaoyi Wang,Yanjie Pan,Xiaobin Hu,Zhenye Gan,Yabiao Wang,Chengjie Wang,Xiangtai Li,Jiangning Zhang*

Main category: cs.CV

TL;DR: 论文提出了Reason50K数据集和ReasonBrain框架，用于处理复杂的假设性指令图像编辑任务，通过细粒度推理和多模态交互提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以处理复杂的隐式假设性指令，且缺乏支持推理的数据集和架构。

Method: 提出Reason50K数据集和ReasonBrain框架，结合MLLM和扩散模型，引入FRCE和CME模块。

Result: ReasonBrain在推理场景中表现优异，并具有零样本泛化能力。

Conclusion: Reason50K和ReasonBrain为复杂指令编辑提供了有效解决方案，数据集和代码将公开。

Abstract: Instruction-based image editing (IIE) has advanced rapidly with the success
of diffusion models. However, existing efforts primarily focus on simple and
explicit instructions to execute editing operations such as adding, deleting,
moving, or swapping objects. They struggle to handle more complex implicit
hypothetical instructions that require deeper reasoning to infer plausible
visual changes and user intent. Additionally, current datasets provide limited
support for training and evaluating reasoning-aware editing capabilities.
Architecturally, these methods also lack mechanisms for fine-grained detail
extraction that support such reasoning. To address these limitations, we
propose Reason50K, a large-scale dataset specifically curated for training and
evaluating hypothetical instruction reasoning image editing, along with
ReasonBrain, a novel framework designed to reason over and execute implicit
hypothetical instructions across diverse scenarios. Reason50K includes over 50K
samples spanning four key reasoning scenarios: Physical, Temporal, Causal, and
Story reasoning. ReasonBrain leverages Multimodal Large Language Models (MLLMs)
for editing guidance generation and a diffusion model for image synthesis,
incorporating a Fine-grained Reasoning Cue Extraction (FRCE) module to capture
detailed visual and textual semantics essential for supporting instruction
reasoning. To mitigate the semantic loss, we further introduce a Cross-Modal
Enhancer (CME) that enables rich interactions between the fine-grained cues and
MLLM-derived features. Extensive experiments demonstrate that ReasonBrain
consistently outperforms state-of-the-art baselines on reasoning scenarios
while exhibiting strong zero-shot generalization to conventional IIE tasks. Our
dataset and code will be released publicly.

</details>


### [79] [Modality Agnostic, patient-specific digital twins modeling temporally varying digestive motion](https://arxiv.org/abs/2507.01909)
*Jorge Tapias Gomez,Nishant Nadkarni,Lando S. Bosma,Jue Jiang,Ergys D. Subashi,William P. Segars,James M. Balter,Mert R Sabuncu,Neelam Tyagi,Harini Veeraraghavan*

Main category: cs.CV

TL;DR: 提出了一种基于患者特异性数字孪生（DT）的管道，用于评估可变形图像配准（DIR）方法在胃肠道（GI）器官运动中的准确性。


<details>
  <summary>Details</summary>
Motivation: 临床实施DIR需要基于体素的空间精度指标，但对于高度移动的GI器官，手动识别标志物具有挑战性。

Method: 通过半自动化管道，从静态3D患者扫描生成21个运动阶段的4D序列，模拟GI运动，并评估六种DIR方法的性能。

Result: 生成的DT模拟了真实的GI运动，运动幅度与真实患者数据相似，并提供了详细的DIR性能指标和剂量映射验证。

Conclusion: 该管道能够严格测试DIR工具在动态复杂区域的性能，实现空间和剂量学的精确评估。

Abstract: Objective: Clinical implementation of deformable image registration (DIR)
requires voxel-based spatial accuracy metrics such as manually identified
landmarks, which are challenging to implement for highly mobile
gastrointestinal (GI) organs. To address this, patient-specific digital twins
(DT) modeling temporally varying motion were created to assess the accuracy of
DIR methods. Approach: 21 motion phases simulating digestive GI motion as 4D
sequences were generated from static 3D patient scans using published
analytical GI motion models through a semi-automated pipeline. Eleven datasets,
including six T2w FSE MRI (T2w MRI), two T1w 4D golden-angle stack-of-stars,
and three contrast-enhanced CT scans. The motion amplitudes of the DTs were
assessed against real patient stomach motion amplitudes extracted from
independent 4D MRI datasets. The generated DTs were then used to assess six
different DIR methods using target registration error, Dice similarity
coefficient, and the 95th percentile Hausdorff distance using summary metrics
and voxel-level granular visualizations. Finally, for a subset of T2w MRI scans
from patients treated with MR-guided radiation therapy, dose distributions were
warped and accumulated to assess dose warping errors, including evaluations of
DIR performance in both low- and high-dose regions for patient-specific error
estimation. Main results: Our proposed pipeline synthesized DTs modeling
realistic GI motion, achieving mean and maximum motion amplitudes and a mean
log Jacobian determinant within 0.8 mm and 0.01, respectively, similar to
published real-patient gastric motion data. It also enables the extraction of
detailed quantitative DIR performance metrics and rigorous validation of dose
mapping accuracy. Significance: The pipeline enables rigorously testing DIR
tools for dynamic, anatomically complex regions enabling granular spatial and
dosimetric accuracies.

</details>


### [80] [3D Reconstruction and Information Fusion between Dormant and Canopy Seasons in Commercial Orchards Using Deep Learning and Fast GICP](https://arxiv.org/abs/2507.01912)
*Ranjan Sapkota,Zhichao Meng,Martin Churuvija,Xiaoqiang Du,Zenghong Ma,Manoj Karkee*

Main category: cs.CV

TL;DR: 提出了一种多季节信息融合框架，结合休眠期和生长期的RGB-D图像，通过实例分割、3D重建和模型对齐，提升果园自动化管理的精度。


<details>
  <summary>Details</summary>
Motivation: 果园生长期茂密的树冠严重遮挡树干和树枝结构，限制了机器视觉系统的能力，而休眠期树冠结构更开放可见。

Method: 使用YOLOv9-Seg进行实例分割，Kinect Fusion进行3D重建，Fast GICP进行模型对齐，融合多季节数据。

Result: YOLOv9-Seg在休眠期数据集上MSE为0.0047，mAP@50达0.78；Kinect Fusion重建误差小（树干直径RMSE 5.23 mm）；Fast GICP配准精度高（最小适应分数0.00197）。

Conclusion: 多季节融合框架显著提升了机器人系统对树冠结构的建模能力，改善了修剪和疏果等自动化操作的精度。

Abstract: In orchard automation, dense foliage during the canopy season severely
occludes tree structures, minimizing visibility to various canopy parts such as
trunks and branches, which limits the ability of a machine vision system.
However, canopy structure is more open and visible during the dormant season
when trees are defoliated. In this work, we present an information fusion
framework that integrates multi-seasonal structural data to support robotic and
automated crop load management during the entire growing season. The framework
combines high-resolution RGB-D imagery from both dormant and canopy periods
using YOLOv9-Seg for instance segmentation, Kinect Fusion for 3D
reconstruction, and Fast Generalized Iterative Closest Point (Fast GICP) for
model alignment. Segmentation outputs from YOLOv9-Seg were used to extract
depth-informed masks, which enabled accurate 3D point cloud reconstruction via
Kinect Fusion; these reconstructed models from each season were subsequently
aligned using Fast GICP to achieve spatially coherent multi-season fusion. The
YOLOv9-Seg model, trained on manually annotated images, achieved a mean squared
error (MSE) of 0.0047 and segmentation mAP@50 scores up to 0.78 for trunks in
dormant season dataset. Kinect Fusion enabled accurate reconstruction of tree
geometry, validated with field measurements resulting in root mean square
errors (RMSE) of 5.23 mm for trunk diameter, 4.50 mm for branch diameter, and
13.72 mm for branch spacing. Fast GICP achieved precise cross-seasonal
registration with a minimum fitness score of 0.00197, allowing integrated,
comprehensive tree structure modeling despite heavy occlusions during the
growing season. This fused structural representation enables robotic systems to
access otherwise obscured architectural information, improving the precision of
pruning, thinning, and other automated orchard operations.

</details>


### [81] [IC-Custom: Diverse Image Customization via In-Context Learning](https://arxiv.org/abs/2507.01926)
*Yaowei Li,Xiaoyu Li,Zhaoyang Zhang,Yuxuan Bian,Gan Liu,Xinyuan Li,Jiale Xu,Wenbo Hu,Yating Liu,Lingen Li,Jing Cai,Yuexian Zou,Yancheng He,Ying Shan*

Main category: cs.CV

TL;DR: IC-Custom是一个统一的图像定制框架，通过上下文学习整合位置感知和无位置定制，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有图像定制方法缺乏通用框架的问题，提升多样场景下的应用能力。

Method: 提出IC-Custom框架，结合多模态注意力机制和任务导向的注册令牌，利用高质量数据集进行训练。

Result: 在身份一致性、和谐性和文本对齐等指标上，IC-Custom比现有方法高出73%，且仅训练0.4%的参数量。

Conclusion: IC-Custom为工业应用提供了高效、通用的图像定制解决方案。

Abstract: Image customization, a crucial technique for industrial media production,
aims to generate content that is consistent with reference images. However,
current approaches conventionally separate image customization into
position-aware and position-free customization paradigms and lack a universal
framework for diverse customization, limiting their applications across various
scenarios. To overcome these limitations, we propose IC-Custom, a unified
framework that seamlessly integrates position-aware and position-free image
customization through in-context learning. IC-Custom concatenates reference
images with target images to a polyptych, leveraging DiT's multi-modal
attention mechanism for fine-grained token-level interactions. We introduce the
In-context Multi-Modal Attention (ICMA) mechanism with learnable task-oriented
register tokens and boundary-aware positional embeddings to enable the model to
correctly handle different task types and distinguish various inputs in
polyptych configurations. To bridge the data gap, we carefully curated a
high-quality dataset of 12k identity-consistent samples with 8k from real-world
sources and 4k from high-quality synthetic data, avoiding the overly glossy and
over-saturated synthetic appearance. IC-Custom supports various industrial
applications, including try-on, accessory placement, furniture arrangement, and
creative IP customization. Extensive evaluations on our proposed ProductBench
and the publicly available DreamBench demonstrate that IC-Custom significantly
outperforms community workflows, closed-source models, and state-of-the-art
open-source approaches. IC-Custom achieves approximately 73% higher human
preference across identity consistency, harmonicity, and text alignment
metrics, while training only 0.4% of the original model parameters. Project
page: https://liyaowei-stu.github.io/project/IC_Custom

</details>


### [82] [evMLP: An Efficient Event-Driven MLP Architecture for Vision](https://arxiv.org/abs/2507.01927)
*Zhentan Zheng*

Main category: cs.CV

TL;DR: 本文提出了一种名为evMLP的新方法，通过事件驱动的局部更新机制，选择性处理图像或特征图中的变化区域，显著提升了计算效率。


<details>
  <summary>Details</summary>
Motivation: 探索多层感知机（MLPs）在视觉任务中的应用，并解决传统方法在处理序列图像数据（如视频）时的冗余计算问题。

Method: 提出evMLP，结合事件驱动机制，仅处理连续帧间发生变化的区域（定义为“事件”），避免冗余计算。

Result: 在ImageNet分类任务中表现优异，同时在视频数据集上显著降低计算成本，保持与基线模型一致的输出。

Conclusion: evMLP通过事件驱动机制高效处理视觉任务，为MLP在视觉模型中的应用提供了新思路。

Abstract: Deep neural networks have achieved remarkable results in computer vision
tasks. In the early days, Convolutional Neural Networks (CNNs) were the
mainstream architecture. In recent years, Vision Transformers (ViTs) have
become increasingly popular. In addition, exploring applications of multi-layer
perceptrons (MLPs) has provided new perspectives for research into vision model
architectures. In this paper, we present evMLP accompanied by a simple
event-driven local update mechanism. The proposed evMLP can independently
process patches on images or feature maps via MLPs. We define changes between
consecutive frames as "events". Under the event-driven local update mechanism,
evMLP selectively processes patches where events occur. For sequential image
data (e.g., video processing), this approach improves computational performance
by avoiding redundant computations. Through ImageNet image classification
experiments, evMLP attains accuracy competitive with state-of-the-art models.
More significantly, experimental results on multiple video datasets demonstrate
that evMLP reduces computational cost via its event-driven local update
mechanism while maintaining output consistency with its non-event-driven
baseline. The code and trained models are available at
https://github.com/i-evi/evMLP.

</details>


### [83] [CI-VID: A Coherent Interleaved Text-Video Dataset](https://arxiv.org/abs/2507.01938)
*Yiming Ju,Jijin Hu,Zhengxiong Luo,Haoge Deng,hanyu Zhao,Li Du,Chengwei Wu,Donglin Hao,Xinlong Wang,Tengfei Pan*

Main category: cs.CV

TL;DR: 论文介绍了CI-VID数据集，用于支持连贯多场景视频序列的生成，超越了现有的孤立文本-视频对数据集。


<details>
  <summary>Details</summary>
Motivation: 现有公开数据集主要为孤立的文本-视频对，无法支持连贯多场景视频序列的建模。

Method: 提出CI-VID数据集，包含34万样本，每个样本为连贯的视频片段序列，附带文本描述。设计了多维基准验证其有效性。

Result: 实验表明，基于CI-VID训练的模型在生成视频序列时，准确性和内容一致性显著提升。

Conclusion: CI-VID数据集支持生成具有视觉连贯性和时间一致性的故事驱动内容，具有高质量和实用价值。

Abstract: Text-to-video (T2V) generation has recently attracted considerable attention,
resulting in the development of numerous high-quality datasets that have
propelled progress in this area. However, existing public datasets are
primarily composed of isolated text-video (T-V) pairs and thus fail to support
the modeling of coherent multi-clip video sequences. To address this
limitation, we introduce CI-VID, a dataset that moves beyond isolated
text-to-video (T2V) generation toward text-and-video-to-video (TV2V)
generation, enabling models to produce coherent, multi-scene video sequences.
CI-VID contains over 340,000 samples, each featuring a coherent sequence of
video clips with text captions that capture both the individual content of each
clip and the transitions between them, enabling visually and textually grounded
generation. To further validate the effectiveness of CI-VID, we design a
comprehensive, multi-dimensional benchmark incorporating human evaluation,
VLM-based assessment, and similarity-based metrics. Experimental results
demonstrate that models trained on CI-VID exhibit significant improvements in
both accuracy and content consistency when generating video sequences. This
facilitates the creation of story-driven content with smooth visual transitions
and strong temporal coherence, underscoring the quality and practical utility
of the CI-VID dataset We release the CI-VID dataset and the accompanying code
for data construction and evaluation at: https://github.com/ymju-BAAI/CI-VID

</details>


### [84] [LongAnimation: Long Animation Generation with Dynamic Global-Local Memory](https://arxiv.org/abs/2507.01945)
*Nan Chen,Mengqi Huang,Yihao Meng,Zhendong Mao*

Main category: cs.CV

TL;DR: 提出了一种动态全局-局部范式框架LongAnimation，用于解决长动画着色中的颜色一致性问题，结合SketchDiT、DGLM模块和颜色一致性奖励。


<details>
  <summary>Details</summary>
Motivation: 长动画着色在动画产业中成本高昂，现有研究局限于短时着色且忽视全局信息，无法保持长期颜色一致性。

Method: 提出LongAnimation框架，包含SketchDiT、DGLM模块和颜色一致性奖励，动态提取全局特征并与局部特征融合。

Result: 实验表明，LongAnimation在短时（14帧）和长时（平均500帧）动画着色任务中均能有效保持颜色一致性。

Conclusion: 动态全局-局部范式能显著提升长动画着色的颜色一致性，具有实际应用价值。

Abstract: Animation colorization is a crucial part of real animation industry
production. Long animation colorization has high labor costs. Therefore,
automated long animation colorization based on the video generation model has
significant research value. Existing studies are limited to short-term
colorization. These studies adopt a local paradigm, fusing overlapping features
to achieve smooth transitions between local segments. However, the local
paradigm neglects global information, failing to maintain long-term color
consistency. In this study, we argue that ideal long-term color consistency can
be achieved through a dynamic global-local paradigm, i.e., dynamically
extracting global color-consistent features relevant to the current generation.
Specifically, we propose LongAnimation, a novel framework, which mainly
includes a SketchDiT, a Dynamic Global-Local Memory (DGLM), and a Color
Consistency Reward. The SketchDiT captures hybrid reference features to support
the DGLM module. The DGLM module employs a long video understanding model to
dynamically compress global historical features and adaptively fuse them with
the current generation features. To refine the color consistency, we introduce
a Color Consistency Reward. During inference, we propose a color consistency
fusion to smooth the video segment transition. Extensive experiments on both
short-term (14 frames) and long-term (average 500 frames) animations show the
effectiveness of LongAnimation in maintaining short-term and long-term color
consistency for open-domain animation colorization task. The code can be found
at https://cn-makers.github.io/long_animation_web/.

</details>


### [85] [Kwai Keye-VL Technical Report](https://arxiv.org/abs/2507.01949)
*Kwai Keye Team,Biao Yang,Bin Wen,Changyi Liu,Chenglong Chu,Chengru Song,Chongling Rao,Chuan Yi,Da Li,Dunju Zang,Fan Yang,Guorui Zhou,Hao Peng,Haojie Ding,Jiaming Huang,Jiangxia Cao,Jiankang Chen,Jingyun Hua,Jin Ouyang,Kaibing Chen,Kaiyu Jiang,Kaiyu Tang,Kun Gai,Shengnan Zhang,Siyang Mao,Sui Huang,Tianke Zhang,Tingting Gao,Wei Chen,Wei Yuan,Xiangyu Wu,Xiao Hu,Xingyu Lu,Yang Zhou,Yi-Fan Zhang,Yiping Yang,Yulong Chen,Zhenhua Wu,Zhenyu Li,Zhixin Ling,Ziming Li,Dehua Ma,Di Xu,Haixuan Gao,Hang Li,Jiawei Guo,Jing Wang,Lejian Ren,Muhao Wei,Qianqian Wang,Qigen Hu,Shiyao Wang,Tao Yu,Xinchen Luo,Yan Li,Yiming Liang,Yuhang Hu,Zeyi Lu,Zhuoran Yang,Zixing Zhang*

Main category: cs.CV

TL;DR: Kwai Keye-VL是一个80亿参数的多模态基础模型，专为短视频理解设计，同时保持通用视觉语言能力。通过大规模数据集和创新的训练方法，该模型在视频和图像任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在静态图像上表现优秀，但在动态、信息密集的短视频理解上不足。Kwai Keye-VL旨在填补这一空白。

Method: 模型开发基于6000亿标记的高质量数据集和创新的四阶段预训练与两阶段后训练方法，包括五种模式的数据混合和强化学习。

Result: Keye-VL在公共视频基准测试中达到领先水平，并在通用图像任务中保持竞争力。

Conclusion: Kwai Keye-VL通过创新的数据和方法设计，显著提升了短视频理解能力，并发布了新的评测基准KC-MMBench。

Abstract: While Multimodal Large Language Models (MLLMs) demonstrate remarkable
capabilities on static images, they often fall short in comprehending dynamic,
information-dense short-form videos, a dominant medium in today's digital
landscape. To bridge this gap, we introduce \textbf{Kwai Keye-VL}, an
8-billion-parameter multimodal foundation model engineered for leading-edge
performance in short-video understanding while maintaining robust
general-purpose vision-language abilities. The development of Keye-VL rests on
two core pillars: a massive, high-quality dataset exceeding 600 billion tokens
with a strong emphasis on video, and an innovative training recipe. This recipe
features a four-stage pre-training process for solid vision-language alignment,
followed by a meticulous two-phase post-training process. The first
post-training stage enhances foundational capabilities like instruction
following, while the second phase focuses on stimulating advanced reasoning. In
this second phase, a key innovation is our five-mode ``cold-start'' data
mixture, which includes ``thinking'', ``non-thinking'', ``auto-think'', ``think
with image'', and high-quality video data. This mixture teaches the model to
decide when and how to reason. Subsequent reinforcement learning (RL) and
alignment steps further enhance these reasoning capabilities and correct
abnormal model behaviors, such as repetitive outputs. To validate our approach,
we conduct extensive evaluations, showing that Keye-VL achieves
state-of-the-art results on public video benchmarks and remains highly
competitive on general image-based tasks (Figure 1). Furthermore, we develop
and release the \textbf{KC-MMBench}, a new benchmark tailored for real-world
short-video scenarios, where Keye-VL shows a significant advantage.

</details>


### [86] [FreeMorph: Tuning-Free Generalized Image Morphing with Diffusion Model](https://arxiv.org/abs/2507.01953)
*Yukang Cao,Chenyang Si,Jinghao Wang,Ziwei Liu*

Main category: cs.CV

TL;DR: FreeMorph是一种无需调优的图像变形方法，适用于不同语义或布局的输入，通过创新设计解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖预训练扩散模型的微调，受限于时间和语义/布局差异，FreeMorph旨在无需实例训练实现高质量图像变形。

Method: 1) 提出基于引导的球面插值设计，修改自注意力模块；2) 引入步骤导向的变化趋势，混合输入图像的自注意力模块。

Result: FreeMorph比现有方法快10~50倍，在图像变形领域达到新SOTA。

Conclusion: FreeMorph通过创新设计解决了调优方法的局限性，实现了高效高质量的图像变形。

Abstract: We present FreeMorph, the first tuning-free method for image morphing that
accommodates inputs with different semantics or layouts. Unlike existing
methods that rely on finetuning pre-trained diffusion models and are limited by
time constraints and semantic/layout discrepancies, FreeMorph delivers
high-fidelity image morphing without requiring per-instance training. Despite
their efficiency and potential, tuning-free methods face challenges in
maintaining high-quality results due to the non-linear nature of the multi-step
denoising process and biases inherited from the pre-trained diffusion model. In
this paper, we introduce FreeMorph to address these challenges by integrating
two key innovations. 1) We first propose a guidance-aware spherical
interpolation design that incorporates explicit guidance from the input images
by modifying the self-attention modules, thereby addressing identity loss and
ensuring directional transitions throughout the generated sequence. 2) We
further introduce a step-oriented variation trend that blends self-attention
modules derived from each input image to achieve controlled and consistent
transitions that respect both inputs. Our extensive evaluations demonstrate
that FreeMorph outperforms existing methods, being 10x ~ 50x faster and
establishing a new state-of-the-art for image morphing.

</details>


### [87] [How Well Does GPT-4o Understand Vision? Evaluating Multimodal Foundation Models on Standard Computer Vision Tasks](https://arxiv.org/abs/2507.01955)
*Rahul Ramachandran,Ali Garjani,Roman Bachmann,Andrei Atanov,Oğuzhan Fatih Kar,Amir Zamir*

Main category: cs.CV

TL;DR: 论文评估了多模态基础模型在标准计算机视觉任务上的表现，发现它们虽不及专业模型，但作为通用模型表现尚可，且在语义任务上优于几何任务。


<details>
  <summary>Details</summary>
Motivation: 了解多模态基础模型在视觉理解方面的实际能力，并解决其原生输出限制和API访问问题。

Method: 通过提示链将标准视觉任务转化为文本可提示和API兼容的任务，建立标准化评估框架。

Result: 模型在语义任务上表现较好，几何任务较差；GPT-4o在非推理模型中表现最佳；提示链技术影响性能，但更好的模型对提示变化不敏感。

Conclusion: 多模态基础模型在视觉任务中表现尚可，但仍需改进，尤其是在几何任务和减少幻觉方面。

Abstract: Multimodal foundation models, such as GPT-4o, have recently made remarkable
progress, but it is not clear where exactly these models stand in terms of
understanding vision. In this paper, we benchmark the performance of popular
multimodal foundation models (GPT-4o, o4-mini, Gemini 1.5 Pro and Gemini 2.0
Flash, Claude 3.5 Sonnet, Qwen2-VL, Llama 3.2) on standard computer vision
tasks (semantic segmentation, object detection, image classification, depth and
surface normal prediction) using established datasets (e.g., COCO, ImageNet and
its variants, etc).
  The main challenges to performing this are: 1) most models are trained to
output text and cannot natively express versatile domains, such as segments or
3D geometry, and 2) many leading models are proprietary and accessible only at
an API level, i.e., there is no weight access to adapt them. We address these
challenges by translating standard vision tasks into equivalent text-promptable
and API-compatible tasks via prompt chaining to create a standardized
benchmarking framework.
  We observe that 1) the models are not close to the state-of-the-art
specialist models at any task. However, 2) they are respectable generalists;
this is remarkable as they are presumably trained on primarily image-text-based
tasks. 3) They perform semantic tasks notably better than geometric ones. 4)
While the prompt-chaining techniques affect performance, better models exhibit
less sensitivity to prompt variations. 5) GPT-4o performs the best among
non-reasoning models, securing the top position in 4 out of 6 tasks, 6)
reasoning models, e.g. o3, show improvements in geometric tasks, and 7) a
preliminary analysis of models with native image generation, like the latest
GPT-4o, shows they exhibit quirks like hallucinations and spatial
misalignments.

</details>


### [88] [Locality-aware Parallel Decoding for Efficient Autoregressive Image Generation](https://arxiv.org/abs/2507.01957)
*Zhuoyang Zhang,Luke J. Huang,Chengyue Wu,Shang Yang,Kelly Peng,Yao Lu,Song Han*

Main category: cs.CV

TL;DR: Locality-aware Parallel Decoding (LPD) 通过灵活的自回归建模和局部感知生成顺序，显著加速了自回归图像生成，减少了生成步骤并降低了延迟。


<details>
  <summary>Details</summary>
Motivation: 传统自回归图像生成依赖逐块预测，导致高延迟，现有方法并行化效果有限。LPD旨在实现高并行化同时保持生成质量。

Method: 引入灵活并行自回归建模（支持任意生成顺序和并行度）和局部感知生成顺序（最小化组内依赖，最大化上下文支持）。

Result: 在ImageNet类条件生成中，生成步骤从256减少到20（256×256分辨率），1024减少到48（512×512分辨率），延迟降低至少3.4倍。

Conclusion: LPD通过创新架构和调度策略，实现了高质量图像生成的高效并行化。

Abstract: We present Locality-aware Parallel Decoding (LPD) to accelerate
autoregressive image generation. Traditional autoregressive image generation
relies on next-patch prediction, a memory-bound process that leads to high
latency. Existing works have tried to parallelize next-patch prediction by
shifting to multi-patch prediction to accelerate the process, but only achieved
limited parallelization. To achieve high parallelization while maintaining
generation quality, we introduce two key techniques: (1) Flexible Parallelized
Autoregressive Modeling, a novel architecture that enables arbitrary generation
ordering and degrees of parallelization. It uses learnable position query
tokens to guide generation at target positions while ensuring mutual visibility
among concurrently generated tokens for consistent parallel decoding. (2)
Locality-aware Generation Ordering, a novel schedule that forms groups to
minimize intra-group dependencies and maximize contextual support, enhancing
generation quality. With these designs, we reduce the generation steps from 256
to 20 (256$\times$256 res.) and 1024 to 48 (512$\times$512 res.) without
compromising quality on the ImageNet class-conditional generation, and
achieving at least 3.4$\times$ lower latency than previous parallelized
autoregressive models.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [89] [Imitation Learning for Satellite Attitude Control under Unknown Perturbations](https://arxiv.org/abs/2507.01161)
*Zhizhuo Zhang,Hao Peng,Xiaoli Bai*

Main category: eess.SY

TL;DR: 提出了一种结合SAC强化学习和GAIL模仿学习的卫星姿态控制框架，提升了在未知扰动下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统控制方法依赖精确模型且对扰动敏感，需改进以应对不确定性。

Method: 先开发基于SAC的专家控制器，再用GAIL训练模仿策略，降低训练成本并提升泛化能力。

Result: SAC专家在多种扰动下表现优异，GAIL学习者能有效模仿专家轨迹。

Conclusion: SAC与GAIL结合显著提升控制性能，为智能自主航天器控制铺平道路。

Abstract: This paper presents a novel satellite attitude control framework that
integrates Soft Actor-Critic (SAC) reinforcement learning with Generative
Adversarial Imitation Learning (GAIL) to achieve robust performance under
various unknown perturbations. Traditional control techniques often rely on
precise system models and are sensitive to parameter uncertainties and external
perturbations. To overcome these limitations, we first develop a SAC-based
expert controller that demonstrates improved resilience against actuator
failures, sensor noise, and attitude misalignments, outperforming our previous
results in several challenging scenarios. We then use GAIL to train a learner
policy that imitates the expert's trajectories, thereby reducing training costs
and improving generalization through expert demonstrations. Preliminary
experiments under single and combined perturbations show that the SAC expert
can rotate the antenna to a specified direction and keep the antenna
orientation reliably stable in most of the listed perturbations. Additionally,
the GAIL learner can imitate most of the features from the trajectories
generated by the SAC expert. Comparative evaluations and ablation studies
confirm the effectiveness of the SAC algorithm and reward shaping. The
integration of GAIL further reduces sample complexity and demonstrates
promising imitation capabilities, paving the way for more intelligent and
autonomous spacecraft control systems.

</details>


### [90] [An Adaptive Estimation Approach based on Fisher Information to Overcome the Challenges of LFP Battery SOC Estimation](https://arxiv.org/abs/2507.01173)
*Junzhe Shi,Shida Jiang,Shengyu Tao,Jaewong Lee,Manashita Borah,Scott Moura*

Main category: eess.SY

TL;DR: 提出了一种自适应估计方法，用于解决LFP电池SOC估计中的挑战，通过融合两种模型的SOC估计，并在多种实际场景下验证其优越性。


<details>
  <summary>Details</summary>
Motivation: LFP电池因其安全性和长寿命在电动汽车和储能系统中广泛应用，但其平坦的OCV-SOC曲线和滞后效应使得SOC估计具有挑战性。

Method: 采用自适应Fisher信息融合策略，结合库仑计数和等效电路模型的SOC估计，并基于3D OCV-H-SOC映射。

Result: 在多种实际场景下的验证表明，该方法优于现有的无迹卡尔曼滤波、长短期记忆网络和Transformer。

Conclusion: 提出的自适应方法在LFP电池SOC估计中表现出鲁棒性和实时性，适用于复杂实际条件。

Abstract: Robust and Real-time State of Charge (SOC) estimation is essential for
Lithium Iron Phosphate (LFP) batteries, which are widely used in electric
vehicles (EVs) and energy storage systems due to safety and longevity. However,
the flat Open Circuit Voltage (OCV)-SOC curve makes this task particularly
challenging. This challenge is complicated by hysteresis effects, and
real-world conditions such as current bias, voltage quantization errors, and
temperature that must be considered in the battery management system use. In
this paper, we proposed an adaptive estimation approach to overcome the
challenges of LFPSOC estimation. Specifically, the method uses an adaptive
fisher information fusion strategy that adaptively combines the SOC estimation
from two different models, which are Coulomb counting and equivalent circuit
model-based parameter identification. The effectiveness of this strategy is
rationalized by the information richness excited by external cycling signals. A
3D OCV-H-SOC map that captures the relationship between OCV, hysteresis, and
SOC was proposed as the backbone, and can be generalizable to other widely
adopted parameter-identification methods. Extensive validation under ideal and
real-world use scenarios, including SOC-OCV flat zones, current bias, voltage
quantization errors, low temperatures, and insufficient current excitations,
have been performed using 4 driving profiles, i.e., the Orange County Transit
Bus Cycle, the California Unified Cycle, the US06 Drive Cycle, and the New York
City Cycle, where the results demonstrate superiority over the state-of-the-art
unscented Kalman filter, long short-term memory networks and transformer in all
validation cases.

</details>


### [91] [A Spectral-Based Tuning Criterion for PI Controllers in IPDT Systems With Unified Tracking and Disturbance Rejection Performance](https://arxiv.org/abs/2507.01197)
*Dhamdhawach Horsuwan*

Main category: eess.SY

TL;DR: 提出了一种基于频谱的PI控制器调谐方法，用于IPDT系统，通过最小化闭环系统的频谱横坐标实现统一的指数衰减。


<details>
  <summary>Details</summary>
Motivation: 解决IPDT系统中PI控制器调谐的问题，避免启发式权衡或权重参数的需求。

Method: 采用二阶半离散模型捕捉积分器和延迟动态，通过牛顿-拉夫森迭代优化连续时间极点。

Result: 相比经典规则（如Ziegler-Nichols）和积分性能准则（如IAE），该方法具有更快的收敛速度和更高的鲁棒性。

Conclusion: 该方法为延迟主导系统提供了一种透明且计算高效的PI控制框架。

Abstract: This paper proposes a spectral-based tuning method for proportional-integral
(PI) controllers in integrating-plus-dead-time (IPDT) systems. The design
objective is to achieve unified exponential decay for both reference tracking
and disturbance rejection by minimizing the spectral abscissa of the
closed-loop system. A second-order semi-discrete model accurately captures the
integrator and delay dynamics while enabling efficient dominant pole
extraction. These discrete-time poles are mapped to continuous time and refined
using Newton-Raphson iterations on the exact transcendental characteristic
equation. The method produces a unique PI gain set without requiring heuristic
trade-offs or weighting parameters. Comparative simulations demonstrate that
the proposed tuning achieves faster convergence and improved robustness margins
compared to classical rules (Ziegler-Nichols, SIMC) and integral performance
criteria (IAE, ITAE). The approach provides a transparent and computationally
efficient framework for PI control in delay-dominant systems.

</details>


### [92] [Teaching Cars to Drive: Spotlight on Connected and Automated Vehicles](https://arxiv.org/abs/2507.01211)
*Filippos N. Tzortzoglou,Andreas A. Malikopoulos*

Main category: eess.SY

TL;DR: 本文探讨了新兴移动系统（如CAV）的现状、潜力与挑战，并提出了模拟和测试CAV算法的解决方案，同时提供了基于运动学原理的建模入门教程。


<details>
  <summary>Details</summary>
Motivation: 研究CAV在安全、效率等方面的潜力及其实际应用中的挑战，推动该领域的发展。

Method: 分析CAV的现状与未来潜力，探讨研究中的模拟与测试难题，并提出解决方案。

Result: 总结了CAV的潜力与挑战，提供了建模教程以促进学习和研究。

Conclusion: CAV具有巨大潜力，但需克服研究与实践中的挑战，开源教程有助于初学者入门。

Abstract: In recent decades, society has witnessed significant advancements in emerging
mobility systems. These systems refer to transportation solutions that
incorporate digital technologies, automation, connectivity, and sustainability
to create safer, more efficient, and user-centered mobility. Examples include
connected and automated vehicles (CAVs), shared mobility services
(car-pooling), electric vehicles, and mobility-as-a-service platforms. These
innovations have the potential to greatly impact areas such as safety,
pollution, comfort, travel time, and fairness. In this article, we explore the
current landscape of CAVs. We discuss their role in daily life and their future
potential, while also addressing the challenges they may introduce. Following,
we also examine the practical difficulties in research associated with CAVs
especially simulating and testing CAV-related algorithms in real-world
settings. We present existing solutions that aim to overcome these limitations.
Finally, we provide an accessible introduction to modeling CAVs using basic
kinematic principles and offer an open-source tutorial to help interested
students begin exploring the field.

</details>


### [93] [Cooperative Target Capture in 3D Engagements over Switched Dynamic Graphs](https://arxiv.org/abs/2507.01350)
*Abhinav Sinha,Shashi Ranjan Kumar*

Main category: eess.SY

TL;DR: 本文提出了一种无领导者的协同制导策略，用于在动态切换图下实现拦截器对静止目标的同步时间约束拦截。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决拦截器缺乏径向加速度能力时的协同制导问题，同时应对3D耦合交战的复杂性及时间估计的不确定性。

Method: 通过解耦俯仰和偏航通道的瞬时优化问题，推导出横向加速度分量，并结合时间估计的不确定性设计鲁棒性制导指令。

Result: 仿真结果表明，所提策略能在预设时间内实现时间一致性，且不受拦截器初始配置影响。

Conclusion: 该策略有效解决了3D耦合交战中的性能退化问题，并具备鲁棒性和控制效率。

Abstract: This paper presents a leaderless cooperative guidance strategy for
simultaneous time-constrained interception of a stationary target when the
interceptors exchange information over switched dynamic graphs. We specifically
focus on scenarios when the interceptors lack radial acceleration capabilities,
relying solely on their lateral acceleration components. This consideration
aligns with their inherent kinematic turn constraints. The proposed strategy
explicitly addresses the complexities of coupled 3D engagements, thereby
mitigating performance degradation that typically arises when the pitch and yaw
channels are decoupled into two separate, mutually orthogonal planar
engagements. Moreover, our formulation incorporates modeling uncertainties
associated with the time-to-go estimation into the derivation of cooperative
guidance commands to ensure robustness against inaccuracies in dynamic
engagement scenarios. To optimize control efficiency, we analytically derive
the lateral acceleration components in the orthogonal pitch and yaw channels by
solving an instantaneous optimization problem, subject to an affine constraint.
We show that the proposed cooperative guidance commands guarantee consensus in
time-to-go values within a predefined time, which can be prescribed as a design
parameter, regardless of the interceptors' initial configurations. We provide
simulations to attest to the efficacy of the proposed method.

</details>


### [94] [Tunnelling Through Time Series: A Probabilistic Visibility Graph for Local and Global Pattern Discovery](https://arxiv.org/abs/2507.01247)
*Roberto Sotero,Jose Sanchez-Bornot*

Main category: eess.SY

TL;DR: 论文提出了一种基于量子隧穿现象的Probabilistic Visibility Graph (PVG)方法，用于捕捉时间序列数据的局部和全局模式，并在模拟信号和ECoG数据分析中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 高分辨率、长期时间序列数据的增多需要能够同时捕捉局部和全局模式的方法。

Method: PVG通过引入概率连接扩展了经典的Visibility Graph (VG)，解决了VG中因中间值遮挡而无法连接的问题。

Result: PVG在休息和麻醉状态下的ECoG数据中表现出不同的网络特性，休息状态显示出更强的小世界和无标度行为。

Conclusion: PVG为分析复杂信号提供了新工具，尤其在神经动力学等领域具有潜在应用价值。

Abstract: The growing availability of high-resolution, long-term time series data has
highlighted the need for methods capable of capturing both local and global
patterns. To address this, we introduce the Probabilistic Visibility Graph
(PVG), a novel approach inspired by the quantum tunnelling phenomenon. The PVG
extends the classical Visibility Graph (VG) by introducing probabilistic
connections between time points that are obstructed in the VG due to
intermediate values. We demonstrate the PVG's effectiveness in capturing
long-range dependencies through simulations of amplitude-modulated signals and
analysis of electrocorticography (ECoG) data under rest and anesthesia
conditions. Key results show that the PVG presents distinct network properties
between rest and anesthesia, with rest exhibiting stronger small-worldness and
scale-free behavior, reflecting a hub-dominated, centralized connectivity
structure, compared to anesthesia. These findings highlight the PVG's potential
for analyzing complex signals with interacting temporal scales, offering new
insights into neural dynamics and other real-world phenomena.

</details>


### [95] [Synchronising DER inverters to weak grid using Kalman filter and LQR current controller](https://arxiv.org/abs/2507.01300)
*Phuoc Sang Nguyen,Ghavameddin Nourbakhsh,Gerard Ledwich*

Main category: eess.SY

TL;DR: 该论文提出了一种用基于卡尔曼滤波和LQR控制器的先进角度估计方法替代PLL，以提高弱电网中GFL逆变器的动态性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: GFL逆变器在弱电网中因PLL的相位角估计不准确可能导致不稳定，需要更鲁棒的控制方法。

Method: 采用基于卡尔曼滤波的先进角度估计方法，结合LQR控制器，将电网阻抗纳入状态空间模型，并通过α-β同步参考帧方程估计瞬时相位角。

Result: 通过两源案例的特征值分析验证了稳定性，LQR控制器在电容电压、逆变电流和PCC电流调节上表现优异，显著降低了畸变。

Conclusion: 该方法在弱电网中表现出更高的鲁棒性和振荡抑制能力，优于现有方法。

Abstract: Grid-following (GFL) inverters are commonly used for integrating renewable
energy sources into power grids. However, the dynamic performance of GFL models
can be significantly impacted by the Phase-Locked Loop (PLL) in a weak grid,
leading to instability due to inaccuracies in grid source phase angle
estimation. The proposed method in this manuscript replaces the PLL with an
Advanced Angle Estimation based Kalman Filter including a Linear Quadratic
Regulator (LQR) controller of the GFL. This method is robust in incorporating
grid impedance terms as part of state space models in the Kalman Filter
approach to estimate instantaneous phase angle using {\alpha}-\b{eta}
Synchronous Reference Frame equations. The stability performance of the
proposed approach is validated through eigenvalue analysis in a two-source
case. Additionally, an LQR controller is employed to regulate capacitor
voltage, inverter current, and the current at the Point of Common Coupling
(PCC). The proposed controller surpasses existing approaches in terms of
accuracy and distortion reduction under abrupt grid impedance increases.
Moreover, drop compensation is integrated into the Kalman Filter to enhance
robustness of the inverter against external oscillation disturbances from a
synchronous machine connected to the GFL via the PCC. The results in this paper
demonstrate substantial improvement in oscillation damping across a range of
frequencies compared with published research works.

</details>


### [96] [Multi-Revolution Low-Thrust Trajectory Optimization With Very Sparse Mesh Pseudospectral Method](https://arxiv.org/abs/2507.01450)
*Yilin Zou,Fanghua Jiang*

Main category: eess.SY

TL;DR: 提出了一种高效、精确且广泛适用的伪谱方法，用于解决多圈低推力轨迹优化问题。


<details>
  <summary>Details</summary>
Motivation: 多圈低推力轨迹优化问题在空间任务设计中具有重要性和挑战性。

Method: 基于Sundman变换和伪谱方法，结合稀疏网格构建，提出了确定性旋转映射和随机自相关序列两种网格构造方法。

Result: 方法在计算时间和精度上表现优异，仅需几秒即可解决复杂问题。

Conclusion: 该方法在多圈低推力轨道交会问题中验证了其高效性和准确性。

Abstract: Multi-revolution low-thrust trajectory optimization problems are important
and challenging in space mission design. In this paper, an efficient, accurate,
and widely applicable pseudospectral method is proposed to solve
multi-revolution low-thrust trajectory optimization problems with various
objective functions and perturbations. The method is based on the Sundman
transformation and pseudospectral method, together with a sparse mesh that is
monotonic, near-uniformly spaced, and uniformly scattered on the unit circle.
Two methods are proposed to construct the mesh: a deterministic method based on
rotation mapping; a stochastic method utilizing autocorrelated random
sequences. Core mechanisms ensuring the correctness of the method are analyzed,
including the dual roles of mesh points as both integration points in the
temporal domain and sampling points in the angular domain, the slow dynamics of
the system excluding the fast angle variable, and the nearly commutative vector
fields generated by applying different control inputs. The method is
demonstrated through a multi-revolution low-thrust orbital rendezvous problem.
Results show that the proposed method achieves high accuracy with only a few
seconds of computational time for challenging problems.

</details>


### [97] [Robust Input Shaping Control for Flexible Structures Based on Unscented Kalman Filter](https://arxiv.org/abs/2507.01460)
*Weiyi Yang,Yu Yuan,Mingsheng Shang*

Main category: eess.SY

TL;DR: 论文提出了一种基于无迹卡尔曼滤波的零振动导数输入整形（UZS）方法，用于抑制柔性结构和欠驱动系统中的残余振动。


<details>
  <summary>Details</summary>
Motivation: 工业自动化和智能制造中，柔性结构和欠驱动系统的残余振动会降低效率并威胁结构完整性，传统输入整形技术因参数不准确和环境干扰而性能下降。

Method: 结合数据驱动的无迹卡尔曼滤波实时识别系统参数，以及零振动导数（ZVD）输入整形器实现鲁棒的振动抑制。

Result: 在垂直柔性梁平台上的实验表明，UZS方法显著优于现有技术。

Conclusion: UZS在工业自动化、机器人和精密工程中具有实际应用潜力。

Abstract: With the rapid development of industrial automation and smart manufacturing,
the control of flexible structures and underactuated systems has become a
critical research focus. Residual vibrations in these systems not only degrade
operational efficiency but also pose risks to structural integrity and
longevity. Traditional input shaping techniques, while effective, often suffer
from performance degradation due to parameter inaccuracies and environmental
disturbances. To address these challenges, this paper introduces an innovative
unscented Kalman filter-based zero vibration derivative input shaping (UZS)
method. The proposed approach combines two key innovations: 1) a data-driven
Unscented Kalman Filterfor real-time system parameter identification, and 2) a
zero-vibration derivative (ZVD) input shaper for robust vibration suppression.
To validate the effectiveness of UZS, we conducted extensive experiments on a
vertical flexible beam platform, and the results demonstrate significant
improvements over state-of-the-art methods. Additionally, we have made the
experimental datasets publicly available to facilitate further research. The
findings highlight UZS's potential for practical applications in industrial
automation, robotics, and precision engineering.

</details>


### [98] [Frequency Domain Design of a Reset-Based Filter: An Add-On Nonlinear Filter for Industrial Motion Control](https://arxiv.org/abs/2507.01491)
*S. Ali Hosseini,Fabian R. Quinten,Luke F. van Eijk,Dragan Kostic,S. Hassan HosseinNia*

Main category: eess.SY

TL;DR: 提出一种改进的CgLp滤波器，通过引入前馈项减少非线性，实现全频段增益稳定，并设计附加滤波器提升现有LTI控制器性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统CgLp滤波器的非线性问题，提升低频振动控制性能。

Method: 采用前馈项和反向计算法优化滤波器参数，提出附加滤波器结构和灵敏度改进指标。

Result: 在工业引线键合机案例中验证了方法的有效性，显著改善低频振动和控制性能。

Conclusion: 改进的CgLp滤波器及其附加结构能有效提升控制性能，适用于工业应用。

Abstract: This study introduces a modified version of the Constant-in-Gain,
Lead-in-Phase (CgLp) filter, which incorporates a feedthrough term in the
First-Order Reset Element (FORE) to reduce the undesirable nonlinearities and
achieve an almost constant gain across all frequencies. A backward calculation
approach is proposed to derive the additional parameter introduced by the
feedthrough term, enabling designers to easily tune the filter to generate the
required phase. The paper also presents an add-on filter structure that can
enhance the performance of an existing LTI controller without altering its
robustness margins. A sensitivity improvement indicator is proposed to guide
the tuning process, enabling designers to visualize the improvements in
closed-loop performance. The proposed methodology is demonstrated through a
case study of an industrial wire bonder machine, showcasing its effectiveness
in addressing low-frequency vibrations and improving overall control
performance.

</details>


### [99] [Time-Varying Coverage Control: A Distributed Tracker-Planner MPC Framework](https://arxiv.org/abs/2507.01567)
*Patrick Benito Eberhard,Johannes Köhler,Oliver Hüsser,Melanie N. Zeilinger,Andrea Carron*

Main category: eess.SY

TL;DR: 提出了一种分布式多智能体控制框架，用于处理非线性约束动态下的时变覆盖问题，结合轨迹规划和跟踪MPC，并验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体在时变环境中协调覆盖的挑战，如自动驾驶出租车部署和搜救任务。

Method: 采用多速率框架，结合参考轨迹规划器和跟踪MPC，处理周期性和非周期性密度函数。

Result: 证明了闭环收敛到最优轨迹配置，满足约束、避碰和递归可行性，并通过硬件实验验证。

Conclusion: 方法适用于实际应用，能有效处理时变覆盖问题。

Abstract: Time-varying coverage control addresses the challenge of coordinating
multiple agents covering an environment where regions of interest change over
time. This problem has broad applications, including the deployment of
autonomous taxis and coordination in search and rescue operations. The
achievement of effective coverage is complicated by the presence of
time-varying density functions, nonlinear agent dynamics, and stringent system
and safety constraints. In this paper, we present a distributed multi-agent
control framework for time-varying coverage under nonlinear constrained
dynamics. Our approach integrates a reference trajectory planner and a tracking
model predictive control (MPC) scheme, which operate at different frequencies
within a multi-rate framework. For periodic density functions, we demonstrate
closed-loop convergence to an optimal configuration of trajectories and provide
formal guarantees regarding constraint satisfaction, collision avoidance, and
recursive feasibility. Additionally, we propose an efficient algorithm capable
of handling nonperiodic density functions, making the approach suitable for
practical applications. Finally, we validate our method through hardware
experiments using a fleet of four miniature race cars.

</details>


### [100] [Vision-Aided ISAC in Low-Altitude Economy Networks via De-Diffused Visual Priors](https://arxiv.org/abs/2507.01574)
*Yulan Gao,Ziqiang Ye,Zhonghao Lyu,Ming Xiao,Yue Xiao,Ping Yang,Agata Manolova*

Main category: eess.SY

TL;DR: 论文提出了一种基于视觉辅助的集成感知与通信（ISAC）框架，用于无人机辅助接入系统，通过De-Diffusion模型提取语义令牌并融合毫米波雷达数据，优化资源调度。


<details>
  <summary>Details</summary>
Motivation: 解决低空经济网络（LAENets）在动态代理移动和有限基础设施支持下的敏捷且隐私保护的资源控制问题。

Method: 提出DeDiff-VARARO算法，结合De-Diffusion模型和DDPG策略，分两阶段进行语义解析和资源优化。

Result: 仿真结果显示DeDiff-VARARO在奖励收敛、链路鲁棒性和语义保真度上优于基线，接近原始图像上限性能的96%。

Conclusion: 该方法在保护用户隐私和可扩展性的同时，显著提升了资源优化效果。

Abstract: Emerging low-altitude economy networks (LAENets) require agile and
privacy-preserving resource control under dynamic agent mobility and limited
infrastructure support. To meet these challenges, we propose a vision-aided
integrated sensing and communication (ISAC) framework for UAV-assisted access
systems, where onboard masked De-Diffusion models extract compact semantic
tokens, including agent type, activity class, and heading orientation, while
explicitly suppressing sensitive visual content. These tokens are fused with
mmWave radar measurements to construct a semantic risk heatmap reflecting
motion density, occlusion, and scene complexity, which guides access technology
selection and resource scheduling. We formulate a multi-objective optimization
problem to jointly maximize weighted energy and perception efficiency via radio
access technology (RAT) assignment, power control, and beamforming, subject to
agent-specific QoS constraints. To solve this, we develop De-Diffusion-driven
vision-aided risk-aware resource optimization algorithm DeDiff-VARARO, a novel
two-stage cross-modal control algorithm: the first stage reconstructs visual
scenes from tokens via De-Diffusion model for semantic parsing, while the
second stage employs a deep deterministic policy gradient (DDPG)-based policy
to adapt RAT selection, power control, and beam assignment based on fused
radar-visual states. Simulation results show that DeDiff-VARARO consistently
outperforms baselines in reward convergence, link robustness, and semantic
fidelity, achieving within $4\%$ of the performance of a raw-image upper bound
while preserving user privacy and scalability in dense environments.

</details>


### [101] [Re-examining the Legendre-Gauss-Lobatto Pseudospectral Methods for Optimal Control](https://arxiv.org/abs/2507.01660)
*Yilin Zou,Fanghua Jiang*

Main category: eess.SY

TL;DR: 本文重新评估了Legendre-Gauss-Lobatto（LGL）配点法在最优控制问题中的性能，提出了一种增强的LGL方法，解决了收敛性问题，并在计算性能上优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统认为LGL配点法在收敛性上不如Legendre-Gauss（LG）和Legendre-Gauss-Radau（LGR）方法，本文旨在通过改进LGL方法证明其潜力。

Method: 引入增强的LGL配点法，通过增加自由度（DOF）改进插值结构，并证明其数学等价于积分形式的LGL方法。

Result: 改进的LGL方法在离散问题维度和辛积分性质上优于LG和LGR方法，数值实验验证了其准确性和计算性能。

Conclusion: 增强的LGL方法在长时域最优控制问题中表现出色，兼具高精度和计算效率。

Abstract: Pseudospectral methods represent an efficient approach for solving optimal
control problems. While Legendre-Gauss-Lobatto (LGL) collocation points have
traditionally been considered inferior to Legendre-Gauss (LG) and
Legendre-Gauss-Radau (LGR) points in terms of convergence properties, this
paper presents a rigorous re-examination of LGL-based methods. We introduce an
augmented formulation that enhances the standard LGL collocation approach by
incorporating an additional degree of freedom (DOF) into the interpolation
structure. We demonstrate that this augmented formulation is mathematically
equivalent to the integral formulation of the LGL collocation method. Through
analytical derivation, we establish that the adjoint system in both the
augmented differential and integral formulations corresponds to a Lobatto IIIB
discontinuous collocation method for the costate vector, thereby resolving the
previously reported convergence issues. Our comparative analysis of LG, LGR,
and LGL collocation methods reveals significant advantages of the improved LGL
approach in terms of discretized problem dimensionality and symplectic
integration properties. Numerical examples validate our theoretical findings,
demonstrating that the proposed LGL-based method achieves comparable accuracy
to LG and LGR methods while offering superior computational performance for
long-horizon optimal control problems due to the preservation of symplecticity.

</details>


### [102] [Auto-optimization of Energy Generation for Wave Energy Converters with Active Learning](https://arxiv.org/abs/2507.01727)
*Siyang Tang,Wen-Hua Chen,Cunjia Liu*

Main category: eess.SY

TL;DR: 提出了一种用于波浪能转换器（WEC）的自动优化控制框架，以在未知和变化的海洋条件下最大化能量生成。


<details>
  <summary>Details</summary>
Motivation: 解决WEC在未知和变化海洋条件下的能量生成优化问题。

Method: 采用双层控制框架，高层控制器基于DCEE概念，主动学习未知波浪参数并生成最优PTO力剖面。

Result: 仿真结果表明，该框架在未知规则和不规则波浪下表现优于模型预测控制、极值搜索和经典Bang-Bang控制。

Conclusion: 该自动优化框架结合主动学习，显著提升了WEC系统的能量生成效率和鲁棒性。

Abstract: This paper presents an auto-optimization control framework for wave energy
converters (WECs) to maximize energy generation under unknown and changing
ocean conditions. The proposed control framework consists of two levels. The
high-level controller operating at a longer time scale aims to maximize the
average energy generation over several wave periods. The generated Power
Take-Off (PTO) profile as the reference for the low-level physical system to
follow. The new auto-optimization process leverages the parameterization of the
non-stationary operation condition in WECs, establishing the relationship
between the average energy generation and the key design parameters of the PTO
force subject to the unknown wave parameters. The high-level controller is
designed based on the concept of Dual Control for Exploration and Exploitation
(DCEE) to quickly learn the unknown wave parameters by actively probing the
ocean condition, while generating the optimal PTO profile. During this process,
the uncertainty of the estimated wave condition is quantified and embedded in
the optimization cost function to enable active learning. Simulation results
under unknown regular and irregular waves demonstrate the effectiveness and
robustness of this novel auto-optimization WEC systems with active learning,
outperforming model predictive control, extremum seeking and classic Bang-Bang
control approaches.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [103] [User-guided Generative Source Separation](https://arxiv.org/abs/2507.01339)
*Yutong Wen,Minje Kim,Paris Smaragdis*

Main category: cs.SD

TL;DR: GuideSep是一种基于扩散模型的音乐源分离方法，支持乐器无关的分离，通过波形模仿和频谱掩码提供灵活性。


<details>
  <summary>Details</summary>
Motivation: 现有方法局限于四音轨分离，缺乏灵活性，无法满足实际需求。

Method: 提出GuideSep，结合波形模仿条件和频谱掩码，采用扩散模型实现乐器无关分离。

Result: GuideSep在客观和主观评估中均表现优异，支持更灵活的乐器提取。

Conclusion: GuideSep展示了基于扩散模型的生成方法在音乐源分离中的潜力，支持用户参与。

Abstract: Music source separation (MSS) aims to extract individual instrument sources
from their mixture. While most existing methods focus on the widely adopted
four-stem separation setup (vocals, bass, drums, and other instruments), this
approach lacks the flexibility needed for real-world applications. To address
this, we propose GuideSep, a diffusion-based MSS model capable of
instrument-agnostic separation beyond the four-stem setup. GuideSep is
conditioned on multiple inputs: a waveform mimicry condition, which can be
easily provided by humming or playing the target melody, and mel-spectrogram
domain masks, which offer additional guidance for separation. Unlike prior
approaches that relied on fixed class labels or sound queries, our conditioning
scheme, coupled with the generative approach, provides greater flexibility and
applicability. Additionally, we design a mask-prediction baseline using the
same model architecture to systematically compare predictive and generative
approaches. Our objective and subjective evaluations demonstrate that GuideSep
achieves high-quality separation while enabling more versatile instrument
extraction, highlighting the potential of user participation in the
diffusion-based generative process for MSS. Our code and demo page are
available at https://yutongwen.github.io/GuideSep/

</details>


### [104] [Real-Time Emergency Vehicle Siren Detection with Efficient CNNs on Embedded Hardware](https://arxiv.org/abs/2507.01563)
*Marco Giordano,Stefano Giacomelli,Claudia Rinaldi,Fabio Graziosi*

Main category: cs.SD

TL;DR: 提出了一种基于E2PANNs的嵌入式硬件实时紧急车辆警报检测系统，通过优化数据集和部署策略实现低延迟、高鲁棒性检测。


<details>
  <summary>Details</summary>
Motivation: 解决标准AudioSet标注可靠性低的问题，并探索在低成本边缘设备上部署分布式声学监测网络的可行性。

Method: 使用E2PANNs（基于EPANNs优化的卷积神经网络）进行二元声音事件检测，构建定制数据集（AudioSet-EV等），并在树莓派5上部署多线程推理引擎。

Result: 系统在真实音频条件下实现了低延迟检测，并提高了鲁棒性。

Conclusion: 展示了在低成本边缘设备上部署分布式声学监测网络的可行性，支持智能城市基础设施中的协作紧急车辆跟踪。

Abstract: We present a full-stack emergency vehicle (EV) siren detection system
designed for real-time deployment on embedded hardware. The proposed approach
is based on E2PANNs, a fine-tuned convolutional neural network derived from
EPANNs, and optimized for binary sound event detection under urban acoustic
conditions. A key contribution is the creation of curated and semantically
structured datasets - AudioSet-EV, AudioSet-EV Augmented, and Unified-EV -
developed using a custom AudioSet-Tools framework to overcome the low
reliability of standard AudioSet annotations. The system is deployed on a
Raspberry Pi 5 equipped with a high-fidelity DAC+microphone board, implementing
a multithreaded inference engine with adaptive frame sizing, probability
smoothing, and a decision-state machine to control false positive activations.
A remote WebSocket interface provides real-time monitoring and facilitates live
demonstration capabilities. Performance is evaluated using both framewise and
event-based metrics across multiple configurations. Results show the system
achieves low-latency detection with improved robustness under realistic audio
conditions. This work demonstrates the feasibility of deploying IoS-compatible
SED solutions that can form distributed acoustic monitoring networks, enabling
collaborative emergency vehicle tracking across smart city infrastructures
through WebSocket connectivity on low-cost edge devices.

</details>


### [105] [Exploring Classical Piano Performance Generation with Expressive Music Variational AutoEncoder](https://arxiv.org/abs/2507.01582)
*Jing Luo,Xinyu Yang,Jie Wei*

Main category: cs.SD

TL;DR: 本文提出了一种名为XMVAE的模型，通过结合ECP表示和双分支结构，实现了从零生成古典钢琴表演，模拟作曲家和钢琴家的双重角色。


<details>
  <summary>Details</summary>
Motivation: 古典音乐的创造力不仅来自作曲家的创作，还来自表演者对静态乐谱的诠释。本文旨在解决从零生成古典钢琴表演的挑战。

Method: 提出ECP表示法捕捉表演的韵律结构和表现细节，并设计XMVAE模型，包含VQ-VAE分支（作曲家）和VAE分支（钢琴家），通过多尺度编码器和正交Transformer解码器联合训练。

Result: XMVAE生成的古典表演在音乐质量上优于现有模型，且作曲家分支的预训练显著提升了性能。

Conclusion: XMVAE成功模拟了作曲家和钢琴家的双重角色，为生成古典音乐表演提供了有效解决方案。

Abstract: The creativity of classical music arises not only from composers who craft
the musical sheets but also from performers who interpret the static notations
with expressive nuances. This paper addresses the challenge of generating
classical piano performances from scratch, aiming to emulate the dual roles of
composer and pianist in the creative process. We introduce the Expressive
Compound Word (ECP) representation, which effectively captures both the
metrical structure and expressive nuances of classical performances. Building
on this, we propose the Expressive Music Variational AutoEncoder (XMVAE), a
model featuring two branches: a Vector Quantized Variational AutoEncoder
(VQ-VAE) branch that generates score-related content, representing the
Composer, and a vanilla VAE branch that produces expressive details, fulfilling
the role of Pianist. These branches are jointly trained with similar Seq2Seq
architectures, leveraging a multiscale encoder to capture beat-level contextual
information and an orthogonal Transformer decoder for efficient compound tokens
decoding. Both objective and subjective evaluations demonstrate that XMVAE
generates classical performances with superior musical quality compared to
state-of-the-art models. Furthermore, pretraining the Composer branch on extra
musical score datasets contribute to a significant performance gain.

</details>


### [106] [A Dataset for Automatic Assessment of TTS Quality in Spanish](https://arxiv.org/abs/2507.01805)
*Alejandro Sosa Welford,Leonardo Pepino*

Main category: cs.SD

TL;DR: 开发了一个用于西班牙语TTS系统自动评估的数据库，提升自然度预测模型的准确性。数据集包含4,326个音频样本，来自52种TTS系统和人类声音，并通过主观测试标注。验证了数据集的实用性，训练了两种自动预测模型，均取得较好效果。


<details>
  <summary>Details</summary>
Motivation: 改进西班牙语TTS系统的自然度预测模型，填补该领域数据集的空白。

Method: 构建包含多种TTS系统和人类声音的音频数据集，基于ITU-T Rec. P.807标准进行主观测试标注，并训练两种自动预测模型（微调现有模型和训练小型下游网络）。

Result: 模型在五级MOS量表上的平均绝对误差为0.8，验证了数据集的质量和多样性。

Conclusion: 该数据集为西班牙语TTS研究提供了重要资源，具有推动该领域发展的潜力。

Abstract: This work addresses the development of a database for the automatic
assessment of text-to-speech (TTS) systems in Spanish, aiming to improve the
accuracy of naturalness prediction models. The dataset consists of 4,326 audio
samples from 52 different TTS systems and human voices and is, up to our
knowledge, the first of its kind in Spanish. To label the audios, a subjective
test was designed based on the ITU-T Rec. P.807 standard and completed by 92
participants. Furthermore, the utility of the collected dataset was validated
by training automatic naturalness prediction systems. We explored two
approaches: fine-tuning an existing model originally trained for English, and
training small downstream networks on top of frozen self-supervised speech
models. Our models achieve a mean absolute error of 0.8 on a five-point MOS
scale. Further analysis demonstrates the quality and diversity of the developed
dataset, and its potential to advance TTS research in Spanish.

</details>


<div id='cs.NE'></div>

# cs.NE [[Back]](#toc)

### [107] [Diversity-Preserving Exploitation of Crossover](https://arxiv.org/abs/2507.01524)
*Johannes Lengler,Tom Offermann*

Main category: cs.NE

TL;DR: 提出了一种名为DiPEC的新方法，通过保留种群多样性来优化交叉操作，并开发了DEGA算法，显著提升了遗传算法的效率。


<details>
  <summary>Details</summary>
Motivation: 解决传统遗传算法中交叉操作在利用多样性时反而减少多样性的矛盾问题。

Method: 引入DiPEC范式，设计DEGA算法，在保留多样性的同时有效利用交叉操作。

Result: DEGA在LeadingOnes问题上表现优异，仅需O(n^{5/3}log^{2/3}n)次评估，优于传统算法的Θ(n^2)。

Conclusion: DiPEC范式具有潜力，值得进一步研究，并在其他基准测试中表现良好。

Abstract: Crossover is a powerful mechanism for generating new solutions from a given
population of solutions. Crossover comes with a discrepancy in itself: on the
one hand, crossover usually works best if there is enough diversity in the
population; on the other hand, exploiting the benefits of crossover reduces
diversity. This antagonism often makes crossover reduce its own effectiveness.
  We introduce a new paradigm for utilizing crossover that reduces this
antagonism, which we call diversity-preserving exploitation of crossover
(DiPEC). The resulting Diversity Exploitation Genetic Algorithm (DEGA) is able
to still exploit the benefits of crossover, but preserves a much higher
diversity than conventional approaches.
  We demonstrate the benefits by proving that the (2+1)-DEGA finds the optimum
of LeadingOnes with $O(n^{5/3}\log^{2/3} n)$ fitness evaluations. This is
remarkable since standard genetic algorithms need $\Theta(n^2)$ evaluations,
and among genetic algorithms only some artificial and specifically tailored
algorithms were known to break this runtime barrier. We confirm the theoretical
results by simulations. Finally, we show that the approach is not overfitted to
Leadingones by testing it empirically on other benchmarks and showing that it
is also competitive in other settings. We believe that our findings justify
further systematic investigations of the DiPEC paradigm.

</details>


### [108] [Adaptive Estimation of the Number of Algorithm Runs in Stochastic Optimization](https://arxiv.org/abs/2507.01629)
*Tome Eftimov,Peter Korošec*

Main category: cs.NE

TL;DR: 本文提出了一种在线动态调整算法运行次数的方法，以提高连续单目标随机优化算法的性能评估准确性，同时减少实验时间和能源消耗。


<details>
  <summary>Details</summary>
Motivation: 确定算法运行次数对实验设计和结果可靠性至关重要，传统方法可能效率低下或资源浪费。

Method: 结合概率理论和鲁棒性检查，动态调整运行次数，并在执行过程中在线更新。

Result: 在多种算法和基准测试中，准确率达到82%-95%，运行次数减少约50%。

Conclusion: 该方法提高了基准测试效率，减少了能源消耗，有助于可持续计算。

Abstract: Determining the number of algorithm runs is a critical aspect of experimental
design, as it directly influences the experiment's duration and the reliability
of its outcomes. This paper introduces an empirical approach to estimating the
required number of runs per problem instance for accurate estimation of the
performance of the continuous single-objective stochastic optimization
algorithm. The method leverages probability theory, incorporating a robustness
check to identify significant imbalances in the data distribution relative to
the mean, and dynamically adjusts the number of runs during execution as an
online approach. The proposed methodology was extensively tested across two
algorithm portfolios (104 Differential Evolution configurations and the
Nevergrad portfolio) and the COCO benchmark suite, totaling 5748000 runs. The
results demonstrate 82% - 95% accuracy in estimations across different
algorithms, allowing a reduction of approximately 50% in the number of runs
without compromising optimization outcomes. This online calculation of required
runs not only improves benchmarking efficiency, but also contributes to energy
reduction, fostering a more environmentally sustainable computing ecosystem.

</details>


### [109] [Customized Exploration of Landscape Features Driving Multi-Objective Combinatorial Optimization Performance](https://arxiv.org/abs/2507.01638)
*Ana Nikolikj,Gabriela Ochoa,Tome Eftimov*

Main category: cs.NE

TL;DR: 分析多目标组合优化算法性能的景观特征，基于C-PLOS-net模型，针对不同rmnk-landscapes和算法揭示特征组合的影响。


<details>
  <summary>Details</summary>
Motivation: 研究景观特征如何预测多目标组合优化算法的性能，以提供更深入的算法选择和优化策略。

Method: 使用C-PLOS-net模型提取特征，评估PLS、GSEMO和NSGA-II算法在rmnk-landscapes上的表现，采用分辨率和超体积指标。

Result: 揭示了特定景观和算法下影响性能的特征组合，提供了针对性的特征重要性分析。

Conclusion: 该研究为特定rmnk-landscapes和算法的性能预测提供了有价值的见解，有助于优化算法选择。

Abstract: We present an analysis of landscape features for predicting the performance
of multi-objective combinatorial optimization algorithms. We consider features
from the recently proposed compressed Pareto Local Optimal Solutions Networks
(C-PLOS-net) model of combinatorial landscapes. The benchmark instances are a
set of rmnk-landscapes with 2 and 3 objectives and various levels of ruggedness
and objective correlation. We consider the performance of three algorithms --
Pareto Local Search (PLS), Global Simple EMO Optimizer (GSEMO), and
Non-dominated Sorting Genetic Algorithm (NSGA-II) - using the resolution and
hypervolume metrics. Our tailored analysis reveals feature combinations that
influence algorithm performance specific to certain landscapes. This study
provides deeper insights into feature importance, tailored to specific
rmnk-landscapes and algorithms.

</details>


### [110] [Comparing Optimization Algorithms Through the Lens of Search Behavior Analysis](https://arxiv.org/abs/2507.01668)
*Gjorgjina Cenikj,Gašper Petelin,Tome Eftimov*

Main category: cs.NE

TL;DR: 论文探讨了统计测试在比较元启发式算法搜索行为中的应用，以区分真正创新与现有方法。


<details>
  <summary>Details</summary>
Motivation: 针对元启发式算法领域缺乏区分度的批评，研究旨在通过统计测试明确算法的独特性。

Method: 使用交叉匹配统计测试比较多元分布，评估MEALPY库中114种算法的解决方案。

Result: 通过实证分析识别出具有相似搜索行为的算法。

Conclusion: 统计测试为区分算法创新提供了有效工具，有助于减少领域内的冗余研究。

Abstract: The field of numerical optimization has recently seen a surge in the
development of "novel" metaheuristic algorithms, inspired by metaphors derived
from natural or human-made processes, which have been widely criticized for
obscuring meaningful innovations and failing to distinguish themselves from
existing approaches. Aiming to address these concerns, we investigate the
applicability of statistical tests for comparing algorithms based on their
search behavior. We utilize the cross-match statistical test to compare
multivariate distributions and assess the solutions produced by 114 algorithms
from the MEALPY library. These findings are incorporated into an empirical
analysis aiming to identify algorithms with similar search behaviors.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [111] [Environment-Aware and Human-Cooperative Swing Control for Lower-Limb Prostheses in Diverse Obstacle Scenarios](https://arxiv.org/abs/2507.01111)
*Haosen Xing,Haoran Ma,Sijin Zhang,Hartmut Geyer*

Main category: cs.RO

TL;DR: 提出了一种新型控制策略，结合环境感知与用户意图，用于下肢假肢在复杂地形中的障碍物导航。


<details>
  <summary>Details</summary>
Motivation: 当前下肢假肢控制策略缺乏对环境与用户意图的感知，尤其在复杂地形中表现明显不足。

Method: 通过机载深度摄像头检测障碍物，动态调整摆动轨迹，结合用户生物力学信号实现自然步态。

Result: 实验显示，在150多次跨越和30次踏上障碍物的测试中，成功率达100%。

Conclusion: 该系统有效解决了障碍物导航问题，展示了在复杂地形中的适应性，具有广泛应用前景。

Abstract: Current control strategies for powered lower limb prostheses often lack
awareness of the environment and the user's intended interactions with it. This
limitation becomes particularly apparent in complex terrains. Obstacle
negotiation, a critical scenario exemplifying such challenges, requires both
real-time perception of obstacle geometry and responsiveness to user intention
about when and where to step over or onto, to dynamically adjust swing
trajectories. We propose a novel control strategy that fuses environmental
awareness and human cooperativeness: an on-board depth camera detects obstacles
ahead of swing phase, prompting an elevated early-swing trajectory to ensure
clearance, while late-swing control defers to natural biomechanical cues from
the user. This approach enables intuitive stepping strategies without requiring
unnatural movement patterns. Experiments with three non-amputee participants
demonstrated 100 percent success across more than 150 step-overs and 30
step-ons with randomly placed obstacles of varying heights (4-16 cm) and
distances (15-70 cm). By effectively addressing obstacle navigation -- a
gateway challenge for complex terrain mobility -- our system demonstrates
adaptability to both environmental constraints and user intentions, with
promising applications across diverse locomotion scenarios.

</details>


### [112] [VISTA: Open-Vocabulary, Task-Relevant Robot Exploration with Online Semantic Gaussian Splatting](https://arxiv.org/abs/2507.01125)
*Keiko Nagami,Timothy Chen,Javier Yu,Ola Shorinwa,Maximilian Adang,Carlyn Dougherty,Eric Cristofalo,Mac Schwager*

Main category: cs.RO

TL;DR: VISTA是一种机器人主动探索方法，通过规划信息丰富的轨迹来提升3D地图质量，专注于任务相关区域。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在开放词汇搜索任务中高效探索环境并构建语义3D地图的需求。

Method: 结合语义相似性和未探索区域优先级，提出一种新颖的视点-语义覆盖度量来评估轨迹。

Result: 在静态数据集上优于现有方法FisherRF和Bayes' Rays，硬件实验中成功率提升6倍。

Conclusion: VISTA具有平台无关性，适用于多种机器人平台，性能显著优于基线方法。

Abstract: We present VISTA (Viewpoint-based Image selection with Semantic Task
Awareness), an active exploration method for robots to plan informative
trajectories that improve 3D map quality in areas most relevant for task
completion. Given an open-vocabulary search instruction (e.g., "find a
person"), VISTA enables a robot to explore its environment to search for the
object of interest, while simultaneously building a real-time semantic 3D
Gaussian Splatting reconstruction of the scene. The robot navigates its
environment by planning receding-horizon trajectories that prioritize semantic
similarity to the query and exploration of unseen regions of the environment.
To evaluate trajectories, VISTA introduces a novel, efficient
viewpoint-semantic coverage metric that quantifies both the geometric view
diversity and task relevance in the 3D scene. On static datasets, our coverage
metric outperforms state-of-the-art baselines, FisherRF and Bayes' Rays, in
computation speed and reconstruction quality. In quadrotor hardware
experiments, VISTA achieves 6x higher success rates in challenging maps,
compared to baseline methods, while matching baseline performance in less
challenging maps. Lastly, we show that VISTA is platform-agnostic by deploying
it on a quadrotor drone and a Spot quadruped robot. Open-source code will be
released upon acceptance of the paper.

</details>


### [113] [A Review on Sound Source Localization in Robotics: Focusing on Deep Learning Methods](https://arxiv.org/abs/2507.01143)
*Reza Jalayer,Masoud Jalayer,Amirali Baniasadi*

Main category: cs.RO

TL;DR: 本文综述了机器人领域中基于深度学习的声源定位方法，填补了现有综述未涵盖机器人约束和最新深度学习的不足。


<details>
  <summary>Details</summary>
Motivation: 现有综述多关注通用音频应用，缺乏对机器人约束和深度学习最新进展的讨论，本文旨在填补这一空白。

Method: 回顾了经典方法（如TDOA、波束成形等）和现代深度学习技术（如CNN、CRNN等），并探讨了数据与训练策略。

Result: 总结了当前挑战（如环境鲁棒性、多声源问题）并提出了未来研究方向。

Conclusion: 为下一代机器人提供了鲁棒、高效且可解释的深度学习声源定位路线图。

Abstract: Sound source localization (SSL) adds a spatial dimension to auditory
perception, allowing a system to pinpoint the origin of speech, machinery
noise, warning tones, or other acoustic events, capabilities that facilitate
robot navigation, human-machine dialogue, and condition monitoring. While
existing surveys provide valuable historical context, they typically address
general audio applications and do not fully account for robotic constraints or
the latest advancements in deep learning. This review addresses these gaps by
offering a robotics-focused synthesis, emphasizing recent progress in deep
learning methodologies. We start by reviewing classical methods such as Time
Difference of Arrival (TDOA), beamforming, Steered-Response Power (SRP), and
subspace analysis. Subsequently, we delve into modern machine learning (ML) and
deep learning (DL) approaches, discussing traditional ML and neural networks
(NNs), convolutional neural networks (CNNs), convolutional recurrent neural
networks (CRNNs), and emerging attention-based architectures. The data and
training strategy that are the two cornerstones of DL-based SSL are explored.
Studies are further categorized by robot types and application domains to
facilitate researchers in identifying relevant work for their specific
contexts. Finally, we highlight the current challenges in SSL works in general,
regarding environmental robustness, sound source multiplicity, and specific
implementation constraints in robotics, as well as data and learning strategies
in DL-based SSL. Also, we sketch promising directions to offer an actionable
roadmap toward robust, adaptable, efficient, and explainable DL-based SSL for
next-generation robots.

</details>


### [114] [SonoGym: High Performance Simulation for Challenging Surgical Tasks with Robotic Ultrasound](https://arxiv.org/abs/2507.01152)
*Yunke Ao,Masoud Moghani,Mayank Mittal,Manish Prajapat,Luohong Wu,Frederic Giraud,Fabio Carrillo,Andreas Krause,Philipp Fürnstahl*

Main category: cs.RO

TL;DR: SonoGym是一个用于复杂机器人超声任务的模拟平台，支持并行模拟，结合物理和生成建模方法，用于训练深度强化学习和模仿学习代理。


<details>
  <summary>Details</summary>
Motivation: 解决机器人超声在复杂手术任务中缺乏高效模拟环境的问题。

Method: 提出SonoGym平台，结合物理和生成建模方法，支持并行模拟，并集成深度强化学习和模仿学习代理。

Result: 成功训练出适用于骨科手术的策略，但现有方法在临床环境中仍有局限性。

Conclusion: SonoGym有助于推动机器人手术学习研究，相关数据和代码已公开。

Abstract: Ultrasound (US) is a widely used medical imaging modality due to its
real-time capabilities, non-invasive nature, and cost-effectiveness. Robotic
ultrasound can further enhance its utility by reducing operator dependence and
improving access to complex anatomical regions. For this, while deep
reinforcement learning (DRL) and imitation learning (IL) have shown potential
for autonomous navigation, their use in complex surgical tasks such as anatomy
reconstruction and surgical guidance remains limited -- largely due to the lack
of realistic and efficient simulation environments tailored to these tasks. We
introduce SonoGym, a scalable simulation platform for complex robotic
ultrasound tasks that enables parallel simulation across tens to hundreds of
environments. Our framework supports realistic and real-time simulation of US
data from CT-derived 3D models of the anatomy through both a physics-based and
a generative modeling approach. Sonogym enables the training of DRL and recent
IL agents (vision transformers and diffusion policies) for relevant tasks in
robotic orthopedic surgery by integrating common robotic platforms and
orthopedic end effectors. We further incorporate submodular DRL -- a recent
method that handles history-dependent rewards -- for anatomy reconstruction and
safe reinforcement learning for surgery. Our results demonstrate successful
policy learning across a range of scenarios, while also highlighting the
limitations of current methods in clinically relevant environments. We believe
our simulation can facilitate research in robot learning approaches for such
challenging robotic surgery applications. Dataset, codes, and videos are
publicly available at https://sonogym.github.io/.

</details>


### [115] [A Differentiable Distance Metric for Robotics Through Generalized Alternating Projection](https://arxiv.org/abs/2507.01181)
*Vinicius M. Gonçalves,Shiqing Wei,Eduardo Malacarne S. de Souza,Krishnamurthy Prashanth,Anthony Tzes,Farshad Khorrami*

Main category: cs.RO

TL;DR: 论文提出了一种更简单实用的平滑投影方法，适用于一般凸多面体，解决了现有可微距离度量的问题。


<details>
  <summary>Details</summary>
Motivation: 传统欧几里得距离不可微，而现有可微距离度量存在重要缺陷，需要改进。

Method: 提供了更简单实用的平滑投影表达式，确保距离在物体重叠时消失。

Result: 实验结果表明了方法的有效性，并通过Python仿真包UAIBot公开了提出的距离度量。

Conclusion: 新方法解决了现有可微距离度量的缺陷，具有实用性和有效性。

Abstract: In many robotics applications, it is necessary to compute not only the
distance between the robot and the environment, but also its derivative - for
example, when using control barrier functions. However, since the traditional
Euclidean distance is not differentiable, there is a need for alternative
distance metrics that possess this property. Recently, a metric with guaranteed
differentiability was proposed [1]. This approach has some important drawbacks,
which we address in this paper. We provide much simpler and practical
expressions for the smooth projection for general convex polytopes.
Additionally, as opposed to [1], we ensure that the distance vanishes as the
objects overlap. We show the efficacy of the approach in experimental results.
Our proposed distance metric is publicly available through the Python-based
simulation package UAIBot.

</details>


### [116] [Search-Based Robot Motion Planning With Distance-Based Adaptive Motion Primitives](https://arxiv.org/abs/2507.01198)
*Benjamin Kraljusic,Zlatan Ajanovic,Nermin Covic,Bakir Lacevic*

Main category: cs.RO

TL;DR: 提出了一种结合采样和搜索的运动规划算法，利用自由配置空间的burs作为自适应运动基元，显著提高了路径规划效率。


<details>
  <summary>Details</summary>
Motivation: 传统固定大小的运动基元在复杂环境中效率较低，特别是对于高自由度机械臂，需要更高效的探索方法。

Method: 使用自由配置空间的burs作为自适应运动基元，结合图搜索算法，在SMPL库中实现。

Result: 在复杂场景中，特别是高自由度机械臂，bur-based方法优于固定基元规划，简单场景中性能相当。

Conclusion: 自适应burs显著提升了运动规划效率，尤其适用于复杂环境和高自由度机械臂。

Abstract: This work proposes a motion planning algorithm for robotic manipulators that
combines sampling-based and search-based planning methods. The core
contribution of the proposed approach is the usage of burs of free
configuration space (C-space) as adaptive motion primitives within the graph
search algorithm. Due to their feature to adaptively expand in free C-space,
burs enable more efficient exploration of the configuration space compared to
fixed-sized motion primitives, significantly reducing the time to find a valid
path and the number of required expansions. The algorithm is implemented within
the existing SMPL (Search-Based Motion Planning Library) library and evaluated
through a series of different scenarios involving manipulators with varying
number of degrees-of-freedom (DoF) and environment complexity. Results
demonstrate that the bur-based approach outperforms fixed-primitive planning in
complex scenarios, particularly for high DoF manipulators, while achieving
comparable performance in simpler scenarios.

</details>


### [117] [BioMARS: A Multi-Agent Robotic System for Autonomous Biological Experiments](https://arxiv.org/abs/2507.01485)
*Yibo Qiu,Zan Huang,Zhiyu Wang,Handi Liu,Yiling Qiao,Yifeng Hu,Shu'ang Sun,Hangke Peng,Ronald X Xu,Mingzhai Sun*

Main category: cs.RO

TL;DR: BioMARS是一个结合LLMs、VLMs和模块化机器人的智能平台，用于自主设计、规划和执行生物实验，性能优于人工操作。


<details>
  <summary>Details</summary>
Motivation: 解决现有LLMs和VLMs在生物研究中应用受限的问题，如协议设计僵化、适应性不足和操作复杂。

Method: 采用分层架构：Biologist Agent生成协议，Technician Agent转化为可执行代码，Inspector Agent通过多模态感知确保完整性。

Result: 在细胞传代和培养任务中性能优于人工，并在视网膜色素上皮细胞分化中表现更优。

Conclusion: BioMARS展示了AI驱动的实验室自动化的可行性，语言推理在生物研究中具有变革性作用。

Abstract: Large language models (LLMs) and vision-language models (VLMs) have the
potential to transform biological research by enabling autonomous
experimentation. Yet, their application remains constrained by rigid protocol
design, limited adaptability to dynamic lab conditions, inadequate error
handling, and high operational complexity. Here we introduce BioMARS
(Biological Multi-Agent Robotic System), an intelligent platform that
integrates LLMs, VLMs, and modular robotics to autonomously design, plan, and
execute biological experiments. BioMARS uses a hierarchical architecture: the
Biologist Agent synthesizes protocols via retrieval-augmented generation; the
Technician Agent translates them into executable robotic pseudo-code; and the
Inspector Agent ensures procedural integrity through multimodal perception and
anomaly detection. The system autonomously conducts cell passaging and culture
tasks, matching or exceeding manual performance in viability, consistency, and
morphological integrity. It also supports context-aware optimization,
outperforming conventional strategies in differentiating retinal pigment
epithelial cells. A web interface enables real-time human-AI collaboration,
while a modular backend allows scalable integration with laboratory hardware.
These results highlight the feasibility of generalizable, AI-driven laboratory
automation and the transformative role of language-based reasoning in
biological research.

</details>


### [118] [2024 NASA SUITS Report: LLM-Driven Immersive Augmented Reality User Interface for Robotics and Space Exploration](https://arxiv.org/abs/2507.01206)
*Kathy Zhuang,Zixun Huang,Yukun Song,Rui Li,Yinuo Zhou,Allen Y. Yang*

Main category: cs.RO

TL;DR: URSA是一个基于LLM的AR系统，用于NASA的太空任务，结合了头戴式AR设备、语音控制和机器人跟踪算法，实现了非侵入式的人机交互和实时3D定位。


<details>
  <summary>Details</summary>
Motivation: 解决复杂动态环境中3D物体姿态估计的挑战，满足未来太空任务（如Artemis）的需求，提升人机交互的效率和安全性。

Method: 集成头戴式AR设备、LLM驱动的语音控制、机器人跟踪算法和数字孪生定位技术，使用DTTD-Mobile数据集和ZED2相机进行实时跟踪。

Result: 开发了URSA系统，包括非侵入式AR界面、专用数据集、任务可视化控制台、优化的6DoF姿态估计器和端到端集成方案。

Conclusion: URSA为机器人和航空航天领域提供了可扩展的数字孪生解决方案，推动了AR和机器人技术的结合应用。

Abstract: As modern computing advances, new interaction paradigms have emerged,
particularly in Augmented Reality (AR), which overlays virtual interfaces onto
physical objects. This evolution poses challenges in machine perception,
especially for tasks like 3D object pose estimation in complex, dynamic
environments. Our project addresses critical issues in human-robot interaction
within mobile AR, focusing on non-intrusive, spatially aware interfaces. We
present URSA, an LLM-driven immersive AR system developed for NASA's 2023-2024
SUITS challenge, targeting future spaceflight needs such as the Artemis
missions. URSA integrates three core technologies: a head-mounted AR device
(e.g., HoloLens) for intuitive visual feedback, voice control powered by large
language models for hands-free interaction, and robot tracking algorithms that
enable accurate 3D localization in dynamic settings. To enhance precision, we
leverage digital twin localization technologies, using datasets like
DTTD-Mobile and specialized hardware such as the ZED2 camera for real-world
tracking under noise and occlusion. Our system enables real-time robot control
and monitoring via an AR interface, even in the absence of ground-truth
sensors--vital for hazardous or remote operations. Key contributions include:
(1) a non-intrusive AR interface with LLM-based voice input; (2) a ZED2-based
dataset tailored for non-rigid robotic bodies; (3) a Local Mission Control
Console (LMCC) for mission visualization; (4) a transformer-based 6DoF pose
estimator (DTTDNet) optimized for depth fusion and real-time tracking; and (5)
end-to-end integration for astronaut mission support. This work advances
digital twin applications in robotics, offering scalable solutions for both
aerospace and industrial domains.

</details>


### [119] [Jump-Start Reinforcement Learning with Self-Evolving Priors for Extreme Monopedal Locomotion](https://arxiv.org/abs/2507.01243)
*Ziang Zheng,Guojian Zhan,Shiqi Liu,Yao Lyu,Tao Zhang,Shengbo Eben Li*

Main category: cs.RO

TL;DR: JumpER是一种通过自进化先验分阶段训练强化学习策略的框架，解决了四足机器人在极端欠驱动和极端地形下实现单足跳跃的挑战。


<details>
  <summary>Details</summary>
Motivation: 直接训练策略同时应对极端欠驱动和极端地形（如单足跳跃任务）的困难，源于早期交互不稳定和奖励反馈不可靠。

Method: JumpER通过多阶段逐步增加复杂性的策略学习，动态生成自进化先验，结合三阶段课程（动作模态、观测空间和任务目标的逐步演化）。

Result: 实现了四足机器人在不可预测地形上的稳健单足跳跃，能应对传统方法难以处理的挑战（如60厘米宽间隙、不规则台阶等）。

Conclusion: JumpER为极端欠驱动和极端地形下的运动任务提供了原则性和可扩展的解决方案。

Abstract: Reinforcement learning (RL) has shown great potential in enabling quadruped
robots to perform agile locomotion. However, directly training policies to
simultaneously handle dual extreme challenges, i.e., extreme underactuation and
extreme terrains, as in monopedal hopping tasks, remains highly challenging due
to unstable early-stage interactions and unreliable reward feedback. To address
this, we propose JumpER (jump-start reinforcement learning via self-evolving
priors), an RL training framework that structures policy learning into multiple
stages of increasing complexity. By dynamically generating self-evolving priors
through iterative bootstrapping of previously learned policies, JumpER
progressively refines and enhances guidance, thereby stabilizing exploration
and policy optimization without relying on external expert priors or
handcrafted reward shaping. Specifically, when integrated with a structured
three-stage curriculum that incrementally evolves action modality, observation
space, and task objective, JumpER enables quadruped robots to achieve robust
monopedal hopping on unpredictable terrains for the first time. Remarkably, the
resulting policy effectively handles challenging scenarios that traditional
methods struggle to conquer, including wide gaps up to 60 cm, irregularly
spaced stairs, and stepping stones with distances varying from 15 cm to 35 cm.
JumpER thus provides a principled and scalable approach for addressing
locomotion tasks under the dual challenges of extreme underactuation and
extreme terrains.

</details>


### [120] [LLM-based Realistic Safety-Critical Driving Video Generation](https://arxiv.org/abs/2507.01264)
*Yongjie Fu,Ruijian Zha,Pei Tian,Xuan Di*

Main category: cs.RO

TL;DR: 提出了一种利用大型语言模型（LLMs）生成驾驶场景代码的框架，结合CARLA模拟器和视频生成技术，用于测试自动驾驶系统的安全性和多样性。


<details>
  <summary>Details</summary>
Motivation: 设计多样且安全关键的驾驶场景对评估自动驾驶系统至关重要，但手动生成复杂场景效率低。

Method: 利用LLMs进行少样本代码生成，结合CARLA模拟器和视频生成技术（Cosmos-Transfer1与ControlNet），自动合成安全关键的驾驶场景。

Result: 实验表明，该方法能高效生成多样且真实的驾驶场景，尤其是罕见但关键的安全事件。

Conclusion: 该框架为自动驾驶系统的仿真测试提供了高效且可控的工具。

Abstract: Designing diverse and safety-critical driving scenarios is essential for
evaluating autonomous driving systems. In this paper, we propose a novel
framework that leverages Large Language Models (LLMs) for few-shot code
generation to automatically synthesize driving scenarios within the CARLA
simulator, which has flexibility in scenario scripting, efficient code-based
control of traffic participants, and enforcement of realistic physical
dynamics. Given a few example prompts and code samples, the LLM generates
safety-critical scenario scripts that specify the behavior and placement of
traffic participants, with a particular focus on collision events. To bridge
the gap between simulation and real-world appearance, we integrate a video
generation pipeline using Cosmos-Transfer1 with ControlNet, which converts
rendered scenes into realistic driving videos. Our approach enables
controllable scenario generation and facilitates the creation of rare but
critical edge cases, such as pedestrian crossings under occlusion or sudden
vehicle cut-ins. Experimental results demonstrate the effectiveness of our
method in generating a wide range of realistic, diverse, and safety-critical
scenarios, offering a promising tool for simulation-based testing of autonomous
vehicles.

</details>


### [121] [VLAD: A VLM-Augmented Autonomous Driving Framework with Hierarchical Planning and Interpretable Decision Process](https://arxiv.org/abs/2507.01284)
*Cristian Gariboldi,Hayato Tokida,Ken Kinjo,Yuki Asada,Alexander Carballo*

Main category: cs.RO

TL;DR: VLAD模型通过将视觉语言模型（VLM）与端到端自动驾驶系统（VAD）结合，提升了自动驾驶的感知、预测和规划能力，并生成可解释的驾驶决策。


<details>
  <summary>Details</summary>
Motivation: 利用开源视觉语言模型（如LLaVA、Qwen-VL）的通用知识，增强自动驾驶系统的透明性和性能。

Method: 采用定制问答数据集对VLM进行微调，提升其空间推理能力，生成高级导航指令供VAD处理。

Result: 在nuScenes数据集上，碰撞率平均降低31.82%，为VLM增强的自动驾驶系统设定了新基准。

Conclusion: VLAD模型通过结合VLM和VAD，显著提升了自动驾驶系统的性能和透明度。

Abstract: Recent advancements in open-source Visual Language Models (VLMs) such as
LLaVA, Qwen-VL, and Llama have catalyzed extensive research on their
integration with diverse systems. The internet-scale general knowledge
encapsulated within these models presents significant opportunities for
enhancing autonomous driving perception, prediction, and planning capabilities.
In this paper we propose VLAD, a vision-language autonomous driving model,
which integrates a fine-tuned VLM with VAD, a state-of-the-art end-to-end
system. We implement a specialized fine-tuning approach using custom
question-answer datasets designed specifically to improve the spatial reasoning
capabilities of the model. The enhanced VLM generates high-level navigational
commands that VAD subsequently processes to guide vehicle operation.
Additionally, our system produces interpretable natural language explanations
of driving decisions, thereby increasing transparency and trustworthiness of
the traditionally black-box end-to-end architecture. Comprehensive evaluation
on the real-world nuScenes dataset demonstrates that our integrated system
reduces average collision rates by 31.82% compared to baseline methodologies,
establishing a new benchmark for VLM-augmented autonomous driving systems.

</details>


### [122] [LANet: A Lane Boundaries-Aware Approach For Robust Trajectory Prediction](https://arxiv.org/abs/2507.01308)
*Muhammad Atta ur Rahman,Dooseop Choi,KyoungWook Min*

Main category: cs.RO

TL;DR: 提出了一种基于多向量地图元素的运动预测模型，通过融合车道边界和道路边缘等信息，提升自动驾驶车辆轨迹预测的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 当前基于车道中心线的运动预测模型无法充分捕捉道路环境和交通规则，限制了预测能力。

Method: 开发了特征融合策略和剪枝机制，结合多向量地图元素并优化计算效率。

Result: 在Argoverse 2数据集上验证了模型的竞争力，性能优于现有方法。

Conclusion: 该方法提供了更丰富、高效的驾驶环境表示，推动了自动驾驶运动预测技术的发展。

Abstract: Accurate motion forecasting is critical for safe and efficient autonomous
driving, enabling vehicles to predict future trajectories and make informed
decisions in complex traffic scenarios. Most of the current designs of motion
prediction models are based on the major representation of lane centerlines,
which limits their capability to capture critical road environments and traffic
rules and constraints. In this work, we propose an enhanced motion forecasting
model informed by multiple vector map elements, including lane boundaries and
road edges, that facilitates a richer and more complete representation of
driving environments. An effective feature fusion strategy is developed to
merge information in different vector map components, where the model learns
holistic information on road structures and their interactions with agents.
Since encoding more information about the road environment increases memory
usage and is computationally expensive, we developed an effective pruning
mechanism that filters the most relevant map connections to the target agent,
ensuring computational efficiency while maintaining essential spatial and
semantic relationships for accurate trajectory prediction. Overcoming the
limitations of lane centerline-based models, our method provides a more
informative and efficient representation of the driving environment and
advances the state of the art for autonomous vehicle motion forecasting. We
verify our approach with extensive experiments on the Argoverse 2 motion
forecasting dataset, where our method maintains competitiveness on AV2 while
achieving improved performance.
  Index Terms-Autonomous driving, trajectory prediction, vector map elements,
road topology, connection pruning, Argoverse 2.

</details>


### [123] [TriVLA: A Unified Triple-System-Based Unified Vision-Language-Action Model for General Robot Control](https://arxiv.org/abs/2507.01424)
*Zhenyang Liu,Yongchong Gu,Sixiao Zheng,Xiangyang Xue,Yanwei Fu*

Main category: cs.RO

TL;DR: TriVLA是一种统一的三系统架构视觉-语言-动作模型，用于通用机器人控制，通过动态感知模块捕捉静态和动态信息，优于现有模仿学习方法。


<details>
  <summary>Details</summary>
Motivation: 现有自回归VLA方法多关注静态信息，忽视了动态信息对机器人任务的重要性。

Method: TriVLA采用三系统架构：视觉语言模块（System 2）解析环境，动态感知模块（System 3）生成包含静态和动态信息的视觉表示，策略学习模块（System 1）实时生成动作。

Result: TriVLA在36 Hz下运行，在仿真和真实世界任务中优于现有模仿学习方法。

Conclusion: TriVLA通过动态感知模块提升了机器人控制的性能，展现了在复杂任务中的潜力。

Abstract: Recent advancements in vision-language models (VLMs) for common-sense
reasoning have led to the development of vision-language-action (VLA) models,
enabling robots to perform generalized manipulation. Although existing
autoregressive VLA methods design a specific architecture like dual-system to
leverage large-scale pretrained knowledge, they tend to capture static
information, often neglecting the dynamic aspects vital for embodied tasks. To
this end, we propose TriVLA, a unified Vision-Language-Action model with a
triple-system architecture for general robot control. The vision-language
module (System 2) interprets the environment through vision and language
instructions. The dynamics perception module (System 3) inherently produces
visual representations that encompass both current static information and
predicted future dynamics, thereby providing valuable guidance for policy
learning. TriVLA utilizes pre-trained VLM model and fine-tunes pre-trained
video foundation model on robot datasets along with internet human manipulation
data. The subsequent policy learning module (System 1) generates fluid motor
actions in real time. Experimental evaluation demonstrates that TriVLA operates
at approximately 36 Hz and surpasses state-of-the-art imitation learning
baselines on standard simulation benchmarks as well as challenging real-world
manipulation tasks.

</details>


### [124] [Approximation-free Control of Unknown Euler-Lagrangian Systems under Input Constraints](https://arxiv.org/abs/2507.01426)
*Ratnangshu Das,Pushpak Jagtap*

Main category: cs.RO

TL;DR: 提出了一种基于漏斗的跟踪控制算法，用于具有未知动态和输入约束的机器人系统，通过两种无近似控制策略确保跟踪误差在预设范围内。


<details>
  <summary>Details</summary>
Motivation: 解决机器人系统在性能与执行器安全性之间的权衡问题，特别是在输入受限的情况下。

Method: 采用Euler-Lagrange建模，提出两种无近似控制策略：一种主动修正误差，另一种阻止进一步偏离。

Result: 通过仿真和实验验证了算法的鲁棒性能和安全性。

Conclusion: 该研究显著提升了漏斗控制在现实机器人系统中的适用性。

Abstract: In this paper, we present a novel funnel-based tracking control algorithm for
robotic systems with unknown dynamics and prescribed input constraints. The
Euler-Lagrange formulation, a common modeling approach for robotic systems, has
been adopted in this study to address the trade-off between performance and
actuator safety. We establish feasibility conditions that ensure tracking
errors evolve within predefined funnel bounds while maintaining bounded control
efforts, a crucial consideration for robots with limited actuation
capabilities. We propose two approximation-free control strategies for
scenarios where these conditions are violated: one actively corrects the error,
and the other stops further deviation. Finally, we demonstrate the robust
performance and safety of the approach through simulations and experimental
validations. This work represents a significant advancement in funnel-based
control, enhancing its applicability to real-world robotics systems with input
constraints.

</details>


### [125] [Quantum-Assisted Automatic Path-Planning for Robotic Quality Inspection in Industry 4.0](https://arxiv.org/abs/2507.01462)
*Eneko Osaba,Estibaliz Garrote,Pablo Miranda-Rodriguez,Alessia Ciacco,Itziar Cabanes,Aitziber Mancisidor*

Main category: cs.RO

TL;DR: 研究探讨了混合量子-经典算法在工业环境中优化基于CAD模型的机器人检测轨迹的应用，展示了量子方法在自动化中的潜力。


<details>
  <summary>Details</summary>
Motivation: 探索量子计算在工业自动化中的应用，特别是在优化机器人检测轨迹方面，以提升效率。

Method: 将任务建模为3D旅行商问题的变体，比较D-Wave量子求解器与经典方法（如GUROBI和Google OR-Tools）的性能。

Result: 在五个实际案例中，量子方法在解质量和计算时间上表现出竞争力。

Conclusion: 量子方法在工业4.0自动化中具有显著潜力，尤其是在计算效率方面。

Abstract: This work explores the application of hybrid quantum-classical algorithms to
optimize robotic inspection trajectories derived from Computer-Aided Design
(CAD) models in industrial settings. By modeling the task as a 3D variant of
the Traveling Salesman Problem, incorporating incomplete graphs and open-route
constraints, this study evaluates the performance of two D-Wave-based solvers
against classical methods such as GUROBI and Google OR-Tools. Results across
five real-world cases demonstrate competitive solution quality with
significantly reduced computation times, highlighting the potential of quantum
approaches in automation under Industry 4.0.

</details>


### [126] [Dynamic System Model Generation for Online Fault Detection and Diagnosis of Robotic Systems](https://arxiv.org/abs/2507.01550)
*Johannes Kohl,Georg Muck,Georg Jäger,Sebastian Zug*

Main category: cs.RO

TL;DR: 提出了一种动态生成系统模型的方法，用于机器人系统的故障检测与诊断，减少对预定义模型和历史数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 随着机器人系统复杂性的增加，传统故障检测与诊断方法因依赖预定义模型和历史数据而难以适应动态变化。

Method: 在运行时动态生成系统模型，并利用该模型定位故障根源，适用于具有相似软件设计的各类机器人系统。

Result: 该方法减少了对专家干预的依赖，同时实现了较低的运行开销。

Conclusion: 提出的方法为动态机器人系统提供了一种高效、自适应的故障检测与诊断解决方案。

Abstract: With the rapid development of more complex robots, Fault Detection and
Diagnosis (FDD) becomes increasingly harder. Especially the need for
predetermined models and historic data is problematic because they do not
encompass the dynamic and fast-changing nature of such systems. To this end, we
propose a concept that actively generates a dynamic system model at runtime and
utilizes it to locate root causes. The goal is to be applicable to all kinds of
robotic systems that share a similar software design. Additionally, it should
exhibit minimal overhead and enhance independence from expert attention.

</details>


### [127] [Self-Closing Suction Grippers for Industrial Grasping via Form-Flexible Design](https://arxiv.org/abs/2507.01561)
*Huijiang Wang,Holger Kunz,Timon Adler,Fumiya Iida*

Main category: cs.RO

TL;DR: 提出了一种基于混合堵塞和吸力机制的形状可变夹具，用于自适应抓取，能够处理尺寸差异大的物体。


<details>
  <summary>Details</summary>
Motivation: 传统夹具难以适应尺寸差异大的物体，因此需要一种更灵活的夹具设计。

Method: 采用混合堵塞和吸力机制，通过被动变形实现自适应抓取。

Result: 夹具能够抓取尺寸仅为孔径54.5%的物体（如鸡蛋），并实现94.3的最大负载质量比。

Conclusion: 混合夹具展示了在自适应抓取中的高效性和灵活性。

Abstract: Shape-morphing robots have shown benefits in industrial grasping. We propose
form-flexible grippers for adaptive grasping. The design is based on the hybrid
jamming and suction mechanism, which deforms to handle objects that vary
significantly in size from the aperture, including both larger and smaller
parts. Compared with traditional grippers, the gripper achieves self-closing to
form an airtight seal. Under a vacuum, a wide range of grasping is realized
through the passive morphing mechanism at the interface that harmonizes
pressure and flow rate. This hybrid gripper showcases the capability to
securely grasp an egg, as small as 54.5% of its aperture, while achieving a
maximum load-to-mass ratio of 94.3.

</details>


### [128] [An RRT* algorithm based on Riemannian metric model for optimal path planning](https://arxiv.org/abs/2507.01697)
*Yu Zhang,Qi Zhou,Xiao-Song Yang*

Main category: cs.RO

TL;DR: 提出了一种基于黎曼度量的模型，用于解决高维空间中二维光滑子流形上的最优路径规划问题，通过构造新的黎曼度量将问题转化为二维平面上的几何问题，并提出了增量算法RRT*-R。


<details>
  <summary>Details</summary>
Motivation: 解决高维空间中机器人路径规划问题，尤其是在复杂环境下（如高度变化剧烈、地面阻力不均等）的路径优化需求。

Method: 在高维空间中构造二维投影平面上的新黎曼度量，并基于此提出增量算法RRT*-R。

Result: RRT*-R算法在复杂多维场景中表现优异，能有效避开环境障碍，路径平滑且优化性能优于原始RRT*算法。

Conclusion: RRT*-R算法在高维路径规划中具有更好的平滑性和优化性能，路径长度接近理论最小测地距离。

Abstract: This paper presents a Riemannian metric-based model to solve the optimal path
planning problem on two-dimensional smooth submanifolds in high-dimensional
space. Our model is based on constructing a new Riemannian metric on a
two-dimensional projection plane, which is induced by the high-dimensional
Euclidean metric on two-dimensional smooth submanifold and reflects the
environmental information of the robot. The optimal path planning problem in
high-dimensional space is therefore transformed into a geometric problem on the
two-dimensional plane with new Riemannian metric. Based on the new Riemannian
metric, we proposed an incremental algorithm RRT*-R on the projection plane.
The experimental results show that the proposed algorithm is suitable for
scenarios with uneven fields in multiple dimensions. The proposed algorithm can
help the robot to effectively avoid areas with drastic changes in height,
ground resistance and other environmental factors. More importantly, the RRT*-R
algorithm shows better smoothness and optimization properties compared with the
original RRT* algorithm using Euclidean distance in high-dimensional workspace.
The length of the entire path by RRT*-R is a good approximation of the
theoretical minimum geodesic distance on projection plane.

</details>


### [129] [Efficient Collision Detection for Long and Slender Robotic Links in Euclidean Distance Fields: Application to a Forestry Crane](https://arxiv.org/abs/2507.01705)
*Marc-Philip Ecker,Bernhard Bischof,Minh Nhat Vu,Christoph Fröhlich,Tobias Glück,Wolfgang Kemmetmüller*

Main category: cs.RO

TL;DR: 提出了一种针对细长机械臂的新型碰撞检测算法，显著提高了运动规划的计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统基于球体近似的方法在处理细长机械臂时效率低且不准确，需要改进。

Method: 利用机械臂的细长结构设计新型碰撞检测算法，无需调整近似精度参数。

Result: 在真实LiDAR数据和模拟环境中验证了算法的高效性。

Conclusion: 该算法显著提升了细长机械臂运动规划的计算效率和准确性。

Abstract: Collision-free motion planning in complex outdoor environments relies heavily
on perceiving the surroundings through exteroceptive sensors. A widely used
approach represents the environment as a voxelized Euclidean distance field,
where robots are typically approximated by spheres. However, for large-scale
manipulators such as forestry cranes, which feature long and slender links,
this conventional spherical approximation becomes inefficient and inaccurate.
This work presents a novel collision detection algorithm specifically designed
to exploit the elongated structure of such manipulators, significantly
enhancing the computational efficiency of motion planning algorithms. Unlike
traditional sphere decomposition methods, our approach not only improves
computational efficiency but also naturally eliminates the need to fine-tune
the approximation accuracy as an additional parameter. We validate the
algorithm's effectiveness using real-world LiDAR data from a forestry crane
application, as well as simulated environment data.

</details>


### [130] [SE(3)-Equivariant Diffusion Policy in Spherical Fourier Space](https://arxiv.org/abs/2507.01723)
*Xupeng Zhu,Fan Wang,Robin Walters,Jane Shi*

Main category: cs.RO

TL;DR: 提出了一种SE(3)等变的球形扩散策略（SDP），通过球形傅里叶空间嵌入状态和动作，实现了对3D场景变换的鲁棒泛化。


<details>
  <summary>Details</summary>
Motivation: 扩散策略在3D空间中物体排列变化时泛化能力差，影响实际性能。

Method: 采用球形傅里叶空间嵌入状态和动作，设计球形FiLM层和球形去噪时间U-net，实现SE(3)等变性。

Result: 在20个仿真任务和5个物理机器人任务中表现优于基线。

Conclusion: SDP通过SE(3)等变性显著提升了3D场景变换下的泛化能力。

Abstract: Diffusion Policies are effective at learning closed-loop manipulation
policies from human demonstrations but generalize poorly to novel arrangements
of objects in 3D space, hurting real-world performance. To address this issue,
we propose Spherical Diffusion Policy (SDP), an SE(3) equivariant diffusion
policy that adapts trajectories according to 3D transformations of the scene.
Such equivariance is achieved by embedding the states, actions, and the
denoising process in spherical Fourier space. Additionally, we employ novel
spherical FiLM layers to condition the action denoising process equivariantly
on the scene embeddings. Lastly, we propose a spherical denoising temporal
U-net that achieves spatiotemporal equivariance with computational efficiency.
In the end, SDP is end-to-end SE(3) equivariant, allowing robust generalization
across transformed 3D scenes. SDP demonstrates a large performance improvement
over strong baselines in 20 simulation tasks and 5 physical robot tasks
including single-arm and bi-manual embodiments. Code is available at
https://github.com/amazon-science/Spherical_Diffusion_Policy.

</details>


### [131] [Augmented Bridge Spinal Fixation: A New Concept for Addressing Pedicle Screw Pullout via a Steerable Drilling Robot and Flexible Pedicle Screws](https://arxiv.org/abs/2507.01753)
*Yash Kulkarni,Susheela Sharma,Omid Rezayof,Siddhartha Kapuria,Jordan P. Amadio,Mohsen Khadem,Maryam Tilton,Farshid Alambeigi*

Main category: cs.RO

TL;DR: 提出了一种增强桥接脊柱固定（AB-SF）技术，利用可操纵钻孔机器人和柔性椎弓根螺钉解决传统刚性螺钉的松动和拔出问题。


<details>
  <summary>Details</summary>
Motivation: 传统刚性椎弓根螺钉在脊柱固定中存在松动和拔出的局限性，需要一种更可靠的技术。

Method: 使用可操纵钻孔机器人（CT-SDR）在椎弓根中钻出J形隧道，植入柔性椎弓根螺钉（FPS），并通过FPS注入骨水泥形成增强桥接。

Result: 成功在椎骨模型中钻出不同深度的J形隧道，植入FPS并模拟骨水泥增强过程。

Conclusion: AB-SF技术具有可行性，有望提高脊柱固定的强度和稳定性。

Abstract: To address the screw loosening and pullout limitations of rigid pedicle
screws in spinal fixation procedures, and to leverage our recently developed
Concentric Tube Steerable Drilling Robot (CT-SDR) and Flexible Pedicle Screw
(FPS), in this paper, we introduce the concept of Augmented Bridge Spinal
Fixation (AB-SF). In this concept, two connecting J-shape tunnels are first
drilled through pedicles of vertebra using the CT-SDR. Next, two FPSs are
passed through this tunnel and bone cement is then injected through the
cannulated region of the FPS to form an augmented bridge between two pedicles
and reinforce strength of the fixated spine. To experimentally analyze and
study the feasibility of AB-SF technique, we first used our robotic system
(i.e., a CT-SDR integrated with a robotic arm) to create two different fixation
scenarios in which two J-shape tunnels, forming a bridge, were drilled at
different depth of a vertebral phantom. Next, we implanted two FPSs within the
drilled tunnels and then successfully simulated the bone cement augmentation
process.

</details>


### [132] [S3D: A Spatial Steerable Surgical Drilling Framework for Robotic Spinal Fixation Procedures](https://arxiv.org/abs/2507.01779)
*Daniyal Maroufi,Xinyuan Huang,Yash Kulkarni,Omid Rezayof,Susheela Sharma,Vaibhav Goggela,Jordan P. Amadio,Mohsen Khadem,Farshid Alambeigi*

Main category: cs.RO

TL;DR: S3D框架为机器人脊柱固定手术提供空间可操控钻孔技术，结合校准、注册和导航流程，验证了其在椎体模型中的可行性。


<details>
  <summary>Details</summary>
Motivation: 解决脊柱固定手术中因解剖限制导致的钻孔难题，提升手术精准度和安全性。

Method: 改进同心管可操控钻孔机器人（CT-SDR），提出四阶段校准、注册和导航流程，并与七自由度机械臂集成。

Result: 在椎体模型中成功完成平面和非平面可操控钻孔实验。

Conclusion: S3D框架为脊柱固定手术提供了可行的空间可操控钻孔解决方案。

Abstract: In this paper, we introduce S3D: A Spatial Steerable Surgical Drilling
Framework for Robotic Spinal Fixation Procedures. S3D is designed to enable
realistic steerable drilling while accounting for the anatomical constraints
associated with vertebral access in spinal fixation (SF) procedures. To achieve
this, we first enhanced our previously designed concentric tube Steerable
Drilling Robot (CT-SDR) to facilitate steerable drilling across all vertebral
levels of the spinal column. Additionally, we propose a four-Phase calibration,
registration, and navigation procedure to perform realistic SF procedures on a
spine holder phantom by integrating the CT-SDR with a seven-degree-of-freedom
robotic manipulator. The functionality of this framework is validated through
planar and out-of-plane steerable drilling experiments in vertebral phantoms.

</details>


### [133] [Towards Design and Development of a Concentric Tube Steerable Drilling Robot for Creating S-shape Tunnels for Pelvic Fixation Procedures](https://arxiv.org/abs/2507.01811)
*Yash Kulkarni,Susheela Sharma,Sarah Go,Jordan P. Amadio,Mohsen Khadem,Farshid Alambeigi*

Main category: cs.RO

TL;DR: 提出了一种新型4自由度骨盆同心管可操纵钻孔机器人（pelvic CT-SDR），用于解决传统刚性钻孔工具在骨盆手术中的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统刚性钻孔工具限制了螺钉的放置路径，导致手术并发症增多，如螺钉错位、手术时间延长和辐射暴露增加。

Method: 设计并开发了一种4自由度的骨盆同心管可操纵钻孔机器人，能够实现S形钻孔路径。

Result: 在模拟骨模型上进行了多次S形钻孔实验，验证了其性能。

Conclusion: 骨盆CT-SDR能够遵循骨盆自然曲率进行钻孔，有望减少手术并发症。

Abstract: Current pelvic fixation techniques rely on rigid drilling tools, which
inherently constrain the placement of rigid medical screws in the complex
anatomy of pelvis. These constraints prevent medical screws from following
anatomically optimal pathways and force clinicians to fixate screws in linear
trajectories. This suboptimal approach, combined with the unnatural placement
of the excessively long screws, lead to complications such as screw
misplacement, extended surgery times, and increased radiation exposure due to
repeated X-ray images taken ensure to safety of procedure. To address these
challenges, in this paper, we present the design and development of a unique 4
degree-of-freedom (DoF) pelvic concentric tube steerable drilling robot (pelvic
CT-SDR). The pelvic CT-SDR is capable of creating long S-shaped drilling
trajectories that follow the natural curvatures of the pelvic anatomy. The
performance of the pelvic CT-SDR was thoroughly evaluated through several
S-shape drilling experiments in simulated bone phantoms.

</details>


### [134] [MoIRA: Modular Instruction Routing Architecture for Multi-Task Robotics](https://arxiv.org/abs/2507.01843)
*Dmytro Kuzmenko,Nadiya Shvai*

Main category: cs.RO

TL;DR: MoIRA是一个模块化的Mixture-of-Experts框架，通过外部文本路由器协调专家模型，支持零样本路由，并在机器人任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决传统MoE架构中路由机制缺乏灵活性和需要额外训练的问题，提出一种模块化、低开销的解决方案。

Method: 采用嵌入相似性和提示驱动的语言模型推理作为零样本路由选项，结合低秩适配器进行高效推理。

Result: 在GR1 Humanoid和LIBERO基准测试中表现优于通用模型，与其他MoE系统竞争。

Conclusion: MoIRA展示了模块化部署的可行性，为未来多专家机器人系统提供了可扩展的基础。

Abstract: Mixture-of-Experts (MoE) approaches have recently gained traction in robotics
applications due to their ability to dynamically allocate computational
resources and specialize sub-networks for distinct tasks or environmental
contexts, enabling more efficient decision-making. Such systems often comprise
sparsely activated experts combined under a single monolithic architecture and
require a well-configured internal routing mechanism, which does not allow for
selective low-level expert and router customization and requires additional
training. We propose MoIRA, an architecture-agnostic modular MoE framework
designed to coordinate existing experts with an external text-based router.
MoIRA incorporates two zero-shot routing options: embedding-based similarity
and prompt-driven language model inference. In our experiments, we choose large
Vision-Language-Action models, gr00t-N1 and $\pi_0$, as the underlying experts,
and train low-rank adapters for low-overhead inference. We evaluate MoIRA on
various GR1 Humanoid tasks and LIBERO Spatial and Goal benchmarks, where it
consistently outperforms generalist models and competes with other MoE
pipelines. Additionally, we analyse the robustness of the proposed approach to
the variations of the instructions. While relying solely on textual
descriptions of tasks and experts, MoIRA demonstrates the practical viability
of modular deployment with precise, low-effort routing and provides an
alternative, scalable foundation for future multi-expert robotic systems.

</details>


### [135] [TypeTele: Releasing Dexterity in Teleoperation by Dexterous Manipulation Types](https://arxiv.org/abs/2507.01857)
*Yuhao Lin,Yi-Lin Wei,Haoran Liao,Mu Lin,Chengyi Xing,Hao Li,Dandan Zhang,Mark Cutkosky,Wei-Shi Zheng*

Main category: cs.RO

TL;DR: TypeTele是一种类型引导的灵巧远程操作系统，通过引入灵巧操作类型库和MLLM辅助检索模块，使灵巧手能够执行不受人类动作模式限制的任务，显著提升了任务成功率和多样性。


<details>
  <summary>Details</summary>
Motivation: 现有灵巧远程操作主要依赖手部重定向模仿人类手部姿势，未能充分利用灵巧手的结构优势，限制了其执行独特动作的能力。

Method: 提出TypeTele系统，构建可扩展的灵巧操作类型库，并利用MLLM辅助检索模块根据任务和指令选择最合适的操作类型。

Result: 实验表明，引入操作类型后，灵巧机器人能够更高效地完成多样化和复杂任务，成功率显著提升。

Conclusion: TypeTele通过类型引导的远程操作，充分发挥了灵巧手的潜力，为机器人操控提供了新思路。

Abstract: Dexterous teleoperation plays a crucial role in robotic manipulation for
real-world data collection and remote robot control. Previous dexterous
teleoperation mostly relies on hand retargeting to closely mimic human hand
postures. However, these approaches may fail to fully leverage the inherent
dexterity of dexterous hands, which can execute unique actions through their
structural advantages compared to human hands. To address this limitation, we
propose TypeTele, a type-guided dexterous teleoperation system, which enables
dexterous hands to perform actions that are not constrained by human motion
patterns. This is achieved by introducing dexterous manipulation types into the
teleoperation system, allowing operators to employ appropriate types to
complete specific tasks. To support this system, we build an extensible
dexterous manipulation type library to cover comprehensive dexterous postures
used in manipulation tasks. During teleoperation, we employ a MLLM
(Multi-modality Large Language Model)-assisted type retrieval module to
identify the most suitable manipulation type based on the specific task and
operator commands. Extensive experiments of real-world teleoperation and
imitation learning demonstrate that the incorporation of manipulation types
significantly takes full advantage of the dexterous robot's ability to perform
diverse and complex tasks with higher success rates.

</details>


### [136] [A Survey on Vision-Language-Action Models: An Action Tokenization Perspective](https://arxiv.org/abs/2507.01925)
*Yifan Zhong,Fengshuo Bai,Shaofei Cai,Xuchuan Huang,Zhang Chen,Xiaowei Zhang,Yuanfei Wang,Shaoyang Guo,Tianrui Guan,Ka Nam Lui,Zhiquan Qi,Yitao Liang,Yuanpei Chen,Yaodong Yang*

Main category: cs.RO

TL;DR: 本文综述了视觉-语言-动作（VLA）模型的统一框架，重点分析了动作标记的分类及其优缺点，旨在指导未来研究。


<details>
  <summary>Details</summary>
Motivation: 当前VLA模型缺乏对动作标记的全面理解，阻碍了有效开发和未来方向。本文希望通过系统分析填补这一空白。

Method: 通过统一框架分类VLA模型，分析动作标记的八种类型（如语言描述、代码等），并评估其优缺点。

Result: 总结了各类动作标记的特点，指出未充分探索但有潜力的方向。

Conclusion: 本文为VLA模型的未来发展提供了系统性指导，推动通用智能的实现。

Abstract: The remarkable advancements of vision and language foundation models in
multimodal understanding, reasoning, and generation has sparked growing efforts
to extend such intelligence to the physical world, fueling the flourishing of
vision-language-action (VLA) models. Despite seemingly diverse approaches, we
observe that current VLA models can be unified under a single framework: vision
and language inputs are processed by a series of VLA modules, producing a chain
of \textit{action tokens} that progressively encode more grounded and
actionable information, ultimately generating executable actions. We further
determine that the primary design choice distinguishing VLA models lies in how
action tokens are formulated, which can be categorized into language
description, code, affordance, trajectory, goal state, latent representation,
raw action, and reasoning. However, there remains a lack of comprehensive
understanding regarding action tokens, significantly impeding effective VLA
development and obscuring future directions. Therefore, this survey aims to
categorize and interpret existing VLA research through the lens of action
tokenization, distill the strengths and limitations of each token type, and
identify areas for improvement. Through this systematic review and analysis, we
offer a synthesized outlook on the broader evolution of VLA models, highlight
underexplored yet promising directions, and contribute guidance for future
research, hoping to bring the field closer to general-purpose intelligence.

</details>


### [137] [Large Language Model-Driven Closed-Loop UAV Operation with Semantic Observations](https://arxiv.org/abs/2507.01930)
*Wenhao Wang,Yanyan Li,Long Jiao,Jiawei Yuan*

Main category: cs.RO

TL;DR: 提出了一种基于LLM的闭环控制框架，通过反馈和优化实现可靠的无人机操作。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在逻辑推理和复杂决策中的挑战，提升无人机操作的可靠性。

Method: 采用两个LLM模块（代码生成器和评估器），将数值状态转化为自然语言描述，并通过模拟优化代码。

Result: 实验表明，框架在任务复杂时显著优于基线方法，成功率和完整性更高。

Conclusion: 该框架为LLM驱动的无人机操作提供了可靠解决方案。

Abstract: Large Language Models (LLMs) have revolutionized robotic autonomy, including
Unmanned Aerial Vehicles (UAVs). Recent studies have demonstrated the potential
of LLMs for translating human instructions into executable control code for UAV
operations. However, LLMs still face challenges from logical reasoning and
complex decision-making, leading to concerns about the reliability of
LLM-driven UAV operations. In this paper, we propose a LLM-driven closed-loop
control framework that enables reliable UAV operations powered by effective
feedback and refinement using two LLM modules, i.e., a Code Generator and an
Evaluator. Our framework transforms numerical state observations from UAV
operations into natural language trajectory descriptions to enhance the
evaluator LLM's understanding of UAV dynamics for precise feedback generation.
Our framework also enables a simulation-based refinement process, and hence
eliminates the risks to physical UAVs caused by incorrect code execution during
the refinement. Extensive experiments on UAV control tasks with different
complexities are conducted. The experimental results show that our framework
can achieve reliable UAV operations using LLMs, which significantly outperforms
baseline approaches in terms of success rate and completeness with the increase
of task complexity.

</details>


### [138] [AC-DiT: Adaptive Coordination Diffusion Transformer for Mobile Manipulation](https://arxiv.org/abs/2507.01961)
*Sixiang Chen,Jiaming Liu,Siyuan Qian,Han Jiang,Lily Li,Renrui Zhang,Zhuoyang Liu,Chenyang Gu,Chengkai Hou,Pengwei Wang,Zhongyuan Wang,Shanghang Zhang*

Main category: cs.RO

TL;DR: 论文提出了一种自适应协调扩散变换器（AC-DiT），通过显式建模移动底座对机械臂的影响和动态调整多模态感知权重，提升了移动操作任务的协调性和性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在移动操作任务中未能显式建模移动底座对机械臂的影响，且忽视了不同阶段的多模态感知需求，导致协调性不足和性能受限。

Method: AC-DiT引入移动底座到机械臂的条件机制和感知感知的多模态条件策略，动态融合2D和3D视觉输入。

Result: 实验验证了AC-DiT在模拟和真实移动操作任务中的有效性。

Conclusion: AC-DiT通过显式协调和动态感知优化，显著提升了移动操作任务的性能。

Abstract: Recently, mobile manipulation has attracted increasing attention for enabling
language-conditioned robotic control in household tasks. However, existing
methods still face challenges in coordinating mobile base and manipulator,
primarily due to two limitations. On the one hand, they fail to explicitly
model the influence of the mobile base on manipulator control, which easily
leads to error accumulation under high degrees of freedom. On the other hand,
they treat the entire mobile manipulation process with the same visual
observation modality (e.g., either all 2D or all 3D), overlooking the distinct
multimodal perception requirements at different stages during mobile
manipulation. To address this, we propose the Adaptive Coordination Diffusion
Transformer (AC-DiT), which enhances mobile base and manipulator coordination
for end-to-end mobile manipulation. First, since the motion of the mobile base
directly influences the manipulator's actions, we introduce a mobility-to-body
conditioning mechanism that guides the model to first extract base motion
representations, which are then used as context prior for predicting whole-body
actions. This enables whole-body control that accounts for the potential impact
of the mobile base's motion. Second, to meet the perception requirements at
different stages of mobile manipulation, we design a perception-aware
multimodal conditioning strategy that dynamically adjusts the fusion weights
between various 2D visual images and 3D point clouds, yielding visual features
tailored to the current perceptual needs. This allows the model to, for
example, adaptively rely more on 2D inputs when semantic information is crucial
for action prediction, while placing greater emphasis on 3D geometric
information when precise spatial understanding is required. We validate AC-DiT
through extensive experiments on both simulated and real-world mobile
manipulation tasks.

</details>


<div id='cs.HC'></div>

# cs.HC [[Back]](#toc)

### [139] [AI-guided digital intervention with physiological monitoring reduces intrusive memories after experimental trauma](https://arxiv.org/abs/2507.01081)
*Megan T. deBettencourt,Sruthi Sakthivel,Emily A. Holmes,Mark Chevillet*

Main category: cs.HC

TL;DR: ANTIDOTE结合AI指导和瞳孔测量技术，自动提供并监测基于证据的数字治疗（ICTI），显著减少创伤后侵入性记忆，瞳孔大小可作为干预效果的生物标志物。


<details>
  <summary>Details</summary>
Motivation: 全球创伤普遍，基于证据的数字治疗需要人工指导，限制了可扩展性。研究探索生成式AI和神经技术是否能提供可扩展的替代方案。

Method: 100名健康志愿者观看创伤视频后，随机分配到干预组或对照组。ANTIDOTE结合AI指导和瞳孔测量技术，自动实施ICTI干预。

Result: 干预组报告侵入性记忆显著减少，AI指导成功实施干预，瞳孔大小与干预效果相关。

Conclusion: ANTIDOTE为可扩展的AI指导数字干预提供了可行路径，瞳孔大小可作为干预效果的生物标志物。

Abstract: Trauma prevalence is vast globally. Evidence-based digital treatments can
help, but most require human guidance. Human guides provide tailored
instructions and responsiveness to internal cognitive states, but limit
scalability. Can generative AI and neurotechnology provide a scalable
alternative? Here we test ANTIDOTE, combining AI guidance and pupillometry to
automatically deliver and monitor an evidence-based digital treatment,
specifically the Imagery Competing Task Intervention (ICTI), to reduce
intrusive memories after psychological trauma. One hundred healthy volunteers
were exposed to videos of traumatic events and randomly assigned to an
intervention or active control condition. As predicted, intervention
participants reported significantly fewer intrusive memories over the following
week. Post-hoc assessment against clinical rubrics confirmed the AI guide
delivered the intervention successfully. Additionally, pupil size tracked
intervention engagement and predicted symptom reduction, providing a candidate
biomarker of intervention effectiveness. These findings open a path toward
rigorous AI-guided digital interventions that can scale to trauma prevalence.

</details>


### [140] [From Literature to ReWA: Discussing Reproductive Well-being in HCI](https://arxiv.org/abs/2507.01121)
*Hafsah Mahzabin Chowdhury,Sharifa Sultana*

Main category: cs.HC

TL;DR: 本文综述了147篇关于生殖健康的文献，揭示了技术设计中的西方中心主义偏见，提出了ReWA框架以促进包容性设计。


<details>
  <summary>Details</summary>
Motivation: 探讨生殖健康技术如何受文化、宗教、性别和政治因素影响，并揭示现有技术的局限性。

Method: 通过分析2015-2025年的147篇文献，识别出三个主题浪潮，并提出ReWA框架。

Result: 发现技术设计中存在性别、地域和利益相关者的缺失，提出了六个设计导向。

Conclusion: ReWA框架为包容性生殖健康技术设计提供了新方向。

Abstract: Reproductive well-being is shaped by intersecting cultural, religious,
gendered, and political contexts, yet current technologies often reflect
narrow, Western-centric assumptions. In this literature review, we synthesize
findings from 147 peer-reviewed papers published between 2015 and 2025 across
HCI, CSCW and social computing, ICTD, digital and public health, and AI for
well-being scholarship to map the evolving reproductive well-being landscape.
We identify three thematic waves that focused on early access and education,
cultural sensitivity and privacy, and AI integration with policy-aware design,
and highlight how technologies support or constrain diverse reproductive
experiences. Our analysis reveals critical gaps in inclusivity, with persistent
exclusions of men and non-binary users, migrants, and users in the Global
South. Additionally, we surfaced the significant absence of literature on the
role of stakeholders (e.g., husband and family members, household maids and
cleaning helping hands, midwife, etc.) in the reproductive well-being space.
Drawing on the findings from the literature, we propose the ReWA framework to
support reproductive well-being for all agendas through six design orientations
associated with: location, culture, and history; polyvocality and agency;
rationality, temporality, distributive roles, and methodology.

</details>


### [141] [Animated Visual Encoding and Layer Blending for Identification of Educational Game Strategies](https://arxiv.org/abs/2507.01134)
*Braden Roper,William Thompson,Chris Weaver*

Main category: cs.HC

TL;DR: 提出了一种基于动态可视化的工具，用于解决游戏学习数据难以解读的问题。


<details>
  <summary>Details</summary>
Motivation: 游戏学习数据复杂且难以解读，尤其是长期策略分析。

Method: 开发了一种动态可视化工具，通过参数插值曲线和混合层构建动画数据叙事。

Result: 工具能够有效解决数据可视化问题，并满足领域专家的需求。

Conclusion: 动态可视化工具为游戏学习数据的解读提供了新方法。

Abstract: Game-Based Learning has proven to be an effective method for enhancing
engagement with educational material. However, gaining a deeper understanding
of player strategies remains challenging. Sequential game-state and
action-based tracking tools often gather extensive data that can be difficult
to interpret as long-term strategy. This data presents unique problems to
visualization, as it can be fairly natural, noisy data but is constrained
within synthetic, controlled environments, leading to issues such as
overplotting which can make interpretation complicated. We propose an animated
visual encoding tool that utilizes kinetic visualization to address these
issues. This tool enables researchers to construct animated data narratives
through the configuration of parameter interpolation curves and blending
layers. Finally, we demonstrate the usefulness of the tool while addressing
specific interests as outlined by a domain expert collaborator.

</details>


### [142] [A Methodological Framework for Capturing Cognitive-Affective States in Collaborative Learning](https://arxiv.org/abs/2507.01166)
*Sifatul Anindho,Videep Venkatesha,Nathaniel Blanchard*

Main category: cs.HC

TL;DR: 论文探讨了在群体协作中识别个体情感和注意状态的方法，通过回顾性提示回忆范式和改进的报告约束方法，分析了状态报告的频率和时间分布。


<details>
  <summary>Details</summary>
Motivation: 在自然协作中识别个体的情感和注意状态而不干扰协作过程是一个挑战。

Method: 采用回顾性提示回忆范式，并改进为约束报告方法，包括自我报告和响应探针报告。

Result: 分析了状态报告的频率和时间分布，比较了两种数据收集方式的标签分布变化。

Conclusion: 该方法对教育数据挖掘社区在协作学习中跟踪认知情感状态和开发自适应学习系统有重要意义。

Abstract: Identification of affective and attentional states of individuals within
groups is difficult to obtain without disrupting the natural flow of
collaboration. Recent work from our group used a retrospect cued recall
paradigm where participants spoke about their cognitive-affective states while
they viewed videos of their groups. We then collected additional participants
where their reports were constrained to a subset of pre-identified
cognitive-affective states. In this latter case, participants either self
reported or reported in response to probes. Here, we present an initial
analysis of the frequency and temporal distribution of participant reports, and
how the distributions of labels changed across the two collections. Our
approach has implications for the educational data mining community in tracking
cognitive-affective states in collaborative learning more effectively and in
developing improved adaptive learning systems that can detect and respond to
cognitive-affective states.

</details>


### [143] [Judgment as Coordination: A Joint Systems View of Visualization Design Practice](https://arxiv.org/abs/2507.01209)
*Paul C. Parsons,Arran Ridley*

Main category: cs.HC

TL;DR: 本文提出了一种系统级的重新框架，探讨可视化设计中的设计判断，强调协作与适应性在不确定性和约束条件下的作用。


<details>
  <summary>Details</summary>
Motivation: 专业可视化设计的研究多集中于个体设计师的决策，缺乏对协作和系统性维度的关注。本文旨在填补这一空白。

Method: 通过民族志观察设计团队和定性研究个体实践者，分析设计过程中的协调与适应行为。

Result: 研究发现，设计中的一致性并非通过选择最优方案实现，而是通过修复对齐、调整计划和重新定义目标来维持。

Conclusion: 本文通过联合认知系统的视角，为研究设计活动的持续性提供了新的概念框架。

Abstract: Professional visualization design has become an increasingly important area
of inquiry, yet much of the field's discourse remains anchored in
researcher-centered contexts. Studies of design practice often focus on
individual designers' decisions and reflections, offering limited insight into
the collaborative and systemic dimensions of professional work. In this paper,
we propose a systems-level reframing of design judgment grounded in the
coordination and adaptation that sustain progress amid uncertainty, constraint,
and misalignment. Drawing on sustained engagement across multiple empirical
studies--including ethnographic observation of design teams and qualitative
studies of individual practitioners--we identify recurring episodes in which
coherence was preserved not by selecting an optimal option, but by repairing
alignment, adjusting plans, and reframing goals. We interpret these dynamics
through the lens of Joint Cognitive Systems, which provide tools for analyzing
how judgment emerges as a distributed capacity within sociotechnical activity.
This perspective surfaces often-invisible work in visualization design and
offers researchers a new conceptual vocabulary for studying how design activity
is sustained in practice.

</details>


### [144] [AI Meets Maritime Training: Precision Analytics for Enhanced Safety and Performance](https://arxiv.org/abs/2507.01274)
*Vishakha Lall,Yisi Liu*

Main category: cs.HC

TL;DR: 该研究开发了一个AI驱动的框架，通过视觉焦点追踪、语音识别和压力检测，客观评估海事培训学员的表现，提升高风险场景的准备能力。


<details>
  <summary>Details</summary>
Motivation: 传统海事培训依赖主观评估，存在主观性、难以量化关键特征和认知限制等问题。

Method: 整合多种AI技术，包括视觉焦点追踪、语音识别、自然语言处理、压力检测等，并在模拟海事场景中评估模型。

Result: AI算法在视觉检测、语音识别和压力检测上分别达到约92%、91%和90%的准确率，超越现有基准。

Conclusion: 研究表明AI可以革新海事培训，提供客观表现分析、个性化反馈，并提升应对现实挑战的准备能力。

Abstract: Traditional simulator-based training for maritime professionals is critical
for ensuring safety at sea but often depends on subjective trainer assessments
of technical skills, behavioral focus, communication, and body language, posing
challenges such as subjectivity, difficulty in measuring key features, and
cognitive limitations. Addressing these issues, this study develops an
AI-driven framework to enhance maritime training by objectively assessing
trainee performance through visual focus tracking, speech recognition, and
stress detection, improving readiness for high-risk scenarios. The system
integrates AI techniques, including visual focus determination using eye
tracking, pupil dilation analysis, and computer vision; communication analysis
through a maritime-specific speech-to-text model and natural language
processing; communication correctness using large language models; and mental
stress detection via vocal pitch. Models were evaluated on data from simulated
maritime scenarios with seafarers exposed to controlled high-stress events. The
AI algorithms achieved high accuracy, with ~92% for visual detection, ~91% for
maritime speech recognition, and ~90% for stress detection, surpassing existing
benchmarks. The system provides insights into visual attention, adherence to
communication checklists, and stress levels under demanding conditions. This
study demonstrates how AI can transform maritime training by delivering
objective performance analytics, enabling personalized feedback, and improving
preparedness for real-world operational challenges.

</details>


### [145] [Challenges & Opportunities with LLM-Assisted Visualization Retargeting](https://arxiv.org/abs/2507.01436)
*Luke S. Snyder,Chenglong Wang,Steven Drucker*

Main category: cs.HC

TL;DR: 论文探讨了如何利用大语言模型（LLMs）简化可视化图表的代码重定向过程，评估了两种方法的效果及其局限性。


<details>
  <summary>Details</summary>
Motivation: 现有可视化图表的代码重定向过程复杂且耗时，需要用户熟悉代码实现和数据转换。LLMs的进步为自动化代码适配提供了可能。

Method: 比较了两种方法：直接生成代码的文本输入法和基于程序合成的结构化引导法。

Result: 两种方法在数据未适当转换时表现不佳，并总结了失败类型和严重性。

Conclusion: 提出了未来重定向系统的重要设计建议。

Abstract: Despite the ubiquity of visualization examples published on the web,
retargeting existing custom chart implementations to new datasets remains
difficult, time-intensive, and tedious. The adaptation process assumes author
familiarity with both the implementation of the example as well as how the new
dataset might need to be transformed to fit into the example code. With recent
advances in Large Language Models (LLMs), automatic adaptation of code can be
achieved from high-level user prompts, reducing the barrier for visualization
retargeting. To better understand how LLMs can assist retargeting and its
potential limitations, we characterize and evaluate the performance of LLM
assistance across multiple datasets and charts of varying complexity,
categorizing failures according to type and severity. In our evaluation, we
compare two approaches: (1) directly instructing the LLM model to fully
generate and adapt code by treating code as text inputs and (2) a more
constrained program synthesis pipeline where the LLM guides the code
construction process by providing structural information (e.g., visual
encodings) based on properties of the example code and data. We find that both
approaches struggle when new data has not been appropriately transformed, and
discuss important design recommendations for future retargeting systems.

</details>


### [146] [Analysis of Drone-Assisted Building Inspection Training in VR vs 2D Monitor Display: an EEG Study](https://arxiv.org/abs/2507.01471)
*Pengkun Liu,Jackson Greene,Jiali Huang,Pingbo Tang,Yu Hou*

Main category: cs.HC

TL;DR: 研究通过脑电图和动态因果模型揭示了无人机辅助建筑能源审计任务中不同显示模态下大脑区域间的因果连接模式，发现训练前后视觉检查性能相关脑区连接模式相似。


<details>
  <summary>Details</summary>
Motivation: 探索无人机飞行员在信息处理和决策中大脑区域间的信息流路径，以提高隐性知识传递效率。

Method: 使用脑电图和动态因果模型分析参与者处理不同显示模态任务时的大脑区域连接。

Result: 不同模拟组显示出相似的单向连接模式，训练前后视觉检查性能相关脑区连接模式相似。

Conclusion: 研究揭示了大脑不对称性的本质，可用于测量认知状态和设计无人机检查中的自适应自动化知识传递。

Abstract: Researchers have been using simulation-based methods for drone-assisted
inspection training. Multiple brain regions are associated with information
processes and decision-making, and the connectivity of these regions may
further influence inspectors' performance. However, researchers do not
understand the pathways of the information flows when drone pilots process the
maintenance and manipulation of information, which may affect the efficiency of
tacit knowledge transfer. This study aims to reveal the causal connection
between participants' brain regions using an electroencephalogram and dynamic
causal modeling when processing drone-assisted building energy audit tasks
using different display modalities. The results showed similar single-direction
connectivity patterns for the different simulation groups. The results also
showed similar patterns between brain regions related to visual inspection
performance before and after training. These findings highlight the nature of
brain asymmetries and may be utilized in measuring cognitive states and
designing adaptive automation in the knowledge transfer of drone-based
inspection.

</details>


### [147] [Crafting Hanzi as Narrative Bridges: An AI Co-Creation Workshop for Elderly Migrants](https://arxiv.org/abs/2507.01548)
*Wen Zhan,Ziqun Hua,Peiyue Lin,Yunfei Chen*

Main category: cs.HC

TL;DR: 研究探讨老年移民如何通过AI辅助共创表达个人叙事，结合口头讲述和汉字重构，无需数字素养即可将经历转化为视觉和触觉表达。


<details>
  <summary>Details</summary>
Motivation: 探索老年移民在城市化背景下如何通过AI辅助表达被忽视或难以言说的个人叙事。

Method: 通过试点工作坊，结合口头叙事和汉字重构（使用小篆字形），参与者与LLM合作，利用实体材料共创新字符形式。

Result: 参与者成功将生活经历转化为视觉和触觉表达，AI作为支持机制而非内容生产者发挥作用。

Conclusion: 该方法为人类-AI协作和老龄化研究提供了新视角，强调AI在支持叙事能动性中的作用。

Abstract: This paper explores how older adults, particularly aging migrants in urban
China, can engage AI-assisted co-creation to express personal narratives that
are often fragmented, underrepresented, or difficult to verbalize. Through a
pilot workshop combining oral storytelling and the symbolic reconstruction of
Hanzi, participants shared memories of migration and recreated new character
forms using Xiaozhuan glyphs, suggested by the Large Language Model (LLM),
together with physical materials. Supported by human facilitation and a soft AI
presence, participants transformed lived experience into visual and tactile
expressions without requiring digital literacy. This approach offers new
perspectives on human-AI collaboration and aging by repositioning AI not as a
content producer but as a supportive mechanism, and by supporting narrative
agency within sociotechnical systems.

</details>


### [148] [Designing for Community Care: Reimagining Support for Equity & Well-being in Academia](https://arxiv.org/abs/2507.01690)
*Beatriz Severes,Ana O. Henriques,Rory Clark,Paulo Bala,Anna Carter,Rua Mae Williams,Geraldine Fitzpatrick*

Main category: cs.HC

TL;DR: 该研讨会通过HCI方法和参与式设计，探讨如何将关怀、公平和可持续性融入学术同伴支持网络，从非正式模式转向结构化、包容性的生态系统。


<details>
  <summary>Details</summary>
Motivation: 学术幸福感受同伴支持网络影响，但这些网络通常是非正式、不公平且不可持续的，同时机构对教职工的情感劳动关注不足。

Method: 采用HCI方法、参与式设计和关怀伦理，通过会前互动、共同设计和反思活动，分析系统性差距。

Result: 参与者将共同开发设计策略、资源，并建立一个致力于支持学术社区的同伴网络。

Conclusion: 研讨会旨在推动学术支持网络向更具包容性和关怀性的生态系统转变。

Abstract: Academic well-being is deeply influenced by peer-support networks, yet they
remain informal, inequitable, and unsustainable, often relying on personal
connections and social capital rather than structured, inclusive systems.
Additionally, institutional well-being responses frequently focus on student
populations, neglecting the emotional labour of faculty and staff, reinforcing
an exclusionary academic culture. Drawing on HCI methodologies, participatory
design, and care ethics, this workshop will provide a space for rethinking how
academic communities can support inclusive networks. Through pre-workshop
engagement, co-design activities, and reflection, participants will examine
systemic gaps in networks and explore ways to embed care, equity, and
sustainability into academic peer-support frameworks -- from informal,
exclusionary models to structured, inclusive care-based ecosystems. At the end
of the workshop, participants will co-develop design strategies for integrating
care and resilience in academic ecosystems, resources for designing equitable
support systems, and a peer network invested and committed to fostering a
supportive academic community.

</details>


### [149] [Towards culturally-appropriate conversational AI for health in the majority world: An exploratory study with citizens and professionals in Latin America](https://arxiv.org/abs/2507.01719)
*Dorian Peters,Fernanda Espinoza,Marco da Re,Guido Ivetta,Luciana Benotti,Rafael A. Calvo*

Main category: cs.HC

TL;DR: 论文探讨了在多元文化背景下开发适合的对话式AI（CAI）的必要性，提出了一种基于拉丁美洲参与式工作坊的本地化方法，并引入了一个新框架。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型（LLM）未能涵盖全球多样化的生活经验，尤其是在健康领域，需要一种更本地化和文化敏感的方法。

Method: 通过拉丁美洲的参与式工作坊收集定性数据，分析文化错位、区域对健康聊天机器人的看法及文化适应性策略。

Result: 研究发现学术文化概念在现实中失去意义，技术需考虑经济、政治、地理等多维因素，提出了'Pluriversal Conversational AI for Health'框架。

Conclusion: 论文强调关系性和包容性比单纯增加数据更重要，为开发文化敏感的CAI提供了新思路。

Abstract: There is justifiable interest in leveraging conversational AI (CAI) for
health across the majority world, but to be effective, CAI must respond
appropriately within culturally and linguistically diverse contexts. Therefore,
we need ways to address the fact that current LLMs exclude many lived
experiences globally. Various advances are underway which focus on top-down
approaches and increasing training data. In this paper, we aim to complement
these with a bottom-up locally-grounded approach based on qualitative data
collected during participatory workshops in Latin America. Our goal is to
construct a rich and human-centred understanding of: a) potential areas of
cultural misalignment in digital health; b) regional perspectives on chatbots
for health and c)strategies for creating culturally-appropriate CAI; with a
focus on the understudied Latin American context. Our findings show that
academic boundaries on notions of culture lose meaning at the ground level and
technologies will need to engage with a broader framework; one that
encapsulates the way economics, politics, geography and local logistics are
entangled in cultural experience. To this end, we introduce a framework for
'Pluriversal Conversational AI for Health' which allows for the possibility
that more relationality and tolerance, rather than just more data, may be
called for.

</details>


### [150] [Human-Machine Collaboration-Guided Space Design: Combination of Machine Learning Models and Humanistic Design Concepts](https://arxiv.org/abs/2507.01776)
*Yuxuan Yang*

Main category: cs.HC

TL;DR: 论文提出了一种人机协作框架，将机器学习的效率与人类创造力结合，以优化空间设计，同时满足情感和文化需求。


<details>
  <summary>Details</summary>
Motivation: 空间设计中，机器学习虽能提升效率和功能性，但无法单独处理情感、文化和美学等主观维度，需与人类创造力结合。

Method: 提出人机协作框架，利用机器学习自动化设计和优化，人类设计师则负责情感共鸣和文化相关性。

Result: 通过办公和住宅设计的案例研究，展示了该框架如何平衡效率和情感影响。

Conclusion: 结合机器学习与人类创造力，可实现功能性与情感共鸣的空间设计。

Abstract: The integration of machine learning (ML) into spatial design holds immense
potential for optimizing space utilization, enhancing functionality, and
streamlining design processes. ML can automate tasks, predict performance
outcomes, and tailor spaces to user preferences. However, the emotional,
cultural, and aesthetic dimensions of design remain crucial for creating spaces
that truly resonate with users-elements that ML alone cannot address. The key
challenge lies in harmonizing data-driven efficiency with the nuanced,
subjective aspects of design. This paper proposes a human-machine collaboration
framework to bridge this gap. An effective framework should recognize that
while ML enhances design efficiency through automation and prediction, it must
be paired with human creativity to ensure spaces are emotionally engaging and
culturally relevant. Human designers contribute intuition, empathy, and
cultural insight, guiding ML-generated solutions to align with users' emotional
and cultural needs. Additionally, we explore how various ML models can be
integrated with human-centered design principles. These models can automate
design generation and optimization, while human designers refine the outputs to
ensure emotional resonance and aesthetic appeal. Through case studies in office
and residential design, we illustrate how this framework fosters both
creativity and cultural relevance. By merging ML with human creativity, spatial
design can achieve a balance of efficiency and emotional impact, resulting in
environments that are both functional and deeply human.

</details>


### [151] [Bridging UI Design and chatbot Interactions: Applying Form-Based Principles to Conversational Agents](https://arxiv.org/abs/2507.01862)
*Sanjay Krishna Anbalagan,Xinrui Nie,Umesh Mohan,Vijay Kumar Kanamarlapudi,Anughna Kommalapati,Xiaodan Zhao*

Main category: cs.HC

TL;DR: 论文提出了一种在大型语言模型（LLM）提示中显式建模GUI启发的确认（类似提交）和上下文切换（类似重置）任务的方法，以提高领域特定聊天机器人的交互清晰度和效率。


<details>
  <summary>Details</summary>
Motivation: 传统GUI通过显式操作（如提交和重置）明确跟踪用户意图，而对话代理依赖语言线索可能导致上下文管理混乱。

Method: 将GUI启发的确认和上下文切换任务建模为LLM提示中的显式任务，并捕获用户确认、重置操作和思维链（CoT）推理作为结构化会话数据。

Result: 在酒店预订和客户管理场景中验证了方法，提升了多轮任务连贯性、用户满意度和效率。

Conclusion: 通过显式建模GUI隐喻，可以改善聊天机器人的上下文管理和用户交互体验。

Abstract: Domain specific chatbot applications often involve multi step interactions,
such as refining search filters, selecting multiple items, or performing
comparisons. Traditional graphical user interfaces (GUIs) handle these
workflows by providing explicit "Submit" (commit data) and "Reset" (discard
data) actions, allowing back-end systems to track user intent unambiguously. In
contrast, conversational agents rely on subtle language cues, which can lead to
confusion and incomplete context management. This paper proposes modeling these
GUI inspired metaphors acknowledgment (submit like) and context switching
(reset-like) as explicit tasks within large language model (LLM) prompts. By
capturing user acknowledgment, reset actions, and chain of thought (CoT)
reasoning as structured session data, we preserve clarity, reduce user
confusion, and align domain-specific chatbot interactions with back-end logic.
We demonstrate our approach in hotel booking and customer management scenarios,
highlighting improvements in multi-turn task coherence, user satisfaction, and
efficiency.

</details>


### [152] [Spatial tangible user interfaces for cognitive assessment and training](https://arxiv.org/abs/2507.01944)
*Ehud Sharlin,Yuichi Itoh,Benjamin Watson,Yoshifumi Kitamura,Steve Sutphen,Lili Liu,Fumio Kishino*

Main category: cs.HC

TL;DR: 探讨Tangible User Interfaces（TUIs）在认知评估和训练中的潜力，特别是空间TUIs如何通过直觉和直接的方式扩展人机交互。


<details>
  <summary>Details</summary>
Motivation: TUIs（尤其是空间TUIs）可以利用人类天生的空间和触觉能力，突破当前交互技术的限制。

Method: 开发了Cognitive Cubes作为测试平台，用于验证空间TUIs在认知评估和训练中的应用。

Result: 实验结果显示Cognitive Cubes在空间能力评估和训练中具有潜力。

Conclusion: 空间TUIs为认知评估和训练提供了新的可能性，未来值得进一步研究。

Abstract: This paper discusses Tangible User Interfaces (TUIs) and their potential
impact on cognitive assessment and cognitive training. We believe that TUIs,
and particularly a subset that we dub spatial TUIs, can extend human computer
interaction beyond some of its current limitations. Spatial TUIs exploit human
innate spatial and tactile ability in an intuitive and direct manner, affording
interaction paradigms that are practically impossible using current interface
technology. As proof-of-concept we examine implementations in the field of
cognitive assessment and training. In this paper we use Cognitive Cubes, a
novel TUI we developed, as an applied test bed for our beliefs, presenting
promising experimental results for cognitive assessment of spatial ability, and
possibly for training purposes.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [153] [A LoD of Gaussians: Unified Training and Rendering for Ultra-Large Scale Reconstruction with External Memory](https://arxiv.org/abs/2507.01110)
*Felix Windisch,Lukas Radl,Thomas Köhler,Michael Steiner,Dieter Schmalstieg,Markus Steinberger*

Main category: cs.GR

TL;DR: 提出了一种名为A LoD of Gaussians的框架，用于在单块消费级GPU上训练和渲染超大规模高斯场景，无需分区。


<details>
  <summary>Details</summary>
Motivation: 解决高斯喷绘技术在扩展到大场景时因分区策略导致的边界伪影、训练复杂性和GPU内存限制问题。

Method: 采用混合数据结构（高斯层次结构与顺序点树）和轻量级缓存视图调度系统，动态流式传输相关高斯数据。

Result: 实现了复杂场景的无缝多尺度重建和交互式可视化，支持从广域航拍到细粒度地面细节的渲染。

Conclusion: A LoD of Gaussians框架有效解决了大规模高斯场景的训练和渲染问题，提升了性能和适用性。

Abstract: Gaussian Splatting has emerged as a high-performance technique for novel view
synthesis, enabling real-time rendering and high-quality reconstruction of
small scenes. However, scaling to larger environments has so far relied on
partitioning the scene into chunks -- a strategy that introduces artifacts at
chunk boundaries, complicates training across varying scales, and is poorly
suited to unstructured scenarios such as city-scale flyovers combined with
street-level views. Moreover, rendering remains fundamentally limited by GPU
memory, as all visible chunks must reside in VRAM simultaneously. We introduce
A LoD of Gaussians, a framework for training and rendering ultra-large-scale
Gaussian scenes on a single consumer-grade GPU -- without partitioning. Our
method stores the full scene out-of-core (e.g., in CPU memory) and trains a
Level-of-Detail (LoD) representation directly, dynamically streaming only the
relevant Gaussians. A hybrid data structure combining Gaussian hierarchies with
Sequential Point Trees enables efficient, view-dependent LoD selection, while a
lightweight caching and view scheduling system exploits temporal coherence to
support real-time streaming and rendering. Together, these innovations enable
seamless multi-scale reconstruction and interactive visualization of complex
scenes -- from broad aerial views to fine-grained ground-level details.

</details>


### [154] [Semiautomatic Simplification](https://arxiv.org/abs/2507.01116)
*Gong Li,Benjamin Watson*

Main category: cs.GR

TL;DR: semisimp是一个半自动简化三维多边形模型的工具，允许用户干预简化过程以保留重要语义区域。


<details>
  <summary>Details</summary>
Motivation: 现有自动简化技术对语义区域（如面部和肢体）和动画等使用约束不敏感。

Method: 用户可操纵简化顺序、重新定位顶点并调整模型表面的分层分区。

Result: 工具能够重新分配模型细节并改进简化模型的质量。

Conclusion: semisimp提供了对简化过程的更好控制，适用于需要保留语义细节的场景。

Abstract: We present semisimp, a tool for semiautomatic simplification of three
dimensional polygonal models. Existing automatic simplification technology is
quite mature, but is not sensitive to the heightened importance of distinct
semantic model regions such as faces and limbs, nor to simplification
constraints imposed by model usage such as animation. semisimp allows users to
preserve such regions by intervening in the simplification process. Users can
manipulate the order in which basic simplifications are applied to redistribute
model detail, improve the simplified models themselves by repositioning
vertices with propagation to neighboring levels of detail, and adjust the
hierarchical partitioning of the model surface to segment simplification and
improve control of reordering and position propagation.

</details>


### [155] [Multi-Focus Probes for Context-Preserving Network Exploration and Interaction in Immersive Analytics](https://arxiv.org/abs/2507.01140)
*Eric Zimmermann,Stefan Bruckner*

Main category: cs.GR

TL;DR: 提出了一种多焦点探针技术，用于沉浸式环境中管理局部与全局视图的过渡，支持用户同时操作多个局部子图视图并保持与全局网络的联系。


<details>
  <summary>Details</summary>
Motivation: 解决用户在沉浸式环境中管理局部与全局视图过渡的挑战，提升复杂网络数据的交互与编辑效率。

Method: 采用多焦点探针技术，结合视觉和触觉引导机制，支持用户创建多个局部视图并保持与全局网络的链接。

Result: 技术实现了在沉浸式环境中高效编辑网络数据，同时保持多尺度交互的上下文一致性。

Conclusion: 多焦点探针技术有效解决了沉浸式环境中局部与全局视图管理的难题，提升了网络数据的交互与编辑体验。

Abstract: Immersive visualization of network data enables users to physically navigate
and interact with complex structures, but managing transitions between detailed
local (egocentric) views and global (exocentric) overviews remains a major
challenge. We present a multifocus probe technique for immersive environments
that allows users to instantiate multiple egocentric subgraph views while
maintaining persistent links to the global network context. Each probe acts as
a portable local focus, enabling fine-grained inspection and editing of distant
or occluded regions. Visual and haptic guidance mechanisms ensure context
preservation during multi-scale interaction. We demonstrate and discuss the
usability of our technique for the editing of network data.

</details>


<div id='cs.GT'></div>

# cs.GT [[Back]](#toc)

### [156] [Counterfactual Explanation of Shapley Value in Data Coalitions](https://arxiv.org/abs/2507.01267)
*Michelle Si,Jian Pei*

Main category: cs.GT

TL;DR: 论文探讨了数据联盟中Shapley值的反事实解释问题，提出了SV-Exp算法以高效计算。


<details>
  <summary>Details</summary>
Motivation: 解释数据联盟中所有者的Shapley值是一个未被探索且具有挑战性的任务，需要找到最小的数据子集转移以改变Shapley值。

Method: 通过蒙特卡洛估计和启发式技术（如估计差分Shapley值、计算单数据条目的影响力、贪心子集转移）开发了SV-Exp算法。

Result: 实验证明SV-Exp算法高效，反事实解释能有效解释Shapley值。

Conclusion: 反事实解释存在且有效，SV-Exp算法为解释Shapley值提供了实用工具。

Abstract: The Shapley value is widely used for data valuation in data markets. However,
explaining the Shapley value of an owner in a data coalition is an unexplored
and challenging task. To tackle this, we formulate the problem of finding the
counterfactual explanation of Shapley value in data coalitions. Essentially,
given two data owners $A$ and $B$ such that $A$ has a higher Shapley value than
$B$, a counterfactual explanation is a smallest subset of data entries in $A$
such that transferring the subset from $A$ to $B$ makes the Shapley value of
$A$ less than that of $B$. We show that counterfactual explanations always
exist, but finding an exact counterfactual explanation is NP-hard. Using Monte
Carlo estimation to approximate counterfactual explanations directly according
to the definition is still very costly, since we have to estimate the Shapley
values of owners $A$ and $B$ after each possible subset shift. We develop a
series of heuristic techniques to speed up computation by estimating
differential Shapley values, computing the power of singular data entries, and
shifting subsets greedily, culminating in the SV-Exp algorithm. Our
experimental results on real datasets clearly demonstrate the efficiency of our
method and the effectiveness of counterfactuals in interpreting the Shapley
value of an owner.

</details>


### [157] [Evaluating LLM Agent Collusion in Double Auctions](https://arxiv.org/abs/2507.01413)
*Kushal Agrawal,Verona Teo,Juan J. Vazquez,Sudarsh Kunnavakkam,Vishak Srikanth,Andy Liu*

Main category: cs.GT

TL;DR: 研究探讨了大型语言模型（LLM）作为市场代理时可能出现的合谋行为，分析了沟通能力、模型选择和环境压力对合谋行为的影响。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在社会经济互动中的应用增加，识别其潜在不良行为（如合谋）变得至关重要。

Method: 通过模拟连续双向拍卖市场，研究LLM代理作为卖家的行为，分析沟通能力、模型选择和环境压力对合谋行为的影响。

Result: 直接沟通增加合谋倾向，不同模型的合谋倾向不同，环境压力（如监管和紧迫性）影响合谋行为。

Conclusion: 研究强调了部署基于LLM的市场代理时需考虑的经济和伦理问题。

Abstract: Large language models (LLMs) have demonstrated impressive capabilities as
autonomous agents with rapidly expanding applications in various domains. As
these agents increasingly engage in socioeconomic interactions, identifying
their potential for undesirable behavior becomes essential. In this work, we
examine scenarios where they can choose to collude, defined as secretive
cooperation that harms another party. To systematically study this, we
investigate the behavior of LLM agents acting as sellers in simulated
continuous double auction markets. Through a series of controlled experiments,
we analyze how parameters such as the ability to communicate, choice of model,
and presence of environmental pressures affect the stability and emergence of
seller collusion. We find that direct seller communication increases collusive
tendencies, the propensity to collude varies across models, and environmental
pressures, such as oversight and urgency from authority figures, influence
collusive behavior. Our findings highlight important economic and ethical
considerations for the deployment of LLM-based market agents.

</details>


### [158] [Rational Censorship Attack: Breaking Blockchain with a Blackboard](https://arxiv.org/abs/2507.01453)
*Michelle Yeo,Haoqian Zhang*

Main category: cs.GT

TL;DR: 论文提出了一种基于博弈论的区块链理性审查攻击，揭示了在用户完全理性的假设下，区块链的审查弹性可能被破坏。


<details>
  <summary>Details</summary>
Motivation: 研究区块链安全性时，经济与博弈论视角日益重要，但现有研究未充分探讨理性用户对审查弹性的影响。

Method: 通过博弈论框架建模攻击，假设用户理性且具备足够投票权的合谋团体可以审查其他节点，独占奖励。

Result: 证明攻击策略是子博弈完美均衡，成功攻击需合谋团体公开真实投票权。

Conclusion: 攻击对区块链用户和协议设计者具有深远影响，需探索潜在防御措施。

Abstract: Censorship resilience is a fundamental assumption underlying the security of
blockchain protocols. Additionally, the analysis of blockchain security from an
economic and game theoretic perspective has been growing in popularity in
recent years. In this work, we present a surprising rational censorship attack
on blockchain censorship resilience when we adopt the analysis of blockchain
security from a game theoretic lens and assume all users are rational. In our
attack, a colluding group with sufficient voting power censors the remainder
nodes such that the group alone can gain all the rewards from maintaining the
blockchain. We show that if nodes are rational, coordinating this attack just
requires a public read and write blackboard and we formally model the attack
using a game theoretic framework. Furthermore, we note that to ensure the
success of the attack, nodes need to know the total true voting power held by
the colluding group. We prove that the strategy to join the rational censorship
attack and also for nodes to honestly declare their power is a subgame perfect
equilibrium in the corresponding extensive form game induced by our attack.
Finally, we discuss the implications of the attack on blockchain users and
protocol designers as well as some potential countermeasures.

</details>


<div id='cs.LG'></div>

# cs.LG [[Back]](#toc)

### [159] [Few-Shot Inspired Generative Zero-Shot Learning](https://arxiv.org/abs/2507.01026)
*Md Shakil Ahamed Shohag,Q. M. Jonathan Wu,Farhad Pourpanah*

Main category: cs.LG

TL;DR: FSIGenZ提出了一种基于少样本的生成零样本学习框架，通过动态调整属性评分和原型估计，减少了对大规模特征合成的依赖。


<details>
  <summary>Details</summary>
Motivation: 传统生成零样本学习方法需要大量计算资源和合成数据，且假设所有属性均匀存在，而实际中属性可能存在缺失或部分可见。

Method: 引入模型特定属性评分（MSAS）动态调整属性评分，估计组级原型作为未见类的代表特征，并使用双用途语义正则化（DPSR）训练语义感知对比分类器（SCC）。

Result: 在SUN、AwA2和CUB基准测试中，FSIGenZ使用更少的合成特征实现了竞争性性能。

Conclusion: FSIGenZ通过减少对大规模特征合成的依赖，提高了零样本学习的效率和实用性。

Abstract: Generative zero-shot learning (ZSL) methods typically synthesize visual
features for unseen classes using predefined semantic attributes, followed by
training a fully supervised classification model. While effective, these
methods require substantial computational resources and extensive synthetic
data, thereby relaxing the original ZSL assumptions. In this paper, we propose
FSIGenZ, a few-shot-inspired generative ZSL framework that reduces reliance on
large-scale feature synthesis. Our key insight is that class-level attributes
exhibit instance-level variability, i.e., some attributes may be absent or
partially visible, yet conventional ZSL methods treat them as uniformly
present. To address this, we introduce Model-Specific Attribute Scoring (MSAS),
which dynamically re-scores class attributes based on model-specific
optimization to approximate instance-level variability without access to unseen
data. We further estimate group-level prototypes as clusters of instances based
on MSAS-adjusted attribute scores, which serve as representative synthetic
features for each unseen class. To mitigate the resulting data imbalance, we
introduce a Dual-Purpose Semantic Regularization (DPSR) strategy while training
a semantic-aware contrastive classifier (SCC) using these prototypes.
Experiments on SUN, AwA2, and CUB benchmarks demonstrate that FSIGenZ achieves
competitive performance using far fewer synthetic features.

</details>


### [160] [DBellQuant: Breaking the Bell with Double-Bell Transformation for LLMs Post Training Binarization](https://arxiv.org/abs/2507.01027)
*Zijian Ye,Wei Huang,Yifei Yu,Tianhe Ren,Zhongrui Wang,Xiaojuan Qi*

Main category: cs.LG

TL;DR: DBellQuant是一种创新的后训练量化框架，通过双钟形分布变换减少量化误差，实现1比特权重压缩和6比特激活量化，性能损失极小。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型（LLMs）因计算和内存需求高而难以实际部署的问题，以及现有量化方法因权重分布不友好和激活异常值导致的量化误差问题。

Method: 采用可学习的双钟形变换（LTDB）算法，将单钟形权重分布转换为双钟形以减少二值化误差，并通过逆变换平滑激活。

Result: 在Wikitext2数据集上，DBellQuant在LLaMA2-13B上实现了14.39的困惑度，显著优于BiLLM的21.35。

Conclusion: DBellQuant在激进量化的同时保持模型性能，为LLMs的实际应用提供了高效的压缩方案。

Abstract: Large language models (LLMs) demonstrate remarkable performance but face
substantial computational and memory challenges that limit their practical
deployment. Quantization has emerged as a promising solution; however, its
effectiveness is often limited by quantization errors arising from weight
distributions that are not quantization-friendly and the presence of activation
outliers. To address these challenges, we introduce DBellQuant, an innovative
post-training quantization (PTQ) framework that achieves nearly 1-bit weight
compression and 6-bit activation quantization with minimal performance
degradation. DBellQuant uses Learnable Transformation for Dual-Bell (LTDB)
algorithm, which transforms single-bell weight distributions into dual-bell
forms to reduce binarization errors and applies inverse transformations to
smooth activations. DBellQuant sets a new state-of-the-art by preserving
superior model performance under aggressive weight and activation quantization.
For example, on the Wikitext2 dataset, DBellQuant achieves a perplexity of
14.39 on LLaMA2-13B with 6-bit activation quantization, significantly
outperforming BiLLM's 21.35 without activation quantization, underscoring its
potential in compressing LLMs for real-world applications.

</details>


### [161] [Dual Perspectives on Non-Contrastive Self-Supervised Learning](https://arxiv.org/abs/2507.01028)
*Jean Ponce,Martial Hebert,Basile Terver*

Main category: cs.LG

TL;DR: 论文研究了自监督学习中非对比方法的优化和动态系统视角，证明了停止梯度和指数移动平均方法能避免表征崩溃，并分析了其稳定性。


<details>
  <summary>Details</summary>
Motivation: 探索非对比自监督学习方法中停止梯度和指数移动平均的理论基础，以理解其避免表征崩溃的机制。

Method: 从优化和动态系统的双重理论视角分析停止梯度和指数移动平均方法，并通过线性案例验证其有效性。

Result: 证明这些方法虽不优化原始目标函数，但能避免崩溃；在动态系统中，其极限点是渐近稳定的平衡点。

Conclusion: 停止梯度和指数移动平均方法在非对比自监督学习中有效避免崩溃，且具有理论稳定性。

Abstract: The objective of non-contrastive approaches to self-supervised learning is to
train on pairs of different views of the data an encoder and a predictor that
minimize the mean discrepancy between the code predicted from the embedding of
the first view and the embedding of the second one. In this setting, the stop
gradient and exponential moving average iterative procedures are commonly used
to avoid representation collapse, with excellent performance in downstream
supervised applications. This presentation investigates these procedures from
the dual theoretical viewpoints of optimization and dynamical systems. We first
show that, in general, although they do not optimize the original objective, or
for that matter, any other smooth function, they do avoid collapse. Following
Tian et al. [2021], but without any of the extra assumptions used in their
proofs, we then show using a dynamical system perspective that, in the linear
case, minimizing the original objective function without the use of a stop
gradient or exponential moving average always leads to collapse. Conversely, we
finally show that the limit points of the dynamical systems associated with
these two procedures are, in general, asymptotically stable equilibria, with no
risk of degenerating to trivial solutions.

</details>


### [162] [PathCoT: Chain-of-Thought Prompting for Zero-shot Pathology Visual Reasoning](https://arxiv.org/abs/2507.01029)
*Junjie Zhou,Yingli Zuo,Shichang Feng,Peng Wan,Qi Zhu,Daoqiang Zhang,Wei Shao*

Main category: cs.LG

TL;DR: 提出PathCoT方法，结合病理学专家知识和自评估步骤，提升多模态大语言模型在病理视觉推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在病理视觉推理任务中表现不佳，主要因为缺乏领域知识和推理步骤可能引入错误。

Method: PathCoT通过整合病理学专家知识和自评估步骤，优化MLLMs的推理过程。

Result: 在PathMMU数据集上验证了PathCoT的有效性。

Conclusion: PathCoT显著提升了MLLMs在病理视觉推理任务中的性能。

Abstract: With the development of generative artificial intelligence and instruction
tuning techniques, multimodal large language models (MLLMs) have made
impressive progress on general reasoning tasks. Benefiting from the
chain-of-thought (CoT) methodology, MLLMs can solve the visual reasoning
problem step-by-step. However, existing MLLMs still face significant challenges
when applied to pathology visual reasoning tasks: (1) LLMs often underperforms
because they lack domain-specific information, which can lead to model
hallucinations. (2) The additional reasoning steps in CoT may introduce errors,
leading to the divergence of answers. To address these limitations, we propose
PathCoT, a novel zero-shot CoT prompting method which integrates the pathology
expert-knowledge into the reasoning process of MLLMs and incorporates
self-evaluation to mitigate divergence of answers. Specifically, PathCoT guides
the MLLM with prior knowledge to perform as pathology experts, and provides
comprehensive analysis of the image with their domain-specific knowledge. By
incorporating the experts' knowledge, PathCoT can obtain the answers with CoT
reasoning. Furthermore, PathCoT incorporates a self-evaluation step that
assesses both the results generated directly by MLLMs and those derived through
CoT, finally determining the reliable answer. The experimental results on the
PathMMU dataset demonstrate the effectiveness of our method on pathology visual
understanding and reasoning.

</details>


### [163] [Fast Clifford Neural Layers](https://arxiv.org/abs/2507.01040)
*Tianxiang Xia,Max Neuwinger,Lin Xiao*

Main category: cs.LG

TL;DR: Clifford Neural Layers通过引入Clifford代数优化PDE建模，在CPU上实现了比标准PyTorch快30%的性能。


<details>
  <summary>Details</summary>
Motivation: 提升2/3D Clifford卷积层和多向量激活层在单核CPU上的推理效率。

Method: 优化Clifford卷积层和多向量激活层的实现，测试真实网络块。

Result: 在较大数据和网络规模下，性能提升30%。

Conclusion: 开源代码，展示了Clifford Neural Layers在PDE建模中的高效性。

Abstract: Clifford Neural Layers improve PDE modeling by introducing Clifford Algebra
into neural networks. In this project we focus on optimizing the inference of
2/3D Clifford convolutional layers and multivector activation layers for one
core CPU performance.
  Overall, by testing on a real network block involving Clifford convolutional
layers and multivector activation layers, we observe that our implementation is
30% faster than standard PyTorch implementation in relatively large data +
network size (>L2 cache).
  We open source our code base at
https://github.com/egretwAlker/c-opt-clifford-layers

</details>


### [164] [Optimizing Flamelet Generated Manifold Models: A Machine Learning Performance Study](https://arxiv.org/abs/2507.01030)
*Reza Lotfi Navaei,Mohammad Safarzadeh,Seyed Mohammad Jafar Sobhani*

Main category: cs.LG

TL;DR: 研究利用机器学习算法（MLP、随机森林、线性回归、SVM）重建甲烷燃烧的FGM库，MLP方法表现最佳，优化后准确率达99.81%。


<details>
  <summary>Details</summary>
Motivation: FGM库在燃烧模拟中精度高但内存需求大，机器学习可优化其生成过程。

Method: 采用四种机器学习算法重建FGM库，通过超参数调优优化MLP模型。

Result: MLP方法表现最佳，优化后准确率99.81%，误差率2.30%。

Conclusion: 机器学习可高效生成FGM库，MLP为最优方法，适用于甲烷燃烧模拟。

Abstract: In chemistry tabulations and Flamelet combustion models, the Flamelet
Generated Manifold (FGM) is recognized for its precision and physical
representation. The practical implementation of FGM requires a significant
allocation of memory resources. FGM libraries are developed specifically for a
specific fuel and subsequently utilized for all numerical problems using
machine learning techniques. This research aims to develop libraries of Laminar
FGM utilizing machine learning algorithms for application in combustion
simulations of methane fuel. This study employs four Machine Learning
algorithms to regenerate Flamelet libraries, based on an understanding of data
sources, techniques, and data-driven concepts. 1. Multi-Layer Perceptron; 2.
Random Forest; 3. Linear Regression; 4. Support Vector Machine. Seven libraries
were identified as appropriate for constructing a database for training machine
learning models, giving an error rate of 2.30%. The default architectures of
each method were evaluated to determine the optimal approach, leading to the
selection of the MLP method as the primary choice. The method was enhanced
through hyperparameter tuning to improve accuracy. The quantity of hidden
layers and neurons significantly influences method performance. The optimal
model, comprising four hidden layers with 10, 15, 20, and 25 neurons
respectively, achieved an accuracy of 99.81%.

</details>


### [165] [Long-Sequence Memory with Temporal Kernels and Dense Hopfield Functionals](https://arxiv.org/abs/2507.01052)
*Ahmed Farooq*

Main category: cs.LG

TL;DR: 提出了一种基于密集Hopfield网络的新型能量函数，用于长序列记忆，通过高阶交互实现指数存储容量，并引入时间核以高效检索序列模式。


<details>
  <summary>Details</summary>
Motivation: 解决长序列任务中Transformer的局限性，如长上下文建模和时间序列数据的长期依赖问题。

Method: 提出时间核$K(m, k)$，结合密集Hopfield网络的高阶交互，实现高效序列模式存储与检索。

Result: 成功应用于电影帧的存储与序列检索，展示了在高维向量空间中的有效性。

Conclusion: 该模型为长序列任务提供了新思路，对自然语言处理、预测等领域有潜在影响。

Abstract: In this study we introduce a novel energy functional for long-sequence
memory, building upon the framework of dense Hopfield networks which achieves
exponential storage capacity through higher-order interactions. Building upon
earlier work on long-sequence Hopfield memory models, we propose a temporal
kernal $K(m, k)$ to incorporate temporal dependencies, enabling efficient
sequential retrieval of patterns over extended sequences. We demonstrate the
successful application of this technique for the storage and sequential
retrieval of movies frames which are well suited for this because of the high
dimensional vectors that make up each frame creating enough variation between
even sequential frames in the high dimensional space. The technique has
applications in modern transformer architectures, including efficient
long-sequence modeling, memory augmentation, improved attention with temporal
bias, and enhanced handling of long-term dependencies in time-series data. Our
model offers a promising approach to address the limitations of transformers in
long-context tasks, with potential implications for natural language
processing, forecasting, and beyond.

</details>


### [166] [PyTorch-based Geometric Learning with Non-CUDA Processing Units: Experiences from Intel Gaudi-v2 HPUs](https://arxiv.org/abs/2507.01031)
*Fanchen Bu,Kijung Shin*

Main category: cs.LG

TL;DR: 论文介绍了将基于PyTorch的几何学习框架移植到Gaudi-v2 HPU的经验，提供了核心工具和教程，降低了非CUDA硬件上几何学习的门槛。


<details>
  <summary>Details</summary>
Motivation: 几何学习在非欧几里得数据建模中表现优异，但非CUDA硬件（如Gaudi-v2 HPU）的使用需要大量工程努力和软件适配。

Method: 开发核心工具恢复HPU上的基本操作，并提供教程和实例分析。

Result: 成功移植框架，提供公开的GitHub资源库，支持研究人员在非CUDA硬件上实验几何学习算法。

Conclusion: 工作为几何学习在非CUDA硬件上的优化和跨平台移植奠定了基础。

Abstract: Geometric learning has emerged as a powerful paradigm for modeling
non-Euclidean data, especially graph-structured ones, with applications
spanning social networks, molecular structures, knowledge graphs, and
recommender systems. While Nvidia's CUDA-enabled graphics processing units
(GPUs) largely dominate the hardware landscape, emerging accelerators such as
Intel's Gaudi Habana Processing Units (HPUs) offer competitive performance and
energy efficiency. However, the usage of such non-CUDA processing units
requires significant engineering effort and novel software adaptations. In this
work, we present our experiences porting PyTorch-based geometric learning
frameworks to Gaudi-v2 HPUs. We introduce a collection of core utilities that
restore essential operations (e.g., scatter, sparse indexing, k-nearest
neighbors) on Gaudi-v2 HPUs, and we consolidate sixteen guided tutorials and
eleven real-world examples with diagnostic analyses of encountered failures and
detailed workarounds. We collect all our experiences into a publicly accessible
GitHub repository. Our contributions lower the barrier for researchers to
experiment with geometric-learning algorithms and models on non-CUDA hardware,
providing a foundation for further optimization and cross-platform portability.

</details>


### [167] [An Uncertainty-Aware Dynamic Decision Framework for Progressive Multi-Omics Integration in Classification Tasks](https://arxiv.org/abs/2507.01032)
*Nan Mu,Hongbo Yang,Chen Zhao*

Main category: cs.LG

TL;DR: 提出了一种不确定性感知的多视图动态决策框架，用于多组学数据分类，旨在降低测试成本的同时保持高诊断准确性。


<details>
  <summary>Details</summary>
Motivation: 多组学技术成本高昂，可能导致资源浪费，因此需要一种方法在保证诊断准确性的同时减少不必要的测试。

Method: 在单组学层面，通过改进神经网络激活函数生成Dirichlet分布参数，利用主观逻辑量化分类结果的置信度和不确定性；在多组学层面，采用Dempster-Shafer理论融合异质模态，并动态引入数据源直至模型置信度达标。

Result: 在四个基准数据集（ROSMAP、LGG、BRCA、KIPAN）上，超过50%的病例仅需单组学数据即可准确分类，同时诊断性能与全组学模型相当。

Conclusion: 该方法有效减少了冗余测试，同时保持了诊断准确性和生物学洞察力。

Abstract: Background and Objective: High-throughput multi-omics technologies have
proven invaluable for elucidating disease mechanisms and enabling early
diagnosis. However, the high cost of multi-omics profiling imposes a
significant economic burden, with over reliance on full omics data potentially
leading to unnecessary resource consumption. To address these issues, we
propose an uncertainty-aware, multi-view dynamic decision framework for omics
data classification that aims to achieve high diagnostic accuracy while
minimizing testing costs. Methodology: At the single-omics level, we refine the
activation functions of neural networks to generate Dirichlet distribution
parameters, utilizing subjective logic to quantify both the belief masses and
uncertainty mass of classification results. Belief mass reflects the support of
a specific omics modality for a disease class, while the uncertainty parameter
captures limitations in data quality and model discriminability, providing a
more trustworthy basis for decision-making. At the multi omics level, we employ
a fusion strategy based on Dempster-Shafer theory to integrate heterogeneous
modalities, leveraging their complementarity to boost diagnostic accuracy and
robustness. A dynamic decision mechanism is then applied that omics data are
incrementally introduced for each patient until either all data sources are
utilized or the model confidence exceeds a predefined threshold, potentially
before all data sources are utilized. Results and Conclusion: We evaluate our
approach on four benchmark multi-omics datasets, ROSMAP, LGG, BRCA, and KIPAN.
In three datasets, over 50% of cases achieved accurate classification using a
single omics modality, effectively reducing redundant testing. Meanwhile, our
method maintains diagnostic performance comparable to full-omics models and
preserves essential biological insights.

</details>


### [168] [Data-driven Insights for Informed Decision-Making: Applying LSTM Networks for Robust Electricity Forecasting in Libya](https://arxiv.org/abs/2507.01034)
*Asma Agaal,Mansour Essgaer,Hend M. Farkash,Zulaiha Ali Othman*

Main category: cs.LG

TL;DR: 该研究提出了一种基于数据驱动的方法，利用历史数据预测2025年利比亚班加西的电力负荷、发电量和缺口，LSTM模型表现最佳。


<details>
  <summary>Details</summary>
Motivation: 班加西电力供应不稳定，基础设施有限，准确预测电力需求对电网稳定和能源规划至关重要。

Method: 使用ARIMA、季节性ARIMA、动态回归ARIMA、指数平滑、XGBoost和LSTM等多种时间序列模型，并对数据进行缺失值填补、异常值平滑和对数转换。

Result: LSTM模型在预测非平稳和季节性模式方面表现最优，且整合了温度和湿度等外生变量。

Conclusion: 优化的LSTM框架为数据稀缺且波动大的地区提供了实用的电力预测工具，有助于政策制定者和电网运营商进行主动管理。

Abstract: Accurate electricity forecasting is crucial for grid stability and energy
planning, especially in Benghazi, Libya, where frequent load shedding,
generation deficits, and infrastructure limitations persist. This study
proposes a data-driven approach to forecast electricity load, generation, and
deficits for 2025 using historical data from 2019 (a year marked by
instability) and 2023 (a more stable year). Multiple time series models were
applied, including ARIMA, seasonal ARIMA, dynamic regression ARIMA, exponential
smoothing, extreme gradient boosting, and Long Short-Term Memory (LSTM) neural
networks. The dataset was enhanced through missing value imputation, outlier
smoothing, and log transformation. Performance was assessed using mean squared
error, root mean squared error, mean absolute error, and mean absolute
percentage error. LSTM outperformed all other models, showing strong
capabilities in modeling non-stationary and seasonal patterns. A key
contribution of this work is an optimized LSTM framework that integrates
exogenous factors such as temperature and humidity, offering robust performance
in forecasting multiple electricity indicators. These results provide practical
insights for policymakers and grid operators to enable proactive load
management and resource planning in data-scarce, volatile regions.

</details>


### [169] [Research on Low-Latency Inference and Training Efficiency Optimization for Graph Neural Network and Large Language Model-Based Recommendation Systems](https://arxiv.org/abs/2507.01035)
*Yushang Zhao,Haotian Lyu,Yike Peng,Aijia Sun,Feng Jiang,Xinyue Han*

Main category: cs.LG

TL;DR: 本研究通过结合GNN和LLM的混合推荐系统，优化推理延迟和训练效率，采用量化、LoRA、蒸馏等方法，结合硬件加速（FPGA、DeepSpeed），显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 在线服务对高效推荐系统的需求日益增长，需要解决混合GNN和LLM推荐系统的计算瓶颈问题。

Method: 采用混合GNN-LLM架构，结合量化、LoRA、蒸馏等优化策略，以及FPGA和DeepSpeed硬件加速。

Result: 最优配置（Hybrid + FPGA + DeepSpeed）在NDCG@10上达到0.75，延迟40-60ms，LoRA将训练时间减少66%（3.8小时）。

Conclusion: 硬件-软件协同设计和参数高效调优使混合模型优于独立GNN或LLM方法，建议使用FPGA和LoRA进行实时部署。未来工作可探索联邦学习和高级融合架构。

Abstract: The incessant advent of online services demands high speed and efficient
recommender systems (ReS) that can maintain real-time performance along with
processing very complex user-item interactions. The present study, therefore,
considers computational bottlenecks involved in hybrid Graph Neural Network
(GNN) and Large Language Model (LLM)-based ReS with the aim optimizing their
inference latency and training efficiency. An extensive methodology was used:
hybrid GNN-LLM integrated architecture-optimization strategies(quantization,
LoRA, distillation)-hardware acceleration (FPGA, DeepSpeed)-all under R 4.4.2.
Experimental improvements were significant, with the optimal Hybrid + FPGA +
DeepSpeed configuration reaching 13.6% more accuracy (NDCG@10: 0.75) at 40-60ms
of latency, while LoRA brought down training time by 66% (3.8 hours) in
comparison to the non-optimized baseline. Irrespective of domain, such as
accuracy or efficiency, it can be established that hardware-software co-design
and parameter-efficient tuning permit hybrid models to outperform GNN or LLM
approaches implemented independently. It recommends the use of FPGA as well as
LoRA for real-time deployment. Future work should involve federated learning
along with advanced fusion architectures for better scalability and privacy
preservation. Thus, this research marks the fundamental groundwork concerning
next-generation ReS balancing low-latency response with cutting-edge
personalization.

</details>


### [170] [Learning to Segment for Vehicle Routing Problems](https://arxiv.org/abs/2507.01037)
*Wenbin Ouyang,Sirui Li,Yining Ma,Cathy Wu*

Main category: cs.LG

TL;DR: 提出FSTA分解技术和L2Seg神经网络框架，加速迭代求解器，提升VRP求解效率。


<details>
  <summary>Details</summary>
Motivation: 迭代求解器在解决VRP时存在大量冗余计算，因部分解在迭代中保持稳定。

Method: FSTA技术保留稳定解段，聚合为超节点；L2Seg框架智能识别稳定与不稳定部分。

Result: L2Seg将求解器加速至多7倍，NAR与AR协同效果最佳。

Conclusion: L2Seg是灵活框架，兼容多种求解器，适用于广泛VRP问题。

Abstract: Iterative search heuristics are widely recognized as state-of-the-art for
solving Vehicle Routing Problems (VRPs). In this work, we identify and exploit
a critical observation: within these solvers, a large portion of the solution
remains stable, i.e., unchanged across search iterations, causing redundant
computations, especially for large-scale VRPs with long subtours. To address
this, we pioneer the formal study of the First-Segment-Then-Aggregate (FSTA)
decomposition technique to accelerate iterative solvers. Specifically, FSTA
preserves stable solution segments during the search, aggregates nodes within
each segment into fixed hypernodes, and focuses the search only on unstable
portions. Yet, a key challenge lies in identifying which segments should be
aggregated by FSTA. To this end, we then introduce Learning-to-Segment (L2Seg),
a novel neural framework to intelligently differentiate potentially stable and
unstable portions for FSTA decomposition. We present three L2Seg variants:
non-autoregressive (globally comprehensive but locally indiscriminate),
autoregressive (locally refined but globally deficient), and their synergy,
with bespoke training and inference strategies. Empirical results on CVRP and
VRPTW suggest that L2Seg accelerates state-of-the-art iterative solvers by up
to 7x. Additionally, we provide in-depth analysis showing NAR and AR synergy
achieves best performance by combining their complementary strengths. Notably,
L2Seg is a flexible framework that is compatible with traditional,
learning-based, and hybrid solvers, while supporting a broad class of VRPs.

</details>


### [171] [On-Policy Optimization of ANFIS Policies Using Proximal Policy Optimization](https://arxiv.org/abs/2507.01039)
*Kaaustaaub Shankar,Wilhelm Louw,Kelly Cohen*

Main category: cs.LG

TL;DR: 提出一种基于PPO的强化学习方法训练神经模糊控制器，相比DQN方法表现更稳定且收敛更快。


<details>
  <summary>Details</summary>
Motivation: 改进现有基于DQN的神经模糊控制器训练方法，利用PPO的稳定性和高效性提升性能。

Method: 使用PPO替代DQN，构建稳定的on-policy actor-critic循环，并在CartPole-v1环境中进行测试。

Result: PPO训练的模糊控制器在CartPole-v1中平均回报达500，方差更小且收敛更快。

Conclusion: PPO为训练可解释的神经模糊控制器提供了有前景的途径。

Abstract: We propose a reinforcement learning (RL) approach for training neuro-fuzzy
controllers using Proximal Policy Optimization (PPO). Building on prior work
that applied Deep Q-Learning to Adaptive Neuro-Fuzzy Inference Systems (ANFIS),
our method replaces the off-policy value-based framework with a stable
on-policy actor-critic loop. We evaluate this approach in the CartPole-v1
environment using multiple random seeds and compare its learning performance
against ANFIS-Deep Q-Network (DQN) baselines. It was found that PPO-trained
fuzzy agents achieved a mean return of 500 +/- 0 on CartPole-v1 after 20000
updates, showcasing less variance than prior DQN-based methods during training
and overall faster convergence. These findings suggest that PPO offers a
promising pathway for training explainable neuro-fuzzy controllers in
reinforcement learning tasks.

</details>


### [172] [Fast AI Model Splitting over Edge Networks](https://arxiv.org/abs/2507.01041)
*Zuguang Li,Wen Wu,Shaohua Wu,Songge Zhang,Ye Wang,Xuemin,Shen*

Main category: cs.LG

TL;DR: 提出了一种基于DAG的快速模型分割算法，通过最大流方法找到最优分割，显著降低训练延迟。


<details>
  <summary>Details</summary>
Motivation: 解决复杂AI模型分割的高计算复杂度问题，提升设备端计算效率。

Method: 将AI模型表示为DAG，重新定义分割问题为最小s-t割搜索，并提出快速DAG分割算法和块状分割算法。

Result: 算法在毫秒内找到最优分割，动态边缘网络中训练延迟降低24.62%-38.95%。

Conclusion: 提出的算法在计算效率和性能上优于现有方法，适用于动态边缘网络。

Abstract: Split learning (SL) has emerged as a computationally efficient approach for
artificial intelligence (AI) model training, which can alleviate device-side
computational workloads. However, complex AI model architectures pose high
computational complexity to obtain the optimal model splitting. In this paper,
we represent an arbitrary AI model as a directed acyclic graph (DAG), and then
reformulate the optimal model splitting problem as a minimum s-t cut search
problem. To solve the problem, we propose a fast DAG-based model splitting
algorithm, which restructures the DAG to enable the optimal model splitting
identification via a maximum flow method. Theoretical analysis indicates that
the proposed algorithm is optimal. Furthermore, considering AI models with
block structures, we propose a block-wise model splitting algorithm to reduce
computational complexity. The algorithm abstracts each block, i.e., a component
consisting of multiple layers, into a single vertex, thereby obtaining the
optimal model splitting via a simplified DAG. Extensive experimental results
demonstrate that the proposed algorithms can determine the optimal model
splitting within milliseconds, as well as reduce training delay by
24.62%-38.95% in dynamic edge networks as compared to the state-of-the-art
benchmarks.

</details>


### [173] [Data Classification with Dynamically Growing and Shrinking Neural Networks](https://arxiv.org/abs/2507.01043)
*Szymon Świderski,Agnieszka Jastrzębska*

Main category: cs.LG

TL;DR: 提出了一种动态调整神经网络架构的新方法，通过蒙特卡洛树搜索优化模型结构，适用于视觉和时间序列分类任务。


<details>
  <summary>Details</summary>
Motivation: 传统神经网络架构固定，无法动态调整，限制了模型的适应性和性能。

Method: 使用蒙特卡洛树搜索动态调整神经网络架构，支持训练中动态增减模型结构。

Result: 在视觉和时间序列分类任务中表现优异，尤其在多变量时间序列分类中效果显著。

Conclusion: 该方法通过动态调整架构提升了模型性能，展现了强大的适应性和鲁棒性。

Abstract: The issue of data-driven neural network model construction is one of the core
problems in the domain of Artificial Intelligence. A standard approach assumes
a fixed architecture with trainable weights. A conceptually more advanced
assumption is that we not only train the weights, but also find out the optimal
model architecture. We present a new method that realizes just that. This
article is an extended version of our conference paper titled "Dynamic Growing
and Shrinking of Neural Networks with Monte Carlo Tree Search [26]". In the
paper, we show in detail how to create a neural network with a procedure that
allows dynamic shrinking and growing of the model while it is being trained.
The decision-making mechanism for the architectural design is governed by a
Monte Carlo tree search procedure which simulates network behavior and allows
to compare several candidate architecture changes to choose the best one. The
proposed method was validated using both visual and time series datasets,
demonstrating its particular effectiveness in multivariate time series
classification. This is attributed to the architecture's ability to adapt
dynamically, allowing independent modifications for each time series. The
approach is supplemented by Python source code for reproducibility.
Experimental evaluations in visual pattern and multivariate time series
classification tasks revealed highly promising performance, underscoring the
method's robustness and adaptability.

</details>


### [174] [Sensing Cardiac Health Across Scenarios and Devices: A Multi-Modal Foundation Model Pretrained on Heterogeneous Data from 1.7 Million Individuals](https://arxiv.org/abs/2507.01045)
*Xiao Gu,Wei Tang,Jinpei Han,Veer Sangha,Fenglin Liu,Shreyank N Gowda,Antonio H. Ribeiro,Patrick Schwab,Kim Branson,Lei Clifton,Antonio Luiz P. Ribeiro,Zhangdaihong Liu,David A. Clifton*

Main category: cs.LG

TL;DR: 该研究提出了一种心脏感知基础模型（CSFM），利用Transformer架构和生成式掩码预训练策略，从大规模异构健康数据中学习统一表示，显著提升了心脏信号分析的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法在心脏信号分析中依赖同质数据集和静态定制模型，限制了其在不同临床环境和采集协议中的鲁棒性和泛化性。

Method: 采用Transformer架构和生成式掩码预训练策略，整合多模态数据（包括MIMIC-III-WDB、MIMIC-IV-ECG和CODE数据集），涵盖约170万人的心脏信号及临床或机器生成的文本报告。

Result: CSFM在多种心脏感知场景中表现出色，支持跨输入配置和传感器模态的无缝迁移学习，显著优于传统单模态单任务方法。

Conclusion: CSFM作为一种多功能、可扩展的解决方案，有望实现全面的心脏监测。

Abstract: Cardiac biosignals, such as electrocardiograms (ECG) and photoplethysmograms
(PPG), are of paramount importance for the diagnosis, prevention, and
management of cardiovascular diseases, and have been extensively used in a
variety of clinical tasks. Conventional deep learning approaches for analyzing
these signals typically rely on homogeneous datasets and static bespoke models,
limiting their robustness and generalizability across diverse clinical settings
and acquisition protocols. In this study, we present a cardiac sensing
foundation model (CSFM) that leverages advanced transformer architectures and a
generative, masked pretraining strategy to learn unified representations from
vast, heterogeneous health records. Our model is pretrained on an innovative
multi-modal integration of data from multiple large-scale datasets (including
MIMIC-III-WDB, MIMIC-IV-ECG, and CODE), comprising cardiac signals and the
corresponding clinical or machine-generated text reports from approximately 1.7
million individuals. We demonstrate that the embeddings derived from our CSFM
not only serve as effective feature extractors across diverse cardiac sensing
scenarios, but also enable seamless transfer learning across varying input
configurations and sensor modalities. Extensive evaluations across diagnostic
tasks, demographic information recognition, vital sign measurement, clinical
outcome prediction, and ECG question answering reveal that CSFM consistently
outperforms traditional one-modal-one-task approaches. Notably, CSFM exhibits
robust performance across multiple ECG lead configurations from standard
12-lead systems to single-lead setups, and in scenarios where only ECG, only
PPG, or a combination thereof is available. These findings highlight the
potential of CSFM as a versatile and scalable solution, for comprehensive
cardiac monitoring.

</details>


### [175] [Variational Digital Twins](https://arxiv.org/abs/2507.01047)
*Logan A. Burnett,Umme Mahbuba Nabila,Majdi I. Radaideh*

Main category: cs.LG

TL;DR: 论文提出了一种变分数字孪生（VDT）框架，通过贝叶斯输出层和高效更新算法，解决了现有数字孪生在实时性、模型不确定性和信息交换方面的不足。


<details>
  <summary>Details</summary>
Motivation: 当前数字孪生技术缺乏实时实现的关键特性、模型不确定性关注不足，且缺乏清晰的信息交换框架。

Method: 提出VDT框架，结合标准神经网络架构和贝叶斯输出层，并开发了一种高效的更新算法。

Result: 在四个能源领域问题中验证了VDT的有效性，包括减少实验次数、提高预测精度和适应传感器退化等。

Conclusion: VDT通过轻量级的贝叶斯增强和高效更新，将传统模型转化为具有不确定性感知和数据高效的数字孪生，适用于工业和科学能源系统。

Abstract: While digital twins (DT) hold promise for providing real-time insights into
complex energy assets, much of the current literature either does not offer a
clear framework for information exchange between the model and the asset, lacks
key features needed for real-time implementation, or gives limited attention to
model uncertainty. Here, we aim to solve these gaps by proposing a variational
digital twin (VDT) framework that augments standard neural architectures with a
single Bayesian output layer. This lightweight addition, along with a novel VDT
updating algorithm, lets a twin update in seconds on commodity GPUs while
producing calibrated uncertainty bounds that can inform experiment design,
control algorithms, and model reliability. The VDT is evaluated on four
energy-sector problems. For critical-heat-flux prediction, uncertainty-driven
active learning reaches R2 = 0.98 using 47 % fewer experiments and one-third
the training time of random sampling. A three-year renewable-generation twin
maintains R2 > 0.95 for solar output and curbs error growth for volatile wind
forecasts via monthly updates that process only one month of data at a time. A
nuclear reactor transient cooldown twin reconstructs thermocouple signals with
R2 > 0.99 and preserves accuracy after 50 % sensor loss, demonstrating
robustness to degraded instrumentation. Finally, a physics-informed Li-ion
battery twin, retrained after every ten discharges, lowers voltage mean-squared
error by an order of magnitude relative to the best static model while adapting
its credible intervals as the cell approaches end-of-life. These results
demonstrate that combining modest Bayesian augmentation with efficient update
schemes turns conventional surrogates into uncertainty-aware, data-efficient,
and computationally tractable DTs, paving the way for dependable models across
industrial and scientific energy systems.

</details>


### [176] [Evaluation of a Foundational Model and Stochastic Models for Forecasting Sporadic or Spiky Production Outages of High-Performance Machine Learning Services](https://arxiv.org/abs/2507.01067)
*Keun Soo Yim*

Main category: cs.LG

TL;DR: 本文优化了最先进的基础模型，用于预测高性能机器学习服务中的罕见、峰值事件（如生产中断），并与经典随机模型进行比较，发现基础模型在特定场景下表现更优。


<details>
  <summary>Details</summary>
Motivation: 基础模型在时间序列预测中表现优异，但尚未用于预测罕见、峰值事件，这是极端事件的特殊情况，具有挑战性。

Method: 优化基础模型，并与经典随机模型（如移动平均和自回归）进行预测误差比较。

Result: 基础模型在预测峰值事件时表现优于随机模型，且能准确估计特定根因的年中断统计，误差低于6%。

Conclusion: 基础模型在罕见、峰值事件预测中具有潜力，为实际应用提供了更优的解决方案。

Abstract: Time series forecasting models have diverse real world applications (e.g.,
from electricity metrics to software workload). Latest foundational models
trained for time series forecasting show strengths (e.g., for long sequences
and in zero-shot settings). However, foundational model was not yet used for
forecasting rare, spiky events, i.e., a challenging target because those are a
corner case of extreme events. In this paper, we optimize a state-of-the-art
foundational model to forecast sporadic or spiky production outages of
high-performance machine learning services powering billions of client devices.
We evaluate the forecasting errors of the foundational model compared with
classical stochastic forecasting models (e.g., moving average and
autoregressive). The analysis helps us understand how each of the evaluated
models performs for the sporadic or spiky events. For example, it identifies
the key patterns in the target data that are well tracked by the foundational
model vs. each of the stochastic models. We use the models with optimal
parameters to estimate a year-long outage statistics of a particular root cause
with less than 6% value errors.

</details>


### [177] [3W Dataset 2.0.0: a realistic and public dataset with rare undesirable real events in oil wells](https://arxiv.org/abs/2507.01048)
*Ricardo Emanuel Vaz Vargas,Afrânio José de Melo Junior,Celso José Munaro,Cláudio Benevenuto de Campos Lima,Eduardo Toledo de Lima Junior,Felipe Muntzberg Barrocas,Flávio Miguel Varejão,Guilherme Fidelis Peixer,Igor de Melo Nery Oliveira,Jader Riso Barbosa Jr.,Jaime Andrés Lozano Cadena,Jean Carlos Dias de Araújo,João Neuenschwander Escosteguy Carneiro,Lucas Gouveia Omena Lopes,Lucas Pereira de Gouveia,Mateus de Araujo Fernandes,Matheus Lima Scramignon,Patrick Marques Ciarelli,Rodrigo Castello Branco,Rogério Leite Alves Pinto*

Main category: cs.LG

TL;DR: Petrobras发布了3W数据集，用于基于AI/ML的早期检测油井不良事件，支持研究和开发。


<details>
  <summary>Details</summary>
Motivation: 油井不良事件可能导致经济损失、环境事故和人员伤亡，需要早期检测解决方案。

Method: 开发并公开了3W数据集，包含多变量时间序列和专家标注。

Result: 3W数据集成为该领域的基础参考，支持改进现有结果和开发新方法。

Conclusion: 3W数据集的最新版本鼓励社区开发更强大的检测方法，以提前采取纠正措施。

Abstract: In the oil industry, undesirable events in oil wells can cause economic
losses, environmental accidents, and human casualties. Solutions based on
Artificial Intelligence and Machine Learning for Early Detection of such events
have proven valuable for diverse applications across industries. In 2019,
recognizing the importance and the lack of public datasets related to
undesirable events in oil wells, Petrobras developed and publicly released the
first version of the 3W Dataset, which is essentially a set of Multivariate
Time Series labeled by experts. Since then, the 3W Dataset has been developed
collaboratively and has become a foundational reference for numerous works in
the field. This data article describes the current publicly available version
of the 3W Dataset, which contains structural modifications and additional
labeled data. The detailed description provided encourages and supports the 3W
community and new 3W users to improve previous published results and to develop
new robust methodologies, digital products and services capable of detecting
undesirable events in oil wells with enough anticipation to enable corrective
or mitigating actions.

</details>


### [178] [Text Detoxification: Data Efficiency, Semantic Preservation and Model Generalization](https://arxiv.org/abs/2507.01050)
*Jing Yu,Yibo Zhao,Jiapeng Zhu,Wenming Shao,Bo Pang,Zhao Zhang,Xiang Li*

Main category: cs.LG

TL;DR: 提出了一种两阶段训练框架，用于高效去毒文本并保留语义，减少对标注数据的依赖。


<details>
  <summary>Details</summary>
Motivation: 社交媒体上毒害内容的广泛传播威胁公共讨论，现有方法难以同时实现去毒、语义保留和泛化能力。

Method: 两阶段训练框架：先在小规模高质量平行数据上微调，再利用未标注数据和奖励模型通过GRPO训练LLM。

Result: 实验表明该方法有效平衡去毒与语义保留，泛化能力强且减少对标注数据的依赖。

Conclusion: 该方法在去毒任务中表现优异，具有更高的数据效率和泛化能力。

Abstract: The widespread dissemination of toxic content on social media poses a serious
threat to both online environments and public discourse, highlighting the
urgent need for detoxification methods that effectively remove toxicity while
preserving the original semantics. However, existing approaches often struggle
to simultaneously achieve strong detoxification performance, semantic
preservation, and robustness to out-of-distribution data. Moreover, they
typically rely on costly, manually annotated parallel corpora while showing
poor data efficiency. To address these challenges, we propose a two-stage
training framework that jointly optimizes for data efficiency, semantic
preservation, and model generalization. We first perform supervised fine-tuning
on a small set of high-quality, filtered parallel data to establish a strong
initialization. Then, we leverage unlabeled toxic inputs and a custom-designed
reward model to train the LLM using Group Relative Policy Optimization.
Experimental results demonstrate that our method effectively mitigates the
trade-offs faced by previous work, achieving state-of-the-art performance with
improved generalization and significantly reduced dependence on annotated data.
Our code is available at:
https://anonymous.4open.science/r/Detoxification-of-Text-725F/

</details>


### [179] [Chargax: A JAX Accelerated EV Charging Simulator](https://arxiv.org/abs/2507.01522)
*Koen Ponse,Jan Felix Kleuker,Aske Plaat,Thomas Moerland*

Main category: cs.LG

TL;DR: Chargax是一个基于JAX的电动汽车充电站模拟环境，显著提升了强化学习训练效率，性能提升100x-1000x。


<details>
  <summary>Details</summary>
Motivation: 电网系统拥堵问题急需解决，传统强化学习方法效率低，现有研究多局限于经典玩具问题。

Method: 开发了Chargax，一个基于JAX的模拟环境，支持真实数据场景下的快速训练。

Result: 性能提升显著（100x-1000x），支持多样化的真实充电站配置。

Conclusion: Chargax为可持续能源挑战提供了高效的强化学习解决方案。

Abstract: Deep Reinforcement Learning can play a key role in addressing sustainable
energy challenges. For instance, many grid systems are heavily congested,
highlighting the urgent need to enhance operational efficiency. However,
reinforcement learning approaches have traditionally been slow due to the high
sample complexity and expensive simulation requirements. While recent works
have effectively used GPUs to accelerate data generation by converting
environments to JAX, these works have largely focussed on classical toy
problems. This paper introduces Chargax, a JAX-based environment for realistic
simulation of electric vehicle charging stations designed for accelerated
training of RL agents. We validate our environment in a variety of scenarios
based on real data, comparing reinforcement learning agents against baselines.
Chargax delivers substantial computational performance improvements of over
100x-1000x over existing environments. Additionally, Chargax' modular
architecture enables the representation of diverse real-world charging station
configurations.

</details>


### [180] [Are Large Brainwave Foundation Models Capable Yet? Insights from Fine-tuning](https://arxiv.org/abs/2507.01196)
*Na Lee,Konstantinos Barmpas,Yannis Panagakis,Dimitrios Adamos,Nikolaos Laskaris,Stefanos Zafeiriou*

Main category: cs.LG

TL;DR: 当前大型脑波基础模型（LBMs）在脑机接口（BCI）任务中表现有限，仅比传统深度学习模型略有提升（0.9%-1.2%），但参数需求显著增加。通过LoRA技术，可减少参数而不损失性能，表明LBMs需针对BCI领域优化设计。


<details>
  <summary>Details</summary>
Motivation: 评估大型脑波基础模型（LBMs）在脑机接口（BCI）任务中的表现，探索其效率与适用性。

Method: 通过系统微调实验和低秩适应（LoRA）技术，比较LBMs与传统深度学习模型在BCI任务（如记忆任务和睡眠阶段分类）中的性能。

Result: LBMs仅带来微小性能提升（0.9%-1.2%），但参数需求大幅增加；LoRA可显著减少参数且不影响性能。

Conclusion: LBMs需针对BCI领域优化架构和训练策略，当前设计未能充分发挥基础模型潜力。

Abstract: Foundation Models have demonstrated significant success across various
domains in Artificial Intelligence (AI), yet their capabilities for brainwave
modeling remain unclear. In this paper, we comprehensively evaluate current
Large Brainwave Foundation Models (LBMs) through systematic fine-tuning
experiments across multiple Brain-Computer Interface (BCI) benchmark tasks,
including memory tasks and sleep stage classification. Our extensive analysis
shows that state-of-the-art LBMs achieve only marginal improvements (0.9%-1.2%)
over traditional deep architectures while requiring significantly more
parameters (millions vs thousands), raising important questions about their
efficiency and applicability in BCI contexts. Moreover, through detailed
ablation studies and Low-Rank Adaptation (LoRA), we significantly reduce
trainable parameters without performance degradation, while demonstrating that
architectural and training inefficiencies limit LBMs' current capabilities. Our
experiments span both full model fine-tuning and parameter-efficient adaptation
techniques, providing insights into optimal training strategies for BCI
applications. We pioneer the application of LoRA to LBMs, revealing that
performance benefits generally emerge when adapting multiple neural network
components simultaneously. These findings highlight the critical need for
domain-specific development strategies to advance LBMs, suggesting that current
architectures may require redesign to fully leverage the potential of
foundation models in brainwave analysis.

</details>


### [181] [XxaCT-NN: Structure Agnostic Multimodal Learning for Materials Science](https://arxiv.org/abs/2507.01054)
*Jithendaraa Subramanian,Linda Hung,Daniel Schweigert,Santosh Suram,Weike Ye*

Main category: cs.LG

TL;DR: 提出了一种基于元素组成和XRD的多模态框架，无需晶体结构输入，通过自监督预训练策略提升材料发现的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决传统基于晶体结构的模型在实际应用中因结构数据难以获取而受限的问题。

Method: 开发了多模态框架，结合元素组成和XRD数据，采用掩码XRD建模和对比对齐作为自监督预训练策略。

Result: 预训练显著加速收敛（最高4.2倍），并提高了准确性和表征质量，多模态性能随数据规模增长优于单模态基线。

Conclusion: 为材料科学提供了一种无需结构输入、基于实验数据的通用模型框架。

Abstract: Recent advances in materials discovery have been driven by structure-based
models, particularly those using crystal graphs. While effective for
computational datasets, these models are impractical for real-world
applications where atomic structures are often unknown or difficult to obtain.
We propose a scalable multimodal framework that learns directly from elemental
composition and X-ray diffraction (XRD) -- two of the more available modalities
in experimental workflows without requiring crystal structure input. Our
architecture integrates modality-specific encoders with a cross-attention
fusion module and is trained on the 5-million-sample Alexandria dataset. We
present masked XRD modeling (MXM), and apply MXM and contrastive alignment as
self-supervised pretraining strategies. Pretraining yields faster convergence
(up to 4.2x speedup) and improves both accuracy and representation quality. We
further demonstrate that multimodal performance scales more favorably with
dataset size than unimodal baselines, with gains compounding at larger data
regimes. Our results establish a path toward structure-free, experimentally
grounded foundation models for materials science.

</details>


### [182] [Evaluating Pavement Deterioration Rates Due to Flooding Events Using Explainable AI](https://arxiv.org/abs/2507.01056)
*Lidan Peng,Lu Gao,Feng Hong,Jingran Sun*

Main category: cs.LG

TL;DR: 研究分析了洪水对路面粗糙度的影响，利用20年数据和XAI技术发现洪水加速路面劣化，建议采取防洪措施。


<details>
  <summary>Details</summary>
Motivation: 洪水对路面基础设施造成严重损害，研究旨在量化洪水对路面粗糙度的影响。

Method: 结合TxDOT的PMIS数据库和洪水事件数据，进行统计分析，并应用SHAP和LIME等XAI技术。

Result: 洪水影响的路面粗糙度增加更快，劣化速率更高。

Conclusion: 需采取防洪措施（如排水系统改进、抗洪材料）提升路面抗灾能力。

Abstract: Flooding can damage pavement infrastructure significantly, causing both
immediate and long-term structural and functional issues. This research
investigates how flooding events affect pavement deterioration, specifically
focusing on measuring pavement roughness by the International Roughness Index
(IRI). To quantify these effects, we utilized 20 years of pavement condition
data from TxDOT's PMIS database, which is integrated with flood event data,
including duration and spatial extent. Statistical analyses were performed to
compare IRI values before and after flooding and to calculate the deterioration
rates influenced by flood exposure. Moreover, we applied Explainable Artificial
Intelligence (XAI) techniques, such as SHapley Additive exPlanations (SHAP) and
Local Interpretable Model-Agnostic Explanations (LIME), to assess the impact of
flooding on pavement performance. The results demonstrate that flood-affected
pavements experience a more rapid increase in roughness compared to non-flooded
sections. These findings emphasize the need for proactive flood mitigation
strategies, including improved drainage systems, flood-resistant materials, and
preventative maintenance, to enhance pavement resilience in vulnerable regions.

</details>


### [183] [Loop2Net: Data-Driven Generation and Optimization of Airfoil CFD Meshes from Sparse Boundary Coordinates](https://arxiv.org/abs/2507.01057)
*Lushun Fan,Yuqin Xia,Jun Li,Karl Jenkins*

Main category: cs.LG

TL;DR: 提出了一种基于深度卷积神经网络的智能网格质量优化系统，通过Loop2Net生成器和损失函数实现网格生成与优化。


<details>
  <summary>Details</summary>
Motivation: 解决传统网格生成方法的效率和质量问题，利用深度学习技术提升网格优化的自动化水平。

Method: 采用Loop2Net生成器和两种关键损失函数，通过训练不断优化模型性能，并结合惩罚机制实现目标。

Result: 成功实现了基于给定翼坐标的网格预测，并通过优化达到了网格生成的目标。

Conclusion: 该智能优化系统为网格生成提供了一种高效且自动化的解决方案，具有潜在的应用价值。

Abstract: In this study, an innovative intelligent optimization system for mesh quality
is proposed, which is based on a deep convolutional neural network
architecture, to achieve mesh generation and optimization. The core of the
study is the Loop2Net generator and loss function, it predicts the mesh based
on the given wing coordinates. And the model's performance is continuously
optimised by two key loss functions during the training. Then discipline by
adding penalties, the goal of mesh generation was finally reached.

</details>


### [184] [Prediction of Freezing of Gait in Parkinsons Disease using Explainable AI and Federated Deep Learning for Wearable Sensors](https://arxiv.org/abs/2507.01068)
*Biplov Paneru*

Main category: cs.LG

TL;DR: 利用IMU数据和可解释AI方法，开发了早期检测和预测帕金森病冻结步态（FOG）的模型，集成学习方法表现最佳，准确率达99%。


<details>
  <summary>Details</summary>
Motivation: 解决帕金森病中常见的冻结步态（FOG）早期检测和预测问题。

Method: 使用CatBoost、XGBoost和Extra Trees分类器，结合Stacking Ensemble模型和联邦学习方法。

Result: Stacking Ensemble模型表现最优，分类准确率接近99%，SHAP分析显示时间是关键因素。

Conclusion: 提出的框架结合联邦学习和可解释AI，为FOG预测提供了高效且隐私保护的方法。

Abstract: This study leverages an Inertial Measurement Unit (IMU) dataset to develop
explainable AI methods for the early detection and prediction of Freezing of
Gait (FOG), a common symptom in Parkinson's disease. Machine learning models,
including CatBoost, XGBoost, and Extra Trees classifiers, are employed to
accurately categorize FOG episodes based on relevant clinical features. A
Stacking Ensemble model achieves superior performance, surpassing a hybrid
bidirectional GRU model and reaching nearly 99% classification accuracy. SHAP
interpretability analysis reveals that time (seconds) is the most influential
factor in distinguishing gait patterns. Additionally, the proposed FOG
prediction framework incorporates federated learning, where models are trained
locally on individual devices and aggregated on a central server using a
federated averaging approach, utilizing a hybrid Conv1D + LSTM architecture for
enhanced predictive capability.

</details>


### [185] [Rotational Sampling: A Plug-and-Play Encoder for Rotation-Invariant 3D Molecular GNNs](https://arxiv.org/abs/2507.01073)
*Dian Jin*

Main category: cs.LG

TL;DR: 提出了一种新的3D编码模块，通过旋转采样和SO(3)旋转群计算实现近似旋转不变性，并通过后对齐策略实现严格不变性，显著提升了分子属性预测的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统图神经网络难以有效编码分子的3D空间结构，现有方法在不变性和计算成本上存在不足。

Method: 提出了一种基于旋转采样的3D编码模块，结合SO(3)旋转群计算和后对齐策略。

Result: 在QM9和C10数据集上表现出更高的预测准确性、鲁棒性和泛化能力，同时保持低计算复杂度。

Conclusion: 该方法为药物发现和材料设计中的3D分子信息处理提供了高效且有效的解决方案。

Abstract: Graph neural networks (GNNs) have achieved remarkable success in molecular
property prediction. However, traditional graph representations struggle to
effectively encode the inherent 3D spatial structures of molecules, as
molecular orientations in 3D space introduce significant variability, severely
limiting model generalization and robustness. Existing approaches primarily
focus on rotation-invariant and rotation-equivariant methods. Invariant methods
often rely heavily on prior knowledge and lack sufficient generalizability,
while equivariant methods suffer from high computational costs. To address
these limitations, this paper proposes a novel plug-and-play 3D encoding module
leveraging rotational sampling. By computing the expectation over the SO(3)
rotational group, the method naturally achieves approximate rotational
invariance. Furthermore, by introducing a carefully designed post-alignment
strategy, strict invariance can be achieved without compromising performance.
Experimental evaluations on the QM9 and C10 Datasets demonstrate superior
predictive accuracy, robustness, and generalization performance compared to
existing methods. Moreover, the proposed approach maintains low computational
complexity and enhanced interpretability, providing a promising direction for
efficient and effective handling of 3D molecular information in drug discovery
and material design.

</details>


### [186] [Provenance Tracking in Large-Scale Machine Learning Systems](https://arxiv.org/abs/2507.01075)
*Gabriele Padovani,Valentine Anantharaj,Sandro Fiore*

Main category: cs.LG

TL;DR: 论文介绍了yProv4ML库，用于收集符合W3C PROV和ProvML标准的JSON格式的溯源数据，以优化大规模AI模型的训练效率、执行时间、准确性和能耗。


<details>
  <summary>Details</summary>
Motivation: 随着大规模AI模型需求的增长，如何在计算效率、执行时间、准确性和能耗之间实现平衡成为关键挑战。溯源数据在这一过程中至关重要，可以帮助理解资源使用模式、识别低效环节并确保AI开发的可重复性和责任性。

Method: 引入yProv4ML库，支持通过插件集成其他数据收集工具，并与yProv框架完全集成，适用于工作流管理系统。

Result: yProv4ML库提供了灵活且可扩展的解决方案，能够高效收集和分析AI模型训练的溯源数据。

Conclusion: yProv4ML库为优化大规模AI模型的训练和部署提供了实用工具，有助于提升资源利用效率和能源效率。

Abstract: As the demand for large scale AI models continues to grow, the optimization
of their training to balance computational efficiency, execution time, accuracy
and energy consumption represents a critical multidimensional challenge.
Achieving this balance requires not only innovative algorithmic techniques and
hardware architectures but also comprehensive tools for monitoring, analyzing,
and understanding the underlying processes involved in model training and
deployment. Provenance data information about the origins, context, and
transformations of data and processes has become a key component in this
pursuit. By leveraging provenance, researchers and engineers can gain insights
into resource usage patterns, identify inefficiencies, and ensure
reproducibility and accountability in AI development workflows. For this
reason, the question of how distributed resources can be optimally utilized to
scale large AI models in an energy efficient manner is a fundamental one. To
support this effort, we introduce the yProv4ML library, a tool designed to
collect provenance data in JSON format, compliant with the W3C PROV and ProvML
standards. yProv4ML focuses on flexibility and extensibility, and enables users
to integrate additional data collection tools via plugins. The library is fully
integrated with the yProv framework, allowing for higher level pairing in tasks
run also through workflow management systems.

</details>


### [187] [Good Enough to Learn: LLM-based Anomaly Detection in ECU Logs without Reliable Labels](https://arxiv.org/abs/2507.01077)
*Bogdan Bogdan,Arina Cazacu,Laura Vasilie*

Main category: cs.LG

TL;DR: 提出了一种基于解码器的大型语言模型（LLM），用于检测电子控制单元（ECU）通信日志中的异常，解决了现有方法在专业领域中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有异常检测方法在汽车通信系统等专业领域效果有限，且缺乏针对ECU通信的LLM模型。

Method: 使用解码器LLM学习UDP通信日志，通过时间偏差检测异常，并引入熵正则化技术处理不一致的标注数据。

Result: 提出了一种新的解码器异常检测架构，能够处理不一致标注，并适应不同ECU通信场景，提高了检测准确性。

Conclusion: 该方法通过生成能力减少了手动标注的高成本和错误，提供了一种更可扩展的解决方案。

Abstract: Anomaly detection often relies on supervised or clustering approaches, with
limited success in specialized domains like automotive communication systems
where scalable solutions are essential. We propose a novel decoder-only Large
Language Model (LLM) to detect anomalies in Electronic Control Unit (ECU)
communication logs. Our approach addresses two key challenges: the lack of LLMs
tailored for ECU communication and the complexity of inconsistent ground truth
data. By learning from UDP communication logs, we formulate anomaly detection
simply as identifying deviations in time from normal behavior. We introduce an
entropy regularization technique that increases model's uncertainty in known
anomalies while maintaining consistency in similar scenarios. Our solution
offers three novelties: a decoder-only anomaly detection architecture, a way to
handle inconsistent labeling, and an adaptable LLM for different ECU
communication use cases. By leveraging the generative capabilities of
decoder-only models, we present a new technique that addresses the high cost
and error-prone nature of manual labeling through a more scalable system that
is able to learn from a minimal set of examples, while improving detection
accuracy in complex communication environments.

</details>


### [188] [yProv4ML: Effortless Provenance Tracking for Machine Learning Systems](https://arxiv.org/abs/2507.01078)
*Gabriele Padovani,Valentine Anantharaj,Sandro Fiore*

Main category: cs.LG

TL;DR: 本文提出yProv4ML框架，用于以PROV-JSON格式捕获机器学习过程中的来源信息，解决现有工具在透明性和数据溯源方面的不足。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的发展缺乏透明性和严谨性，尤其是在超参数选择和模型优化方面。现有工具（如MLFlow）虽能自动化收集信息，但使用专有格式且忽视数据溯源。

Method: 提出yProv4ML框架，通过最小代码修改，捕获机器学习过程中的来源信息，并以PROV-JSON格式存储。

Result: yProv4ML能够有效记录机器学习过程中的关键信息，提升透明性和可追溯性。

Conclusion: yProv4ML为机器学习过程提供了更好的透明性和数据溯源支持，有助于提高研究的严谨性和可重复性。

Abstract: The rapid growth of interest in large language models (LLMs) reflects their
potential for flexibility and generalization, and attracted the attention of a
diverse range of researchers. However, the advent of these techniques has also
brought to light the lack of transparency and rigor with which development is
pursued. In particular, the inability to determine the number of epochs and
other hyperparameters in advance presents challenges in identifying the best
model. To address this challenge, machine learning frameworks such as MLFlow
can automate the collection of this type of information. However, these tools
capture data using proprietary formats and pose little attention to lineage.
This paper proposes yProv4ML, a framework to capture provenance information
generated during machine learning processes in PROV-JSON format, with minimal
code modifications.

</details>


### [189] [Development and Comparative Evaluation of Three Artificial Intelligence Models (NLP, LLM, JEPA) for Predicting Triage in Emergency Departments: A 7-Month Retrospective Proof-of-Concept](https://arxiv.org/abs/2507.01080)
*Edouard Lansiaux,Ramy Azzouz,Emmanuel Chazard,Amélie Vromant,Eric Wiel*

Main category: cs.LG

TL;DR: 研究比较了三种AI模型（NLP、LLM、JEPA）在急诊分诊中的表现，发现LLM模型（URGENTIAPARSE）准确率最高，优于护士分诊。


<details>
  <summary>Details</summary>
Motivation: 急诊分诊中的错误（如过度或不足分诊）是持续挑战，AI的引入有望提升分诊准确性和效率。

Method: 回顾性分析急诊患者数据，训练并验证三种AI模型（NLP、LLM、JEPA），评估其与FRENCH标准的吻合度。

Result: LLM模型表现最佳，尤其在预测住院需求和结构化数据处理上优于其他模型。

Conclusion: AI（尤其是LLM）可提升急诊分诊准确性和效率，但需解决模型局限性和伦理问题。

Abstract: Triage errors, including undertriage and overtriage, are persistent
challenges in emergency departments (EDs). With increasing patient influx and
staff shortages, the integration of artificial intelligence (AI) into triage
protocols has gained attention. This study compares the performance of three AI
models [Natural Language Processing (NLP), Large Language Models (LLM), and
Joint Embedding Predictive Architecture (JEPA)] in predicting triage outcomes
against the FRENCH scale and clinical practice.We conducted a retrospective
analysis of a prospectively recruited cohort gathering adult patient triage
data over a 7-month period at the Roger Salengro Hospital ED (Lille, France).
Three AI models were trained and validated : (1) TRIAGEMASTER (NLP), (2)
URGENTIAPARSE (LLM), and (3) EMERGINET (JEPA). Data included demographic
details, verbatim chief complaints, vital signs, and triage outcomes based on
the FRENCH scale and GEMSA coding. The primary outcome was the concordance of
AI-predicted triage level with the FRENCH gold-standard. It was assessed thanks
to various indicators : F1-Score, Weighted Kappa, Spearman, MAE, RMSE. The LLM
model (URGENTIAPARSE) showed higher accuracy (composite score: 2.514) compared
to JEPA (EMERGINET, 0.438) and NLP (TRIAGEMASTER, -3.511), outperforming nurse
triage (-4.343). Secondary analyses highlighted the effectiveness of
URGENTIAPARSE in predicting hospitalization needs (GEMSA) and its robustness
with structured data versus raw transcripts (either for GEMSA prediction or for
FRENCH prediction). LLM architecture, through abstraction of patient
representations, offers the most accurate triage predictions among tested
models. Integrating AI into ED workflows could enhance patient safety and
operational efficiency, though integration into clinical workflows requires
addressing model limitations and ensuring ethical transparency.

</details>


### [190] [Proof of a perfect platonic representation hypothesis](https://arxiv.org/abs/2507.01098)
*Liu Ziyin,Isaac Chuang*

Main category: cs.LG

TL;DR: 本文详细解释了Ziyin等人（2025）关于嵌入式深度线性网络模型（EDLN）的“完美”柏拉图表示假设（PRH）的证明。研究发现，使用SGD训练时，不同宽度和深度的EDLN会学习到相同的表示（仅相差旋转），且这种现象与渐进锐化有共同原因。


<details>
  <summary>Details</summary>
Motivation: 探讨SGD训练下EDLN模型中出现完美柏拉图表示的原因，并揭示其与渐进锐化的潜在联系。

Method: 通过理论分析和证明，研究SGD训练下EDLN模型的表示学习行为。

Result: 发现SGD仅找到完美柏拉图解，且该现象与渐进锐化有共同原因。

Conclusion: 研究强调了理解SGD训练中不可逆性导致的“熵力”及其在表示学习中的重要性。

Abstract: In this note, we elaborate on and explain in detail the proof given by Ziyin
et al. (2025) of the "perfect" Platonic Representation Hypothesis (PRH) for the
embedded deep linear network model (EDLN). We show that if trained with SGD,
two EDLNs with different widths and depths and trained on different data will
become Perfectly Platonic, meaning that every possible pair of layers will
learn the same representation up to a rotation. Because most of the global
minima of the loss function are not Platonic, that SGD only finds the perfectly
Platonic solution is rather extraordinary. The proof also suggests at least six
ways the PRH can be broken. We also show that in the EDLN model, the emergence
of the Platonic representations is due to the same reason as the emergence of
progressive sharpening. This implies that these two seemingly unrelated
phenomena in deep learning can, surprisingly, have a common cause. Overall, the
theory and proof highlight the importance of understanding emergent "entropic
forces" due to the irreversibility of SGD training and their role in
representation learning. The goal of this note is to be instructive and avoid
lengthy technical details.

</details>


### [191] [A Neural Operator based on Dynamic Mode Decomposition](https://arxiv.org/abs/2507.01117)
*Nikita Sakovich,Dmitry Aksenov,Ekaterina Pleshakova,Sergey Gataullin*

Main category: cs.LG

TL;DR: 论文提出了一种基于动态模式分解（DMD）和深度学习的神经算子，用于高效建模时空过程，降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 科学计算与人工智能结合是研究热点，但需平衡轻量化和准确性。传统PDE求解方法计算资源消耗大。

Method: 结合DMD和深度学习，自动提取关键模式与系统动态，用于预测。

Result: 在热方程、拉普拉斯方程和Burgers方程的近似解中，表现优于DeepONet和FNO，重建精度高。

Conclusion: 该方法为高效建模时空过程提供了新思路，显著降低计算成本。

Abstract: The scientific computation methods development in conjunction with artificial
intelligence technologies remains a hot research topic. Finding a balance
between lightweight and accurate computations is a solid foundation for this
direction. The study presents a neural operator based on the dynamic mode
decomposition algorithm (DMD), mapping functional spaces, which combines DMD
and deep learning (DL) for spatiotemporal processes efficient modeling. Solving
PDEs for various initial and boundary conditions requires significant
computational resources. The method suggested automatically extracts key modes
and system dynamics using them to construct predictions, reducing computational
costs compared to traditional numerical methods. The approach has demonstrated
its efficiency through comparative analysis of performance with closest
analogues DeepONet and FNO in the heat equation, Laplaces equation, and Burgers
equation solutions approximation, where it achieves high reconstruction
accuracy.

</details>


### [192] [On Design Principles for Private Adaptive Optimizers](https://arxiv.org/abs/2507.01129)
*Arun Ganesh,Brendan McMahan,Abhradeep Thakurta*

Main category: cs.LG

TL;DR: 论文分析了差分隐私训练中球形噪声对自适应优化器的影响，提出了一种名为“scale-then-privatize”的简单技术，优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 球形噪声在差分隐私训练中削弱了自适应优化器的性能，现有研究局限于简单任务和模型，结论可能不适用于实际模型训练。

Method: 调查了多种改进算法，并通过理论分析和实证研究比较了它们，重点关注“scale-then-privatize”技术。

Result: 发现追求无偏二阶矩估计的直觉是错误的，“scale-then-privatize”在理论行为和实际任务中表现最佳。

Conclusion: “scale-then-privatize”技术更匹配实际需求，优于其他方法，适用于小规模语言模型训练。

Abstract: The spherical noise added to gradients in differentially private (DP)
training undermines the performance of adaptive optimizers like AdaGrad and
Adam, and hence many recent works have proposed algorithms to address this
challenge. However, the empirical results in these works focus on simple tasks
and models and the conclusions may not generalize to model training in
practice. In this paper we survey several of these variants, and develop better
theoretical intuition for them as well as perform empirical studies comparing
them. We find that a common intuition of aiming for unbiased estimates of
second moments of gradients in adaptive optimizers is misguided, and instead
that a simple technique called scale-then-privatize (which does not achieve
unbiased second moments) has more desirable theoretical behaviors and
outperforms all other variants we study on a small-scale language model
training task. We additionally argue that scale-then-privatize causes the noise
addition to better match the application of correlated noise mechanisms which
are more desirable to use in practice.

</details>


### [193] [Tensor Decomposition Networks for Fast Machine Learning Interatomic Potential Computations](https://arxiv.org/abs/2507.01131)
*Yuchao Lin,Cong Fu,Zachary Krueger,Haiyang Yu,Maho Nakata,Jianwen Xie,Emine Kucukbenli,Xiaofeng Qian,Shuiwang Ji*

Main category: cs.LG

TL;DR: 论文提出了一种近似等变的网络结构（TDNs），通过低秩张量分解（如CP分解）替代计算昂贵的Clebsch-Gordan张量积，显著加速了计算，同时保持了SO(3)等变性。


<details>
  <summary>Details</summary>
Motivation: 现有的SO(3)-等变网络在计算Clebsch-Gordan张量积时效率低下，需要一种更高效的方法来加速计算。

Method: 采用低秩张量分解（如CP分解）替代Clebsch-Gordan张量积，并提出路径权重共享以减少参数数量。

Result: 在PubChemQCR、OC20和OC22数据集上，TDNs实现了与现有方法竞争的性能，同时计算速度显著提升。

Conclusion: TDNs作为一种高效且近似等变的网络结构，可替代现有网络中的张量积操作，适用于大规模分子模拟任务。

Abstract: $\rm{SO}(3)$-equivariant networks are the dominant models for machine
learning interatomic potentials (MLIPs). The key operation of such networks is
the Clebsch-Gordan (CG) tensor product, which is computationally expensive. To
accelerate the computation, we develop tensor decomposition networks (TDNs) as
a class of approximately equivariant networks whose CG tensor products are
replaced by low-rank tensor decompositions, such as the CANDECOMP/PARAFAC (CP)
decomposition. With the CP decomposition, we prove (i) a uniform bound on the
induced error of $\rm{SO}(3)$-equivariance, and (ii) the universality of
approximating any equivariant bilinear map. To further reduce the number of
parameters, we propose path-weight sharing that ties all multiplicity-space
weights across the $O(L^3)$ CG paths into a single path without compromising
equivariance, where $L$ is the maximum angular degree. The resulting layer acts
as a plug-and-play replacement for tensor products in existing networks, and
the computational complexity of tensor products is reduced from $O(L^6)$ to
$O(L^4)$. We evaluate TDNs on PubChemQCR, a newly curated molecular relaxation
dataset containing 105 million DFT-calculated snapshots. We also use existing
datasets, including OC20, and OC22. Results show that TDNs achieve competitive
performance with dramatic speedup in computations.

</details>


### [194] [Spectral Manifold Harmonization for Graph Imbalanced Regression](https://arxiv.org/abs/2507.01132)
*Brenda Nogueira,Gabe Gomes,Meng Jiang,Nitesh V. Chawla,Nuno Moniz*

Main category: cs.LG

TL;DR: 论文提出了一种名为Spectral Manifold Harmonization (SMH)的新方法，用于解决图结构数据中的不平衡回归问题，通过生成合成样本来改善对特定目标值范围的预测性能。


<details>
  <summary>Details</summary>
Motivation: 图结构数据在科学领域中普遍存在，但现有研究在处理不平衡回归问题时，往往忽视了对特定目标值范围的关注，导致模型偏向于平均目标值。

Method: SMH方法通过生成合成图样本，既保留了拓扑特性，又专注于目标分布中常被低估的区域。

Result: 实验结果表明，SMH在化学和药物发现基准数据集上显著提升了特定目标域范围的预测性能。

Conclusion: SMH为解决图结构数据中的不平衡回归问题提供了一种有效的新方法。

Abstract: Graph-structured data is ubiquitous in scientific domains, where models often
face imbalanced learning settings. In imbalanced regression, domain preferences
focus on specific target value ranges representing the most scientifically
valuable cases; we observe a significant lack of research. In this paper, we
present Spectral Manifold Harmonization (SMH), a novel approach for addressing
this imbalanced regression challenge on graph-structured data by generating
synthetic graph samples that preserve topological properties while focusing on
often underrepresented target distribution regions. Conventional methods fail
in this context because they either ignore graph topology in case generation or
do not target specific domain ranges, resulting in models biased toward average
target values. Experimental results demonstrate the potential of SMH on
chemistry and drug discovery benchmark datasets, showing consistent
improvements in predictive performance for target domain ranges.

</details>


### [195] [FlashDP: Private Training Large Language Models with Efficient DP-SGD](https://arxiv.org/abs/2507.01154)
*Liangyu Wang,Junxiao Wang,Jie Ren,Zihang Xiang,David E. Keyes,Di Wang*

Main category: cs.LG

TL;DR: FlashDP是一种创新的缓存友好型DP-SGD方法，通过单次融合计算梯度，显著减少内存需求和冗余计算，同时保持隐私保护效果。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型（LLMs）的广泛应用，训练数据的隐私保护成为关键问题。现有DP-SGD方法在内存和计算效率上存在不足。

Method: 提出FlashDP，一种缓存友好的逐层DP-SGD方法，通过单次融合计算梯度，减少内存移动和冗余计算。

Result: FlashDP减少50%内存移动和20%冗余计算，在Llama-13B预训练中达到非DP方法90%的吞吐量，且精度与标准DP-SGD相当。

Conclusion: FlashDP为高效且隐私保护的LLM训练提供了重要解决方案，其代码已开源。

Abstract: As large language models (LLMs) increasingly underpin technological
advancements, the privacy of their training data emerges as a critical concern.
Differential Privacy (DP) serves as a rigorous mechanism to protect this data,
yet its integration via Differentially Private Stochastic Gradient Descent
(DP-SGD) introduces substantial challenges, primarily due to the complexities
of per-sample gradient clipping. Current explicit methods, such as Opacus,
necessitate extensive storage for per-sample gradients, significantly inflating
memory requirements. Conversely, implicit methods like GhostClip reduce storage
needs by recalculating gradients multiple times, which leads to inefficiencies
due to redundant computations. This paper introduces FlashDP, an innovative
cache-friendly per-layer DP-SGD that consolidates necessary operations into a
single task, calculating gradients only once in a fused manner. This approach
not only diminishes memory movement by up to \textbf{50\%} but also cuts down
redundant computations by \textbf{20\%}, compared to previous methods.
Consequently, FlashDP does not increase memory demands and achieves a
\textbf{90\%} throughput compared to the Non-DP method on a four-A100 system
during the pre-training of the Llama-13B model, while maintaining parity with
standard per-layer clipped DP-SGD in terms of accuracy. These advancements
establish FlashDP as a pivotal development for efficient and privacy-preserving
training of LLMs. FlashDP's code has been open-sourced in
https://github.com/kaustpradalab/flashdp.

</details>


### [196] [Diffusion Explorer: Interactive Exploration of Diffusion Models](https://arxiv.org/abs/2507.01178)
*Alec Helbling,Duen Horng Chau*

Main category: cs.LG

TL;DR: Diffusion Explorer是一个交互式工具，用于解释扩散模型的几何特性，用户可以在浏览器中训练2D扩散模型并观察采样过程的动态。


<details>
  <summary>Details</summary>
Motivation: 现有解释扩散模型的资源要么需要高深的理论基础，要么过于关注神经网络架构，而忽略了其丰富的几何特性。

Method: 开发了Diffusion Explorer，利用交互式动画直观展示扩散模型的动态过程。

Result: 用户可以通过浏览器直接体验和观察扩散模型的几何特性，工具开源且提供在线演示。

Conclusion: Diffusion Explorer为理解和教学扩散模型的几何特性提供了直观且易用的工具。

Abstract: Diffusion models have been central to the development of recent image, video,
and even text generation systems. They posses striking geometric properties
that can be faithfully portrayed in low-dimensional settings. However, existing
resources for explaining diffusion either require an advanced theoretical
foundation or focus on their neural network architectures rather than their
rich geometric properties. We introduce Diffusion Explorer, an interactive tool
to explain the geometric properties of diffusion models. Users can train 2D
diffusion models in the browser and observe the temporal dynamics of their
sampling process. Diffusion Explorer leverages interactive animation, which has
been shown to be a powerful tool for making engaging visualizations of dynamic
systems, making it well suited to explaining diffusion models which represent
stochastic processes that evolve over time. Diffusion Explorer is open source
and a live demo is available at alechelbling.com/Diffusion-Explorer.

</details>


### [197] [TD-MPC-Opt: Distilling Model-Based Multi-Task Reinforcement Learning Agents](https://arxiv.org/abs/2507.01823)
*Dmytro Kuzmenko,Nadiya Shvai*

Main category: cs.LG

TL;DR: 提出了一种基于模型强化学习的新型知识迁移方法，将大型世界模型高效压缩为紧凑模型，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决在资源受限环境中部署大型世界模型的挑战，实现高效多任务强化学习。

Method: 通过蒸馏技术将高容量多任务代理（317M参数）压缩为紧凑模型（1M参数），并采用FP16量化进一步优化。

Result: 蒸馏模型在MT30基准测试中达到28.45的标准化分数，优于原始1M参数模型的18.93，模型大小减少约50%。

Conclusion: 该方法为资源受限应用中的多任务强化学习提供了高效解决方案，并为大型世界模型的知识表示提供了新见解。

Abstract: We present a novel approach to knowledge transfer in model-based
reinforcement learning, addressing the critical challenge of deploying large
world models in resource-constrained environments. Our method efficiently
distills a high-capacity multi-task agent (317M parameters) into a compact
model (1M parameters) on the MT30 benchmark, significantly improving
performance across diverse tasks. Our distilled model achieves a
state-of-the-art normalized score of 28.45, surpassing the original 1M
parameter model score of 18.93. This improvement demonstrates the ability of
our distillation technique to capture and consolidate complex multi-task
knowledge. We further optimize the distilled model through FP16 post-training
quantization, reducing its size by $\sim$50\%. Our approach addresses practical
deployment limitations and offers insights into knowledge representation in
large world models, paving the way for more efficient and accessible multi-task
reinforcement learning systems in robotics and other resource-constrained
applications. Code available at https://github.com/dmytro-kuzmenko/td-mpc-opt.

</details>


### [198] [Escaping Platos Cave: JAM for Aligning Independently Trained Vision and Language Models](https://arxiv.org/abs/2507.01201)
*Hyoseo,Yoon,Yisong Yue,Been Kim*

Main category: cs.LG

TL;DR: 论文提出JAM框架，通过联合训练模态特定自编码器，优化视觉与语言模型的表示对齐，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 探索独立训练的视觉与语言模型是否可以通过优化实现表示对齐，验证柏拉图表示假设。

Method: 提出JAM框架，结合重建和跨模态目标，优化对齐；比较不同损失函数、层深度和模型规模的影响。

Result: JAM框架能有效诱导对齐，即使模型表示独立且冻结，为多模态模型提供实用路径。

Conclusion: JAM框架为多模态模型对齐提供理论支持和实践方法，验证了柏拉图表示假设的可行性。

Abstract: Independently trained vision and language models inhabit disjoint
representational spaces, shaped by their respective modalities, objectives, and
architectures. Yet an emerging hypothesis - the Platonic Representation
Hypothesis - suggests that such models may nonetheless converge toward a shared
statistical model of reality. This compatibility, if it exists, raises a
fundamental question: can we move beyond post-hoc statistical detection of
alignment and explicitly optimize for it between such disjoint representations?
We cast this Platonic alignment problem as a multi-objective optimization task
- preserve each modality's native structure while aligning for mutual
coherence. We introduce the Joint Autoencoder Modulator (JAM) framework that
jointly trains modality-specific autoencoders on the latent representations of
pre-trained single modality models, encouraging alignment through both
reconstruction and cross-modal objectives. By analogy, this framework serves as
a method to escape Plato's Cave, enabling the emergence of shared structure
from disjoint inputs. We evaluate this framework across three critical design
axes: (i) the alignment objective - comparing contrastive loss (Con), its
hard-negative variant (NegCon), and our Spread loss, (ii) the layer depth at
which alignment is most effective, and (iii) the impact of foundation model
scale on representational convergence. Our findings show that our lightweight
Pareto-efficient framework reliably induces alignment, even across frozen,
independently trained representations, offering both theoretical insight and
practical pathways for transforming generalist unimodal foundations into
specialist multimodal models.

</details>


### [199] [Deep Learning-Based Intrusion Detection for Automotive Ethernet: Evaluating & Optimizing Fast Inference Techniques for Deployment on Low-Cost Platform](https://arxiv.org/abs/2507.01208)
*Pedro R. X. Carmo,Igor de Moura,Assis T. de Oliveira Filho,Djamel Sadok,Cleber Zanchettin*

Main category: cs.LG

TL;DR: 论文探讨了在低成本平台上实时部署深度学习入侵检测系统（IDS）的方法，通过蒸馏和剪枝技术优化模型，实现了高效的入侵检测。


<details>
  <summary>Details</summary>
Motivation: 现代车辆通信系统易受攻击，传统深度学习IDS需要昂贵硬件，限制了其实际应用。

Method: 采用蒸馏和剪枝技术优化神经网络模型，以在低成本平台（如树莓派4）上实现实时推理。

Result: 优化后的模型在树莓派4上实现了727微秒的检测时间，AUCROC值达0.9890。

Conclusion: 蒸馏和剪枝技术能有效降低计算成本，使深度学习IDS在低成本平台上实时运行成为可能。

Abstract: Modern vehicles are increasingly connected, and in this context, automotive
Ethernet is one of the technologies that promise to provide the necessary
infrastructure for intra-vehicle communication. However, these systems are
subject to attacks that can compromise safety, including flow injection
attacks. Deep Learning-based Intrusion Detection Systems (IDS) are often
designed to combat this problem, but they require expensive hardware to run in
real time. In this work, we propose to evaluate and apply fast neural network
inference techniques like Distilling and Prunning for deploying IDS models on
low-cost platforms in real time. The results show that these techniques can
achieve intrusion detection times of up to 727 {\mu}s using a Raspberry Pi 4,
with AUCROC values of 0.9890.

</details>


### [200] [PAE MobiLLM: Privacy-Aware and Efficient LLM Fine-Tuning on the Mobile Device via Additive Side-Tuning](https://arxiv.org/abs/2507.01216)
*Xingke Yang,Liang Li,Zhiyi Wan,Sicong Li,Hao Wang,Xiaoqi Qi,Jiang Liu,Tomoaki Ohtsuki,Xin Fu,Miao Pan*

Main category: cs.LG

TL;DR: PAE MobiLLM是一种隐私感知且高效的LLM微调方法，通过服务器辅助的侧调优和激活缓存技术，解决了移动设备资源有限和通信负担重的问题。


<details>
  <summary>Details</summary>
Motivation: 移动设备资源有限，现有服务器辅助方法存在通信负担重和隐私泄露问题。

Method: 采用服务器辅助的侧调优、激活缓存、单令牌激活快捷方式和加性适配器侧网络设计。

Result: 减少了通信成本，提高了计算效率，保护了数据和模型隐私。

Conclusion: PAE MobiLLM为移动设备上的LLM微调提供了一种高效且隐私安全的解决方案。

Abstract: There is a huge gap between numerous intriguing applications fostered by
on-device large language model (LLM) fine-tuning (FT) from fresh mobile data
and the limited resources of a mobile device. While existing server-assisted
methods (e.g., split learning or side-tuning) may enable LLM FT on the local
mobile device, they suffer from heavy communication burdens of activation
transmissions, and may disclose data, labels or fine-tuned models to the
server. To address those issues, we develop PAE MobiLLM, a privacy-aware and
efficient LLM FT method which can be deployed on the mobile device via
server-assisted additive side-tuning. To further accelerate FT convergence and
improve computing efficiency, PAE MobiLLM integrates activation caching on the
server side, which allows the server to reuse historical activations and saves
the mobile device from repeatedly computing forward passes for the recurring
data samples. Besides, to reduce communication cost, PAE MobiLLM develops a
one-token (i.e., ``pivot'' token) activation shortcut that transmits only a
single activation dimension instead of full activation matrices to guide the
side network tuning. Last but not least, PAE MobiLLM introduces the additive
adapter side-network design which makes the server train the adapter modules
based on device-defined prediction differences rather than raw ground-truth
labels. In this way, the server can only assist device-defined side-network
computing, and learn nothing about data, labels or fine-tuned models.

</details>


### [201] [Quantum Machine Learning in Transportation: A Case Study of Pedestrian Stress Modelling](https://arxiv.org/abs/2507.01235)
*Bara Rababa,Bilal Farooq*

Main category: cs.LG

TL;DR: 论文探讨了量子机器学习在建模皮肤电导反应（SCR）事件中的应用，比较了量子支持向量机（QSVM）和量子神经网络（QNN）的性能。


<details>
  <summary>Details</summary>
Motivation: 量子计算为复杂机器学习任务提供了新方法，尤其是在智能交通系统中需要高维数据表示的场景。

Method: 开发了基于Pennylane的QSVM（使用八量子位ZZ特征映射）和QNN（使用树张量网络结构和八量子位ZZ特征映射）模型。

Result: QSVM训练准确率高但测试准确率低（45%），存在过拟合问题；QNN测试准确率更高（55%），优于QSVM和经典模型。

Conclusion: QNN在分类任务中表现更优，展示了量子机器学习在复杂数据建模中的潜力。

Abstract: Quantum computing has opened new opportunities to tackle complex machine
learning tasks, for instance, high-dimensional data representations commonly
required in intelligent transportation systems. We explore quantum machine
learning to model complex skin conductance response (SCR) events that reflect
pedestrian stress in a virtual reality road crossing experiment. For this
purpose, Quantum Support Vector Machine (QSVM) with an eight-qubit ZZ feature
map and a Quantum Neural Network (QNN) using a Tree Tensor Network ansatz and
an eight-qubit ZZ feature map, were developed on Pennylane. The dataset
consists of SCR measurements along with features such as the response amplitude
and elapsed time, which have been categorized into amplitude-based classes. The
QSVM achieved good training accuracy, but had an overfitting problem, showing a
low test accuracy of 45% and therefore impacting the reliability of the
classification model. The QNN model reached a higher test accuracy of 55%,
making it a better classification model than the QSVM and the classic versions.

</details>


### [202] [Beyond First-Order: Training LLMs with Stochastic Conjugate Subgradients and AdamW](https://arxiv.org/abs/2507.01241)
*Di Zhang,Yihang Zhang*

Main category: cs.LG

TL;DR: 本文提出了一种针对大规模语言模型（LLM）训练的随机共轭次梯度方法，结合自适应采样，相比传统SGD方法，实现了更快的收敛速度和更好的扩展性。


<details>
  <summary>Details</summary>
Motivation: 传统SGD方法在大规模应用中表现出性能限制，因此需要一种更高效的方法来训练LLM。

Method: 提出了一种结合自适应采样的随机共轭次梯度方法，利用样本复杂度分析选择样本大小，采用AdamW类算法调整步长。

Result: 实验表明，该方法在速度和准确性上均优于传统SGD，同时保持了扩展性。

Conclusion: 该方法有效解决了LLM训练中的非凸性和非光滑性问题，显著提升了优化效率。

Abstract: Stochastic gradient-based descent (SGD), have long been central to training
large language models (LLMs). However, their effectiveness is increasingly
being questioned, particularly in large-scale applications where empirical
evidence suggests potential performance limitations. In response, this paper
proposes a stochastic conjugate subgradient method together with adaptive
sampling tailored specifically for training LLMs. The method not only achieves
faster convergence per iteration but also demonstrates improved scalability
compared to traditional SGD techniques. It leverages sample complexity analysis
to adaptively choose the sample size, employs a stochastic conjugate
subgradient approach to determine search directions and utilizing an AdamW-like
algorithm to adaptively adjust step sizes. This approach preserves the key
advantages of first-order methods while effectively addressing the nonconvexity
and non-smoothness inherent in LLMs training. Additionally, we provide a
detailed analysis of the advantage of the algorithm. Experimental results show
that the proposed method not only maintains, but in many cases surpasses, the
scalability of traditional SGD techniques, significantly enhancing both the
speed and accuracy of the optimization process.

</details>


### [203] [PULSE: Practical Evaluation Scenarios for Large Multimodal Model Unlearning](https://arxiv.org/abs/2507.01271)
*Tatsuki Kawakami,Kazuki Egashira,Atsuyuki Miyai,Go Irie,Kiyoharu Aizawa*

Main category: cs.LG

TL;DR: 该论文提出了PULSE协议，用于评估大型多模态模型（LMMs）的遗忘技术，重点关注预训练知识遗忘和长期可持续性评估。


<details>
  <summary>Details</summary>
Motivation: 解决现有遗忘基准仅关注单次遗忘操作的问题，提出更现实的遗忘场景评估框架。

Method: 引入PULSE协议，从预训练知识遗忘和长期可持续性两个维度评估现有遗忘方法。

Result: 现有技术能有效遗忘微调知识，但对预训练知识效果不佳；批量遗忘在分步操作时性能下降明显。

Conclusion: PULSE协议为LMMs的遗忘技术提供了更全面的评估标准，揭示了现有方法的局限性。

Abstract: In recent years, unlearning techniques, which are methods for inducing a
model to "forget" previously learned information, have attracted attention as a
way to address privacy and copyright concerns in large language models (LLMs)
and large multimodal models (LMMs). While several unlearning benchmarks have
been established for LLMs, a practical evaluation framework for unlearning in
LMMs has been less explored. Specifically, existing unlearning benchmark for
LMMs considers only scenarios in which the model is required to unlearn
fine-tuned knowledge through a single unlearning operation. In this study, we
introduce PULSE protocol for realistic unlearning scenarios for LMMs by
introducing two critical perspectives: (i) Pre-trained knowledge Unlearning for
analyzing the effect across different knowledge acquisition phases and (ii)
Long-term Sustainability Evaluation to address sequential requests. We then
evaluate existing unlearning methods along these dimensions. Our results reveal
that, although some techniques can successfully unlearn knowledge acquired
through fine-tuning, they struggle to eliminate information learned during
pre-training. Moreover, methods that effectively unlearn a batch of target data
in a single operation exhibit substantial performance degradation when the same
data are split and unlearned sequentially.

</details>


### [204] [Far From Sight, Far From Mind: Inverse Distance Weighting for Graph Federated Recommendation](https://arxiv.org/abs/2507.01285)
*Aymen Rayane Khouas,Mohamed Reda Bouadjenek,Hakim Hacid,Sunil Aryal*

Main category: cs.LG

TL;DR: Dist-FedAvg是一种基于距离的聚合方法，用于提升图联邦学习中的个性化和聚合效率，优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 传统聚合方法在图联邦推荐系统中忽视了用户嵌入的独特性和用户相似性的重要性，且缺乏对动态用户交互的自适应性。

Method: 提出Dist-FedAvg方法，通过为相似嵌入用户分配更高聚合权重，并保留锚用户的影响力，优化聚合过程。

Result: 在多数据集上的实验表明，Dist-FedAvg在推荐准确性上优于基线方法，且易于集成到现有联邦学习框架中。

Conclusion: Dist-FedAvg有效解决了传统聚合方法的局限性，提升了图联邦推荐系统的性能和适应性。

Abstract: Graph federated recommendation systems offer a privacy-preserving alternative
to traditional centralized recommendation architectures, which often raise
concerns about data security. While federated learning enables personalized
recommendations without exposing raw user data, existing aggregation methods
overlook the unique properties of user embeddings in this setting. Indeed,
traditional aggregation methods fail to account for their complexity and the
critical role of user similarity in recommendation effectiveness. Moreover,
evolving user interactions require adaptive aggregation while preserving the
influence of high-relevance anchor users (the primary users before expansion in
graph-based frameworks). To address these limitations, we introduce
Dist-FedAvg, a novel distance-based aggregation method designed to enhance
personalization and aggregation efficiency in graph federated learning. Our
method assigns higher aggregation weights to users with similar embeddings,
while ensuring that anchor users retain significant influence in local updates.
Empirical evaluations on multiple datasets demonstrate that Dist-FedAvg
consistently outperforms baseline aggregation techniques, improving
recommendation accuracy while maintaining seamless integration into existing
federated learning frameworks.

</details>


### [205] [Neural Hamiltonian Operator](https://arxiv.org/abs/2507.01313)
*Qian Qi*

Main category: cs.LG

TL;DR: 论文提出了一种基于深度学习的神经哈密顿算子（NHO）框架，用于解决高维随机控制问题，通过神经网络参数化FBSDE系统，并证明了其通用逼近能力。


<details>
  <summary>Details</summary>
Motivation: 高维随机控制问题因维度灾难难以解决，传统动态规划方法效率低下，因此需要一种新方法。

Method: 引入神经哈密顿算子（NHO），通过神经网络参数化FBSDE系统，并利用PMP一致性条件训练网络。

Result: 证明了NHO在一般鞅驱动下的通用逼近能力，并分析了优化挑战。

Conclusion: NHO框架为高维随机控制问题提供了有效的深度学习解决方案，并具有理论保障。

Abstract: Stochastic control problems in high dimensions are notoriously difficult to
solve due to the curse of dimensionality. An alternative to traditional dynamic
programming is Pontryagin's Maximum Principle (PMP), which recasts the problem
as a system of Forward-Backward Stochastic Differential Equations (FBSDEs). In
this paper, we introduce a formal framework for solving such problems with deep
learning by defining a \textbf{Neural Hamiltonian Operator (NHO)}. This
operator parameterizes the coupled FBSDE dynamics via neural networks that
represent the feedback control and an ansatz for the value function's spatial
gradient. We show how the optimal NHO can be found by training the underlying
networks to enforce the consistency conditions dictated by the PMP. By adopting
this operator-theoretic view, we situate the deep FBSDE method within the
rigorous language of statistical inference, framing it as a problem of learning
an unknown operator from simulated data. This perspective allows us to prove
the universal approximation capabilities of NHOs under general martingale
drivers and provides a clear lens for analyzing the significant optimization
challenges inherent to this class of models.

</details>


### [206] [ICLShield: Exploring and Mitigating In-Context Learning Backdoor Attacks](https://arxiv.org/abs/2507.01321)
*Zhiyao Ren,Siyuan Liang,Aishan Liu,Dacheng Tao*

Main category: cs.LG

TL;DR: 论文提出双学习假设，揭示大语言模型在上下文学习中同时学习任务相关和潜在后门概念，并提出防御机制ICLShield，动态调整概念偏好比例，有效抵御后门攻击。


<details>
  <summary>Details</summary>
Motivation: 上下文学习（ICL）因其适应性和无参数特性在大语言模型中表现优异，但也易受后门攻击影响。研究旨在揭示攻击机制并提出防御方法。

Method: 提出双学习假设，分析ICL后门效应上界，设计ICLShield机制，通过置信度和相似度动态调整概念偏好比例。

Result: 实验表明ICLShield在防御效果上显著优于现有方法（平均提升26.02%），且对闭源模型（如GPT-4）也表现出色。

Conclusion: ICLShield通过动态调整概念偏好比例，有效提升大语言模型对后门攻击的防御能力，具有广泛适用性和高效性。

Abstract: In-context learning (ICL) has demonstrated remarkable success in large
language models (LLMs) due to its adaptability and parameter-free nature.
However, it also introduces a critical vulnerability to backdoor attacks, where
adversaries can manipulate LLM behaviors by simply poisoning a few ICL
demonstrations. In this paper, we propose, for the first time, the
dual-learning hypothesis, which posits that LLMs simultaneously learn both the
task-relevant latent concepts and backdoor latent concepts within poisoned
demonstrations, jointly influencing the probability of model outputs. Through
theoretical analysis, we derive an upper bound for ICL backdoor effects,
revealing that the vulnerability is dominated by the concept preference ratio
between the task and the backdoor. Motivated by these findings, we propose
ICLShield, a defense mechanism that dynamically adjusts the concept preference
ratio. Our method encourages LLMs to select clean demonstrations during the ICL
phase by leveraging confidence and similarity scores, effectively mitigating
susceptibility to backdoor attacks. Extensive experiments across multiple LLMs
and tasks demonstrate that our method achieves state-of-the-art defense
effectiveness, significantly outperforming existing approaches (+26.02% on
average). Furthermore, our method exhibits exceptional adaptability and
defensive performance even for closed-source models (e.g., GPT-4).

</details>


### [207] [Reasoner for Real-World Event Detection: Scaling Reinforcement Learning via Adaptive Perplexity-Aware Sampling Strategy](https://arxiv.org/abs/2507.01327)
*Xiaoyun Zhang,Jingqing Ruan,Xing Ma,Yawen Zhu,Jiansong Chen,Ke Zeng,Xunliang Cai*

Main category: cs.LG

TL;DR: 提出了一种基于大型语言模型的自适应困惑感知强化学习框架（APARL），用于客户服务对话中的异常事件检测，显著提升了模型的适应性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决客户服务对话中异常事件检测的复杂性和动态性挑战，同时提升模型的跨领域泛化能力。

Method: 采用双环动态课程学习架构，逐步聚焦更具挑战性的样本，结合大型语言模型的推理能力。

Result: 在食品配送对话任务中，F1分数平均提升17.19%，跨领域转移测试中平均提升9.59%。

Conclusion: APARL为工业部署提供了高效的异常检测解决方案，提升了运营效率和商业价值。

Abstract: Detecting abnormal events in real-world customer service dialogues is highly
challenging due to the complexity of business data and the dynamic nature of
customer interactions. Moreover, models must demonstrate strong out-of-domain
(OOD) generalization to enable rapid adaptation across different business
scenarios and maximize commercial value. In this work, we propose a novel
Adaptive Perplexity-Aware Reinforcement Learning (APARL) framework that
leverages the advanced reasoning capabilities of large language models for
abnormal event detection. APARL introduces a dual-loop dynamic curriculum
learning architecture, enabling the model to progressively focus on more
challenging samples as its proficiency increases. This design effectively
addresses performance bottlenecks and significantly enhances OOD
transferability. Extensive evaluations on food delivery dialogue tasks show
that our model achieves significantly enhanced adaptability and robustness,
attaining the highest F1 score with an average improvement of 17.19\%, and an
average improvement of 9.59\% in OOD transfer tests. This method provides a
superior solution for industrial deployment of anomaly detection models,
contributing to improved operational efficiency and commercial benefits.

</details>


### [208] [Efficient Kilometer-Scale Precipitation Downscaling with Conditional Wavelet Diffusion](https://arxiv.org/abs/2507.01354)
*Chugang Yi,Minghan Yu,Weikang Qian,Yixin Wen,Haizhao Yang*

Main category: cs.LG

TL;DR: 提出了一种基于小波的生成模型（WDM），用于将降水数据从10 km分辨率降尺度到1 km，显著提升了精度和速度。


<details>
  <summary>Details</summary>
Motivation: 现有全球降水数据（如IMERG）分辨率较低（10 km），无法满足水文建模和极端天气分析的需求。

Method: WDM是一种条件扩散模型，直接在小波域中学习降水数据的复杂结构，专注于高频小波系数以生成高分辨率降水场。

Result: WDM实现了10倍空间超分辨率，推理速度比像素级扩散模型快9倍，生成结果更真实且细节丰富。

Conclusion: WDM为地球科学超分辨率问题提供了准确且高效的解决方案，有助于提升水文预报的可靠性。

Abstract: Effective hydrological modeling and extreme weather analysis demand
precipitation data at a kilometer-scale resolution, which is significantly
finer than the 10 km scale offered by standard global products like IMERG. To
address this, we propose the Wavelet Diffusion Model (WDM), a generative
framework that achieves 10x spatial super-resolution (downscaling to 1 km) and
delivers a 9x inference speedup over pixel-based diffusion models. WDM is a
conditional diffusion model that learns the learns the complex structure of
precipitation from MRMS radar data directly in the wavelet domain. By focusing
on high-frequency wavelet coefficients, it generates exceptionally realistic
and detailed 1-km precipitation fields. This wavelet-based approach produces
visually superior results with fewer artifacts than pixel-space models, and
delivers a significant gains in sampling efficiency. Our results demonstrate
that WDM provides a robust solution to the dual challenges of accuracy and
speed in geoscience super-resolution, paving the way for more reliable
hydrological forecasts.

</details>


### [209] [Distributional Soft Actor-Critic with Diffusion Policy](https://arxiv.org/abs/2507.01381)
*Tong Liu,Yinuo Wang,Xujie Song,Wenjun Zou,Liangfa Chen,Likun Wang,Bin Shuai,Jingliang Duan,Shengbo Eben Li*

Main category: cs.LG

TL;DR: DSAC-D算法通过引入扩散模型和熵优化，解决了传统强化学习中值函数估计偏差和多模态策略表示的问题，在控制任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习方法使用单模态分布（如高斯分布）建模值分布，容易导致估计偏差和性能下降。

Method: 提出DSAC-D算法，结合扩散模型和熵优化，构建多模态分布策略迭代框架和扩散值网络。

Result: 在MuJoCo任务中表现最优，平均回报提升10%，并在真实车辆测试中成功表征多模态驾驶风格。

Conclusion: DSAC-D算法有效抑制估计偏差，实现多模态策略学习，性能显著优于现有方法。

Abstract: Reinforcement learning has been proven to be highly effective in handling
complex control tasks. Traditional methods typically use unimodal
distributions, such as Gaussian distributions, to model the output of value
distributions. However, unimodal distribution often and easily causes bias in
value function estimation, leading to poor algorithm performance. This paper
proposes a distributional reinforcement learning algorithm called DSAC-D
(Distributed Soft Actor Critic with Diffusion Policy) to address the challenges
of estimating bias in value functions and obtaining multimodal policy
representations. A multimodal distributional policy iteration framework that
can converge to the optimal policy was established by introducing policy
entropy and value distribution function. A diffusion value network that can
accurately characterize the distribution of multi peaks was constructed by
generating a set of reward samples through reverse sampling using a diffusion
model. Based on this, a distributional reinforcement learning algorithm with
dual diffusion of the value network and the policy network was derived. MuJoCo
testing tasks demonstrate that the proposed algorithm not only learns
multimodal policy, but also achieves state-of-the-art (SOTA) performance in all
9 control tasks, with significant suppression of estimation bias and total
average return improvement of over 10\% compared to existing mainstream
algorithms. The results of real vehicle testing show that DSAC-D can accurately
characterize the multimodal distribution of different driving styles, and the
diffusion policy network can characterize multimodal trajectories.

</details>


### [210] [Surrogate Modeling via Factorization Machine and Ising Model with Enhanced Higher-Order Interaction Learning](https://arxiv.org/abs/2507.01389)
*Anbang Wang,Dunbo Cai,Yu Zhang,Yangqing Huang,Xiangyang Feng,Zhihong Zhang*

Main category: cs.LG

TL;DR: 提出了一种增强的代理模型，通过引入松弛变量将两步过程统一为一步，并在训练阶段迭代更新松弛变量以捕捉高阶特征交互。实验表明该方法在预测药物组合效果上表现更优。


<details>
  <summary>Details</summary>
Motivation: 受现有代理模型启发，希望通过引入松弛变量优化模型性能，同时探索量子优势。

Method: 在因子分解机及其Ising表示中引入松弛变量，将原两步过程整合为一步，并在训练中迭代更新松弛变量。

Result: 实验结果显示，松弛变量的引入显著提升了模型性能。

Conclusion: 该方法为构建高效代理模型提供了有前景的途径，并可能利用量子优势。

Abstract: Recently, a surrogate model was proposed that employs a factorization machine
to approximate the underlying input-output mapping of the original system, with
quantum annealing used to optimize the resulting surrogate function. Inspired
by this approach, we propose an enhanced surrogate model that incorporates
additional slack variables into both the factorization machine and its
associated Ising representation thereby unifying what was by design a two-step
process into a single, integrated step. During the training phase, the slack
variables are iteratively updated, enabling the model to account for
higher-order feature interactions. We apply the proposed method to the task of
predicting drug combination effects. Experimental results indicate that the
introduction of slack variables leads to a notable improvement of performance.
Our algorithm offers a promising approach for building efficient surrogate
models that exploit potential quantum advantages.

</details>


### [211] [Decomposing Prediction Mechanisms for In-Context Recall](https://arxiv.org/abs/2507.01414)
*Sultan Daniels,Dylan Davis,Dhruv Gautam,Wentinn Liao,Gireeja Ranade,Anant Sahai*

Main category: cs.LG

TL;DR: 论文介绍了一种结合线性回归式连续上下文学习（ICL）和离散关联记忆的玩具问题，研究了Transformer模型在此任务中的表现，发现其需要两种机制：关联记忆和贝叶斯式预测。


<details>
  <summary>Details</summary>
Motivation: 研究Transformer模型在结合连续和离散任务中的表现，探索其学习动态和机制分离现象。

Method: 通过预训练Transformer模型在符号标记的线性确定性动态系统样本上，分析其在关联记忆和状态预测中的能力。

Result: 模型在训练中表现出两种机制的分离：关联记忆能力较晚出现，而状态预测能力较早发展。

Conclusion: 多机制现象不仅限于玩具问题，在真实任务（如ICL翻译）中也观察到类似现象。

Abstract: We introduce a new family of toy problems that combine features of
linear-regression-style continuous in-context learning (ICL) with discrete
associative recall. We pretrain transformer models on sample traces from this
toy, specifically symbolically-labeled interleaved state observations from
randomly drawn linear deterministic dynamical systems. We study if the
transformer models can recall the state of a sequence previously seen in its
context when prompted to do so with the corresponding in-context label. Taking
a closer look at this task, it becomes clear that the model must perform two
functions: (1) identify which system's state should be recalled and apply that
system to its last seen state, and (2) continuing to apply the correct system
to predict the subsequent states. Training dynamics reveal that the first
capability emerges well into a model's training. Surprisingly, the second
capability, of continuing the prediction of a resumed sequence, develops much
earlier.
  Via out-of-distribution experiments, and a mechanistic analysis on model
weights via edge pruning, we find that next-token prediction for this toy
problem involves at least two separate mechanisms. One mechanism uses the
discrete symbolic labels to do the associative recall required to predict the
start of a resumption of a previously seen sequence. The second mechanism,
which is largely agnostic to the discrete symbolic labels, performs a
"Bayesian-style" prediction based on the previous token and the context. These
two mechanisms have different learning dynamics.
  To confirm that this multi-mechanism (manifesting as separate phase
transitions) phenomenon is not just an artifact of our toy setting, we used
OLMo training checkpoints on an ICL translation task to see a similar
phenomenon: a decisive gap in the emergence of first-task-token performance vs
second-task-token performance.

</details>


### [212] [Tensor Program Optimization for the RISC-V Vector Extension Using Probabilistic Programs](https://arxiv.org/abs/2507.01457)
*Federico Nicolas Peccia,Frederik Haxel,Oliver Bringmann*

Main category: cs.LG

TL;DR: 本文提出了一种基于TVM编译器的工作流，用于高效地将AI工作负载映射到RISC-V向量单元，相比现有方法显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: RISC-V的向量扩展（RVV）对AI工作负载加速具有潜力，但缺乏高效的自动调优框架支持，限制了其实际部署。

Method: 将RVV扩展集成到TVM的MetaSchedule框架中，通过概率程序调优方法优化AI工作负载在RISC-V上的执行。

Result: 实验表明，该方法比GCC自动向量化性能提升46%，比muRISCV-NN提升29%，且代码内存占用更小。在商用RISC-V SoC上，性能比LLVM提升35%。

Conclusion: 该方法显著提升了RISC-V上AI工作负载的执行效率，适合嵌入式设备，并已开源供社区扩展。

Abstract: RISC-V provides a flexible and scalable platform for applications ranging
from embedded devices to high-performance computing clusters. Particularly, its
RISC-V Vector Extension (RVV) becomes of interest for the acceleration of AI
workloads. But writing software that efficiently utilizes the vector units of
RISC-V CPUs without expert knowledge requires the programmer to rely on the
autovectorization features of compilers or hand-crafted libraries like
muRISCV-NN. Smarter approaches, like autotuning frameworks, have been missing
the integration with the RISC-V RVV extension, thus heavily limiting the
efficient deployment of complex AI workloads. In this paper, we present a
workflow based on the TVM compiler to efficiently map AI workloads onto RISC-V
vector units. Instead of relying on hand-crafted libraries, we integrated the
RVV extension into TVM's MetaSchedule framework, a probabilistic program
framework for tensor operation tuning. We implemented different RISC-V SoCs on
an FPGA and tuned a wide range of AI workloads on them. We found that our
proposal shows a mean improvement of 46% in execution latency when compared
against the autovectorization feature of GCC, and 29% against muRISCV-NN.
Moreover, the binary resulting from our proposal has a smaller code memory
footprint, making it more suitable for embedded devices. Finally, we also
evaluated our solution on a commercially available RISC-V SoC implementing the
RVV 1.0 Vector Extension and found our solution is able to find mappings that
are 35% faster on average than the ones proposed by LLVM. We open-sourced our
proposal for the community to expand it to target other RISC-V extensions.

</details>


### [213] [Cross-platform Smartphone Positioning at Museums](https://arxiv.org/abs/2507.01469)
*Alessio Ferrato,Fabio Gasparetti,Carla Limongelli,Stefano Mastandrea,Giuseppe Sansonetti,Joaquín Torres-Sospedra*

Main category: cs.LG

TL;DR: 本文提出BAR数据集，解决博物馆环境中RSS数据缺乏的问题，并提供了基于邻近性和k-NN算法的分类基线。


<details>
  <summary>Details</summary>
Motivation: 博物馆等文化机构在实施室内定位系统（IPS）时面临环境和技术限制，缺乏公开的RSS数据集阻碍了算法的开发与评估。

Method: 收集了90件艺术品前的RSS数据，使用Android和iOS平台，提出基于邻近性和k-NN算法的分类基线。

Result: 提供了BAR数据集，并展示了其用于定位算法的潜力。

Conclusion: BAR数据集填补了博物馆环境RSS数据的空白，为未来研究提供了基础。

Abstract: Indoor Positioning Systems (IPSs) hold significant potential for enhancing
visitor experiences in cultural heritage institutions. By enabling personalized
navigation, efficient artifact organization, and better interaction with
exhibits, IPSs can transform the modalities of how individuals engage with
museums, galleries and libraries. However, these institutions face several
challenges in implementing IPSs, including environmental constraints, technical
limits, and limited experimentation. In other contexts, Received Signal
Strength (RSS)-based approaches using Bluetooth Low Energy (BLE) and WiFi have
emerged as preferred solutions due to their non-invasive nature and minimal
infrastructure requirements. Nevertheless, the lack of publicly available RSS
datasets that specifically reflect museum environments presents a substantial
barrier to developing and evaluating positioning algorithms designed for the
intricate spatial characteristics typical of cultural heritage sites. To
address this limitation, we present BAR, a novel RSS dataset collected in front
of 90 artworks across 13 museum rooms using two different platforms, i.e.,
Android and iOS. Additionally, we provide an advanced position classification
baseline taking advantage of a proximity-based method and $k$-NN algorithms. In
our analysis, we discuss the results and offer suggestions for potential
research directions.

</details>


### [214] [Zero-Incentive Dynamics: a look at reward sparsity through the lens of unrewarded subgoals](https://arxiv.org/abs/2507.01470)
*Yannick Molinghen,Tom Lenaerts*

Main category: cs.LG

TL;DR: 论文重新审视了奖励频率作为强化学习中任务难度可靠指标的假设，揭示了当前方法在关键子目标无直接奖励时的局限性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探索奖励频率假设的局限性，特别是在关键子目标无直接奖励时，现有方法的失效问题。

Method: 方法包括形式化零激励动态问题，并分析现有深度子目标算法在此类动态下的表现。

Result: 结果表明，现有算法无法有效利用零激励动态，且学习性能对子目标完成与最终奖励的时间接近性高度敏感。

Conclusion: 结论指出当前方法存在根本限制，需要开发能推断潜在任务结构而不依赖即时奖励的机制。

Abstract: This work re-examines the commonly held assumption that the frequency of
rewards is a reliable measure of task difficulty in reinforcement learning. We
identify and formalize a structural challenge that undermines the effectiveness
of current policy learning methods: when essential subgoals do not directly
yield rewards. We characterize such settings as exhibiting zero-incentive
dynamics, where transitions critical to success remain unrewarded. We show that
state-of-the-art deep subgoal-based algorithms fail to leverage these dynamics
and that learning performance is highly sensitive to the temporal proximity
between subgoal completion and eventual reward. These findings reveal a
fundamental limitation in current approaches and point to the need for
mechanisms that can infer latent task structure without relying on immediate
incentives.

</details>


### [215] [Loss Functions in Diffusion Models: A Comparative Study](https://arxiv.org/abs/2507.01516)
*Dibyanshu Kumar,Philipp Vaeth,Magda Gregorová*

Main category: cs.LG

TL;DR: 本文系统研究了扩散模型中的损失函数，统一了多种目标函数框架，并通过理论和实证分析揭示了其性能差异及影响因素。


<details>
  <summary>Details</summary>
Motivation: 扩散模型的损失函数选择是关键问题，但现有研究存在多种不同目标函数，缺乏统一理解。本文旨在填补这一空白。

Method: 通过理论分析将多种目标函数统一到变分下界框架，并进行实证研究比较其性能差异。

Result: 研究发现不同目标函数在性能和适用场景上存在显著差异，为模型设计提供了指导。

Conclusion: 本文为扩散模型的损失函数提供了统一理解，有助于未来更高效和针对性的模型设计。

Abstract: Diffusion models have emerged as powerful generative models, inspiring
extensive research into their underlying mechanisms. One of the key questions
in this area is the loss functions these models shall train with. Multiple
formulations have been introduced in the literature over the past several years
with some links and some critical differences stemming from various initial
considerations. In this paper, we explore the different target objectives and
corresponding loss functions in detail. We present a systematic overview of
their relationships, unifying them under the framework of the variational lower
bound objective. We complement this theoretical analysis with an empirical
study providing insights into the conditions under which these objectives
diverge in performance and the underlying factors contributing to such
deviations. Additionally, we evaluate how the choice of objective impacts the
model ability to achieve specific goals, such as generating high-quality
samples or accurately estimating likelihoods. This study offers a unified
understanding of loss functions in diffusion models, contributing to more
efficient and goal-oriented model designs in future research.

</details>


### [216] [MARVIS: Modality Adaptive Reasoning over VISualizations](https://arxiv.org/abs/2507.01544)
*Benjamin Feuer,Lennart Purucker,Oussama Elachqar,Chinmay Hegde*

Main category: cs.LG

TL;DR: MARVIS是一种无需训练的方法，通过将潜在嵌入空间转换为视觉表示，利用视觉语言模型的空间和细粒度推理能力，实现多模态数据的高精度预测。


<details>
  <summary>Details</summary>
Motivation: 解决小规模专用模型缺乏灵活性和基础模型在非传统模态和长尾领域表现不佳的问题。

Method: 将潜在嵌入空间转换为视觉表示，利用视觉语言模型的空间和细粒度推理能力进行预测。

Result: 在视觉、音频、生物和表格领域表现优异，平均性能超过Gemini 16%，接近专用方法。

Conclusion: MARVIS提供了一种无需训练、保护隐私的多模态预测方法，具有广泛的应用潜力。

Abstract: Scientific applications of machine learning often rely on small, specialized
models tuned to particular domains. Such models often achieve excellent
performance, but lack flexibility. Foundation models offer versatility, but
typically underperform specialized approaches, especially on non-traditional
modalities and long-tail domains. We propose MARVIS (Modality Adaptive
Reasoning over VISualizations), a training-free method that enables even small
vision-language models to predict any data modality with high accuracy. MARVIS
transforms latent embedding spaces into visual representations and then
leverages the spatial and fine-grained reasoning skills of VLMs to successfully
interpret and utilize them. MARVIS achieves competitive performance on vision,
audio, biological, and tabular domains using a single 3B parameter model,
achieving results that beat Gemini by 16\% on average and approach specialized
methods, without exposing personally identifiable information (P.I.I.) or
requiring any domain-specific training. We open source our code and datasets at
https://github.com/penfever/marvis

</details>


### [217] [Self-Guided Process Reward Optimization with Masked Step Advantage for Process Reinforcement Learning](https://arxiv.org/abs/2507.01551)
*Wu Fei,Hao Kong,Shuxian Liang,Yang Lin,Yibo Yang,Jing Tang,Lei Chen,Xiansheng Hua*

Main category: cs.LG

TL;DR: SPRO是一种自引导过程奖励优化框架，通过内在奖励和掩码步骤优势估计提升LLM的推理能力，显著提高训练效率和测试准确性。


<details>
  <summary>Details</summary>
Motivation: 解决过程强化学习中计算开销大和缺乏统一理论框架的问题。

Method: 提出SPRO框架，包括内在过程奖励和掩码步骤优势估计（MSA）。

Result: SPRO训练效率提高3.4倍，测试准确率提升17.5%，同时减少响应长度1/3。

Conclusion: SPRO在无需额外计算开销的情况下，显著提升了LLM的推理能力和训练稳定性。

Abstract: Process Reinforcement Learning~(PRL) has demonstrated considerable potential
in enhancing the reasoning capabilities of Large Language Models~(LLMs).
However, introducing additional process reward models incurs substantial
computational overhead, and there is no unified theoretical framework for
process-level advantage estimation. To bridge this gap, we propose
\textbf{S}elf-Guided \textbf{P}rocess \textbf{R}eward
\textbf{O}ptimization~(\textbf{SPRO}), a novel framework that enables
process-aware RL through two key innovations: (1) we first theoretically
demonstrate that process rewards can be derived intrinsically from the policy
model itself, and (2) we introduce well-defined cumulative process rewards and
\textbf{M}asked \textbf{S}tep \textbf{A}dvantage (\textbf{MSA}), which
facilitates rigorous step-wise action advantage estimation within shared-prompt
sampling groups. Our experimental results demonstrate that SPRO outperforms
vaniila GRPO with 3.4x higher training efficiency and a 17.5\% test accuracy
improvement. Furthermore, SPRO maintains a stable and elevated policy entropy
throughout training while reducing the average response length by approximately
$1/3$, evidencing sufficient exploration and prevention of reward hacking.
Notably, SPRO incurs no additional computational overhead compared to
outcome-supervised RL methods such as GRPO, which benefit industrial
implementation.

</details>


### [218] [How Weight Resampling and Optimizers Shape the Dynamics of Continual Learning and Forgetting in Neural Networks](https://arxiv.org/abs/2507.01559)
*Lapo Frati,Neil Traft,Jeff Clune,Nick Cheney*

Main category: cs.LG

TL;DR: 论文研究了神经网络最后一层权重重采样（“zapping”）在持续学习和少样本迁移学习中的作用，发现其能加速模型在新领域的恢复，并探讨了优化器选择对学习动态的影响。


<details>
  <summary>Details</summary>
Motivation: 探索zapping在持续学习和少样本迁移学习中的有效性及其背后的机制。

Method: 在卷积神经网络中，通过实验分析zapping和不同优化器对学习与遗忘模式的影响，使用手写字符和自然图像数据集。

Result: zapping能帮助模型更快适应新领域；优化器选择会显著影响学习动态，导致任务间复杂的协同/干扰模式。

Conclusion: zapping和优化器选择在持续学习中起关键作用，影响模型的学习与遗忘动态。

Abstract: Recent work in continual learning has highlighted the beneficial effect of
resampling weights in the last layer of a neural network (``zapping"). Although
empirical results demonstrate the effectiveness of this approach, the
underlying mechanisms that drive these improvements remain unclear. In this
work, we investigate in detail the pattern of learning and forgetting that take
place inside a convolutional neural network when trained in challenging
settings such as continual learning and few-shot transfer learning, with
handwritten characters and natural images. Our experiments show that models
that have undergone zapping during training more quickly recover from the shock
of transferring to a new domain. Furthermore, to better observe the effect of
continual learning in a multi-task setting we measure how each individual task
is affected. This shows that, not only zapping, but the choice of optimizer can
also deeply affect the dynamics of learning and forgetting, causing complex
patterns of synergy/interference between tasks to emerge when the model learns
sequentially at transfer time.

</details>


### [219] [A Privacy-Preserving Indoor Localization System based on Hierarchical Federated Learning](https://arxiv.org/abs/2507.01581)
*Masood Jan,Wafa Njima,Xun Zhang*

Main category: cs.LG

TL;DR: 提出了一种基于联邦学习的动态室内定位方法，解决了传统方法的数据隐私和效率问题。


<details>
  <summary>Details</summary>
Motivation: 传统室内定位技术存在误差大和隐私问题，机器学习方法虽有效但需要集中数据，引发隐私和效率问题。

Method: 采用联邦学习和深度神经网络模型进行动态室内定位。

Result: 实验显示联邦学习性能接近集中式模型，同时保障数据隐私、带宽效率和服务器可靠性。

Conclusion: 联邦学习为隐私增强的室内定位提供了可行方案，推动了安全高效定位系统的发展。

Abstract: Location information serves as the fundamental element for numerous Internet
of Things (IoT) applications. Traditional indoor localization techniques often
produce significant errors and raise privacy concerns due to centralized data
collection. In response, Machine Learning (ML) techniques offer promising
solutions by capturing indoor environment variations. However, they typically
require central data aggregation, leading to privacy, bandwidth, and server
reliability issues. To overcome these challenges, in this paper, we propose a
Federated Learning (FL)-based approach for dynamic indoor localization using a
Deep Neural Network (DNN) model. Experimental results show that FL has the
nearby performance to Centralized Model (CL) while keeping the data privacy,
bandwidth efficiency and server reliability. This research demonstrates that
our proposed FL approach provides a viable solution for privacy-enhanced indoor
localization, paving the way for advancements in secure and efficient indoor
localization systems.

</details>


### [220] [Analysis of Muon's Convergence and Critical Batch Size](https://arxiv.org/abs/2507.01598)
*Naoki Sato,Hiroki Naganuma,Hideaki Iiduka*

Main category: cs.LG

TL;DR: 本文对Muon优化器进行了理论分析，证明了其收敛性，并探讨了权重衰减和批大小的影响。


<details>
  <summary>Details</summary>
Motivation: 研究Muon优化器的理论性质，包括其收敛性和参数控制能力。

Method: 分析了四种Muon变体（带/不带Nesterov动量，带/不带权重衰减），并推导了收敛证明和批大小优化。

Result: 权重衰减能更严格地控制参数和梯度范数，批大小优化降低了计算成本。

Conclusion: Muon优化器在理论和实验中均表现出色，权重衰减和批大小优化对其性能至关重要。

Abstract: This paper presents a theoretical analysis of Muon, a new optimizer that
leverages the inherent matrix structure of neural network parameters. We
provide convergence proofs for four practical variants of Muon: with and
without Nesterov momentum, and with and without weight decay. We then show that
adding weight decay leads to strictly tighter bounds on both the parameter and
gradient norms, and we clarify the relationship between the weight decay
coefficient and the learning rate. Finally, we derive Muon's critical batch
size minimizing the stochastic first-order oracle (SFO) complexity, which is
the stochastic computational cost, and validate our theoretical findings with
experiments.

</details>


### [221] [Kernel Recursive Least Squares Dictionary Learning Algorithm](https://arxiv.org/abs/2507.01636)
*Ghasem Alipoor,Karl Skretting*

Main category: cs.LG

TL;DR: 提出了一种高效的在线字典学习算法，用于基于核的稀疏表示，通过递归最小二乘法更新字典，实验显示其优于现有方法且接近批量训练模型的分类精度。


<details>
  <summary>Details</summary>
Motivation: 解决在线核字典学习中的效率和性能问题，以支持单样本或小批量更新。

Method: 使用递归最小二乘法（RLS）递归更新字典，适用于单样本或小批量数据，保持低计算复杂度。

Result: 在四个数据集上的实验表明，该方法优于现有在线核字典学习方法，分类精度接近批量训练模型，且效率更高。

Conclusion: 提出的在线字典学习算法在性能和效率上均表现出色，适用于实际应用。

Abstract: We propose an efficient online dictionary learning algorithm for kernel-based
sparse representations. In this framework, input signals are nonlinearly mapped
to a high-dimensional feature space and represented sparsely using a virtual
dictionary. At each step, the dictionary is updated recursively using a novel
algorithm based on the recursive least squares (RLS) method. This update
mechanism works with single samples or mini-batches and maintains low
computational complexity. Experiments on four datasets across different domains
show that our method not only outperforms existing online kernel dictionary
learning approaches but also achieves classification accuracy close to that of
batch-trained models, while remaining significantly more efficient.

</details>


### [222] [Dance Dance ConvLSTM](https://arxiv.org/abs/2507.01644)
*Miguel O'Malley*

Main category: cs.LG

TL;DR: DDCL是一种基于ConvLSTM的新方法，用于自动生成DDR游戏图表，改进了之前的DDC方法并显著提高了准确性。


<details>
  <summary>Details</summary>
Motivation: 改进Dance Dance Convolution (DDC)方法的不足，提高自动生成DDR游戏图表的准确性。

Method: 使用ConvLSTM架构的模型（DDCL）来生成DDR游戏图表。

Result: DDCL显著提高了图表生成的准确性。

Conclusion: DDCL是一种有效的改进方法，适用于DDR游戏图表的自动生成。

Abstract: \textit{Dance Dance Revolution} is a rhythm game consisting of songs and
accompanying choreography, referred to as charts. Players press arrows on a
device referred to as a dance pad in time with steps determined by the song's
chart. In 2017, the authors of Dance Dance Convolution (DDC) developed an
algorithm for the automatic generation of \textit{Dance Dance Revolution}
charts, utilizing a CNN-LSTM architecture. We introduce Dance Dance ConvLSTM
(DDCL), a new method for the automatic generation of DDR charts using a
ConvLSTM based model, which improves upon the DDC methodology and substantially
increases the accuracy of chart generation.

</details>


### [223] [GradMetaNet: An Equivariant Architecture for Learning on Gradients](https://arxiv.org/abs/2507.01649)
*Yoav Gelberg,Yam Eitan,Aviv Navon,Aviv Shamsian,Theo,Putterman,Michael Bronstein,Haggai Maron*

Main category: cs.LG

TL;DR: 本文提出了一种名为GradMetaNet的新架构，专门设计用于处理神经网络梯度，基于三个原则：等变性设计、多数据点梯度集处理和高效梯度表示。


<details>
  <summary>Details</summary>
Motivation: 现有的梯度处理算法通常使用非专门设计的架构，限制了其适用性。本文旨在设计一种专门用于梯度处理的架构。

Method: 基于等变性设计、多数据点梯度集处理和高效梯度表示（秩1分解）的原则，提出了GradMetaNet架构。

Result: GradMetaNet能够逼近自然梯度函数，并在多项梯度任务（如优化、编辑和曲率估计）中表现出色。

Conclusion: GradMetaNet是一种高效且通用的梯度处理架构，适用于多种任务。

Abstract: Gradients of neural networks encode valuable information for optimization,
editing, and analysis of models. Therefore, practitioners often treat gradients
as inputs to task-specific algorithms, e.g. for pruning or optimization. Recent
works explore learning algorithms that operate directly on gradients but use
architectures that are not specifically designed for gradient processing,
limiting their applicability. In this paper, we present a principled approach
for designing architectures that process gradients. Our approach is guided by
three principles: (1) equivariant design that preserves neuron permutation
symmetries, (2) processing sets of gradients across multiple data points to
capture curvature information, and (3) efficient gradient representation
through rank-1 decomposition. Based on these principles, we introduce
GradMetaNet, a novel architecture for learning on gradients, constructed from
simple equivariant blocks. We prove universality results for GradMetaNet, and
show that previous approaches cannot approximate natural gradient-based
functions that GradMetaNet can. We then demonstrate GradMetaNet's effectiveness
on a diverse set of gradient-based tasks on MLPs and transformers, such as
learned optimization, INR editing, and estimating loss landscape curvature.

</details>


### [224] [AsyncFlow: An Asynchronous Streaming RL Framework for Efficient LLM Post-Training](https://arxiv.org/abs/2507.01663)
*Zhenyu Han,Ansheng You,Haibo Wang,Kui Luo,Guang Yang,Wenqi Shi,Menglong Chen,Sicheng Zhang,Zeshun Lan,Chunshi Deng,Huazhong Ji,Wenjie Liu,Yu Huang,Yixiang Zhang,Chenyi Pan,Jing Wang,Xin Huang,Chunsheng Li,Jianping Wu*

Main category: cs.LG

TL;DR: AsyncFlow是一个异步流式强化学习框架，用于高效的后训练，解决了传统RL框架的可扩展性和资源利用问题。


<details>
  <summary>Details</summary>
Motivation: 传统RL框架在扩展性、数据流复杂性和资源利用方面存在瓶颈，且与LLM训练或推理引擎紧密耦合，难以支持自定义引擎。

Method: 提出分布式数据存储和传输模块，实现统一数据管理和细粒度调度；采用生产者-消费者异步工作流，减少计算闲置；架构上与训练和推理引擎解耦。

Result: 实验显示吞吐量平均提升1.59倍。

Conclusion: AsyncFlow为下一代RL训练系统设计提供了可行方案。

Abstract: Reinforcement learning (RL) has become a pivotal technology in the
post-training phase of large language models (LLMs). Traditional task-colocated
RL frameworks suffer from significant scalability bottlenecks, while
task-separated RL frameworks face challenges in complex dataflows and the
corresponding resource idling and workload imbalance. Moreover, most existing
frameworks are tightly coupled with LLM training or inference engines, making
it difficult to support custom-designed engines. To address these challenges,
we propose AsyncFlow, an asynchronous streaming RL framework for efficient
post-training. Specifically, we introduce a distributed data storage and
transfer module that provides a unified data management and fine-grained
scheduling capability in a fully streamed manner. This architecture inherently
facilitates automated pipeline overlapping among RL tasks and dynamic load
balancing. Moreover, we propose a producer-consumer-based asynchronous workflow
engineered to minimize computational idleness by strategically deferring
parameter update process within staleness thresholds. Finally, the core
capability of AsynFlow is architecturally decoupled from underlying training
and inference engines and encapsulated by service-oriented user interfaces,
offering a modular and customizable user experience. Extensive experiments
demonstrate an average of 1.59 throughput improvement compared with
state-of-the-art baseline. The presented architecture in this work provides
actionable insights for next-generation RL training system designs.

</details>


### [225] [Blending Supervised and Reinforcement Fine-Tuning with Prefix Sampling](https://arxiv.org/abs/2507.01679)
*Zeyu Huang,Tianhao Cheng,Zihan Qiu,Zili Wang,Yinghui Xu,Edoardo M. Ponti,Ivan Titov*

Main category: cs.LG

TL;DR: 论文提出了一种结合监督微调（SFT）和强化微调（RFT）的混合方法Prefix-RFT，通过数学推理问题验证其简单高效，性能优于单独使用SFT或RFT，且易于集成到现有框架中。


<details>
  <summary>Details</summary>
Motivation: 现有后训练技术SFT和RFT各有优缺点，SFT易导致行为克隆问题，RFT性能敏感且可能学习意外行为。论文旨在统一这两种方法，提出更优的混合方案。

Method: 提出Prefix-RFT，结合SFT和RFT的优势，通过演示和探索学习，并在数学推理问题上进行实验验证。

Result: Prefix-RFT性能优于单独SFT和RFT，且优于并行混合策略RFT方法，对演示数据质量和数量的变化具有鲁棒性。

Conclusion: Prefix-RFT有效统一了SFT和RFT，展示了结合演示和探索的潜力，为未来LLM后训练研究提供了新方向。

Abstract: Existing post-training techniques for large language models are broadly
categorized into Supervised Fine-Tuning (SFT) and Reinforcement Fine-Tuning
(RFT). Each paradigm presents a distinct trade-off: SFT excels at mimicking
demonstration data but can lead to problematic generalization as a form of
behavior cloning. Conversely, RFT can significantly enhance a model's
performance but is prone to learn unexpected behaviors, and its performance is
highly sensitive to the initial policy. In this paper, we propose a unified
view of these methods and introduce Prefix-RFT, a hybrid approach that
synergizes learning from both demonstration and exploration. Using mathematical
reasoning problems as a testbed, we empirically demonstrate that Prefix-RFT is
both simple and effective. It not only surpasses the performance of standalone
SFT and RFT but also outperforms parallel mixed-policy RFT methods. A key
advantage is its seamless integration into existing open-source frameworks,
requiring only minimal modifications to the standard RFT pipeline. Our analysis
highlights the complementary nature of SFT and RFT, and validates that
Prefix-RFT effectively harmonizes these two learning paradigms. Furthermore,
ablation studies confirm the method's robustness to variations in the quality
and quantity of demonstration data. We hope this work offers a new perspective
on LLM post-training, suggesting that a unified paradigm that judiciously
integrates demonstration and exploration could be a promising direction for
future research.

</details>


### [226] [GPT, But Backwards: Exactly Inverting Language Model Outputs](https://arxiv.org/abs/2507.01693)
*Adrians Skapars,Edoardo Manino,Youcheng Sun,Lucas C. Cordeiro*

Main category: cs.LG

TL;DR: 论文提出了一种名为SODA的梯度算法，用于从大型语言模型（LLM）的输出中精确重建输入，解决了现有审计技术的补充问题。


<details>
  <summary>Details</summary>
Motivation: 现有审计技术主要关注识别LLM中的潜在不良行为，而本文旨在解决从现有LLM输出中重建输入的取证问题，以支持事后分析和检测虚假报告。

Method: 将精确输入重建问题形式化为具有唯一全局最小值的离散优化问题，并引入SODA算法，该算法基于梯度优化，在连续松弛的输入搜索空间中运行，结合周期性重启和参数衰减。

Result: 在33M至3B参数的LLM上实验表明，SODA显著优于现有方法，成功恢复了79.5%的短分布外输入，且无假阳性，但对长序列（15+ token）的隐私信息提取效果较差。

Conclusion: 标准部署实践可能已足够防止恶意使用该方法，但SODA在短输入重建方面表现出色，为LLM的取证分析提供了有效工具。

Abstract: While existing auditing techniques attempt to identify potential unwanted
behaviours in large language models (LLMs), we address the complementary
forensic problem of reconstructing the exact input that led to an existing LLM
output - enabling post-incident analysis and potentially the detection of fake
output reports. We formalize exact input reconstruction as a discrete
optimisation problem with a unique global minimum and introduce SODA, an
efficient gradient-based algorithm that operates on a continuous relaxation of
the input search space with periodic restarts and parameter decay. Through
comprehensive experiments on LLMs ranging in size from 33M to 3B parameters, we
demonstrate that SODA significantly outperforms existing approaches. We succeed
in fully recovering 79.5% of shorter out-of-distribution inputs from next-token
logits, without a single false positive, but struggle to extract private
information from the outputs of longer (15+ token) input sequences. This
suggests that standard deployment practices may currently provide adequate
protection against malicious use of our method. Our code is available at
https://doi.org/10.5281/zenodo.15539879.

</details>


### [227] [PERTINENCE: Input-based Opportunistic Neural Network Dynamic Execution](https://arxiv.org/abs/2507.01695)
*Omkar Shende,Gayathri Ananthanarayanan,Marcello Traiola*

Main category: cs.LG

TL;DR: PERTINENCE是一种动态选择预训练模型的方法，通过分析输入特征复杂度，平衡准确性和计算效率，减少36%的计算量。


<details>
  <summary>Details</summary>
Motivation: 大型DNN模型虽准确但资源消耗高，需在不显著降低准确性的情况下减少对它们的依赖。

Method: 使用遗传算法训练输入调度器，动态选择最适合的模型处理输入。

Result: 在CIFAR-10、CIFAR-100和TinyImageNet上，PERTINENCE在减少36%计算量的同时保持或提升准确性。

Conclusion: PERTINENCE通过动态模型选择，有效平衡了准确性和计算效率。

Abstract: Deep neural networks (DNNs) have become ubiquitous thanks to their remarkable
ability to model complex patterns across various domains such as computer
vision, speech recognition, robotics, etc. While large DNN models are often
more accurate than simpler, lightweight models, they are also resource- and
energy-hungry. Hence, it is imperative to design methods to reduce reliance on
such large models without significant degradation in output accuracy. The high
computational cost of these models is often necessary only for a reduced set of
challenging inputs, while lighter models can handle most simple ones. Thus,
carefully combining properties of existing DNN models in a dynamic, input-based
way opens opportunities to improve efficiency without impacting accuracy.
  In this work, we introduce PERTINENCE, a novel online method designed to
analyze the complexity of input features and dynamically select the most
suitable model from a pre-trained set to process a given input effectively. To
achieve this, we employ a genetic algorithm to explore the training space of an
ML-based input dispatcher, enabling convergence towards the Pareto front in the
solution space that balances overall accuracy and computational efficiency.
  We showcase our approach on state-of-the-art Convolutional Neural Networks
(CNNs) trained on the CIFAR-10 and CIFAR-100, as well as Vision Transformers
(ViTs) trained on TinyImageNet dataset. We report results showing PERTINENCE's
ability to provide alternative solutions to existing state-of-the-art models in
terms of trade-offs between accuracy and number of operations. By
opportunistically selecting among models trained for the same task, PERTINENCE
achieves better or comparable accuracy with up to 36% fewer operations.

</details>


### [228] [Variational Graph Convolutional Neural Networks](https://arxiv.org/abs/2507.01699)
*Illia Oleksiienko,Juho Kanniainen,Alexandros Iosifidis*

Main category: cs.LG

TL;DR: 提出变分神经网络版本的图卷积网络，估计模型输出和注意力层的不确定性，提升模型可解释性和准确性。


<details>
  <summary>Details</summary>
Motivation: 通过估计模型不确定性，提升图卷积网络的可解释性和准确性，适用于关键应用中的结果验证。

Method: 提出空间和时空图卷积网络的变分神经网络版本，估计输出和层注意力的不确定性。

Result: 在社交交易分析和骨架动作识别任务中展示模型准确性和不确定性估计的提升。

Conclusion: 变分图卷积网络在提升模型可解释性和准确性方面具有潜力。

Abstract: Estimation of model uncertainty can help improve the explainability of Graph
Convolutional Networks and the accuracy of the models at the same time.
Uncertainty can also be used in critical applications to verify the results of
the model by an expert or additional models. In this paper, we propose
Variational Neural Network versions of spatial and spatio-temporal Graph
Convolutional Networks. We estimate uncertainty in both outputs and layer-wise
attentions of the models, which has the potential for improving model
explainability. We showcase the benefits of these models in the social trading
analysis and the skeleton-based human action recognition tasks on the Finnish
board membership, NTU-60, NTU-120 and Kinetics datasets, where we show
improvement in model accuracy in addition to estimated model uncertainties.

</details>


### [229] [Relational Causal Discovery with Latent Confounders](https://arxiv.org/abs/2507.01700)
*Andrea Piras,Matteo Negro,Ragib Ahsan,David Arbour,Elena Zheleva*

Main category: cs.LG

TL;DR: 提出了一种名为RelFCI的因果发现算法，用于处理具有潜在混杂因素的关系数据，填补了现有方法的不足。


<details>
  <summary>Details</summary>
Motivation: 现有因果发现算法在处理关系数据和潜在混杂因素时存在局限性，无法满足实际需求。

Method: 基于FCI和RCD算法，定义了新的图模型，并建立了关系d-分离的理论保证。

Result: 实验证明RelFCI能有效识别具有潜在混杂因素的关系因果模型中的正确因果结构。

Conclusion: RelFCI是一种可靠且完整的关系数据因果发现算法，适用于复杂现实场景。

Abstract: Estimating causal effects from real-world relational data can be challenging
when the underlying causal model and potential confounders are unknown. While
several causal discovery algorithms exist for learning causal models with
latent confounders from data, they assume that the data is independent and
identically distributed (i.i.d.) and are not well-suited for learning from
relational data. Similarly, existing relational causal discovery algorithms
assume causal sufficiency, which is unrealistic for many real-world datasets.
To address this gap, we propose RelFCI, a sound and complete causal discovery
algorithm for relational data with latent confounders. Our work builds upon the
Fast Causal Inference (FCI) and Relational Causal Discovery (RCD) algorithms
and it defines new graphical models, necessary to support causal discovery in
relational domains. We also establish soundness and completeness guarantees for
relational d-separation with latent confounders. We present experimental
results demonstrating the effectiveness of RelFCI in identifying the correct
causal structure in relational causal models with latent confounders.

</details>


### [230] [B-PL-PINN: Stabilizing PINN Training with Bayesian Pseudo Labeling](https://arxiv.org/abs/2507.01714)
*Kevin Innerebner,Franz M. Rohrhofer,Bernhard C. Geiger*

Main category: cs.LG

TL;DR: 本文提出用贝叶斯物理信息神经网络（PINN）替代集成方法，通过评估后验方差提升信息传播效果，在基准问题上表现优于集成方法。


<details>
  <summary>Details</summary>
Motivation: 解决传统PINN在前向问题中信息传播不足的收敛问题。

Method: 用贝叶斯PINN替代集成方法，利用后验方差评估信息传播效果。

Result: 在基准问题上表现优于集成方法，且与结合Adam和LBFGS的PINN集成方法竞争。

Conclusion: 贝叶斯PINN是一种数学上更严谨的方法，能有效提升信息传播效果。

Abstract: Training physics-informed neural networks (PINNs) for forward problems often
suffers from severe convergence issues, hindering the propagation of
information from regions where the desired solution is well-defined.
Haitsiukevich and Ilin (2023) proposed an ensemble approach that extends the
active training domain of each PINN based on i) ensemble consensus and ii)
vicinity to (pseudo-)labeled points, thus ensuring that the information from
the initial condition successfully propagates to the interior of the
computational domain.
  In this work, we suggest replacing the ensemble by a Bayesian PINN, and
consensus by an evaluation of the PINN's posterior variance. Our experiments
show that this mathematically principled approach outperforms the ensemble on a
set of benchmark problems and is competitive with PINN ensembles trained with
combinations of Adam and LBFGS.

</details>


### [231] [Revisiting Learning Rate Control](https://arxiv.org/abs/2507.01724)
*Micha Henheik,Theresa Eimer,Marius Lindauer*

Main category: cs.LG

TL;DR: 论文比较了学习率控制的不同方法，发现现有方法在特定任务中表现良好但缺乏普适性，需关注算法选择和新兴方向如元学习。


<details>
  <summary>Details</summary>
Motivation: 探讨学习率控制的重要性及现有方法的局限性，以推动AutoML和深度学习社区对其改进。

Method: 比较多保真度超参数优化、固定学习率调度和无超参数学习等方法在深度学习任务中的表现。

Result: 现有方法在复杂模型和任务中效果下降，需关注算法选择和新兴技术。

Conclusion: 未来应聚焦相关测试任务和元学习等方向，以提升学习率控制的效果。

Abstract: The learning rate is one of the most important hyperparameters in deep
learning, and how to control it is an active area within both AutoML and deep
learning research. Approaches for learning rate control span from classic
optimization to online scheduling based on gradient statistics. This paper
compares paradigms to assess the current state of learning rate control. We
find that methods from multi-fidelity hyperparameter optimization,
fixed-hyperparameter schedules, and hyperparameter-free learning often perform
very well on selected deep learning tasks but are not reliable across settings.
This highlights the need for algorithm selection methods in learning rate
control, which have been neglected so far by both the AutoML and deep learning
communities. We also observe a trend of hyperparameter optimization approaches
becoming less effective as models and tasks grow in complexity, even when
combined with multi-fidelity approaches for more expensive model trainings. A
focus on more relevant test tasks and new promising directions like finetunable
methods and meta-learning will enable the AutoML community to significantly
strengthen its impact on this crucial factor in deep learning.

</details>


### [232] [A Real-Time Digital Twin for Type 1 Diabetes using Simulation-Based Inference](https://arxiv.org/abs/2507.01740)
*Trung-Dung Hoang,Alceu Bissoto,Vihangkumar V. Naik,Tim Flühmann,Artemii Shlychkov,José Garcia-Tirado,Lisa M. Koch*

Main category: cs.LG

TL;DR: 提出了一种基于神经后验估计的模拟推理方法，用于高效估计1型糖尿病生理模型参数，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 准确估计生理模型参数对实现可靠的数字孪生至关重要，但传统方法在高维参数空间中效率低下。

Method: 采用基于神经后验估计的模拟推理方法，捕捉饮食、胰岛素和血糖水平的复杂关系。

Result: 实验表明，该方法在参数估计上优于传统方法，且能更好地泛化到未见条件，提供实时后验推断。

Conclusion: 该方法为1型糖尿病模型参数估计提供了高效、可靠的解决方案。

Abstract: Accurately estimating parameters of physiological models is essential to
achieving reliable digital twins. For Type 1 Diabetes, this is particularly
challenging due to the complexity of glucose-insulin interactions. Traditional
methods based on Markov Chain Monte Carlo struggle with high-dimensional
parameter spaces and fit parameters from scratch at inference time, making them
slow and computationally expensive. In this study, we propose a
Simulation-Based Inference approach based on Neural Posterior Estimation to
efficiently capture the complex relationships between meal intake, insulin, and
glucose level, providing faster, amortized inference. Our experiments
demonstrate that SBI not only outperforms traditional methods in parameter
estimation but also generalizes better to unseen conditions, offering real-time
posterior inference with reliable uncertainty quantification.

</details>


### [233] [Tuning without Peeking: Provable Privacy and Generalization Bounds for LLM Post-Training](https://arxiv.org/abs/2507.01752)
*Ismail Labiad,Mathurin Videau,Matthieu Kowalski,Marc Schoenauer,Alessandro Leite,Julia Kempe,Olivier Teytaud*

Main category: cs.LG

TL;DR: BBoxER是一种基于进化的黑盒优化方法，用于大型语言模型（LLM）的后训练，通过隐式压缩训练数据引入信息瓶颈，提供理论保证和轻量级增强。


<details>
  <summary>Details</summary>
Motivation: 解决梯度优化方法在隐私、安全和过拟合方面的局限性，以及黑盒方法在高维参数空间和计算成本上的挑战。

Method: BBoxER通过信息瓶颈隐式压缩训练数据，提供理论边界，并作为预训练LLM的轻量级模块化增强。

Result: 实验表明，BBoxER在推理数据集上提升性能并实现良好的泛化。

Conclusion: BBoxER是梯度优化方法的有吸引力的补充，适用于隐私敏感或受限环境。

Abstract: Gradient-based optimization is the workhorse of deep learning, offering
efficient and scalable training via backpropagation. However, its reliance on
large volumes of labeled data raises privacy and security concerns such as
susceptibility to data poisoning attacks and the risk of overfitting. In
contrast, black box optimization methods, which treat the model as an opaque
function, relying solely on function evaluations to guide optimization, offer a
promising alternative in scenarios where data access is restricted, adversarial
risks are high, or overfitting is a concern. However, black box methods also
pose significant challenges, including poor scalability to high-dimensional
parameter spaces, as prevalent in large language models (LLMs), and high
computational costs due to reliance on numerous model evaluations. This paper
introduces BBoxER, an evolutionary black-box method for LLM post-training that
induces an information bottleneck via implicit compression of the training
data. Leveraging the tractability of information flow, we provide strong
theoretical bounds on generalization, differential privacy, susceptibility to
data poisoning attacks, and robustness to extraction attacks. BBoxER operates
on top of pre-trained LLMs, offering a lightweight and modular enhancement
suitable for deployment in restricted or privacy-sensitive environments, in
addition to non-vacuous generalization guarantees. In experiments with LLMs, we
demonstrate empirically that Retrofitting methods are able to learn, showing
how a few iterations of BBoxER improve performance and generalize well on a
benchmark of reasoning datasets. This positions BBoxER as an attractive add-on
on top of gradient-based optimization.

</details>


### [234] [Enhanced Generative Model Evaluation with Clipped Density and Coverage](https://arxiv.org/abs/2507.01761)
*Nicolas Salvy,Hugues Talbot,Bertrand Thirion*

Main category: cs.LG

TL;DR: 论文提出了两种新指标Clipped Density和Clipped Coverage，用于更可靠、可解释地评估生成模型样本质量，解决了现有指标在鲁棒性和校准方面的不足。


<details>
  <summary>Details</summary>
Motivation: 生成模型在关键应用中的使用受到样本质量评估不可靠的限制，现有指标缺乏校准或对异常值的鲁棒性。

Method: 通过剪裁单个样本贡献和最近邻球半径，提出Clipped Density和Clipped Coverage指标，防止异常样本影响聚合值。

Result: 新指标在合成和真实数据集上表现出更好的鲁棒性、敏感性和可解释性，且分数随劣质样本比例线性下降。

Conclusion: Clipped Density和Clipped Coverage为生成模型样本质量评估提供了更可靠和直观的解决方案。

Abstract: Although generative models have made remarkable progress in recent years,
their use in critical applications has been hindered by their incapacity to
reliably evaluate sample quality. Quality refers to at least two complementary
concepts: fidelity and coverage. Current quality metrics often lack reliable,
interpretable values due to an absence of calibration or insufficient
robustness to outliers. To address these shortcomings, we introduce two novel
metrics, Clipped Density and Clipped Coverage. By clipping individual sample
contributions and, for fidelity, the radii of nearest neighbor balls, our
metrics prevent out-of-distribution samples from biasing the aggregated values.
Through analytical and empirical calibration, these metrics exhibit linear
score degradation as the proportion of poor samples increases. Thus, they can
be straightforwardly interpreted as equivalent proportions of good samples.
Extensive experiments on synthetic and real-world datasets demonstrate that
Clipped Density and Clipped Coverage outperform existing methods in terms of
robustness, sensitivity, and interpretability for evaluating generative models.

</details>


### [235] [BranchNet: A Neuro-Symbolic Learning Framework for Structured Multi-Class Classification](https://arxiv.org/abs/2507.01781)
*Dalia Rodríguez-Salas,Christian Riess*

Main category: cs.LG

TL;DR: BranchNet将决策树集成转化为稀疏神经网络，保留符号结构并支持梯度优化，性能优于XGBoost。


<details>
  <summary>Details</summary>
Motivation: 结合神经网络的梯度优化能力与决策树的符号可解释性，提出一种紧凑且无需手动调参的模型。

Method: 将决策树的每条路径映射为神经网络的隐藏神经元，保留符号结构并实现梯度优化。

Result: 在多分类任务中，BranchNet在准确性上显著优于XGBoost。

Conclusion: BranchNet在符号可解释性和性能上表现优异，但在二分类任务中可能需要进一步优化。

Abstract: We introduce BranchNet, a neuro-symbolic learning framework that transforms
decision tree ensembles into sparse, partially connected neural networks. Each
branch, defined as a decision path from root to a parent of leaves, is mapped
to a hidden neuron, preserving symbolic structure while enabling gradient-based
optimization. The resulting models are compact, interpretable, and require no
manual architecture tuning. Evaluated on a suite of structured multi-class
classification benchmarks, BranchNet consistently outperforms XGBoost in
accuracy, with statistically significant gains. We detail the architecture,
training procedure, and sparsity dynamics, and discuss the model's strengths in
symbolic interpretability as well as its current limitations, particularly on
binary tasks where further adaptive calibration may be beneficial.

</details>


### [236] [Towards Decentralized and Sustainable Foundation Model Training with the Edge](https://arxiv.org/abs/2507.01803)
*Leyang Xue,Meghana Madhyastha,Randal Burns,Myungjin Lee,Mahesh K. Marina*

Main category: cs.LG

TL;DR: 提出了一种去中心化和可持续的基础模型训练愿景，利用边缘AI设备的集体计算能力，以减少环境影响和集中控制风险。


<details>
  <summary>Details</summary>
Motivation: 基础模型的计算需求大，导致环境问题和集中控制风险，需要更可持续和去中心化的解决方案。

Method: 利用连接边缘AI设备的闲置计算资源进行分布式训练。

Result: 提出了实现这一愿景的挑战和可持续发展优势。

Conclusion: 去中心化和可持续的基础模型训练是可行的，但需解决一系列技术挑战。

Abstract: Foundation models are at the forefront of AI research, appealing for their
ability to learn from vast datasets and cater to diverse tasks. Yet, their
significant computational demands raise issues of environmental impact and the
risk of centralized control in their development. We put forward a vision
towards decentralized and sustainable foundation model training that leverages
the collective compute of sparingly used connected edge AI devices. We present
the rationale behind our vision, particularly in support of its sustainability
benefit. We further outline a set of challenges that need to be addressed to
turn this vision into reality.

</details>


### [237] [LoRA Fine-Tuning Without GPUs: A CPU-Efficient Meta-Generation Framework for LLMs](https://arxiv.org/abs/2507.01806)
*Reza Arabpour,Haitz Sáez de Ocáriz Borde,Anastasis Kratsios*

Main category: cs.LG

TL;DR: 提出了一种基于CPU的低秩适配器（LoRA）微调方法，适用于计算资源有限的用户，通过组合预训练适配器生成新适配器，性能优于基础模型但不及GPU训练版本。


<details>
  <summary>Details</summary>
Motivation: 解决LoRA微调对GPU的依赖问题，为计算资源有限的用户提供可行方案。

Method: 利用预训练适配器库，通过轻量级组合生成新适配器，避免梯度更新，直接在CPU上操作。

Result: 生成的适配器性能优于基础模型，但不及GPU训练版本，为资源有限用户提供实用替代方案。

Conclusion: 该方法为计算资源受限的用户提供了一种可行的LoRA微调替代方案，尽管性能略逊于GPU训练版本。

Abstract: Low-Rank Adapters (LoRAs) have transformed the fine-tuning of Large Language
Models (LLMs) by enabling parameter-efficient updates. However, their
widespread adoption remains limited by the reliance on GPU-based training. In
this work, we propose a theoretically grounded approach to LoRA fine-tuning
designed specifically for users with limited computational resources,
particularly those restricted to standard laptop CPUs. Our method learns a
meta-operator that maps any input dataset, represented as a probability
distribution, to a set of LoRA weights by leveraging a large bank of
pre-trained adapters for the Mistral-7B-Instruct-v0.2 model. Instead of
performing new gradient-based updates, our pipeline constructs adapters via
lightweight combinations of existing LoRAs directly on CPU. While the resulting
adapters do not match the performance of GPU-trained counterparts, they
consistently outperform the base Mistral model on downstream tasks, offering a
practical and accessible alternative to traditional GPU-based fine-tuning.

</details>


### [238] [MILP-SAT-GNN: Yet Another Neural SAT Solver](https://arxiv.org/abs/2507.01825)
*Franco Alberto Cardillo,Hamza Khyari,Umberto Straccia*

Main category: cs.LG

TL;DR: 提出一种新方法，利用GNN解决SAT问题，通过将k-CNF公式映射为MILP问题，再编码为加权二分图输入GNN。理论证明方法具有排列和等价不变性，但也存在对可折叠公式的局限性。实验显示方法效果良好。


<details>
  <summary>Details</summary>
Motivation: 探索GNN在解决SAT问题中的应用，结合MILP技术提升性能。

Method: 将k-CNF公式映射为MILP问题，编码为加权二分图后输入GNN训练和测试。

Result: 理论证明方法具有不变性和局限性，实验显示效果良好。

Conclusion: 该方法在有限数据集上近似解决SAT问题，对不可折叠公式无需RNI即可实现近似保证。

Abstract: We proposes a novel method that enables Graph Neural Networks (GNNs) to solve
SAT problems by leveraging a technique developed for applying GNNs to Mixed
Integer Linear Programming (MILP). Specifically, k-CNF formulae are mapped into
MILP problems, which are then encoded as weighted bipartite graphs and
subsequently fed into a GNN for training and testing. From a theoretical
perspective: (i) we establish permutation and equivalence invariance results,
demonstrating that the method produces outputs that are stable under reordering
of clauses and variables; (ii) we identify a theoretical limitation, showing
that for a class of formulae called foldable formulae, standard GNNs cannot
always distinguish satisfiable from unsatisfiable instances; (iii) we prove a
universal approximation theorem, establishing that with Random Node
Initialization (RNI), the method can approximate SAT solving to arbitrary
precision on finite datasets, that is, the GNN becomes approximately sound and
complete on such datasets. Furthermore, we show that for unfoldable formulae,
the same approximation guarantee can be achieved without the need for RNI.
Finally, we conduct an experimental evaluation of our approach, which show
that, despite the simplicity of the neural architecture, the method achieves
promising results.

</details>


### [239] [mGRADE: Minimal Recurrent Gating Meets Delay Convolutions for Lightweight Sequence Modeling](https://arxiv.org/abs/2507.01829)
*Tristan Torchet,Christian Metzner,Laura Kriener,Melika Payvand*

Main category: cs.LG

TL;DR: mGRADE是一种混合内存系统，结合了1D卷积和最小门控循环单元，适用于边缘设备的时序处理，内存占用更低。


<details>
  <summary>Details</summary>
Motivation: 边缘设备需要同时捕捉短时和长时动态的模型，但现有方法（如Transformer、RNN、TCN）在内存或效率上存在不足。

Method: 提出mGRADE，结合可学习间距的1D卷积和minGRU，实现灵活延迟嵌入和高效全局上下文维护。

Result: 在合成任务和图像分类基准测试中，mGRADE表现优于纯卷积或循环模型，内存占用减少20%。

Conclusion: mGRADE是一种高效的内存受限多尺度时序处理解决方案，适合边缘设备。

Abstract: Edge devices for temporal processing demand models that capture both short-
and long- range dynamics under tight memory constraints. While Transformers
excel at sequence modeling, their quadratic memory scaling with sequence length
makes them impractical for such settings. Recurrent Neural Networks (RNNs)
offer constant memory but train sequentially, and Temporal Convolutional
Networks (TCNs), though efficient, scale memory with kernel size. To address
this, we propose mGRADE (mininally Gated Recurrent Architecture with Delay
Embedding), a hybrid-memory system that integrates a temporal 1D-convolution
with learnable spacings followed by a minimal gated recurrent unit (minGRU).
This design allows the convolutional layer to realize a flexible delay
embedding that captures rapid temporal variations, while the recurrent module
efficiently maintains global context with minimal memory overhead. We validate
our approach on two synthetic tasks, demonstrating that mGRADE effectively
separates and preserves multi-scale temporal features. Furthermore, on
challenging pixel-by-pixel image classification benchmarks, mGRADE consistently
outperforms both pure convolutional and pure recurrent counterparts using
approximately 20% less memory footprint, highlighting its suitability for
memory-constrained temporal processing at the edge. This highlights mGRADE's
promise as an efficient solution for memory-constrained multi-scale temporal
processing at the edge.

</details>


### [240] [Out-of-Distribution Detection Methods Answer the Wrong Questions](https://arxiv.org/abs/2507.01831)
*Yucen Lily Li,Daohan Lu,Polina Kirichenko,Shikai Qiu,Tim G. J. Rudner,C. Bayan Bruss,Andrew Gordon Wilson*

Main category: cs.LG

TL;DR: 论文重新审视了基于预测不确定性和特征的OOD检测方法，指出这些方法存在根本性错误，无法有效识别OOD样本，且现有改进方法也无法解决这一核心问题。


<details>
  <summary>Details</summary>
Motivation: 当前OOD检测方法依赖监督模型的预测不确定性或特征，但这些方法未能正确识别OOD样本，存在根本性缺陷。

Method: 通过分析现有OOD检测方法的局限性，探讨了不确定性方法和特征方法的错误根源，并评估了改进方法的有效性。

Result: 研究发现，现有方法无法有效区分OOD样本，且改进方法如混合特征-logit方法、模型规模扩展等也无法解决核心问题。

Conclusion: 论文指出OOD检测需要新的方法，因为现有方法在目标和实现上存在根本性不匹配。

Abstract: To detect distribution shifts and improve model safety, many
out-of-distribution (OOD) detection methods rely on the predictive uncertainty
or features of supervised models trained on in-distribution data. In this
paper, we critically re-examine this popular family of OOD detection
procedures, and we argue that these methods are fundamentally answering the
wrong questions for OOD detection. There is no simple fix to this misalignment,
since a classifier trained only on in-distribution classes cannot be expected
to identify OOD points; for instance, a cat-dog classifier may confidently
misclassify an airplane if it contains features that distinguish cats from
dogs, despite generally appearing nothing alike. We find that uncertainty-based
methods incorrectly conflate high uncertainty with being OOD, while
feature-based methods incorrectly conflate far feature-space distance with
being OOD. We show how these pathologies manifest as irreducible errors in OOD
detection and identify common settings where these methods are ineffective.
Additionally, interventions to improve OOD detection such as feature-logit
hybrid methods, scaling of model and data size, epistemic uncertainty
representation, and outlier exposure also fail to address this fundamental
misalignment in objectives. We additionally consider unsupervised density
estimation and generative models for OOD detection, which we show have their
own fundamental limitations.

</details>


### [241] [Automatic Rank Determination for Low-Rank Adaptation via Submodular Function Maximization](https://arxiv.org/abs/2507.01841)
*Yihang Gao,Vincent Y. F. Tan*

Main category: cs.LG

TL;DR: SubLoRA提出了一种基于子模函数最大化的LoRA秩确定方法，利用二阶信息（Hessian矩阵）改进传统一阶方法的不足，并通过贪心算法实现高效求解。


<details>
  <summary>Details</summary>
Motivation: 传统LoRA秩确定方法（如AdaLoRA）依赖一阶近似，在参数优化后可能不准确且病态，需要更可靠且精细的二阶方法。

Method: 将秩确定问题转化为组合优化问题，提出子模函数最大化框架和贪心算法，结合Hessian矩阵的闭式投影保证计算效率。

Result: 在物理信息神经网络（PINNs）微调实验中，SubLoRA在秩确定和联合训练性能上优于现有方法。

Conclusion: SubLoRA结合理论严谨性、二阶精度和计算效率，为LoRA秩确定提供了更优解决方案。

Abstract: In this paper, we propose SubLoRA, a rank determination method for Low-Rank
Adaptation (LoRA) based on submodular function maximization. In contrast to
prior approaches, such as AdaLoRA, that rely on first-order (linearized)
approximations of the loss function, SubLoRA utilizes second-order information
to capture the potentially complex loss landscape by incorporating the Hessian
matrix. We show that the linearization becomes inaccurate and ill-conditioned
when the LoRA parameters have been well optimized, motivating the need for a
more reliable and nuanced second-order formulation. To this end, we reformulate
the rank determination problem as a combinatorial optimization problem with a
quadratic objective. However, solving this problem exactly is NP-hard in
general. To overcome the computational challenge, we introduce a submodular
function maximization framework and devise a greedy algorithm with
approximation guarantees. We derive a sufficient and necessary condition under
which the rank-determination objective becomes submodular, and construct a
closed-form projection of the Hessian matrix that satisfies this condition
while maintaining computational efficiency. Our method combines solid
theoretical foundations, second-order accuracy, and practical computational
efficiency. We further extend SubLoRA to a joint optimization setting,
alternating between LoRA parameter updates and rank determination under a rank
budget constraint. Extensive experiments on fine-tuning physics-informed neural
networks (PINNs) for solving partial differential equations (PDEs) demonstrate
the effectiveness of our approach. Results show that SubLoRA outperforms
existing methods in both rank determination and joint training performance.

</details>


### [242] [Towards Foundation Auto-Encoders for Time-Series Anomaly Detection](https://arxiv.org/abs/2507.01875)
*Gastón García González,Pedro Casas,Emilio Martínez,Alicia Fernández*

Main category: cs.LG

TL;DR: FAE是一种基于变分自编码器和扩张卷积神经网络的基础生成AI模型，用于时间序列异常检测。


<details>
  <summary>Details</summary>
Motivation: 受大型预训练基础模型成功的启发，研究如何利用预训练模型处理时间序列数据中的复杂模式。

Method: 结合VAEs和DCNNs构建通用时间序列模型，支持零样本异常检测。

Result: 在多维时间序列数据集（包括移动ISP数据和KDD 2021数据集）上展示了初步结果。

Conclusion: FAE为时间序列建模和异常检测提供了一种通用且高效的解决方案。

Abstract: We investigate a novel approach to time-series modeling, inspired by the
successes of large pretrained foundation models. We introduce FAE (Foundation
Auto-Encoders), a foundation generative-AI model for anomaly detection in
time-series data, based on Variational Auto-Encoders (VAEs). By foundation, we
mean a model pretrained on massive amounts of time-series data which can learn
complex temporal patterns useful for accurate modeling, forecasting, and
detection of anomalies on previously unseen datasets. FAE leverages VAEs and
Dilated Convolutional Neural Networks (DCNNs) to build a generic model for
univariate time-series modeling, which could eventually perform properly in
out-of-the-box, zero-shot anomaly detection applications. We introduce the main
concepts of FAE, and present preliminary results in different multi-dimensional
time-series datasets from various domains, including a real dataset from an
operational mobile ISP, and the well known KDD 2021 Anomaly Detection dataset.

</details>


### [243] [Exploring a Hybrid Deep Learning Approach for Anomaly Detection in Mental Healthcare Provider Billing: Addressing Label Scarcity through Semi-Supervised Anomaly Detection](https://arxiv.org/abs/2507.01924)
*Samirah Bakker,Yao Ma,Seyed Sahand Mohammadi Ziabari*

Main category: cs.LG

TL;DR: 该研究提出了一种结合LSTM和Transformer的混合深度学习模型，利用iForest和AE进行伪标签生成，用于心理健康账单异常检测，解决了类别不平衡和标签稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 心理健康账单的复杂性容易导致异常和欺诈，传统机器学习方法在类别不平衡、标签稀缺和复杂序列模式上表现不佳。

Method: 采用混合深度学习模型（LSTM和Transformer），结合iForest和AE生成伪标签，并在两个真实心理健康账单数据集上评估。

Result: iForest LSTM在声明级数据上召回率最高（0.963）；在操作级数据上，基于iForest的混合模型召回率最高（0.744），但精度较低。

Conclusion: 研究表明，伪标签与混合深度学习结合在复杂、不平衡的异常检测场景中具有潜力。

Abstract: The complexity of mental healthcare billing enables anomalies, including
fraud. While machine learning methods have been applied to anomaly detection,
they often struggle with class imbalance, label scarcity, and complex
sequential patterns. This study explores a hybrid deep learning approach
combining Long Short-Term Memory (LSTM) networks and Transformers, with
pseudo-labeling via Isolation Forests (iForest) and Autoencoders (AE). Prior
work has not evaluated such hybrid models trained on pseudo-labeled data in the
context of healthcare billing. The approach is evaluated on two real-world
billing datasets related to mental healthcare. The iForest LSTM baseline
achieves the highest recall (0.963) on declaration-level data. On the
operation-level data, the hybrid iForest-based model achieves the highest
recall (0.744), though at the cost of lower precision. These findings highlight
the potential of combining pseudo-labeling with hybrid deep learning in
complex, imbalanced anomaly detection settings.

</details>


### [244] [Test-Time Scaling with Reflective Generative Model](https://arxiv.org/abs/2507.01951)
*Zixiao Wang,Yuxin Wang,Xiaorui Wang,Mengting Xing,Jie Gao,Jianjun Xu,Guangcan Liu,Chenhui Jin,Zhuo Wang,Shengzhuo Zhang,Hongtao Xie*

Main category: cs.LG

TL;DR: MetaStone-S1是一种反射生成模型，通过自监督过程奖励模型（SPRM）实现高效推理，性能媲美OpenAI o3，且参数规模仅为32B。


<details>
  <summary>Details</summary>
Motivation: 旨在通过统一接口整合策略模型和过程奖励模型，减少参数需求并提升推理效率。

Method: 采用共享主干网络和任务特定头，结合SPRM实现无额外标注的高效推理，并支持测试时扩展（TTS）。

Result: MetaStone-S1性能与OpenAI-o3-mini系列相当，参数规模显著减少。

Conclusion: MetaStone-S1为研究社区提供了高效且可扩展的生成模型，并已开源。

Abstract: We introduce our first reflective generative model MetaStone-S1, which
obtains OpenAI o3's performance via the self-supervised process reward model
(SPRM). Through sharing the backbone network and using task-specific heads for
next token prediction and process scoring respectively, SPRM successfully
integrates the policy model and process reward model(PRM) into a unified
interface without extra process annotation, reducing over 99% PRM parameters
for efficient reasoning. Equipped with SPRM, MetaStone-S1 is naturally suitable
for test time scaling (TTS), and we provide three reasoning effort modes (low,
medium, and high), based on the controllable thinking length. Moreover, we
empirically establish a scaling law that reveals the relationship between total
thinking computation and TTS performance. Experiments demonstrate that our
MetaStone-S1 achieves comparable performance to OpenAI-o3-mini's series with
only 32B parameter size. To support the research community, we have
open-sourced MetaStone-S1 at https://github.com/MetaStone-AI/MetaStone-S1.

</details>


<div id='cs.MA'></div>

# cs.MA [[Back]](#toc)

### [245] [Automated Vehicles Should be Connected with Natural Language](https://arxiv.org/abs/2507.01059)
*Xiangbo Gao,Keshu Wu,Hao Zhang,Kexin Tian,Yang Zhou,Zhengzhong Tu*

Main category: cs.MA

TL;DR: 论文提出使用自然语言进行多智能体协同驾驶的意图和推理通信，以解决现有通信媒介的局限性，提升交通系统的安全性、效率和透明度。


<details>
  <summary>Details</summary>
Motivation: 现有协同驾驶通信媒介（如原始传感器数据、神经网络特征和感知结果）在带宽效率、信息完整性和智能体互操作性方面存在不足，且忽视了决策级融合。

Method: 提出从感知导向的数据交换转向使用自然语言进行明确的意图和推理通信，以平衡语义密度和通信带宽，适应实时条件并连接异构智能体平台。

Result: 自然语言通信使智能体能够直接传达意图、推理和决策，将协同驾驶从被动的感知数据共享转变为主动的协调。

Conclusion: 自然语言通信是提升智能交通系统安全性、效率和透明度的有效方法。

Abstract: Multi-agent collaborative driving promises improvements in traffic safety and
efficiency through collective perception and decision making. However, existing
communication media -- including raw sensor data, neural network features, and
perception results -- suffer limitations in bandwidth efficiency, information
completeness, and agent interoperability. Moreover, traditional approaches have
largely ignored decision-level fusion, neglecting critical dimensions of
collaborative driving. In this paper we argue that addressing these challenges
requires a transition from purely perception-oriented data exchanges to
explicit intent and reasoning communication using natural language. Natural
language balances semantic density and communication bandwidth, adapts flexibly
to real-time conditions, and bridges heterogeneous agent platforms. By enabling
the direct communication of intentions, rationales, and decisions, it
transforms collaborative driving from reactive perception-data sharing into
proactive coordination, advancing safety, efficiency, and transparency in
intelligent transportation systems.

</details>


### [246] [RALLY: Role-Adaptive LLM-Driven Yoked Navigation for Agentic UAV Swarms](https://arxiv.org/abs/2507.01378)
*Ziyao Wang,Rongpeng Li,Sizhao Li,Yuming Xiang,Haiping Wang,Zhifeng Zhao,Honggang Zhang*

Main category: cs.MA

TL;DR: 论文提出了一种名为RALLY的角色自适应LLM驱动导航算法，通过结合LLM的语义推理能力和MARL的在线学习，解决了无人机群智能控制中的语义通信和角色适应性问题。


<details>
  <summary>Details</summary>
Motivation: 传统MARL方法在无人机群控制中存在语义通信和角色结构僵化的问题，而现有LLM框架缺乏在线学习能力，导致探索效果不佳。

Method: RALLY结合LLM驱动的语义决策框架、动态角色异构机制和基于RMIX的角色分配策略，实现半离线训练。

Result: 在MPE和SITL平台上的实验表明，RALLY在任务覆盖率、收敛速度和泛化能力上优于传统方法。

Conclusion: RALLY展示了在多无人机系统中协作导航的潜力，为智能控制提供了新思路。

Abstract: Intelligent control of Unmanned Aerial Vehicles (UAVs) swarms has emerged as
a critical research focus, and it typically requires the swarm to navigate
effectively while avoiding obstacles and achieving continuous coverage over
multiple mission targets. Although traditional Multi-Agent Reinforcement
Learning (MARL) approaches offer dynamic adaptability, they are hindered by the
semantic gap in numerical communication and the rigidity of homogeneous role
structures, resulting in poor generalization and limited task scalability.
Recent advances in Large Language Model (LLM)-based control frameworks
demonstrate strong semantic reasoning capabilities by leveraging extensive
prior knowledge. However, due to the lack of online learning and over-reliance
on static priors, these works often struggle with effective exploration,
leading to reduced individual potential and overall system performance. To
address these limitations, we propose a Role-Adaptive LLM-Driven Yoked
navigation algorithm RALLY. Specifically, we first develop an LLM-driven
semantic decision framework that uses structured natural language for efficient
semantic communication and collaborative reasoning. Afterward, we introduce a
dynamic role-heterogeneity mechanism for adaptive role switching and
personalized decision-making. Furthermore, we propose a Role-value Mixing
Network (RMIX)-based assignment strategy that integrates LLM offline priors
with MARL online policies to enable semi-offline training of role selection
strategies. Experiments in the Multi-Agent Particle Environment (MPE)
environment and a Software-In-The-Loop (SITL) platform demonstrate that RALLY
outperforms conventional approaches in terms of task coverage, convergence
speed, and generalization, highlighting its strong potential for collaborative
navigation in agentic multi-UAV systems.

</details>


### [247] [Exploring Advanced LLM Multi-Agent Systems Based on Blackboard Architecture](https://arxiv.org/abs/2507.01701)
*Bochen Han,Songmao Zhang*

Main category: cs.MA

TL;DR: 论文提出将黑板架构引入LLM多智能体系统，实现信息共享、动态选择执行智能体，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体系统中信息共享不足和动态问题解决的挑战。

Method: 结合黑板架构，动态选择执行智能体，迭代直至达成共识。

Result: 在常识、推理和数学数据集上表现优于现有方法，且消耗更少token。

Conclusion: 该方法为复杂动态问题解决提供了潜力，尤其在缺乏明确结构时。

Abstract: In this paper, we propose to incorporate the blackboard architecture into LLM
multi-agent systems (MASs) so that (1) agents with various roles can share all
the information and others' messages during the whole problem-solving process,
(2) agents that will take actions are selected based on the current content of
the blackboard, and (3) the selection and execution round is repeated until a
consensus is reached on the blackboard. We develop the first implementation of
this proposal and conduct experiments on commonsense knowledge, reasoning and
mathematical datasets. The results show that our system can be competitive with
the SOTA static and dynamic MASs by achieving the best average performance, and
at the same time manage to spend less tokens. Our proposal has the potential to
enable complex and dynamic problem-solving where well-defined structures or
workflows are unavailable.

</details>


### [248] [Distance-based Relative Orbital Transition for Satellite Swarm Array Deployment Under J2 Perturbation](https://arxiv.org/abs/2507.01769)
*Yuta Takahashi,Shin-ichiro Sakai*

Main category: cs.MA

TL;DR: 本文提出了一种卫星群自主导航与控制策略，用于实现可扩展的分布式空间结构，支持创新科学和商业机会。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决卫星群在分布式空间结构中因轨道动力学不稳定导致的控制能力丧失问题，特别是在自主卫星群中。

Method: 通过推导平均$J_2$轨道参数及其目标值，设计了基于距离的轨道稳定器，实现自主部署为共面等距配置。采用无燃料驱动（如卫星磁场相互作用和差动气动力）实现持续编队控制。

Result: 提出的分散部署控制器在意外通信中断时最小化了漂移距离，确保了长期编队稳定性。

Conclusion: 该方法为卫星群的自主部署和长期稳定提供了可行解决方案，适用于小型卫星的共面等距编队部署。

Abstract: This paper presents an autonomous guidance and control strategy for a
satellite swarm that enables scalable distributed space structures for
innovative science and business opportunities. The averaged $J_2$ orbital
parameters that describe the drift and periodic orbital motion were derived
along with their target values to achieve a distributed space structure in a
decentralized manner. This enabled the design of a distance-based orbital
stabilizer to ensure autonomous deployment into a monolithic formation of a
coplanar equidistant configuration on a user-defined orbital plane. Continuous
formation control was assumed to be achieved through fuel-free actuation, such
as satellite magnetic field interaction and differential aerodynamic forces,
thereby maintaining long-term formation stability without thruster usage. A
major challenge for such actuation systems is the potential loss of control
capability due to increasing inter-satellite distances resulting from unstable
orbital dynamics, particularly for autonomous satellite swarms. To mitigate
this risk, our decentralized deployment controller minimized drift distance
during unexpected communication outages. As a case study, we consider the
deployment of palm-sized satellites into a coplanar equidistant formation in a
$J_2$-perturbed orbit. Moreover, centralized grouping strategies are presented.

</details>
