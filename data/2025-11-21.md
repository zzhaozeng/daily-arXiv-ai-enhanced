<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 21]
- [cs.AI](#cs.AI) [Total: 38]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Mind the Motions: Benchmarking Theory-of-Mind in Everyday Body Language](https://arxiv.org/abs/2511.15887)
*Seungbeen Lee,Jinhong Jeong,Donghyun Kim,Yejin Son,Youngjae Yu*

Main category: cs.CL

TL;DR: 提出Motion2Mind框架评估机器解读非语言线索的心理状态能力，揭示当前AI在该领域的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的ToM基准主要关注信念错误任务和不对称信息推理，忽视了信念之外的心理状态和丰富的非语言交流。

Method: 利用专家精选的体态语言参考作为知识库，构建了包含精细非语言线索标注和心理解释的Motion2Mind视频数据集，涵盖222种非语言线索和397种心理状态。

Result: 评估显示，当前AI系统在非语言线索解读方面表现不佳，检测性能差距大，并且在解释上表现出过度解读的倾向。

Conclusion: Motion2Mind揭示了当前AI在非语言线索解读方面的局限性，为未来改进提供了方向。

Abstract: Our ability to interpret others' mental states through nonverbal cues (NVCs) is fundamental to our survival and social cohesion. While existing Theory of Mind (ToM) benchmarks have primarily focused on false-belief tasks and reasoning with asymmetric information, they overlook other mental states beyond belief and the rich tapestry of human nonverbal communication. We present Motion2Mind, a framework for evaluating the ToM capabilities of machines in interpreting NVCs. Leveraging an expert-curated body-language reference as a proxy knowledge base, we build Motion2Mind, a carefully curated video dataset with fine-grained nonverbal cue annotations paired with manually verified psychological interpretations. It encompasses 222 types of nonverbal cues and 397 mind states. Our evaluation reveals that current AI systems struggle significantly with NVC interpretation, exhibiting not only a substantial performance gap in Detection, as well as patterns of over-interpretation in Explanation compared to human annotators.

</details>


### [2] [TOD-ProcBench: Benchmarking Complex Instruction-Following in Task-Oriented Dialogues](https://arxiv.org/abs/2511.15976)
*Sarik Ghazarian,Abhinav Gullapalli,Swair Shah,Anurag Beniwal,Nanyun Peng,Narayanan Sadagopan,Zhou Yu*

Main category: cs.CL

TL;DR: 提出TOD-ProcBench，一个用于评估大型语言模型在多轮任务导向对话中遵循复杂指令能力的基准。


<details>
  <summary>Details</summary>
Motivation: 现有TOD基准简化了指令的复杂性，不能充分评估LLMs的指令遵循能力，因此需要一个更系统且复杂的基准。

Method: 利用高质量ABCD数据集，创建包含复杂过程指令的基准数据集，并设计三个任务以全面评估LLMs的指令遵循能力。

Result: TOD-ProcBench包含复杂的指令文档和人工质量控制下的对话，通过三项任务评估LLMs在复杂多轮对话中的表现。

Conclusion: TOD-ProcBench能够有效评估和提升LLMs在复杂指令下的多轮对话能力，并支持多语言和不同指令格式的研究。

Abstract: In real-world task-oriented dialogue (TOD) settings, agents are required to strictly adhere to complex instructions while conducting multi-turn conversations with customers. These instructions are typically presented in natural language format and include general guidelines and step-by-step procedures with complex constraints. Existing TOD benchmarks often oversimplify the complex nature of these instructions by reducing them to simple schemas composed of intents, slots, and API call configurations. To address this gap and systematically benchmark LLMs' instruction-following capabilities, we propose TOD-ProcBench, a challenging benchmark featuring complex process instructions with intricate, fine-grained constraints that evaluates various LLMs' abilities to understand and follow instructions in multi-turn TODs. Our benchmark dataset comprises instruction documents derived from the high-quality ABCD dataset with corresponding conversations under human quality control. We formulate fine-grained constraints and action procedures as multi-level condition-action instruction statements. We design three tasks to comprehensively benchmark LLMs' complex instruction-following capabilities in multi-turn TODs. Task 1 evaluates how LLMs retrieve the most relevant statement from a complex instruction and predict the corresponding next action. In Task 2, we synthesize instruction-violating responses by injecting inconsistencies and manipulating the original instructions, and then we analyze how effectively LLMs can identify instruction-violating responses. Task 3 investigates LLMs' abilities in conditional generation of instruction-following responses based on the original complex instructions. Additionally, we conduct studies on the impact of multilingual settings and different instruction text formats on compliance performance. We release our benchmark under the Llama 3.3 Community License Agreement.

</details>


### [3] [Liars' Bench: Evaluating Lie Detectors for Language Models](https://arxiv.org/abs/2511.16035)
*Kieron Kretschmar,Walter Laurito,Sharan Maiya,Samuel Marks*

Main category: cs.CL

TL;DR: 本文介绍了LIARS' BENCH，一个用于检测大型语言模型说谎的测试平台，包含72,863个谎言和诚实回应的示例。


<details>
  <summary>Details</summary>
Motivation: 先前的工作介绍了检测大型语言模型（LLMs）说谎的技术，但这些技术通常在狭窄的环境中进行验证，未能捕捉到LLMs可以生成的多样化谎言。因此，作者提出了一个更全面的测试平台。

Method: 引入了LIARS' BENCH测试平台，包含四个开放权重模型在七个数据集上生成的72,863个谎言和诚实回应。测试平台涵盖不同类型的谎言，并在两个维度上变化：模型说谎的原因和谎言所针对的信念对象。评估了三种黑盒和白盒谎言检测技术。

Result: 评估发现，现有的谎言检测技术系统地无法识别某些类型的谎言，特别是在无法仅从对话记录中确定模型是否说谎的情况下。

Conclusion: LIARS' BENCH揭示了现有技术的局限性，并为谎言检测的进展提供了一个实用的测试平台。

Abstract: Prior work has introduced techniques for detecting when large language models (LLMs) lie, that is, generating statements they believe are false. However, these techniques are typically validated in narrow settings that do not capture the diverse lies LLMs can generate. We introduce LIARS' BENCH, a testbed consisting of 72,863 examples of lies and honest responses generated by four open-weight models across seven datasets. Our settings capture qualitatively different types of lies and vary along two dimensions: the model's reason for lying and the object of belief targeted by the lie. Evaluating three black- and white-box lie detection techniques on LIARS' BENCH, we find that existing techniques systematically fail to identify certain types of lies, especially in settings where it's not possible to determine whether the model lied from the transcript alone. Overall, LIARS' BENCH reveals limitations in prior techniques and provides a practical testbed for guiding progress in lie detection.

</details>


### [4] [Early science acceleration experiments with GPT-5](https://arxiv.org/abs/2511.16072)
*Sébastien Bubeck,Christian Coester,Ronen Eldan,Timothy Gowers,Yin Tat Lee,Alexandru Lupsasca,Mehtaab Sawhney,Robert Scherrer,Mark Sellke,Brian K. Spears,Derya Unutmaz,Kevin Weil,Steven Yin,Nikita Zhivotovskiy*

Main category: cs.CL

TL;DR: 本文通过多个学科案例研究展示了GPT-5如何加速科学研究，并强调了人类专家与AI协作的重要性。


<details>
  <summary>Details</summary>
Motivation: 科学家尚未充分利用前沿AI（如GPT-5）的潜力。本文旨在通过具体案例展示AI在多个学科中的实际贡献，以促进科学家对AI工具的认识和应用。

Method: 作者们在数学、物理学、天文学、计算机科学、生物学和材料科学等领域开展了多个案例研究，记录他们与GPT-5的互动，分析AI在各个环节中的作用和局限性。

Result: 在多个学科中，GPT-5成功提出了具体的研究步骤，显著加速了研究进程。尤其在数学领域，GPT-5帮助解决了四个新问题，这些结果经过作者仔细验证。

Conclusion: GPT-5在科学研究中具有巨大潜力，但人类专家的指导和验证仍然至关重要。AI和人类的协作可以显著提高研究效率，并解决以前难以解决的问题。这一合作模式对未来的科研具有重要启示。

Abstract: AI models like GPT-5 are an increasingly valuable tool for scientists, but many remain unaware of the capabilities of frontier AI. We present a collection of short case studies in which GPT-5 produced new, concrete steps in ongoing research across mathematics, physics, astronomy, computer science, biology, and materials science. In these examples, the authors highlight how AI accelerated their work, and where it fell short; where expert time was saved, and where human input was still key. We document the interactions of the human authors with GPT-5, as guiding examples of fruitful collaboration with AI. Of note, this paper includes four new results in mathematics (carefully verified by the human authors), underscoring how GPT-5 can help human mathematicians settle previously unsolved problems. These contributions are modest in scope but profound in implication, given the rate at which frontier AI is progressing.

</details>


### [5] [ELPO: Ensemble Learning Based Prompt Optimization for Large Language Models](https://arxiv.org/abs/2511.16122)
*Qing Zhang,Bing Xu,Xudong Zhang,Yifan Shi,Yang Li,Chen Zhang,Yik Chung Wu,Ngai Wong,Yijie Chen,Hong Dai,Xiansen Chen,Mian Zhang*

Main category: cs.CL

TL;DR: 提出了一种基于集成学习的自动提示优化框架ELPO，通过投票机制和共享生成策略及不同搜索方法，实现更准确和鲁棒的提示优化。


<details>
  <summary>Details</summary>
Motivation: 手动提示工程繁琐，成为应用LLMs的瓶颈，而现有APO方法在处理复杂任务时性能受限，因此提出集成学习方法以提高效果。

Method: ELPO框架利用集成学习的思想，采用投票机制、共享生成策略和不同的搜索方法，并提出了更高效的提示生成和搜索算法。

Result: 实验结果显示，ELPO在不同任务上优于现有提示优化方法，如在ArSarcasm数据集上F1分数提高了7.6。

Conclusion: ELPO通过集成学习的方法，在提示优化上实现了更高的准确性和鲁棒性，为复杂任务提供了更好的解决方案。

Abstract: The remarkable performance of Large Language Models (LLMs) highly relies on crafted prompts. However, manual prompt engineering is a laborious process, creating a core bottleneck for practical application of LLMs. This phenomenon has led to the emergence of a new research area known as Automatic Prompt Optimization (APO), which develops rapidly in recent years. Existing APO methods such as those based on evolutionary algorithms or trial-and-error approaches realize an efficient and accurate prompt optimization to some extent. However, those researches focus on a single model or algorithm for the generation strategy and optimization process, which limits their performance when handling complex tasks. To address this, we propose a novel framework called Ensemble Learning based Prompt Optimization (ELPO) to achieve more accurate and robust results. Motivated by the idea of ensemble learning, ELPO conducts voting mechanism and introduces shared generation strategies along with different search methods for searching superior prompts. Moreover, ELPO creatively presents more efficient algorithms for the prompt generation and search process. Experimental results demonstrate that ELPO outperforms state-of-the-art prompt optimization methods across different tasks, e.g., improving F1 score by 7.6 on ArSarcasm dataset.

</details>


### [6] [TS-PEFT: Token-Selective Parameter-Efficient Fine-Tuning with Learnable Threshold Gating](https://arxiv.org/abs/2511.16147)
*Dabiao Ma,Ziming Dai,Zhimin Xin,Shu Wang,Ye Wang,Haojun Fei*

Main category: cs.CL

TL;DR: 本文提出了一种新的参数高效微调（PEFT）方法，Token-Selective PEFT (TS-PEFT)，通过选择性地对部分位置索引进行微调，提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 传统PEFT方法对所有位置索引进行修改，可能不仅多余，还可能导致性能下降。因此，作者提出选择性地对部分位置进行修改，以提高效率。

Method: 引入Token-Selective PEFT (TS-PEFT)，通过函数S选择性地将PEFT修改应用于部分位置索引，而非所有位置。

Result: 实验结果表明，对所有位置索引进行无差别PEFT修改不仅多余，还可能适得其反，而TS-PEFT能提升下游任务性能。

Conclusion: 该研究为大型模型的微调提供了新视角，提倡更有针对性的修改方法，为未来研究提供了一个优化PEFT的框架。

Abstract: In the field of large models (LMs) for natural language processing (NLP) and computer vision (CV), Parameter-Efficient Fine-Tuning (PEFT) has emerged as a resource-efficient method that modifies a limited number of parameters while keeping the pretrained weights fixed. This paper investigates the traditional PEFT approach, which applies modifications to all position indices, and questions its necessity. We introduce a new paradigm called Token-Selective PEFT (TS-PEFT), in which a function S selectively applies PEFT modifications to a subset of position indices, potentially enhancing performance on downstream tasks. Our experimental results reveal that the indiscriminate application of PEFT to all indices is not only superfluous, but may also be counterproductive. This study offers a fresh perspective on PEFT, advocating for a more targeted approach to modifications and providing a framework for future research to optimize the fine-tuning process for large models.

</details>


### [7] [SemanticCite: Citation Verification with AI-Powered Full-Text Analysis and Evidence-Based Reasoning](https://arxiv.org/abs/2511.16198)
*Sebastian Haan*

Main category: cs.CL

TL;DR: SemanticCite是一个AI驱动的系统，通过全文源分析验证引文准确性，并提供详细的推理和相关文本片段以丰富上下文信息。


<details>
  <summary>Details</summary>
Motivation: 当前学术文献面临语义引用错误、AI生成虚构引用和传统引用格式无法指明具体支持部分等挑战。

Method: SemanticCite结合了多种检索方法和一个四类分类系统（支持、部分支持、不支持、不确定），并微调轻量级语言模型进行引文验证。

Result: 实验表明，微调后的轻量级语言模型性能与大型商业系统相当，且计算需求显著降低，使其在大规模引文验证中实际可行。

Conclusion: SemanticCite通过可伸缩的引文验证、简化的同行评审和AI生成内容的质量控制，为维护大规模引文准确性提供了开源基础。

Abstract: Effective scientific communication depends on accurate citations that validate sources and guide readers to supporting evidence. Yet academic literature faces mounting challenges: semantic citation errors that misrepresent sources, AI-generated hallucinated references, and traditional citation formats that point to entire papers without indicating which sections substantiate specific claims. We introduce SemanticCite, an AI-powered system that verifies citation accuracy through full-text source analysis while providing rich contextual information via detailed reasoning and relevant text snippets. Our approach combines multiple retrieval methods with a four-class classification system (Supported, Partially Supported, Unsupported, Uncertain) that captures nuanced claim-source relationships and enables appropriate remedial actions for different error types. Our experiments show that fine-tuned lightweight language models achieve performance comparable to large commercial systems with significantly lower computational requirements, making large-scale citation verification practically feasible. The system provides transparent, evidence-based explanations that support user understanding and trust. We contribute a comprehensive dataset of over 1,000 citations with detailed alignments, functional classifications, semantic annotations, and bibliometric metadata across eight disciplines, alongside fine-tuned models and the complete verification framework as open-source software. SemanticCite addresses critical challenges in research integrity through scalable citation verification, streamlined peer review, and quality control for AI-generated content, providing an open-source foundation for maintaining citation accuracy at scale.

</details>


### [8] [SeSE: A Structural Information-Guided Uncertainty Quantification Framework for Hallucination Detection in LLMs](https://arxiv.org/abs/2511.16275)
*Xingtao Zhao,Hao Peng,Dingli Su,Xianghua Zeng,Chunyang Liu,Jinzhi Liao,Philip S. Yu*

Main category: cs.CL

TL;DR: 本文提出了一种新的不确定性量化框架SeSE，通过语义结构信息来提升大语言模型在不确定性判断和幻觉检测方面的能力。


<details>
  <summary>Details</summary>
Motivation: 在安全关键场景中，可靠的不确定性量化对大语言模型至关重要，但现有方法忽视了有助于更精确不确定性估计的潜在语义结构信息。

Method: 提出了一种名为Semantic Structural Entropy (SeSE)的UQ框架，通过自适应稀疏化有向语义图捕捉语义空间中的方向性依赖关系，并利用最优语义编码树的结构熵来形式化语义空间的不确定性。

Result: 在29个模型-数据集组合上的大量实验表明，SeSE显著优于先进UQ基线方法，包括强监督方法和最近提出的KLE。

Conclusion: SeSE框架通过挖掘和利用语义结构信息，有效提高了大语言模型在不确定性量化和幻觉检测上的性能，为安全关键场景中的模型部署提供了更可靠的保障。

Abstract: Reliable uncertainty quantification (UQ) is essential for deploying large language models (LLMs) in safety-critical scenarios, as it enables them to abstain from responding when uncertain, thereby avoiding hallucinating falsehoods. However, state-of-the-art UQ methods primarily rely on semantic probability distributions or pairwise distances, overlooking latent semantic structural information that could enable more precise uncertainty estimates. This paper presents Semantic Structural Entropy (SeSE), a principled UQ framework that quantifies the inherent semantic uncertainty of LLMs from a structural information perspective for hallucination detection. Specifically, to effectively model semantic spaces, we first develop an adaptively sparsified directed semantic graph construction algorithm that captures directional semantic dependencies while automatically pruning unnecessary connections that introduce negative interference. We then exploit latent semantic structural information through hierarchical abstraction: SeSE is defined as the structural entropy of the optimal semantic encoding tree, formalizing intrinsic uncertainty within semantic spaces after optimal compression. A higher SeSE value corresponds to greater uncertainty, indicating that LLMs are highly likely to generate hallucinations. In addition, to enhance fine-grained UQ in long-form generation -- where existing methods often rely on heuristic sample-and-count techniques -- we extend SeSE to quantify the uncertainty of individual claims by modeling their random semantic interactions, providing theoretically explicable hallucination detection. Extensive experiments across 29 model-dataset combinations show that SeSE significantly outperforms advanced UQ baselines, including strong supervised methods and the recently proposed KLE.

</details>


### [9] [SDA: Steering-Driven Distribution Alignment for Open LLMs without Fine-Tuning](https://arxiv.org/abs/2511.16324)
*Wei Xia,Zhi-Hong Deng*

Main category: cs.CL

TL;DR: 提出一种无需训练且模型无关的对齐框架SDA，通过动态调整输出概率，提升开源大语言模型与人类意图的对齐效果。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在现实世界应用中的广泛使用，确保其响应与用户意图对齐，尤其是在推理过程中高效实现，是一个关键且具挑战性的任务。

Method: SDA（Steering-Driven Distribution Alignment）框架通过用户定义的对齐指令，动态重新分配模型输出概率，无需微调或大量监督。

Result: SDA在8个不同规模和来源的开源大语言模型上，评估三个关键对齐维度（3H），实现了平均64.4%的有用性提升，30%的诚实性提升，以及11.5%的无害性提升。

Conclusion: SDA是一种轻量级、资源高效且通用的解决方案，可以在推理过程中独立使用，或与基于训练的对齐策略结合，有效支持个性化偏好对齐。

Abstract: With the rapid advancement of large language models (LLMs), their deployment in real-world applications has become increasingly widespread. LLMs are expected to deliver robust performance across diverse tasks, user preferences, and practical scenarios. However, as demands grow, ensuring that LLMs produce responses aligned with human intent remains a foundational challenge. In particular, aligning model behavior effectively and efficiently during inference, without costly retraining or extensive supervision, is both a critical requirement and a non-trivial technical endeavor. To address the challenge, we propose SDA (Steering-Driven Distribution Alignment), a training-free and model-agnostic alignment framework designed for open-source LLMs. SDA dynamically redistributes model output probabilities based on user-defined alignment instructions, enhancing alignment between model behavior and human intents without fine-tuning. The method is lightweight, resource-efficient, and compatible with a wide range of open-source LLMs. It can function independently during inference or be integrated with training-based alignment strategies. Moreover, SDA supports personalized preference alignment, enabling flexible control over the model response behavior. Empirical results demonstrate that SDA consistently improves alignment performance across 8 open-source LLMs with varying scales and diverse origins, evaluated on three key alignment dimensions, helpfulness, harmlessness, and honesty (3H). Specifically, SDA achieves average gains of 64.4% in helpfulness, 30% in honesty and 11.5% in harmlessness across the tested models, indicating its effectiveness and generalization across diverse models and application scenarios.

</details>


### [10] [Incorporating Self-Rewriting into Large Language Model Reasoning Reinforcement](https://arxiv.org/abs/2511.16331)
*Jiashu Yao,Heyan Huang,Shuang Zeng,Chuwei Luo,WangJie You,Jie Tang,Qingsong Liu,Yuhang Guo,Yangyang Kang*

Main category: cs.CL

TL;DR: 本文介绍了一种自我重写框架，通过强化学习改进大型推理模型的内部推理过程。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在复杂推理任务中成功，但仅关注最终正确性的单方面奖励机制限制了对内部推理过程的详细监督。

Method: 引入自我重写框架，通过选择性重写“简单”样本并学习重写后的推理过程，提升内部思维过程质量。在同一批次中实现重写和原始生成，保持强化学习算法的可扩展性。

Result: 在不同模型规模和多样化任务上的实验验证了自我重写的有效性，实现了更高的准确性和更短的推理长度，显著提升了内部推理质量。

Conclusion: 自我重写框架不仅提高了推理准确性，还成功缓解了内部推理过程中的缺陷，为大型推理模型的优化提供了新方向。

Abstract: Through reinforcement learning (RL) with outcome correctness rewards, large reasoning models (LRMs) with scaled inference computation have demonstrated substantial success on complex reasoning tasks. However, the one-sided reward, focused solely on final correctness, limits its ability to provide detailed supervision over internal reasoning process. This deficiency leads to suboptimal internal reasoning quality, manifesting as issues like over-thinking, under-thinking, redundant-thinking, and disordered-thinking. Inspired by the recent progress in LRM self-rewarding, we introduce self-rewriting framework, where a model rewrites its own reasoning texts, and subsequently learns from the rewritten reasoning to improve the internal thought process quality. For algorithm design, we propose a selective rewriting approach wherein only "simple" samples, defined by the model's consistent correctness, are rewritten, thereby preserving all original reward signals of GRPO. For practical implementation, we compile rewriting and vanilla generation within one single batch, maintaining the scalability of the RL algorithm and introducing only ~10% overhead. Extensive experiments on diverse tasks with different model sizes validate the effectiveness of self-rewriting. In terms of the accuracy-length tradeoff, the self-rewriting approach achieves improved accuracy (+0.6) with substantially shorter reasoning (-46%) even without explicit instructions in rewriting prompts to reduce reasoning length, outperforming existing strong baselines. In terms of internal reasoning quality, self-rewriting achieves significantly higher scores (+7.2) under the LLM-as-a-judge metric, successfully mitigating internal reasoning flaws.

</details>


### [11] [NLP Datasets for Idiom and Figurative Language Tasks](https://arxiv.org/abs/2511.16345)
*Blake Matheny,Phuong Minh Nguyen,Minh Le Nguyen,Stephanie Reynolds*

Main category: cs.CL

TL;DR: 本文提出了用于习语和比喻性语言识别的新数据集，旨在提升大型语言模型在这类语言处理上的表现。


<details>
  <summary>Details</summary>
Motivation: 习语和比喻性语言在日常交流中占比大，但现有大型语言模型仍难以处理。虽然微调方法已显示出优势，但更大更好的数据集能进一步缩小这一差距。

Method: 结合最新的习语和比喻性语言数据集，从大型语料库中提取上下文序列，创建了一个大规模的潜在习语和比喻性语言表达数据集，以及两个人类标注的明确习语和比喻性语言表达数据集，并进行后处理以适配不同模型训练。

Result: 这些数据集经过训练和评估，在槽位标注和序列标注任务中表现良好，为习语和比喻性语言的识别提供了基线能力。

Conclusion: 本文提出的数据集为提升语言模型在习语和比喻性语言处理上的表现提供了一个有效方案，并为未来模型开发和改进提供了多样化的类别和新的方法。

Abstract: Idiomatic and figurative language form a large portion of colloquial speech and writing. With social media, this informal language has become more easily observable to people and trainers of large language models (LLMs) alike. While the advantage of large corpora seems like the solution to all machine learning and Natural Language Processing (NLP) problems, idioms and figurative language continue to elude LLMs. Finetuning approaches are proving to be optimal, but better and larger datasets can help narrow this gap even further. The datasets presented in this paper provide one answer, while offering a diverse set of categories on which to build new models and develop new approaches. A selection of recent idiom and figurative language datasets were used to acquire a combined idiom list, which was used to retrieve context sequences from a large corpus. One large-scale dataset of potential idiomatic and figurative language expressions and two additional human-annotated datasets of definite idiomatic and figurative language expressions were created to evaluate the baseline ability of pre-trained language models in handling figurative meaning through idiom recognition (detection) tasks. The resulting datasets were post-processed for model agnostic training compatibility, utilized in training, and evaluated on slot labeling and sequence tagging.

</details>


### [12] [Learning from Sufficient Rationales: Analysing the Relationship Between Explanation Faithfulness and Token-level Regularisation Strategies](https://arxiv.org/abs/2511.16353)
*Jonathan Kamp,Lisa Beinborn,Antske Fokkens*

Main category: cs.CL

TL;DR: 本文探讨了自然语言模型中解释（rationales）的作用，并评估了充分性（sufficiency）作为信息性度量的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前，充分性作为评估解释信息性的常用度量，但对模型性能的影响提供有限的洞察。本文旨在通过将充分性与模型范式相关联以解决这一局限。

Method: 通过两种模型范式分析：1) 模型识别解释中哪些词元（token）为关键信息的能力（通过词元分类），2) 通过在输入中引入解释来改进模型性能（通过注意力正则化）。

Result: 发现高度信息性的解释未必有助于正确分类实例；充分性捕捉了非解释上下文的分类影响，这与同一输入中的解释信息相干扰。在模型输入中加入解释信息可以提升跨域分类，但结果因任务和模型类型而异。充分性和词元分类似乎没有直接关联。

Conclusion: 这些结果展示了模型解释的复杂性，并表明需要进一步研究能够系统地捕捉这类信息的度量。

Abstract: Human explanations of natural language, rationales, form a tool to assess whether models learn a label for the right reasons or rely on dataset-specific shortcuts. Sufficiency is a common metric for estimating the informativeness of rationales, but it provides limited insight into the effects of rationale information on model performance. We address this limitation by relating sufficiency to two modelling paradigms: the ability of models to identify which tokens are part of the rationale (through token classification) and the ability of improving model performance by incorporating rationales in the input (through attention regularisation). We find that highly informative rationales are not likely to help classify the instance correctly. Sufficiency conversely captures the classification impact of the non-rationalised context, which interferes with rationale information in the same input. We also find that incorporating rationale information in model inputs can boost cross-domain classification, but results are inconsistent per task and model type. Finally, sufficiency and token classification appear to be unrelated. These results exemplify the complexity of rationales, showing that metrics capable of systematically capturing this type of information merit further investigation.

</details>


### [13] [Classification of worldwide news articles by perceived quality, 2018-2024](https://arxiv.org/abs/2511.16416)
*Connor McElroy,Thiago E. A. de Oliveira,Chris Brogly*

Main category: cs.CL

TL;DR: 本研究探讨了有监督机器学习和深度学习模型在区分感知低质量与高质量新闻文章方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 旨在评估机器学习和深度学习模型在识别新闻文章质量方面的能力，以提高信息过滤和推荐的准确性。

Method: 使用了一个新创建的包含1,412,272篇英语新闻文章的数据集，并采用3种机器学习分类器和3种深度学习模型进行评估。通过专家共识评分将文章分为感知低质量和高质量两类，并使用194个语言特征进行训练和测试。

Result: 传统机器学习分类器（如随机森林）表现良好（准确率0.7355，ROC AUC 0.8131）。深度学习模型中，ModernBERT-large（256上下文长度）表现最佳（准确率0.8744，ROC AUC 0.9593，F1 0.8739）。

Conclusion: 感知质量的新闻文章可以通过传统CPU基础的机器学习分类器和深度学习分类器有效区分。

Abstract: This study explored whether supervised machine learning and deep learning models can effectively distinguish perceived lower-quality news articles from perceived higher-quality news articles. 3 machine learning classifiers and 3 deep learning models were assessed using a newly created dataset of 1,412,272 English news articles from the Common Crawl over 2018-2024. Expert consensus ratings on 579 source websites were split at the median, creating perceived low and high-quality classes of about 706,000 articles each, with 194 linguistic features per website-level labelled article. Traditional machine learning classifiers such as the Random Forest demonstrated capable performance (0.7355 accuracy, 0.8131 ROC AUC). For deep learning, ModernBERT-large (256 context length) achieved the best performance (0.8744 accuracy; 0.9593 ROC-AUC; 0.8739 F1), followed by DistilBERT-base (512 context length) at 0.8685 accuracy and 0.9554 ROC-AUC. DistilBERT-base (256 context length) reached 0.8478 accuracy and 0.9407 ROC-AUC, while ModernBERT-base (256 context length) attained 0.8569 accuracy and 0.9470 ROC-AUC. These results suggest that the perceived quality of worldwide news articles can be effectively differentiated by traditional CPU-based machine learning classifiers and deep learning classifiers.

</details>


### [14] [ESGBench: A Benchmark for Explainable ESG Question Answering in Corporate Sustainability Reports](https://arxiv.org/abs/2511.16438)
*Sherine George,Nithish Saji*

Main category: cs.CL

TL;DR: 本文介绍了ESGBench，一个用于评估可解释ESG问答系统的基准数据集和评估框架。


<details>
  <summary>Details</summary>
Motivation: 为了评估企业在环境、社会和治理（ESG）方面的表现，需要一个标准化的基准来衡量问答系统的解释能力。

Method: ESGBench包含多个ESG主题的问题，每个问题配有手动策划的答案和支持证据，以实现对模型推理的细粒度评估。

Result: 分析了最先进的LLMs在ESGBench上的表现，突出了事实一致性、可追溯性和领域对齐等关键挑战。

Conclusion: ESGBench旨在加速透明和负责任的ESG重点AI系统的研究。

Abstract: We present ESGBench, a benchmark dataset and evaluation framework designed to assess explainable ESG question answering systems using corporate sustainability reports. The benchmark consists of domain-grounded questions across multiple ESG themes, paired with human-curated answers and supporting evidence to enable fine-grained evaluation of model reasoning. We analyze the performance of state-of-the-art LLMs on ESGBench, highlighting key challenges in factual consistency, traceability, and domain alignment. ESGBench aims to accelerate research in transparent and accountable ESG-focused AI systems.

</details>


### [15] [Anatomy of an Idiom: Tracing Non-Compositionality in Language Models](https://arxiv.org/abs/2511.16467)
*Andrew Gomes*

Main category: cs.CL

TL;DR: 本文研究了基于Transformer的语言模型处理习语表达的机制，提出了一套新颖的电路发现和分析技术。


<details>
  <summary>Details</summary>
Motivation: 理解Transformer模型如何处理非组合性语言（如习语），并揭示其背后的计算模式。

Method: 采用改进的路径修补算法发现电路，识别“习语头”（Idiom Heads）和“增强接收”（augmented reception）现象，分析这些机制如何平衡计算效率与鲁棒性。

Result: 发现习语处理具有独特的计算模式，包括频繁激活的特定注意力头（Idiom Heads）和因早期处理导致的增强注意力（augmented reception）。

Conclusion: 这些发现揭示了Transformer模型处理非组合性语言的机制，并为理解更复杂语法结构的处理提供了新思路。

Abstract: We investigate the processing of idiomatic expressions in transformer-based language models using a novel set of techniques for circuit discovery and analysis. First discovering circuits via a modified path patching algorithm, we find that idiom processing exhibits distinct computational patterns. We identify and investigate ``Idiom Heads,'' attention heads that frequently activate across different idioms, as well as enhanced attention between idiom tokens due to earlier processing, which we term ``augmented reception.'' We analyze these phenomena and the general features of the discovered circuits as mechanisms by which transformers balance computational efficiency and robustness. Finally, these findings provide insights into how transformers handle non-compositional language and suggest pathways for understanding the processing of more complex grammatical constructions.

</details>


### [16] [Arctic-Extract Technical Report](https://arxiv.org/abs/2511.16470)
*Mateusz Chiliński,Julita Ołtusek,Wojciech Jaśkowski*

Main category: cs.CL

TL;DR: Arctic-Extract 是一个先进的模型，用于从扫描或数字生成的商业文档中提取结构化数据（如问答、实体和表格）。


<details>
  <summary>Details</summary>
Motivation: 设计一个即使在资源受限的硬件上也能部署和运行的高效模型，用于商业文档的数据提取。

Method: 提出 Arctic-Extract 模型，并强调其训练协议和评估结果。

Result: 该模型大小为6.6 GiB，可在24 GB内存的A10 GPU上处理多达125页A4文档。

Conclusion: Arctic-Extract 在文档理解方面表现出强大的性能，适用于资源受限的设备上的长文档处理。

Abstract: Arctic-Extract is a state-of-the-art model designed for extracting structural data (question answering, entities and tables) from scanned or digital-born business documents. Despite its SoTA capabilities, the model is deployable on resource-constrained hardware, weighting only 6.6 GiB, making it suitable for deployment on devices with limited resources, such as A10 GPUs with 24 GB of memory. Arctic-Extract can process up to 125 A4 pages on those GPUs, making suitable for long document processing. This paper highlights Arctic-Extract's training protocols and evaluation results, demonstrating its strong performance in document understanding.

</details>


### [17] [TurkColBERT: A Benchmark of Dense and Late-Interaction Models for Turkish Information Retrieval](https://arxiv.org/abs/2511.16528)
*Özay Ezerceli,Mahmoud El Hussieni,Selva Taş,Reyhan Bayraktar,Fatma Betül Terzioğlu,Yusuf Çelebi,Yağız Asker*

Main category: cs.CL

TL;DR: 本文首次系统评估了晚期交互模型在土耳其语信息检索中的表现，提出了TurkColBERT基准，显示小参数晚期交互模型可超越大型稠密编码器。


<details>
  <summary>Details</summary>
Motivation: 现有神经信息检索在高资源语言表现优异，但土耳其语等形态丰富、低资源语言研究不足；晚期交互模型未被系统评估。

Method: 采用两阶段适配流程：先在土耳其语NLI/STS任务上微调英语和多语言编码器，再用PyLate转换为ColBERT风格检索器；评估10个模型在5个土耳其语BEIR数据集上的表现，并比较不同索引算法。

Result: 晚期交互模型参数效率高，colbert-hash-nano-tr（1.0M参数）比turkish-e5-large（600M参数）小600倍但保留其71%的mAP；ColmmBERT-base-TR在领域特定任务上mAP提升达13.8%；MUVERA+Rerank比PLAID快3.33倍且mAP提升1.7%。

Conclusion: 晚期交互模型在土耳其语检索中显著优于稠密编码器，尤其在小参数场景下；MUVERA索引算法更适合生产环境。局限性是数据集规模较小且依赖翻译基准，大规模评估仍需进一步研究。

Abstract: Neural information retrieval systems excel in high-resource languages but remain underexplored for morphologically rich, lower-resource languages such as Turkish. Dense bi-encoders currently dominate Turkish IR, yet late-interaction models -- which retain token-level representations for fine-grained matching -- have not been systematically evaluated. We introduce TurkColBERT, the first comprehensive benchmark comparing dense encoders and late-interaction models for Turkish retrieval. Our two-stage adaptation pipeline fine-tunes English and multilingual encoders on Turkish NLI/STS tasks, then converts them into ColBERT-style retrievers using PyLate trained on MS MARCO-TR. We evaluate 10 models across five Turkish BEIR datasets covering scientific, financial, and argumentative domains. Results show strong parameter efficiency: the 1.0M-parameter colbert-hash-nano-tr is 600$\times$ smaller than the 600M turkish-e5-large dense encoder while preserving over 71\% of its average mAP. Late-interaction models that are 3--5$\times$ smaller than dense encoders significantly outperform them; ColmmBERT-base-TR yields up to +13.8\% mAP on domain-specific tasks. For production-readiness, we compare indexing algorithms: MUVERA+Rerank is 3.33$\times$ faster than PLAID and offers +1.7\% relative mAP gain. This enables low-latency retrieval, with ColmmBERT-base-TR achieving 0.54 ms query times under MUVERA. We release all checkpoints, configs, and evaluation scripts. Limitations include reliance on moderately sized datasets ($\leq$50K documents) and translated benchmarks, which may not fully reflect real-world Turkish retrieval conditions; larger-scale MUVERA evaluations remain necessary.

</details>


### [18] [Beyond Tokens in Language Models: Interpreting Activations through Text Genre Chunks](https://arxiv.org/abs/2511.16540)
*Éloïse Benito-Rodriguez,Einar Urdshals,Jasmina Nasufi,Nicky Pochinkov*

Main category: cs.CL

TL;DR: 提出了一种基于LLM激活的文本类型预测框架。


<details>
  <summary>Details</summary>
Motivation: 理解大型语言模型（LLM）的安全和有益部署是关键的，但模型结构的解释性困难和输出难以全部人工评估使得这一任务复杂化。

Method: 使用Mistral-7B和两个数据集，通过scikit-learn分类器预测提示文本的类型。

Result: 在一个数据集上F1分数最高达98%，在另一个数据集上为71%，且结果始终优于控制任务。

Conclusion: 文本类型可以从LLM中通过浅层学习模型推断出来。

Abstract: Understanding Large Language Models (LLMs) is key to ensure their safe and beneficial deployment. This task is complicated by the difficulty of interpretability of LLM structures, and the inability to have all their outputs human-evaluated. In this paper, we present the first step towards a predictive framework, where the genre of a text used to prompt an LLM, is predicted based on its activations. Using Mistral-7B and two datasets, we show that genre can be extracted with F1-scores of up to 98% and 71% using scikit-learn classifiers. Across both datasets, results consistently outperform the control task, providing a proof of concept that text genres can be inferred from LLMs with shallow learning models.

</details>


### [19] [WER is Unaware: Assessing How ASR Errors Distort Clinical Understanding in Patient Facing Dialogue](https://arxiv.org/abs/2511.16544)
*Zachary Ellis,Jared Joselowitz,Yash Deo,Yajie He,Anna Kalygina,Aisling Higham,Mana Rahimzadeh,Yan Jia,Ibrahim Habli,Ernest Lim*

Main category: cs.CL

TL;DR: 本文挑战了临床对话ASR评估中对WER的依赖，发现WER等现有指标与临床影响相关性弱，并提出了基于LLM的自动化评估框架（Gemini-2.5-Pro），能更准确评估转录错误对临床安全的影响。


<details>
  <summary>Details</summary>
Motivation: 随着ASR在临床对话中的广泛应用，现有基于WER等文本保真度的评估标准无法有效衡量转录错误的临床影响，亟需与临床风险相关联的评估方法。

Method: 1) 构建由临床专家标注的双数据集金标准，量化转录差异的临床影响（无/轻微/显著）；2) 对比WER等现有指标与临床风险标注的相关性；3) 提出GEPA优化的LLM-as-a-Judge框架（Gemini-2.5-Pro）模拟专家评估。

Result: WER等指标与临床风险标注相关性差；优化后的LLM法官达到90%准确率和0.816的Cohen's κ系数，性能接近人类专家。

Conclusion: 该工作提供了首个临床ASR安全评估的自动化框架，推动评估标准从文本保真度转向临床安全性，具有可扩展性和实践价值。

Abstract: As Automatic Speech Recognition (ASR) is increasingly deployed in clinical dialogue, standard evaluations still rely heavily on Word Error Rate (WER). This paper challenges that standard, investigating whether WER or other common metrics correlate with the clinical impact of transcription errors. We establish a gold-standard benchmark by having expert clinicians compare ground-truth utterances to their ASR-generated counterparts, labeling the clinical impact of any discrepancies found in two distinct doctor-patient dialogue datasets. Our analysis reveals that WER and a comprehensive suite of existing metrics correlate poorly with the clinician-assigned risk labels (No, Minimal, or Significant Impact). To bridge this evaluation gap, we introduce an LLM-as-a-Judge, programmatically optimized using GEPA to replicate expert clinical assessment. The optimized judge (Gemini-2.5-Pro) achieves human-comparable performance, obtaining 90% accuracy and a strong Cohen's $κ$ of 0.816. This work provides a validated, automated framework for moving ASR evaluation beyond simple textual fidelity to a necessary, scalable assessment of safety in clinical dialogue.

</details>


### [20] [Integrating Symbolic Natural Language Understanding and Language Models for Word Sense Disambiguation](https://arxiv.org/abs/2511.16577)
*Kexin Zhao,Ken Forbus*

Main category: cs.CL

TL;DR: 提出了一种无需手工标注训练数据的统计语言模型方法，用于解决词义消歧问题。


<details>
  <summary>Details</summary>
Motivation: 当前方法主要针对粗粒度表示，且需要手工标注训练数据，难以自动进行更丰富表示的消歧，这限制了其应用于复杂推理。

Method: 使用统计语言模型作为‘神谕’进行消歧，将符号自然语言理解系统生成的多个候选意义转换为可区分的自然语言选项，并用其查询LLM以选择合适的解释。

Result: 通过与人工标注的标准答案进行评估，验证了该方法的有效性。

Conclusion: 该方法无需手工标注数据，可以有效地用于复杂推理所需的丰富表示的词义消歧。

Abstract: Word sense disambiguation is a fundamental challenge in natural language understanding. Current methods are primarily aimed at coarse-grained representations (e.g. WordNet synsets or FrameNet frames) and require hand-annotated training data to construct. This makes it difficult to automatically disambiguate richer representations (e.g. built on OpenCyc) that are needed for sophisticated inference. We propose a method that uses statistical language models as oracles for disambiguation that does not require any hand-annotation of training data. Instead, the multiple candidate meanings generated by a symbolic NLU system are converted into distinguishable natural language alternatives, which are used to query an LLM to select appropriate interpretations given the linguistic context. The selected meanings are propagated back to the symbolic NLU system. We evaluate our method against human-annotated gold answers to demonstrate its effectiveness.

</details>


### [21] [Comparison of Text-Based and Image-Based Retrieval in Multimodal Retrieval Augmented Generation Large Language Model Systems](https://arxiv.org/abs/2511.16654)
*Elias Lumer,Alex Cardenas,Matt Melich,Myles Mason,Sara Dieter,Vamse Kumar Subbiah,Pradeep Honaganahalli Basavaraju,Roberto Hernandez*

Main category: cs.CL

TL;DR: 本文分析了两种多模态RAG系统的检索方法，发现直接多模态嵌入检索在保留视觉信息方面优于基于LLM摘要的文本检索。


<details>
  <summary>Details</summary>
Motivation: 当前多模态RAG系统仅存储文本表示，导致重要的上下文信息和视觉细节丢失，影响了下游任务的表现。

Method: 比较了文本块检索（图像转为文本后嵌入）与直接多模态嵌入检索（图像原生存储在向量空间），在6个LLM和2个多模态嵌入模型上进行评估。

Result: 直接多模态嵌入检索在mAP@5和nDCG@5上分别提高了13%和11%，相对提升32%和20%，并且生成的答案更准确、一致。

Conclusion: 直接多模态嵌入检索能更好地保留视觉上下文，减少信息丢失，提高检索和问答的性能。

Abstract: Recent advancements in Retrieval-Augmented Generation (RAG) have enabled Large Language Models (LLMs) to access multimodal knowledge bases containing both text and visual information such as charts, diagrams, and tables in financial documents. However, existing multimodal RAG systems rely on LLM-based summarization to convert images into text during preprocessing, storing only text representations in vector databases, which causes loss of contextual information and visual details critical for downstream retrieval and question answering. To address this limitation, we present a comprehensive comparative analysis of two retrieval approaches for multimodal RAG systems, including text-based chunk retrieval (where images are summarized into text before embedding) and direct multimodal embedding retrieval (where images are stored natively in the vector space). We evaluate all three approaches across 6 LLM models and a two multi-modal embedding models on a newly created financial earnings call benchmark comprising 40 question-answer pairs, each paired with 2 documents (1 image and 1 text chunk). Experimental results demonstrate that direct multimodal embedding retrieval significantly outperforms LLM-summary-based approaches, achieving absolute improvements of 13% in mean average precision (mAP@5) and 11% in normalized discounted cumulative gain. These gains correspond to relative improvements of 32% in mAP@5 and 20% in nDCG@5, providing stronger evidence of their practical impact. We additionally find that direct multimodal retrieval produces more accurate and factually consistent answers as measured by LLM-as-a-judge pairwise comparisons. We demonstrate that LLM summarization introduces information loss during preprocessing, whereas direct multimodal embeddings preserve visual context for retrieval and inference.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [22] [Majority Rules: LLM Ensemble is a Winning Approach for Content Categorization](https://arxiv.org/abs/2511.15714)
*Ariel Kamen,Yakov Kamen*

Main category: cs.AI

TL;DR: 该研究引入了一种集成框架（eLLM），用于使用大型语言模型（LLMs）进行非结构化文本分类，通过整合多个模型，解决了单个系统的常见问题，显著提高了性能。


<details>
  <summary>Details</summary>
Motivation: 解决单一大型语言模型在文本分类中常见的不一致性、幻觉、类别膨胀和错误分类等弱点。

Method: 引入集成大型语言模型（eLLM）框架，通过数学模型形式化集成过程，并使用交互式广告局（IAB）层次分类法，在相同零样本条件下评估十种先进的LLMs。

Result: eLLM方法在F1分数上比最强单一模型提升了65%，并实现了接近人类专家水平的性能。

Conclusion: eLLM通过多样化模型组合，提升了分类的稳健性和准确性，为基于分类法的文本分类提供了可扩展且可靠的解决方案，可能显著减少对人类专家标注的依赖。

Abstract: This study introduces an ensemble framework for unstructured text categorization using large language models (LLMs). By integrating multiple models, the ensemble large language model (eLLM) framework addresses common weaknesses of individual systems, including inconsistency, hallucination, category inflation, and misclassification. The eLLM approach yields a substantial performance improvement of up to 65\% in F1-score over the strongest single model. We formalize the ensemble process through a mathematical model of collective decision-making and establish principled aggregation criteria. Using the Interactive Advertising Bureau (IAB) hierarchical taxonomy, we evaluate ten state-of-the-art LLMs under identical zero-shot conditions on a human-annotated corpus of 8{,}660 samples. Results show that individual models plateau in performance due to the compression of semantically rich text into sparse categorical representations, while eLLM improves both robustness and accuracy. With a diverse consortium of models, eLLM achieves near human-expert-level performance, offering a scalable and reliable solution for taxonomy-based classification that may significantly reduce dependence on human expert labeling.

</details>


### [23] [Graph-Memoized Reasoning: Foundations Structured Workflow Reuse in Intelligent Systems](https://arxiv.org/abs/2511.15715)
*Yash Raj Singh*

Main category: cs.AI

TL;DR: 提出图记忆推理框架，通过存储和重用图结构推理流程提升大模型的推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有大模型推理系统重复计算相似步骤，导致资源浪费、延迟高和不可复现，需建立可复用历史推理路径的持久化机制。

Method: 构建Graph-Memoized Reasoning框架，将推理流程编码为图结构记忆，通过结构和语义相似性检索复用子图；建立最小化推理成本的优化目标。

Result: 提出理论框架和评估协议，支持跨任务推理子图复用，平衡效率与一致性。

Conclusion: 该框架为构建可解释、低成本、自改进的推理架构奠定基础，推动大模型智能体持久记忆能力发展。

Abstract: Modern large language model-based reasoning systems frequently recompute similar reasoning steps across tasks, wasting computational resources, inflating inference latency, and limiting reproducibility. These inefficiencies underscore the need for persistent reasoning mechanisms that can recall and reuse prior computational traces.
  We introduce Graph-Memoized Reasoning, a formal framework for representing, storing, and reusing reasoning workflows as graph-structured memory. By encoding past decision graphs and retrieving them through structural and semantic similarity, our approach enables compositional reuse of subgraphs across new reasoning tasks.
  We formulate an optimization objective that minimizes total reasoning cost regularized by inconsistency between stored and generated workflows, providing a theoretical foundation for efficiency-consistency trade-offs in intelligent systems. We outline a conceptual evaluation protocol aligned with the proposed optimization objective.
  This framework establishes the groundwork for interpretable, cost-efficient, and self-improving reasoning architectures, offering a step toward persistent memory in large-scale agentic systems.

</details>


### [24] [MACIE: Multi-Agent Causal Intelligence Explainer for Collective Behavior Understanding](https://arxiv.org/abs/2511.15716)
*Abraham Itzhak Weinberg*

Main category: cs.AI

TL;DR: 提出了一种用于多智能体强化学习系统的解释框架MACIE，结合结构因果模型、干预性反事实和Shapley值，以解决现有方法无法有效解释集体行为归因、量化涌现行为及捕捉复杂互动的问题。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习系统在安全关键应用中的决策原因和集体行为理解至关重要，但现有AI解释方法在多智能体环境中效果不佳。

Method: MACIE框架整合了结构因果模型、干预性反事实和Shapley值，提出三种解释：个体智能体的因果贡献、系统级涌现智能的协同指标、以及自然语言叙事的可操作解释。

Result: 在四个MARL场景中，MACIE准确归因结果（平均phi_i=5.07，标准差<0.05），检测到合作任务中的正涌现（协同指数达0.461），并在CPU上每数据集仅需0.79秒。

Conclusion: MACIE独特地结合因果严谨性、涌现量化和多智能体支持，为实时可解释、可信赖及可问责的多智能体AI提供实用框架。

Abstract: As Multi Agent Reinforcement Learning systems are used in safety critical applications. Understanding why agents make decisions and how they achieve collective behavior is crucial. Existing explainable AI methods struggle in multi agent settings. They fail to attribute collective outcomes to individuals, quantify emergent behaviors, or capture complex interactions. We present MACIE Multi Agent Causal Intelligence Explainer, a framework combining structural causal models, interventional counterfactuals, and Shapley values to provide comprehensive explanations. MACIE addresses three questions. First, each agent's causal contribution using interventional attribution scores. Second, system level emergent intelligence through synergy metrics separating collective effects from individual contributions. Third, actionable explanations using natural language narratives synthesizing causal insights. We evaluate MACIE across four MARL scenarios: cooperative, competitive, and mixed motive. Results show accurate outcome attribution, mean phi_i equals 5.07, standard deviation less than 0.05, detection of positive emergence in cooperative tasks, synergy index up to 0.461, and efficient computation, 0.79 seconds per dataset on CPU. MACIE uniquely combines causal rigor, emergence quantification, and multi agent support while remaining practical for real time use. This represents a step toward interpretable, trustworthy, and accountable multi agent AI.

</details>


### [25] [How Modality Shapes Perception and Reasoning: A Study of Error Propagation in ARC-AGI](https://arxiv.org/abs/2511.15717)
*Bo Wen,Chen Wang,Erhan Bilal*

Main category: cs.AI

TL;DR: 本文探讨了不同模态（文本和图像）在ARC-AGI任务中如何影响模型感知，提出结合文本和图像能提升执行效果。


<details>
  <summary>Details</summary>
Motivation: 当前指令优先系统在将网格翻译为自然语言或DSL规则时缺乏对编码如何影响模型感知的深入理解，且难以区分指令错误和执行错误。

Method: 通过在九种文本和图像模态中使用加权集合不一致度量和两阶段推理管道，分离感知与推理。

Result: 结构化文本在稀疏特征上提供精确坐标，图像捕捉2D形状但对分辨率敏感，二者结合提升了执行效果（约8个感知点；约0.20中位数相似度）。

Conclusion: 与Transformer归纳偏差对齐并结合文本和图像的表示，可以在不改变基础模型的情况下提高指令准确性和执行可靠性。

Abstract: ARC-AGI and ARC-AGI-2 measure generalization-through-composition on small color-quantized grids, and their prize competitions make progress on these harder held-out tasks a meaningful proxy for systematic generalization. Recent instruction-first systems translate grids into concise natural-language or DSL rules executed in generate-execute-select loops, yet we lack a principled account of how encodings shape model perception and how to separate instruction errors from execution errors. We hypothesize that modality imposes perceptual bottlenecks -- text flattens 2D structure into 1D tokens while images preserve layout but can introduce patch-size aliasing -- thereby shaping which grid features are reliably perceived. To test this, we isolate perception from reasoning across nine text and image modalities using a weighted set-disagreement metric and a two-stage reasoning pipeline, finding that structured text yields precise coordinates on sparse features, images capture 2D shapes yet are resolution-sensitive, and combining them improves execution (about 8 perception points; about 0.20 median similarity). Overall, aligning representations with transformer inductive biases and enabling cross-validation between text and image yields more accurate instructions and more reliable execution without changing the underlying model.

</details>


### [26] [Automated Hazard Detection in Construction Sites Using Large Language and Vision-Language Models](https://arxiv.org/abs/2511.15720)
*Islem Sahraoui*

Main category: cs.AI

TL;DR: 本文提出了一种多模态AI框架，通过结合文本和图像分析来增强建筑工地的安全性。


<details>
  <summary>Details</summary>
Motivation: 在建筑工地等安全关键环境中，事故数据通常以多种格式存在，传统方法难以综合识别危险。

Method: 提出的多模态AI框架结合了文本和图像分析，利用大型语言模型（LLMs）和视觉语言模型（VLMs）进行自动危险识别，通过两个案例研究评估其能力。

Result: 第一个案例研究使用GPT 4o和GPT 4o mini从28,000份OSHA事故报告中提取结构化信息；第二个案例研究使用Molmo 7B和Qwen2 VL 2B在ConstructionSite10k数据集上进行安全违规检测，结果显示轻量级开源模型在特定配置下表现优异。

Conclusion: 尽管Molmo 7B和Qwen2 VL 2B模型较小，但在某些提示配置下表现出有竞争力的性能，证明了低资源多模态系统在安全监控中的可行性。

Abstract: This thesis explores a multimodal AI framework for enhancing construction safety through the combined analysis of textual and visual data. In safety-critical environments such as construction sites, accident data often exists in multiple formats, such as written reports, inspection records, and site imagery, making it challenging to synthesize hazards using traditional approaches. To address this, this thesis proposed a multimodal AI framework that combines text and image analysis to assist in identifying safety hazards on construction sites. Two case studies were consucted to evaluate the capabilities of large language models (LLMs) and vision-language models (VLMs) for automated hazard identification.The first case study introduces a hybrid pipeline that utilizes GPT 4o and GPT 4o mini to extract structured insights from a dataset of 28,000 OSHA accident reports (2000-2025). The second case study extends this investigation using Molmo 7B and Qwen2 VL 2B, lightweight, open-source VLMs. Using the public ConstructionSite10k dataset, the performance of the two models was evaluated on rule-level safety violation detection using natural language prompts. This experiment served as a cost-aware benchmark against proprietary models and allowed testing at scale with ground-truth labels. Despite their smaller size, Molmo 7B and Quen2 VL 2B showed competitive performance in certain prompt configurations, reinforcing the feasibility of low-resource multimodal systems for rule-aware safety monitoring.

</details>


### [27] [Spatial Reasoning in Multimodal Large Language Models: A Survey of Tasks, Benchmarks and Methods](https://arxiv.org/abs/2511.15722)
*Weichen Liu,Qiyao Xue,Haoming Wang,Xiangyu Yin,Boyuan Yang,Wei Gao*

Main category: cs.AI

TL;DR: 这篇论文提出了一个新的分类法，从认知角度组织空间智能，并根据推理复杂性划分任务，以解决多模态大型语言模型（MLLMs）在空间推理方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 空间推理是人类智能的基本方面，但对MLLMs来说仍然是一个持续的挑战。现有的调查通常根据输入模态对最新进展进行分类，但空间能力并不仅仅由输入格式决定。

Method: 引入了一个从认知角度组织空间智能的分类法，并根据推理复杂性划分任务，将这些任务与几种认知功能联系起来。将现有的文本、视觉语言和具身设置中的基准映射到这个分类法上，并回顾了评估空间推理能力的方法和方法学。

Result: 通过认知视角，实现了更有原则的跨任务比较，揭示了当前模型能力与人类推理之间的关键差距。此外，分析了训练和推理两种方法在提高空间能力方面的各自优势，揭示了互补机制。

Conclusion: 通过调查任务、基准和最新进展，旨在为新研究人员提供该领域的全面理解，并为未来的研究提供可操作的方向。

Abstract: Spatial reasoning, which requires ability to perceive and manipulate spatial relationships in the 3D world, is a fundamental aspect of human intelligence, yet remains a persistent challenge for Multimodal large language models (MLLMs). While existing surveys often categorize recent progress based on input modality (e.g., text, image, video, or 3D), we argue that spatial ability is not solely determined by the input format. Instead, our survey introduces a taxonomy that organizes spatial intelligence from cognitive aspect and divides tasks in terms of reasoning complexity, linking them to several cognitive functions. We map existing benchmarks across text only, vision language, and embodied settings onto this taxonomy, and review evaluation metrics and methodologies for assessing spatial reasoning ability. This cognitive perspective enables more principled cross-task comparisons and reveals critical gaps between current model capabilities and human-like reasoning. In addition, we analyze methods for improving spatial ability, spanning both training-based and reasoning-based approaches. This dual perspective analysis clarifies their respective strengths, uncovers complementary mechanisms. By surveying tasks, benchmarks, and recent advances, we aim to provide new researchers with a comprehensive understanding of the field and actionable directions for future research.

</details>


### [28] [Uncertainty-Resilient Multimodal Learning via Consistency-Guided Cross-Modal Transfer](https://arxiv.org/abs/2511.15741)
*Hyo-Jeong Jang*

Main category: cs.AI

TL;DR: 本文提出了一种通过一致性引导的跨模态转移来应对多模态学习系统中的不确定性问题的方法。


<details>
  <summary>Details</summary>
Motivation: 多模态学习系统面临噪声数据、低质量标签和异质模态特性等问题，尤其在人机交互环境中，这些问题变得尤为关键。

Method: 通过将异质模态投射到共享的潜在空间，利用跨模态语义一致性进行鲁棒的表示学习，并探讨增强语义鲁棒性和数据效率的策略。

Result: 在情感识别基准测试中，一致性引导的跨模态转移显著提高了模型的稳定性、判别能力和对噪声或不完整监督的鲁棒性。

Conclusion: 该论文通过整合不确定性建模、语义对齐和数据高效监督，为开发可靠和自适应的脑机接口系统提供了一个统一的视角和实用见解。

Abstract: Multimodal learning systems often face substantial uncertainty due to noisy data, low-quality labels, and heterogeneous modality characteristics. These issues become especially critical in human-computer interaction settings, where data quality, semantic reliability, and annotation consistency vary across users and recording conditions. This thesis tackles these challenges by exploring uncertainty-resilient multimodal learning through consistency-guided cross-modal transfer. The central idea is to use cross-modal semantic consistency as a basis for robust representation learning. By projecting heterogeneous modalities into a shared latent space, the proposed framework mitigates modality gaps and uncovers structural relations that support uncertainty estimation and stable feature learning. Building on this foundation, the thesis investigates strategies to enhance semantic robustness, improve data efficiency, and reduce the impact of noise and imperfect supervision without relying on large, high-quality annotations. Experiments on multimodal affect-recognition benchmarks demonstrate that consistency-guided cross-modal transfer significantly improves model stability, discriminative ability, and robustness to noisy or incomplete supervision. Latent space analyses further show that the framework captures reliable cross-modal structure even under challenging conditions. Overall, this thesis offers a unified perspective on resilient multimodal learning by integrating uncertainty modeling, semantic alignment, and data-efficient supervision, providing practical insights for developing reliable and adaptive brain-computer interface systems.

</details>


### [29] [Identifying the Supply Chain of AI for Trustworthiness and Risk Management in Critical Applications](https://arxiv.org/abs/2511.15763)
*Raymond K. Sheh,Karen Geappen*

Main category: cs.AI

TL;DR: 本文关注AI供应链风险，提出了一种分类法，帮助各组织系统评估和管理AI在关键应用中的风险。


<details>
  <summary>Details</summary>
Motivation: AI在关键应用（如食品供应、医疗、法律等）中的风险引起了广泛关注，但目前缺乏针对AI供应链风险的系统性评估方法。

Method: 调查现有的AI风险评估和管理状况，提出了一个专门用于分类AI供应链实体的分类法。

Result: 该分类法帮助没有广泛AI专业知识的利益相关者系统性地盘点其AI系统的依赖关系。

Conclusion: 本文的贡献在于填补了当前AI治理与关键应用中AI使用的可行动风险评估和管理之间的空白。

Abstract: Risks associated with the use of AI, ranging from algorithmic bias to model hallucinations, have received much attention and extensive research across the AI community, from researchers to end-users. However, a gap exists in the systematic assessment of supply chain risks associated with the complex web of data sources, pre-trained models, agents, services, and other systems that contribute to the output of modern AI systems. This gap is particularly problematic when AI systems are used in critical applications, such as the food supply, healthcare, utilities, law, insurance, and transport.
  We survey the current state of AI risk assessment and management, with a focus on the supply chain of AI and risks relating to the behavior and outputs of the AI system. We then present a proposed taxonomy specifically for categorizing AI supply chain entities. This taxonomy helps stakeholders, especially those without extensive AI expertise, to "consider the right questions" and systematically inventory dependencies across their organization's AI systems. Our contribution bridges a gap between the current state of AI governance and the urgent need for actionable risk assessment and management of AI use in critical applications.

</details>


### [30] [Balancing Natural Language Processing Accuracy and Normalisation in Extracting Medical Insights](https://arxiv.org/abs/2511.15778)
*Paulina Tworek,Miłosz Bargieł,Yousef Khan,Tomasz Pełech-Pilichowski,Marek Mikołajczyk,Roman Lewandowski,Jose Sousa*

Main category: cs.AI

TL;DR: 该研究比较了基于规则的低计算量NLP方法和大型语言模型（LLMs）从波兰电子健康记录中提取信息的性能，强调了混合方法在临床NLP中的潜力。


<details>
  <summary>Details</summary>
Motivation: 从非英语临床文本中提取结构化医学见解是一个挑战，尤其是在资源有限的情况下。该研究旨在评估不同NLP方法在信息提取任务中的表现。

Method: 研究使用了基于规则的方法和LLMs，从波兰的电子健康记录中提取患者人口统计信息、临床表现和处方药物，并评估了文本未标准化和翻译导致信息损失的影响。

Result: 基于规则的方法在信息检索任务中准确率更高，尤其是在年龄和性别提取方面；而LLMs在药物名称识别方面表现更好。

Conclusion: 研究建议采用混合方法，结合基于规则系统的精确性和LLMs的适应性，以实现更可靠和资源高效的临床NLP。

Abstract: Extracting structured medical insights from unstructured clinical text using Natural Language Processing (NLP) remains an open challenge in healthcare, particularly in non-English contexts where resources are scarce. This study presents a comparative analysis of NLP low-compute rule-based methods and Large Language Models (LLMs) for information extraction from electronic health records (EHR) obtained from the Voivodeship Rehabilitation Hospital for Children in Ameryka, Poland. We evaluate both approaches by extracting patient demographics, clinical findings, and prescribed medications while examining the effects of lack of text normalisation and translation-induced information loss. Results demonstrate that rule-based methods provide higher accuracy in information retrieval tasks, particularly for age and sex extraction. However, LLMs offer greater adaptability and scalability, excelling in drug name recognition. The effectiveness of the LLMs was compared with texts originally in Polish and those translated into English, assessing the impact of translation. These findings highlight the trade-offs between accuracy, normalisation, and computational cost when deploying NLP in healthcare settings. We argue for hybrid approaches that combine the precision of rule-based systems with the adaptability of LLMs, offering a practical path toward more reliable and resource-efficient clinical NLP in real-world hospitals.

</details>


### [31] [IMACT-CXR - An Interactive Multi-Agent Conversational Tutoring System for Chest X-Ray Interpretation](https://arxiv.org/abs/2511.15825)
*Tuan-Anh Le,Anh Mai Vu,David Yang,Akash Awasthi,Hien Van Nguyen*

Main category: cs.AI

TL;DR: IMACT-CXR是一个基于AutoGen的多智能体交互式导师系统，旨在通过整合空间标注、视线分析、知识检索和图像推理帮助学员解读胸部X光片。


<details>
  <summary>Details</summary>
Motivation: 该系统旨在提升学员在胸部X光解读中的定位和诊断推理能力，通过多模态输入和智能体协作提供个性化指导。

Method: IMACT-CXR通过多智能体系统处理用户输入的边界框、视线样本和自由文本，利用专门智能体进行定位质量评估、苏格拉底式辅导、证据检索和案例推荐，并结合贝叶斯知识追踪（BKT）来估计技能掌握程度，以驱动知识强化和案例相似性检索。

Result: 初步评估显示，IMACT-CXR在定位和诊断推理方面优于基线系统，并展示了响应式辅导流程、答案泄露的精确控制，以及向实际住院医师部署的可扩展性。

Conclusion: IMACT-CXR通过集成多种技术和模块，为学员提供了一个高效、响应式的胸部X光解读训练系统，具有良好的应用前景。

Abstract: IMACT-CXR is an interactive multi-agent conversational tutor that helps trainees interpret chest X-rays by unifying spatial annotation, gaze analysis, knowledge retrieval, and image-grounded reasoning in a single AutoGen-based workflow. The tutor simultaneously ingests learner bounding boxes, gaze samples, and free-text observations. Specialized agents evaluate localization quality, generate Socratic coaching, retrieve PubMed evidence, suggest similar cases from REFLACX, and trigger NV-Reason-CXR-3B for vision-language reasoning when mastery remains low or the learner explicitly asks. Bayesian Knowledge Tracing (BKT) maintains skill-specific mastery estimates that drive both knowledge reinforcement and case similarity retrieval. A lung-lobe segmentation module derived from a TensorFlow U-Net enables anatomically aware gaze feedback, and safety prompts prevent premature disclosure of ground-truth labels. We describe the system architecture, implementation highlights, and integration with the REFLACX dataset for real DICOM cases. IMACT-CXR demonstrates responsive tutoring flows with bounded latency, precise control over answer leakage, and extensibility toward live residency deployment. Preliminary evaluation shows improved localization and diagnostic reasoning compared to baselines.

</details>


### [32] [Step-Audio-R1 Technical Report](https://arxiv.org/abs/2511.15848)
*Fei Tian,Xiangyu Tony Zhang,Yuxin Zhang,Haoyang Zhang,Yuxin Li,Daijiao Liu,Yayue Deng,Donghang Wu,Jun Chen,Liang Zhao,Chengyuan Yao,Hexin Liu,Eng Siong Chng,Xuerui Yang,Xiangyu Zhang,Daxin Jiang,Gang Yu*

Main category: cs.AI

TL;DR: Step-Audio-R1是首个成功解锁音频领域推理能力的模型，通过MGRD框架实现了音频相关推理链的生成。


<details>
  <summary>Details</summary>
Motivation: 解决音频语言模型在推理任务上表现不佳的问题，探索音频智能是否能够通过深度思考获益。

Method: 提出Modality-Grounded Reasoning Distillation (MGRD)框架，使模型生成基于音频特征的推理链。

Result: Step-Audio-R1在多个音频理解和推理基准测试中超越了Gemini 2.5 Pro，性能与Gemini 3 Pro相当。

Conclusion: 推理是一种可在模态间迁移的能力，Step-Audio-R1为构建真正的多模态推理系统开辟了新途径。

Abstract: Recent advances in reasoning models have demonstrated remarkable success in text and vision domains through extended chain-of-thought deliberation. However, a perplexing phenomenon persists in audio language models: they consistently perform better with minimal or no reasoning, raising a fundamental question - can audio intelligence truly benefit from deliberate thinking? We introduce Step-Audio-R1, the first audio reasoning model that successfully unlocks reasoning capabilities in the audio domain. Through our proposed Modality-Grounded Reasoning Distillation (MGRD) framework, Step-Audio-R1 learns to generate audio-relevant reasoning chains that genuinely ground themselves in acoustic features rather than hallucinating disconnected deliberations. Our model exhibits strong audio reasoning capabilities, surpassing Gemini 2.5 Pro and achieving performance comparable to the state-of-the-art Gemini 3 Pro across comprehensive audio understanding and reasoning benchmarks spanning speech, environmental sounds, and music. These results demonstrate that reasoning is a transferable capability across modalities when appropriately anchored, transforming extended deliberation from a liability into a powerful asset for audio intelligence. By establishing the first successful audio reasoning model, Step-Audio-R1 opens new pathways toward building truly multimodal reasoning systems that think deeply across all sensory modalities.

</details>


### [33] [Decomposing Theory of Mind: How Emotional Processing Mediates ToM Abilities in LLMs](https://arxiv.org/abs/2511.15895)
*Ivan Chulo,Ananya Joshi*

Main category: cs.AI

TL;DR: 该论文通过对比激活分析，发现大模型心智理论(ToM)能力的提升主要依赖情感处理而非分析性思维。


<details>
  <summary>Details</summary>
Motivation: 已有研究表明激活引导能显著提升大模型的ToM能力，但其内部作用机制尚不明确，因此需要分解ToM的激活模式。

Method: 采用线性探针对比分析Gemma-3-4B模型在CAA引导前后的45种认知行为激活差异，基于1000个BigToM信念场景进行评估。

Result: 情感处理相关激活显著增强(情绪感知+2.23，情绪价值+2.20)，分析性过程被抑制(提问-0.78，收敛思维-1.59)，信念归因准确率提升32.5%到46.7%。

Conclusion: 大模型展现的ToM能力本质是由情感理解驱动的，而非分析推理过程，这一发现改变了传统对机器心智理论机制的认知。

Abstract: Recent work shows activation steering substantially improves language models' Theory of Mind (ToM) (Bortoletto et al. 2024), yet the mechanisms of what changes occur internally that leads to different outputs remains unclear. We propose decomposing ToM in LLMs by comparing steered versus baseline LLMs' activations using linear probes trained on 45 cognitive actions. We applied Contrastive Activation Addition (CAA) steering to Gemma-3-4B and evaluated it on 1,000 BigToM forward belief scenarios (Gandhi et al. 2023), we find improved performance on belief attribution tasks (32.5\% to 46.7\% accuracy) is mediated by activations processing emotional content : emotion perception (+2.23), emotion valuing (+2.20), while suppressing analytical processes: questioning (-0.78), convergent thinking (-1.59). This suggests that successful ToM abilities in LLMs are mediated by emotional understanding, not analytical reasoning.

</details>


### [34] [Thinking, Faithful and Stable: Mitigating Hallucinations in LLMs](https://arxiv.org/abs/2511.15921)
*Chelsea Zou,Yiheng Yao,Basant Khalil*

Main category: cs.AI

TL;DR: 开发了一种自我纠正框架，通过细粒度不确定性信号检测和缓解大型语言模型在多步推理过程中的幻觉。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在多步推理中会产生幻觉，影响推理的可靠性和准确性。现有的方法多依赖最终答案的正确性，而不是实时检测不可靠推理。因此，需要一种能够实时检测并纠正不可靠推理的框架。

Method: 利用自我评估置信度对齐和标记级熵峰值两种细粒度不确定性信号，设计复合奖励函数惩罚不合理的高置信度和熵峰值，鼓励稳定和准确的推理轨迹。通过强化学习（RL）策略调整模型生成行为，提高中间推理步骤的连贯性和忠实度。

Result: 实验表明，该方法不仅提高了最终答案的准确性，还改善了推理校准，并通过消融实验验证了每个信号的独立贡献。

Conclusion: 所提出的自我纠正框架有效提升了大型语言模型在多步推理中的表现，特别是在推理的连贯性和忠实度方面。

Abstract: This project develops a self correcting framework for large language models (LLMs) that detects and mitigates hallucinations during multi-step reasoning. Rather than relying solely on final answer correctness, our approach leverages fine grained uncertainty signals: 1) self-assessed confidence alignment, and 2) token-level entropy spikes to detect unreliable and unfaithful reasoning in real time. We design a composite reward function that penalizes unjustified high confidence and entropy spikes, while encouraging stable and accurate reasoning trajectories. These signals guide a reinforcement learning (RL) policy that makes the model more introspective and shapes the model's generation behavior through confidence-aware reward feedback, improving not just outcome correctness but the coherence and faithfulness of their intermediate reasoning steps. Experiments show that our method improves both final answer accuracy and reasoning calibration, with ablations validating the individual contribution of each signal.

</details>


### [35] [Detecting Sleeper Agents in Large Language Models via Semantic Drift Analysis](https://arxiv.org/abs/2511.15992)
*Shahin Zanbaghi,Ryan Rostampour,Farhan Abid,Salim Al Jarmakani*

Main category: cs.AI

TL;DR: 提出了一种结合语义漂移分析和金丝雀基准比较的双方法实时检测系统，用于识别被植入后门的LLM。


<details>
  <summary>Details</summary>
Motivation: LLM可能被植入后门，在特定条件下表现出恶意行为，但现有安全训练无法消除这些后门，且缺乏实际检测方法。

Method: 使用Sentence-BERT嵌入测量语义偏差，并辅以注入的金丝雀问题监控响应一致性，实现双方法检测。

Result: 在Cadenza-Labs dolphin-llama3-8B模型上达到92.5%准确率、100%精确率（零误报）和85%召回率，每查询响应时间<1秒。

Conclusion: 该方法无需修改模型即可实时检测后门，为AI部署提供了首个实用解决方案，有效填补了AI安全的关键空白。

Abstract: Large Language Models (LLMs) can be backdoored to exhibit malicious behavior under specific deployment conditions while appearing safe during training a phenomenon known as "sleeper agents." Recent work by Hubinger et al. demonstrated that these backdoors persist through safety training, yet no practical detection methods exist. We present a novel dual-method detection system combining semantic drift analysis with canary baseline comparison to identify backdoored LLMs in real-time. Our approach uses Sentence-BERT embeddings to measure semantic deviation from safe baselines, complemented by injected canary questions that monitor response consistency. Evaluated on the official Cadenza-Labs dolphin-llama3-8B sleeper agent model, our system achieves 92.5% accuracy with 100% precision (zero false positives) and 85% recall. The combined detection method operates in real-time (<1s per query), requires no model modification, and provides the first practical solution to LLM backdoor detection. Our work addresses a critical security gap in AI deployment and demonstrates that embedding-based detection can effectively identify deceptive model behavior without sacrificing deployment efficiency.

</details>


### [36] [CARE-RAG - Clinical Assessment and Reasoning in RAG](https://arxiv.org/abs/2511.15994)
*Deepthi Potluri,Aby Mammen Mathew,Jeffrey B DeWitt,Alexander L. Rasgon,Yide Hao,Junyuan Hong,Ying Ding*

Main category: cs.AI

TL;DR: 大型语言模型（LLMs）即使在获取正确证据的情况下，也不能保证正确推理。该论文使用书写暴露疗法（WET）指南作为测试平台，提出了一种评估框架来解决检索与推理之间的差距。


<details>
  <summary>Details</summary>
Motivation: 在临床环境中，模型输出必须符合结构化协议，然而即使提供权威文本，模型推理错误仍然存在。这突显了检索与推理之间的差距，特别是在对安全和准确性要求较高的临床环境中。

Method: 使用书写暴露疗法（WET）指南作为测试平台，提出一种评估框架，评估模型推理的准确性、一致性和忠实性。

Result: 结果表明，检索增强生成（RAG）可以限制输出，但安全部署需要对推理过程进行与检索同等严格的评估。

Conclusion: 为了安全部署LLMs，尤其是在临床环境中，需要同等关注模型的推理能力与检索能力。

Abstract: Access to the right evidence does not guarantee that large language models (LLMs) will reason with it correctly. This gap between retrieval and reasoning is especially concerning in clinical settings, where outputs must align with structured protocols. We study this gap using Written Exposure Therapy (WET) guidelines as a testbed. In evaluating model responses to curated clinician-vetted questions, we find that errors persist even when authoritative passages are provided. To address this, we propose an evaluation framework that measures accuracy, consistency, and fidelity of reasoning. Our results highlight both the potential and the risks: retrieval-augmented generation (RAG) can constrain outputs, but safe deployment requires assessing reasoning as rigorously as retrieval.

</details>


### [37] [SpellForger: Prompting Custom Spell Properties In-Game using BERT supervised-trained model](https://arxiv.org/abs/2511.16018)
*Emanuel C. Silva,Emily S. M. Salum,Gabriel M. Arantes,Matheus P. Pereira,Vinicius F. Oliveira,Alessandro L. Bicho*

Main category: cs.AI

TL;DR: 本文提出了一种名为SpellForger的游戏，通过自然语言提示让玩家创造个性化法术，探索了AI作为核心游戏共创工具的潜力。


<details>
  <summary>Details</summary>
Motivation: 人工智能在游戏中的应用已显著发展，但作为核心游戏共创工具的潜力尚未被充分探索，因此作者提出了SpellForger以填补这一空白。

Method: 该系统使用监督训练的BERT模型来解释玩家的提示，将文本描述映射到多个法术预制件之一，并平衡其参数以确保游戏内的竞争性。游戏在Unity游戏引擎中开发，AI后端使用Python。

Result: 预期将提供一个功能原型，展示实时生成法术的过程，应用于具有吸引力的游戏循环中，验证AI作为直接游戏机制的可行性。

Conclusion: 该研究验证了AI作为核心游戏共创工具的潜力，通过自然语言生成法术，为玩家提供个性化和创造性的游戏体验。

Abstract: Introduction: The application of Artificial Intelligence in games has evolved significantly, allowing for dynamic content generation. However, its use as a core gameplay co-creation tool remains underexplored. Objective: This paper proposes SpellForger, a game where players create custom spells by writing natural language prompts, aiming to provide a unique experience of personalization and creativity. Methodology: The system uses a supervisedtrained BERT model to interpret player prompts. This model maps textual descriptions to one of many spell prefabs and balances their parameters (damage, cost, effects) to ensure competitive integrity. The game is developed in the Unity Game Engine, and the AI backend is in Python. Expected Results: We expect to deliver a functional prototype that demonstrates the generation of spells in real time, applied to an engaging gameplay loop, where player creativity is central to the experience, validating the use of AI as a direct gameplay mechanic.

</details>


### [38] [An Aligned Constraint Programming Model For Serial Batch Scheduling With Minimum Batch Size](https://arxiv.org/abs/2511.16045)
*Jorge A. Huertas,Pascal Van Hentenryck*

Main category: cs.AI

TL;DR: 本文提出了一种新型约束编程（CP）模型，用于串行批量（s-batch）调度问题，该模型不依赖于预定义的虚拟批次集合，而是使用关键对齐参数直接在机器上调度相同家庭作业的序列，从而产生更紧凑的公式。


<details>
  <summary>Details</summary>
Motivation: 尽管s-batch调度在避免重复设置方面取得了巨大成功，但现有的CP模型依赖预定义的虚拟批次集合，存在维度灾难和增加问题复杂性的问题。本文旨在提出一种更有效的模型，以克服这些限制。

Method: 本文提出了一种不依赖虚拟批次集合的新型CP模型，并使用关键对齐参数直接在机器上调度相同家庭作业的序列。该模型通过利用问题的结构，采用定制化的搜索阶段和增强的约束传播器推理级别来进一步改进。

Result: 在包含近五千个实例的广泛计算实验中，与文献中现有的方法（包括混合整数编程公式、禁忌搜索元启发式和CP方法）相比，所提出模型在小中型实例（最多100个作业）上表现出色，并且能够在包含最多500个作业、10个家庭和10台机器的大型实例上找到比现有方法好25%的解决方案。

Conclusion: 本文提出的新型CP模型在s-batch调度问题上表现优越，尤其是在大型实例上能够找到更优的解决方案。

Abstract: In serial batch (s-batch) scheduling, jobs from similar families are grouped into batches and processed sequentially to avoid repetitive setups that are required when processing consecutive jobs of different families. Despite its large success in scheduling, only three Constraint Programming (CP) models have been proposed for this problem considering minimum batch sizes, which is a common requirement in many practical settings, including the ion implantation area in semiconductor manufacturing. These existing CP models rely on a predefined virtual set of possible batches that suffers from the curse of dimensionality and adds complexity to the problem. This paper proposes a novel CP model that does not rely on this virtual set. Instead, it uses key alignment parameters that allow it to reason directly on the sequences of same-family jobs scheduled on the machines, resulting in a more compact formulation. This new model is further improved by exploiting the problem's structure with tailored search phases and strengthened inference levels of the constraint propagators. The extensive computational experiments on nearly five thousand instances compare the proposed models against existing methods in the literature, including mixed-integer programming formulations, tabu search meta-heuristics, and CP approaches. The results demonstrate the superiority of the proposed models on small-to-medium instances with up to 100 jobs, and their ability to find solutions up to 25\% better than the ones produces by existing methods on large-scale instances with up to 500 jobs, 10 families, and 10 machines.

</details>


### [39] [Artificial Intelligence and Accounting Research: A Framework and Agenda](https://arxiv.org/abs/2511.16055)
*Theophanis C. Stratopoulos,Victor Xiaoqi Wang*

Main category: cs.AI

TL;DR: 本文提出了一个框架，通过研究重点（会计为中心 vs AI为中心）和方法论（基于AI vs 传统方法）两个维度，对AI与会计结合的研究进行分类，并分析了生成式AI和大型语言模型如何改变研究流程。


<details>
  <summary>Details</summary>
Motivation: 人工智能，特别是生成式AI和大型语言模型，正在彻底改变会计研究，为学者创造机遇和竞争威胁。因此，有必要对现有研究进行分类并识别未来研究机会。

Method: 提出一个二维框架（研究重点和方法论），应用于IJAIS特刊论文和主流会计期刊的AI-会计研究，分析现有研究并确定研究机会。同时，分析会计研究人员如何通过战略定位和协作来利用其专业知识。

Result: 分析揭示了生成式AI如何在提高研究能力的同时加剧竞争，强调了人类判断、创造力和理论深度的重要性。

Conclusion: 这些变化要求改革博士教育，以培养比较优势，同时建立AI的流利性。

Abstract: Recent advances in artificial intelligence, particularly generative AI (GenAI) and large language models (LLMs), are fundamentally transforming accounting research, creating both opportunities and competitive threats for scholars. This paper proposes a framework that classifies AI-accounting research along two dimensions: research focus (accounting-centric versus AI-centric) and methodological approach (AI-based versus traditional methods). We apply this framework to papers from the IJAIS special issue and recent AI-accounting research published in leading accounting journals to map existing studies and identify research opportunities. Using this same framework, we analyze how accounting researchers can leverage their expertise through strategic positioning and collaboration, revealing where accounting scholars' strengths create the most value. We further examine how GenAI and LLMs transform the research process itself, comparing the capabilities of human researchers and AI agents across the entire research workflow. This analysis reveals that while GenAI democratizes certain research capabilities, it simultaneously intensifies competition by raising expectations for higher-order contributions where human judgment, creativity, and theoretical depth remain valuable. These shifts call for reforming doctoral education to cultivate comparative advantages while building AI fluency.

</details>


### [40] [A Hybrid Proactive And Predictive Framework For Edge Cloud Resource Management](https://arxiv.org/abs/2511.16075)
*Hrikshesh Kumar,Anika Garg,Anshul Gupta,Yashika Agarwal*

Main category: cs.AI

TL;DR: 提出了一种主动式云边缘工作负载资源管理框架，通过结合CNN LSTM时间序列预测和多智能体深度强化学习（DRL）实现资源优化。


<details>
  <summary>Details</summary>
Motivation: 传统静态阈值方法存在资源浪费或性能下降的问题，需要从被动响应转向主动预测。

Method: 设计混合架构：CNN LSTM预测模型嵌入DRL智能体的状态空间，使AI管理者能基于未来预测制定长期任务调度计划。

Result: 系统在成本节约、系统稳定性和应用速度方面显著优于传统方法，能同时处理多目标优化（经济、快速、可靠）。

Conclusion: 通过"预见未来"的决策机制，系统实现了更平稳的资源调度路径，解决了传统方法频繁故障切换的问题。

Abstract: Old cloud edge workload resource management is too reactive. The problem with relying on static thresholds is that we are either overspending for more resources than needed or have reduced performance because of their lack. This is why we work on proactive solutions. A framework developed for it stops reacting to the problems but starts expecting them. We design a hybrid architecture, combining two powerful tools: the CNN LSTM model for time series forecasting and an orchestrator based on multi agent Deep Reinforcement Learning In fact the novelty is in how we combine them as we embed the predictive forecast from the CNN LSTM directly into the DRL agent state space. That is what makes the AI manager smarter it sees the future, which allows it to make better decisions about a long term plan for where to run tasks That means finding that sweet spot between how much money is saved while keeping the system healthy and apps fast for users That is we have given it eyes in order to see down the road so that it does not have to lurch from one problem to another it finds a smooth path forward Our tests show our system easily beats the old methods It is great at solving tough problems like making complex decisions and juggling multiple goals at once like being cheap fast and reliable

</details>


### [41] [Multidimensional Rubric-oriented Reward Model Learning via Geometric Projection Reference Constraints](https://arxiv.org/abs/2511.16139)
*Yongnan Jin,Xurui Li,Feng Cao,Liucun Gao,Juanjuan Yao*

Main category: cs.AI

TL;DR: 本文提出了一种名为 MR-RML 的新框架，通过多维标准和几何投影参考约束来提升大型语言模型在医学领域的应用。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在医学实践中存在关键对齐挑战，包括静态评估基准与动态临床需求之间的脱节，难以适应不断变化的多源医疗标准，以及传统奖励模型无法捕捉复杂多维医疗质量指标。

Method: MR-RML 框架引入了三个创新点：(1) “维度-场景-学科”医疗标准系统，(2) 独立的多维奖励模型，(3) 几何投影参考约束，将医学认知逻辑转化为数学正则化。

Result: 在 Healthbench 基准测试中，该方法在基础模型 Qwen-32B 上实现了显著性能提升（完整子集 45%，困难子集 85%），在开源模型中达到 SOTA 水平，得分 62.7（完整子集）和 44.7（困难子集），并超越了大多数闭源模型。

Conclusion: MR-RML 框架通过整合多维标准和几何投影参考约束，显著提升了大型语言模型在医学领域的应用效果，为未来医疗AI的发展提供了新方向。

Abstract: The integration of large language models (LLMs) into medical practice holds transformative potential, yet their real-world clinical utility remains limited by critical alignment challenges: (1) a disconnect between static evaluation benchmarks and dynamic clinical cognitive needs, (2) difficulties in adapting to evolving, multi-source medical standards, and (3) the inability of conventional reward models to capture nuanced, multi-dimensional medical quality criteria. To address these gaps, we propose MR-RML (Multidimensional Rubric-oriented Reward Model Learning) via GPRC (Geometric Projection Reference Constraints), a novel alignment framework that integrates medical standards into a structured "Dimensions-Scenarios-Disciplines" matrix to guide data generation and model optimization. MR-RML introduces three core innovations: (1) a "Dimensions-Scenarios-Disciplines" medical standard system that embeds domain standards into the full training pipeline; (2) an independent multi-dimensional reward model that decomposes evaluation criteria, shifting from real-time rubric-based scoring to internalized reward modeling for improved consistency and cost-efficiency; (3) geometric projection reference constraints that transform medical cognitive logic into mathematical regularization, aligning scoring gradients with clinical reasoning and enabling synthetic data-driven training. Through extensive evaluations on the authoritative medical benchmark Healthbench, our method yields substantial performance gains over the base LLM Qwen-32B (45% on the full subset and 85% on Hard subset, respectively). It achieves a SOTA among open-source LLMs with scores of 62.7 (full subset) and 44.7 (hard subset), while also outperforming the majority of closed-source models.

</details>


### [42] [FOOTPASS: A Multi-Modal Multi-Agent Tactical Context Dataset for Play-by-Play Action Spotting in Soccer Broadcast Videos](https://arxiv.org/abs/2511.16183)
*Jeremie Ochin,Raphael Chekroun,Bogdan Stanciulescu,Sotiris Manitsaris*

Main category: cs.AI

TL;DR: 提出FOOTPASS，首个用于足球比赛的多模态、多智能体战术上下文中播放-播放动作识别的基准数据集。


<details>
  <summary>Details</summary>
Motivation: 当前动作识别方法在构建可靠的逐场数据方面仍显不足，通常仅用于辅助而非完全自动化注释。利用战术知识作为先验，可以支持基于计算机视觉的预测，从而实现更自动化和可靠的逐场数据提取。

Method: 引入FOOTPASS数据集，整合时空动作检测和多重对象追踪，利用计算机视觉任务输出和足球先验知识（包括长期战术规律性）进行球员中心动作识别。

Result: FOOTPASS数据集支持开发新的动作识别方法，这些方法可以生成可靠的逐场数据流，为数据驱动的运动分析提供重要输入。

Conclusion: FOOTPASS数据集是逐场动作识别领域的重要进展，将促进更自动化和可靠的足球数据分析方法的发展。

Abstract: Soccer video understanding has motivated the creation of datasets for tasks such as temporal action localization, spatiotemporal action detection (STAD), or multiobject tracking (MOT). The annotation of structured sequences of events (who does what, when, and where) used for soccer analytics requires a holistic approach that integrates both STAD and MOT. However, current action recognition methods remain insufficient for constructing reliable play-by-play data and are typically used to assist rather than fully automate annotation. Parallel research has advanced tactical modeling, trajectory forecasting, and performance analysis, all grounded in game-state and play-by-play data. This motivates leveraging tactical knowledge as a prior to support computer-vision-based predictions, enabling more automated and reliable extraction of play-by-play data. We introduce Footovision Play-by-Play Action Spotting in Soccer Dataset (FOOTPASS), the first benchmark for play-by-play action spotting over entire soccer matches in a multi-modal, multi-agent tactical context. It enables the development of methods for player-centric action spotting that exploit both outputs from computer-vision tasks (e.g., tracking, identification) and prior knowledge of soccer, including its tactical regularities over long time horizons, to generate reliable play-by-play data streams. These streams form an essential input for data-driven sports analytics.

</details>


### [43] [From Performance to Understanding: A Vision for Explainable Automated Algorithm Design](https://arxiv.org/abs/2511.16201)
*Niki van Stein,Anna V. Kononova,Thomas Bäck*

Main category: cs.AI

TL;DR: 本文提出将自动化与系统基准测试的理解相结合，以实现可解释的自动算法设计。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLM）在自动算法设计中进展迅速，但大多数方法缺乏解释性，无法揭示算法为何有效或各组件的重要性。

Method: 提出了一个可解释自动算法设计的三支柱框架：(i) LLM驱动的算法变体发现，(ii) 可解释基准测试，(iii) 问题类别描述符，将算法行为与问题结构连接。

Result: 形成了一个发现、解释和泛化的闭环知识体系，推动从盲目搜索到可解释、特定类别的算法设计。

Conclusion: 通过整合自动化与理解，该框架不仅加速算法设计进程，还生成可复用的科学见解，解释优化策略成功的原因和时机。

Abstract: Automated algorithm design is entering a new phase: Large Language Models can now generate full optimisation (meta)heuristics, explore vast design spaces and adapt through iterative feedback. Yet this rapid progress is largely performance-driven and opaque. Current LLM-based approaches rarely reveal why a generated algorithm works, which components matter or how design choices relate to underlying problem structures. This paper argues that the next breakthrough will come not from more automation, but from coupling automation with understanding from systematic benchmarking. We outline a vision for explainable automated algorithm design, built on three pillars: (i) LLM-driven discovery of algorithmic variants, (ii) explainable benchmarking that attributes performance to components and hyperparameters and (iii) problem-class descriptors that connect algorithm behaviour to landscape structure. Together, these elements form a closed knowledge loop in which discovery, explanation and generalisation reinforce each other. We argue that this integration will shift the field from blind search to interpretable, class-specific algorithm design, accelerating progress while producing reusable scientific insight into when and why optimisation strategies succeed.

</details>


### [44] [OpenMMReasoner: Pushing the Frontiers for Multimodal Reasoning with an Open and General Recipe](https://arxiv.org/abs/2511.16334)
*Kaichen Zhang,Keming Wu,Zuhao Yang,Kairui Hu,Bin Wang,Ziwei Liu,Xingxuan Li,Lidong Bing*

Main category: cs.AI

TL;DR: 本文介绍了OpenMMReasoner，一个用于多模态推理的透明两阶段训练方案，包含监督微调和强化学习，并开源了相关代码和数据。


<details>
  <summary>Details</summary>
Motivation: 当前多模态推理研究缺乏透明和可复现的数据和训练策略，阻碍了可扩展研究的进展。

Method: 提出两阶段训练方法：第一阶段使用874K样本的监督微调构建冷启动数据集，第二阶段通过74K样本的强化学习提升模型鲁棒性。

Result: 在九个多模态推理基准测试中，相比Qwen2.5-VL-7B-Instruct基线，实现了11.6%的性能提升。

Conclusion: 强调了数据质量和训练设计在多模态推理性能中的关键作用，为未来的大规模多模态推理研究奠定了实证基础。

Abstract: Recent advancements in large reasoning models have fueled growing interest in extending such capabilities to multimodal domains. However, despite notable progress in visual reasoning, the lack of transparent and reproducible data curation and training strategies remains a major barrier to scalable research. In this work, we introduce OpenMMReasoner, a fully transparent two-stage recipe for multimodal reasoning spanning supervised fine-tuning (SFT) and reinforcement learning (RL). In the SFT stage, we construct an 874K-sample cold-start dataset with rigorous step-by-step validation, providing a strong foundation for reasoning capabilities. The subsequent RL stage leverages a 74K-sample dataset across diverse domains to further sharpen and stabilize these abilities, resulting in a more robust and efficient learning process. Extensive evaluations demonstrate that our training recipe not only surpasses strong baselines but also highlights the critical role of data quality and training design in shaping multimodal reasoning performance. Notably, our method achieves a 11.6% improvement over the Qwen2.5-VL-7B-Instruct baseline across nine multimodal reasoning benchmarks, establishing a solid empirical foundation for future large-scale multimodal reasoning research. We open-sourced all our codes, pipeline, and data at https://github.com/EvolvingLMMs-Lab/OpenMMReasoner.

</details>


### [45] [FlipVQA-Miner: Cross-Page Visual Question-Answer Mining from Textbooks](https://arxiv.org/abs/2511.16216)
*Zhen Hao Wong,Jingwen Deng,Hao Liang,Runming He,Chengyu Shen,Wentao Zhang*

Main category: cs.AI

TL;DR: 提出了一种从教育文档中自动提取高质量QA/VQA对的流程，以解决LLM训练数据成本高和合成数据多样性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的发展需要高质量监督数据，但现有数据集成本高且多样性不足，教育材料中的QA内容未得到充分利用。

Method: 结合布局感知OCR和基于LLM的语义解析，从教育文档中提取结构良好的QA和视觉QA（VQA）对。

Result: 实验表明，该方法能生成准确、对齐且低噪声的QA/VQA对，适用于多种文档类型。

Conclusion: 该方法实现了对真实教育内容的可扩展利用，为改善LLM训练提供了实用的替代方案，避免了合成数据的局限性。

Abstract: The development of Large Language Models (LLMs) increasingly depends on high-quality supervised data, yet existing instruction-tuning and RL datasets remain costly to curate and often rely on synthetic samples that introduce hallucination and limited diversity. At the same time, textbooks and exercise materials contain abundant, high-quality human-authored Question-Answer(QA) content that remains underexploited due to the difficulty of transforming raw PDFs into AI-ready supervision. Although modern OCR and vision-language models can accurately parse document structure, their outputs lack the semantic alignment required for training. We propose an automated pipeline that extracts well-formed QA and visual-QA (VQA) pairs from educational documents by combining layout-aware OCR with LLM-based semantic parsing. Experiments across diverse document types show that the method produces accurate, aligned, and low-noise QA/VQA pairs. This approach enables scalable use of real-world educational content and provides a practical alternative to synthetic data generation for improving reasoning-oriented LLM training. All code and data-processing pipelines are open-sourced at https://github.com/OpenDCAI/DataFlow.

</details>


### [46] [TOFA: Training-Free One-Shot Federated Adaptation for Vision-Language Models](https://arxiv.org/abs/2511.16423)
*Li Zhang,Zhongxuan Han,XiaoHua Feng,Jiaming Zhang,Yuyuan Li,Linbo Jiang,Jianan Lin,Chaochao Chen*

Main category: cs.AI

TL;DR: 提出了一种无需训练的单次联邦适应框架TOFA，用于高效、轻量级地适应预训练视觉-语言模型（VLM）到下游任务。


<details>
  <summary>Details</summary>
Motivation: 现有适应算法存在通信成本高和易受攻击的问题。单次联邦训练技术减少客户端-服务器交换，因此开发轻量级单次联邦VLM适应方法具有吸引力。当前方法在利用多模态信息、处理数据异构性和需要额外训练资源方面存在挑战。

Method: TOFA采用视觉和文本管道提取任务相关表征，视觉管道使用分层贝叶斯模型学习个性化、类别特定的原型分布，文本管道评估和全局对齐本地文本提示。还引入自适应权重校准机制结合两种模态的预测。

Result: 在9个数据集上的广泛实验表明，TOFA在各种联邦设置下均有效。

Conclusion: TOFA是一种有效的、无需训练的单次联邦适应框架，能够处理数据异构性，不依赖额外的训练资源，提高了通信效率和安全性。

Abstract: Efficient and lightweight adaptation of pre-trained Vision-Language Models (VLMs) to downstream tasks through collaborative interactions between local clients and a central server is a rapidly emerging research topic in federated learning. Existing adaptation algorithms are typically trained iteratively, which incur significant communication costs and increase the susceptibility to potential attacks. Motivated by the one-shot federated training techniques that reduce client-server exchanges to a single round, developing a lightweight one-shot federated VLM adaptation method to alleviate these issues is particularly attractive. However, current one-shot approaches face certain challenges in adapting VLMs within federated settings: (1) insufficient exploitation of the rich multimodal information inherent in VLMs; (2) lack of specialized adaptation strategies to systematically handle the severe data heterogeneity; and (3) requiring additional training resource of clients or server. To bridge these gaps, we propose a novel Training-free One-shot Federated Adaptation framework for VLMs, named TOFA. To fully leverage the generalizable multimodal features in pre-trained VLMs, TOFA employs both visual and textual pipelines to extract task-relevant representations. In the visual pipeline, a hierarchical Bayesian model learns personalized, class-specific prototype distributions. For the textual pipeline, TOFA evaluates and globally aligns the generated local text prompts for robustness. An adaptive weight calibration mechanism is also introduced to combine predictions from both modalities, balancing personalization and robustness to handle data heterogeneity. Our method is training-free, not relying on additional training resources on either the client or server side. Extensive experiments across 9 datasets in various federated settings demonstrate the effectiveness of the proposed TOFA method.

</details>


### [47] [MuISQA: Multi-Intent Retrieval-Augmented Generation for Scientific Question Answering](https://arxiv.org/abs/2511.16283)
*Zhiyuan Li,Haisheng Yu,Guangchuan Guo,Nan Zhou,Jiajun Zhang*

Main category: cs.AI

TL;DR: 该论文提出了一个多意图科学问题回答（MuISQA）基准测试和一个意图感知检索框架，以提高检索增强生成（RAG）系统在复杂科学问题上的表现。


<details>
  <summary>Details</summary>
Motivation: 复杂科学问题通常包含多个意图，需要多源证据和多跳推理，而传统RAG系统通常是单意图导向，导致证据覆盖不完整。

Method: 引入了MuISQA基准测试以评估RAG系统在子问题上的异质证据覆盖能力。提出了一种意图感知的检索框架，利用大型语言模型（LLM）假设潜在答案，将其分解为特定意图查询，并检索每个潜在意图的支持段落。通过倒数排名融合（RRF）聚合和重排序检索片段，以平衡不同意图的覆盖并减少冗余。

Result: 在MuISQA基准测试和其他通用RAG数据集上的实验表明，该方法始终优于传统方法，特别是在检索准确性和证据覆盖方面。

Conclusion: 提出的意图感知检索框架能够更有效地处理多意图科学问题，提高证据的覆盖率和检索的准确性。

Abstract: Complex scientific questions often entail multiple intents, such as identifying gene mutations and linking them to related diseases. These tasks require evidence from diverse sources and multi-hop reasoning, while conventional retrieval-augmented generation (RAG) systems are usually single-intent oriented, leading to incomplete evidence coverage. To assess this limitation, we introduce the Multi-Intent Scientific Question Answering (MuISQA) benchmark, which is designed to evaluate RAG systems on heterogeneous evidence coverage across sub-questions. In addition, we propose an intent-aware retrieval framework that leverages large language models (LLMs) to hypothesize potential answers, decompose them into intent-specific queries, and retrieve supporting passages for each underlying intent. The retrieved fragments are then aggregated and re-ranked via Reciprocal Rank Fusion (RRF) to balance coverage across diverse intents while reducing redundancy. Experiments on both MuISQA benchmark and other general RAG datasets demonstrate that our method consistently outperforms conventional approaches, particularly in retrieval accuracy and evidence coverage.

</details>


### [48] [Reducing Instability in Synthetic Data Evaluation with a Super-Metric in MalDataGen](https://arxiv.org/abs/2511.16373)
*Anna Luiza Gomes da Silva,Diego Kreutz,Angelo Diniz,Rodrigo Mansilha,Celso Nobre da Fonseca*

Main category: cs.AI

TL;DR: 该论文提出了一种在Android恶意软件领域评估合成数据质量的新方法，通过MalDataGen集成一个超级度量，综合八个指标，生成单一加权分数，提高了度量的稳定性和一致性。


<details>
  <summary>Details</summary>
Motivation: 由于现有度量在Android恶意软件领域的不稳定性和标准化缺乏，评估合成数据质量仍然是一个挑战。

Method: 将超级度量集成到MalDataGen中，通过聚合四个保真度维度的八个指标，生成单一加权分数。

Result: 实验涉及十个生成模型和五个平衡数据集，结果表明超级度量比传统度量更稳定和一致，并且与分类器的实际性能有更强的相关性。

Conclusion: 超级度量为评估Android恶意软件领域的合成数据质量提供了更稳定和一致的度量标准。

Abstract: Evaluating the quality of synthetic data remains a persistent challenge in the Android malware domain due to instability and the lack of standardization among existing metrics. This work integrates into MalDataGen a Super-Metric that aggregates eight metrics across four fidelity dimensions, producing a single weighted score. Experiments involving ten generative models and five balanced datasets demonstrate that the Super-Metric is more stable and consistent than traditional metrics, exhibiting stronger correlations with the actual performance of classifiers.

</details>


### [49] [An Agent-Based Framework for the Automatic Validation of Mathematical Optimization Models](https://arxiv.org/abs/2511.16383)
*Alexander Zadorojniy,Segev Wasserkrug,Eitan Farchi*

Main category: cs.AI

TL;DR: 本文提出了一种基于多智能体的自动验证框架，用于验证从自然语言描述生成的大型语言模型优化模型的正确性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型从自然语言描述生成优化模型时，如何验证生成模型的正确性是一个重要的开放问题。

Method: 提出了一种基于智能体的方法，包括多个智能体，首先生成问题级测试API，然后利用该API生成测试，并生成特定于优化模型的变异体（一种评估测试套件故障检测能力的软件测试技术）。

Result: 通过实验展示了该智能体框架在变异覆盖率这一著名软件测试指标下的高质量验证能力。

Conclusion: 该智能体框架能够有效验证优化模型的正确性，并满足自然语言描述中的需求。

Abstract: Recently, using Large Language Models (LLMs) to generate optimization models from natural language descriptions has became increasingly popular. However, a major open question is how to validate that the generated models are correct and satisfy the requirements defined in the natural language description. In this work, we propose a novel agent-based method for automatic validation of optimization models that builds upon and extends methods from software testing to address optimization modeling . This method consists of several agents that initially generate a problem-level testing API, then generate tests utilizing this API, and, lastly, generate mutations specific to the optimization model (a well-known software testing technique assessing the fault detection power of the test suite). In this work, we detail this validation framework and show, through experiments, the high quality of validation provided by this agent ensemble in terms of the well-known software testing measure called mutation coverage.

</details>


### [50] [Pharos-ESG: A Framework for Multimodal Parsing, Contextual Narration, and Hierarchical Labeling of ESG Report](https://arxiv.org/abs/2511.16417)
*Yan Chen,Yu Zou,Jialei Zeng,Haoran You,Xiaorui Zhou,Aixi Zhong*

Main category: cs.AI

TL;DR: 本文提出Pharos-ESG框架，通过多模态解析、上下文叙述和层次标注将ESG报告转换为结构化表示，并发布了Aurora-ESG数据集。


<details>
  <summary>Details</summary>
Motivation: ESG报告由于布局不规则和内容结构弱，难以大规模理解，因此需要一种能够结构化这些报告的方法。

Method: Pharos-ESG框架包含布局流阅读顺序建模、目录锚点引导的层次感知分割，以及将视觉元素转化为自然语言的多模态聚合管道。

Result: Pharos-ESG在标注基准测试中表现优于专用文档解析系统和通用多模态模型。

Conclusion: Pharos-ESG框架和Aurora-ESG数据集有助于更好地支持ESG在金融治理和决策中的整合。

Abstract: Environmental, Social, and Governance (ESG) principles are reshaping the foundations of global financial gover- nance, transforming capital allocation architectures, regu- latory frameworks, and systemic risk coordination mecha- nisms. However, as the core medium for assessing corpo- rate ESG performance, the ESG reports present significant challenges for large-scale understanding, due to chaotic read- ing order from slide-like irregular layouts and implicit hier- archies arising from lengthy, weakly structured content. To address these challenges, we propose Pharos-ESG, a uni- fied framework that transforms ESG reports into structured representations through multimodal parsing, contextual nar- ration, and hierarchical labeling. It integrates a reading-order modeling module based on layout flow, hierarchy-aware seg- mentation guided by table-of-contents anchors, and a multi- modal aggregation pipeline that contextually transforms vi- sual elements into coherent natural language. The framework further enriches its outputs with ESG, GRI, and sentiment labels, yielding annotations aligned with the analytical de- mands of financial research. Extensive experiments on anno- tated benchmarks demonstrate that Pharos-ESG consistently outperforms both dedicated document parsing systems and general-purpose multimodal models. In addition, we release Aurora-ESG, the first large-scale public dataset of ESG re- ports, spanning Mainland China, Hong Kong, and U.S. mar- kets, featuring unified structured representations of multi- modal content, enriched with fine-grained layout and seman- tic annotations to better support ESG integration in financial governance and decision-making.

</details>


### [51] [From generative AI to the brain: five takeaways](https://arxiv.org/abs/2511.16432)
*Claudius Gros*

Main category: cs.AI

TL;DR: 生成AI的进步主要源于明确的生成原则，而非复杂的算法。该论文建议应深入研究这些原则在大脑中的作用，并探讨机器学习（ML）研究对神经科学的潜在贡献。


<details>
  <summary>Details</summary>
Motivation: 探究生成原则在认知神经科学中的潜在应用，以及ML研究对神经科学的启示。

Method: 通过讨论生成原则在AI中的具体实现，提出这些原则在神经科学中的可能应用，并分析ML研究对神经科学的五个具体启示。

Result: 指出了生成原则在神经科学中可能的应用，并展示了ML研究在神经信息处理系统方面的五个有趣特征。

Conclusion: 神经科学可以从ML研究中获益良多，尤其是在生成原则的应用和神经信息处理的特征方面。

Abstract: The big strides seen in generative AI are not based on somewhat obscure algorithms, but due to clearly defined generative principles. The resulting concrete implementations have proven themselves in large numbers of applications. We suggest that it is imperative to thoroughly investigate which of these generative principles may be operative also in the brain, and hence relevant for cognitive neuroscience. In addition, ML research led to a range of interesting characterizations of neural information processing systems. We discuss five examples, the shortcomings of world modelling, the generation of thought processes, attention, neural scaling laws, and quantization, that illustrate how much neuroscience could potentially learn from ML research.

</details>


### [52] [PersonaDrift: A Benchmark for Temporal Anomaly Detection in Language-Based Dementia Monitoring](https://arxiv.org/abs/2511.16445)
*Joy Lai,Alex Mihailidis*

Main category: cs.AI

TL;DR: 本文介绍了PersonaDrift，一个用于评估检测和跟踪痴呆患者日常交流中行为变化方法的合成基准。


<details>
  <summary>Details</summary>
Motivation: 大多数计算工具无法跟踪痴呆患者随时间的交流行为变化，而看护者通常能非正式地察觉这些变化。因此，需要一个专门的基准来评估相关方法。

Method: PersonaDrift基于看护者访谈模拟了60天合成用户的互动日志，并注入看护者认为重要的情感扁平化和离题回复两种变化。评估了多种异常检测方法、无监督统计方法、序列模型和分类器。

Result: 简单统计模型可以检测低变异性用户的情感扁平化，而语义漂移检测需要时间建模和个性化基线。个性化分类器在所有任务中表现优于通用分类器。

Conclusion: 个性化行为背景对于检测痴呆患者的交流变化非常重要，PersonaDrift为未来研究提供了一个可扩展的框架。

Abstract: People living with dementia (PLwD) often show gradual shifts in how they communicate, becoming less expressive, more repetitive, or drifting off-topic in subtle ways. While caregivers may notice these changes informally, most computational tools are not designed to track such behavioral drift over time. This paper introduces PersonaDrift, a synthetic benchmark designed to evaluate machine learning and statistical methods for detecting progressive changes in daily communication, focusing on user responses to a digital reminder system. PersonaDrift simulates 60-day interaction logs for synthetic users modeled after real PLwD, based on interviews with caregivers. These caregiver-informed personas vary in tone, modality, and communication habits, enabling realistic diversity in behavior. The benchmark focuses on two forms of longitudinal change that caregivers highlighted as particularly salient: flattened sentiment (reduced emotional tone and verbosity) and off-topic replies (semantic drift). These changes are injected progressively at different rates to emulate naturalistic cognitive trajectories, and the framework is designed to be extensible to additional behaviors in future use cases. To explore this novel application space, we evaluate several anomaly detection approaches, unsupervised statistical methods (CUSUM, EWMA, One-Class SVM), sequence models using contextual embeddings (GRU + BERT), and supervised classifiers in both generalized and personalized settings. Preliminary results show that flattened sentiment can often be detected with simple statistical models in users with low baseline variability, while detecting semantic drift requires temporal modeling and personalized baselines. Across both tasks, personalized classifiers consistently outperform generalized ones, highlighting the importance of individual behavioral context.

</details>


### [53] [Utilizing Large Language Models for Zero-Shot Medical Ontology Extension from Clinical Notes](https://arxiv.org/abs/2511.16548)
*Guanchen Wu,Yuzhang Xie,Huanwei Wu,Zhe He,Hui Shao,Xiao Hu,Carl Yang*

Main category: cs.AI

TL;DR: 提出CLOZE框架，利用大型语言模型自动从临床笔记中提取医学实体并整合到医学本体中，实现高效、可扩展且保护隐私的本体扩展。


<details>
  <summary>Details</summary>
Motivation: 临床笔记作为未被充分利用的资源，含有丰富的患者观察信息，有潜力扩展医学本体，但直接利用临床笔记进行本体扩展仍是一个未被充分探索的领域。

Method: CLOZE框架利用预训练的大型语言模型，自动从临床笔记中提取医学实体，并将其整合到分层医学本体中。该框架无需额外训练或标记数据，并可自动去除受保护的健康信息以保护患者隐私。

Result: 实验结果证明，CLOZE能够提供一个准确、可扩展且保护隐私的本体扩展框架。

Conclusion: CLOZE有潜力在生物医学研究和临床信息学中支持多种下游应用，是一个具有成本效益的解决方案。

Abstract: Integrating novel medical concepts and relationships into existing ontologies can significantly enhance their coverage and utility for both biomedical research and clinical applications. Clinical notes, as unstructured documents rich with detailed patient observations, offer valuable context-specific insights and represent a promising yet underutilized source for ontology extension. Despite this potential, directly leveraging clinical notes for ontology extension remains largely unexplored. To address this gap, we propose CLOZE, a novel framework that uses large language models (LLMs) to automatically extract medical entities from clinical notes and integrate them into hierarchical medical ontologies. By capitalizing on the strong language understanding and extensive biomedical knowledge of pre-trained LLMs, CLOZE effectively identifies disease-related concepts and captures complex hierarchical relationships. The zero-shot framework requires no additional training or labeled data, making it a cost-efficient solution. Furthermore, CLOZE ensures patient privacy through automated removal of protected health information (PHI). Experimental results demonstrate that CLOZE provides an accurate, scalable, and privacy-preserving ontology extension framework, with strong potential to support a wide range of downstream applications in biomedical research and clinical informatics.

</details>


### [54] [Consciousness in Artificial Intelligence? A Framework for Classifying Objections and Constraints](https://arxiv.org/abs/2511.16582)
*Andres Campero,Derek Shiller,Jaan Aru,Jonathan Simon*

Main category: cs.AI

TL;DR: 提出一个分类框架，用于区分数字人工智能系统中有意识性挑战的不同粒度和力度。


<details>
  <summary>Details</summary>
Motivation: 为了系统化地分类和区分针对数字意识的各种挑战，并澄清这些挑战的意图和力度。

Method: 提出一个基于Marr层次的分类框架，应用于14个科学和哲学文献中的例子。

Result: 成功应用框架于14个例子，展示了其在区分挑战的不同粒度和力度方面的实用性。

Conclusion: 该框架为讨论数字意识挑战提供了结构和工具，有助于澄清不同挑战之间的区别。

Abstract: We develop a taxonomical framework for classifying challenges to the possibility of consciousness in digital artificial intelligence systems. This framework allows us to identify the level of granularity at which a given challenge is intended (the levels we propose correspond to Marr's levels) and to disambiguate its degree of force: is it a challenge to computational functionalism that leaves the possibility of digital consciousness open (degree 1), a practical challenge to digital consciousness that suggests improbability without claiming impossibility (degree 2), or an argument claiming that digital consciousness is strictly impossible (degree 3)? We apply this framework to 14 prominent examples from the scientific and philosophical literature. Our aim is not to take a side in the debate, but to provide structure and a tool for disambiguating between challenges to computational functionalism and challenges to digital consciousness, as well as between different ways of parsing such challenges.

</details>


### [55] [You Only Forward Once: An Efficient Compositional Judging Paradigm](https://arxiv.org/abs/2511.16600)
*Tianlong Zhang,Hongwei Xue,Shilin Yan,Di Wu,Chen Xu,Yunyun Yang*

Main category: cs.AI

TL;DR: 提出了一种新的评判方法YOFO，通过模板条件化在单次前向传递中评判所有需求，提高速度并保持可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有多模态大语言模型评判方法在输出单一评分时与模型的生成性质不符，且生成评判分析过程较慢，难以适应高吞吐量需求。

Method: YOFO基于自回归模型，通过接受结构化需求模板，在单次推理中通过对与需求相关的最终token的logits进行读取，产生每个需求的二进制是/否决策。

Result: 实验表明YOFO在标准推荐数据集上取得了最先进的成果，并支持依赖感知分析和从后续的思维链（CoT）中受益。

Conclusion: YOFO在提高评判速度的同时保持了可解释性，并在多个应用场景下表现出色。

Abstract: Multimodal large language models (MLLMs) show strong potential as judges. However, existing approaches face a fundamental trade-off: adapting MLLMs to output a single score misaligns with the generative nature of MLLMs and limits fine-grained requirement understanding, whereas autoregressively generating judging analyses is prohibitively slow in high-throughput settings. Observing that judgment reduces to verifying whether inputs satisfy a set of structured requirements, we propose YOFO, a template-conditioned method that judges all requirements in a single forward pass. Built on an autoregressive model, YOFO accepts a structured requirement template and, in one inference step, produces a binary yes/no decision for each requirement by reading the logits of the final token associated with that requirement. This design yields orders-of-magnitude speedups while preserving interpretability. Extensive experiments show that YOFO not only achieves state-of-the-art results on standard recommendation datasets, but also supports dependency-aware analysis-where subsequent judgments are conditioned on previous ones-and further benefits from post-hoc CoT.

</details>


### [56] [Bridging VLMs and Embodied Intelligence with Deliberate Practice Policy Optimization](https://arxiv.org/abs/2511.16602)
*Yi Zhang,Che Liu,Xiancong Ren,Hanchu Ni,Yingji Zhang,Shuai Zhang,Zeyuan Ding,Jiayu Hu,Haozhe Shan,Junbo Qi,Yan Bai,Dengjie Li,Jiachen Luo,Yidong Wang,Yong Dai,Zenglin Xu,Bin Shen,Qifan Wang,Jian Tang,Xiaozhu Ju*

Main category: cs.AI

TL;DR: DPPO是一个解决具身智能系统中数据稀缺和算法效率低下的训练框架。


<details>
  <summary>Details</summary>
Motivation: 当前具身智能系统面临数据稀缺昂贵和现有方法资源消耗大的挑战，需要提高学习效率。

Method: 提出了Deliberate Practice Policy Optimization (DPPO)，通过动态交替进行监督微调和强化学习，实现自动弱点识别和高效学习。

Result: 使用DPPO训练的Pelican-VL 1.0模型性能提升20.3%，在100B参数规模下超越开源模型10.6%。

Conclusion: DPPO框架有效缓解了数据和资源瓶颈，为社区构建多功能具身智能体提供了系统框架，并将模型和代码开源。

Abstract: Developing a universal and versatile embodied intelligence system presents two primary challenges: the critical embodied data bottleneck, where real-world data is scarce and expensive, and the algorithmic inefficiency of existing methods, which are resource-prohibitive. To address these limitations, we introduce Deliberate Practice Policy Optimization (DPPO), a metacognitive ``Metaloop'' training framework that dynamically alternates between supervised fine-tuning (competence expansion) and reinforcement learning (skill refinement). This enables automatic weakness identification and targeted resource allocation, specifically designed to maximize learning efficiency from sparse, finite data. Theoretically, DPPO can be formalised as a unified preference-learning framework. Empirically, training a vision-language embodied model with DPPO, referred to as Pelican-VL 1.0, yields a 20.3% performance improvement over the base model and surpasses open-source models at the 100B-parameter scale by 10.6%. We are open-sourcing both the models and code, providing the first systematic framework that alleviates the data and resource bottleneck and enables the community to build versatile embodied agents efficiently.

</details>


### [57] [MedBayes-Lite: Bayesian Uncertainty Quantification for Safe Clinical Decision Support](https://arxiv.org/abs/2511.16625)
*Elias Hossain,Md Mehedi Hasan Nipu,Maleeha Sheikh,Rajib Rana,Subash Neupane,Niloofar Yousefi*

Main category: cs.AI

TL;DR: 提出MedBayes-Lite，一种轻量级贝叶斯增强框架，用于临床语言模型，提升不确定性感知能力。


<details>
  <summary>Details</summary>
Motivation: 尽管Transformer在临床决策支持中表现出色，但仍然容易过于自信，特别是在需要校准不确定性的模糊医疗情况下。

Method: MedBayes-Lite通过三个组件直接集成不确定性量化到现有的Transformer管道中：（i）使用Monte Carlo dropout进行贝叶斯嵌入校准以处理认知不确定性，（ii）不确定性加权注意力，考虑标记的可靠性，（iii）受临床风险最小化启发的置信度引导决策制定。

Result: 在生物医学问答和临床预测基准（MedQA, PubMedQA, MIMIC-III）上，MedBayes-Lite显著改善了校准和可信度，将过度自信降低了32%到48%。在模拟临床环境中，通过标记不确定预测以供人工审查，可以防止高达41%的诊断错误。

Conclusion: MedBayes-Lite在不需重新训练或架构调整的前提下，有效实现了可靠的不确定性传播，并提升了医疗AI系统的可解释性。

Abstract: We propose MedBayes-Lite, a lightweight Bayesian enhancement for transformer-based clinical language models designed to produce reliable, uncertainty-aware predictions. Although transformers show strong potential for clinical decision support, they remain prone to overconfidence, especially in ambiguous medical cases where calibrated uncertainty is critical. MedBayes-Lite embeds uncertainty quantification directly into existing transformer pipelines without any retraining or architectural rewiring, adding no new trainable layers and keeping parameter overhead under 3 percent. The framework integrates three components: (i) Bayesian Embedding Calibration using Monte Carlo dropout for epistemic uncertainty, (ii) Uncertainty-Weighted Attention that marginalizes over token reliability, and (iii) Confidence-Guided Decision Shaping inspired by clinical risk minimization. Across biomedical QA and clinical prediction benchmarks (MedQA, PubMedQA, MIMIC-III), MedBayes-Lite consistently improves calibration and trustworthiness, reducing overconfidence by 32 to 48 percent. In simulated clinical settings, it can prevent up to 41 percent of diagnostic errors by flagging uncertain predictions for human review. These results demonstrate its effectiveness in enabling reliable uncertainty propagation and improving interpretability in medical AI systems.

</details>


### [58] [Enhancing Forex Forecasting Accuracy: The Impact of Hybrid Variable Sets in Cognitive Algorithmic Trading Systems](https://arxiv.org/abs/2511.16657)
*Juan C. King,Jose M. Amigo*

Main category: cs.AI

TL;DR: 本文介绍了一种基于人工智能的高频算法交易系统在外汇市场EUR-USD货币对上的应用。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过整合基本面和技术面变量，提高EUR-USD货币对在高频环境中的交易表现。

Method: 方法包括整合一系列基本面（如GDP和失业率）和技术面变量（如指标、振荡器、斐波那契水平和价格背离），并使用机器学习指标和回测模拟来评估算法性能。

Result: 通过历史数据评估算法的预测准确性和交易盈利能力，并进行风险分析。

Conclusion: 研究通过比较分析，确定基本面和技术面变量中哪一类对生成盈利交易信号更具预测能力和可靠性。

Abstract: This paper presents the implementation of an advanced artificial intelligence-based algorithmic trading system specifically designed for the EUR-USD pair within the high-frequency environment of the Forex market. The methodological approach centers on integrating a holistic set of input features: key fundamental macroeconomic variables (for example, Gross Domestic Product and Unemployment Rate) collected from both the Euro Zone and the United States, alongside a comprehensive suite of technical variables (including indicators, oscillators, Fibonacci levels, and price divergences). The performance of the resulting algorithm is evaluated using standard machine learning metrics to quantify predictive accuracy and backtesting simulations across historical data to assess trading profitability and risk. The study concludes with a comparative analysis to determine which class of input features, fundamental or technical, provides greater and more reliable predictive capacity for generating profitable trading signals.

</details>


### [59] [Cognitive Foundations for Reasoning and Their Manifestation in LLMs](https://arxiv.org/abs/2511.16660)
*Priyanka Kargupta,Shuyue Stella Li,Haocheng Wang,Jinu Lee,Shan Chen,Orevaoghene Ahia,Dean Light,Thomas L. Griffiths,Max Kleiman-Weiner,Jiawei Han,Asli Celikyilmaz,Yulia Tsvetkov*

Main category: cs.AI

TL;DR: 大型语言模型在简单问题上失败，表明其推理机制与人类不同。本文提出了一个细粒度的认知评估框架，分析170K条模型推理轨迹和54条人类轨迹，揭示了两者在结构上的系统性差异，并开发了测试时推理指导方法，将性能提升高达60%。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂问题上表现出色，但在简单问题上的失败表明其推理机制与人类的根本差异。为了理解这种差异，作者提出了一个细粒度的认知评估框架，旨在分析模型与人类在推理过程中的结构性差异。

Method: 综合认知科学研究，提出包含28个认知元素的分类法，涵盖计算约束、元认知控制、知识表示和转换操作。分析170K条来自17个模型的推理轨迹，以及54条人类思维轨迹，并开发了测试时推理指导方法。

Result: 分析揭示出人类使用层次嵌套和元认知监控，而模型依赖浅层前向链，尤其在结构不良问题上差异显著。元分析发现，研究集中在容易量化的行为（如顺序组织：55%，分解：60%），而忽视与成功相关的元认知控制（如自我意识：16%，评估：8%）。测试时推理指导方法将性能提升高达60%。

Conclusion: 通过连接认知科学和LLM研究，本文建立了开发基于原则性认知机制模型的基础，而非依赖脆弱的 spurious 推理捷径或记忆，为改进模型能力和大规模测试人类认知理论开辟了新方向。

Abstract: Large language models solve complex problems yet fail on simpler variants, suggesting they achieve correct outputs through mechanisms fundamentally different from human reasoning. We synthesize cognitive science research into a taxonomy of 28 cognitive elements spanning computational constraints, meta-cognitive controls, knowledge representations, and transformation operations, then analyze their behavioral manifestations in reasoning traces. We propose a fine-grained cognitive evaluation framework and conduct the first large-scale analysis of 170K traces from 17 models across text, vision, and audio modalities, alongside 54 human think-aloud traces, which we make publicly available. Our analysis reveals systematic structural differences: humans employ hierarchical nesting and meta-cognitive monitoring while models rely on shallow forward chaining, with divergence most pronounced on ill-structured problems. Meta-analysis of 1,598 LLM reasoning papers reveals the research community concentrates on easily quantifiable behaviors (sequential organization: 55%, decomposition: 60%) while neglecting meta-cognitive controls (self-awareness: 16%, evaluation: 8%) that correlate with success. Models possess behavioral repertoires associated with success but fail to deploy them spontaneously. Leveraging these patterns, we develop test-time reasoning guidance that automatically scaffold successful structures, improving performance by up to 60% on complex problems. By bridging cognitive science and LLM research, we establish a foundation for developing models that reason through principled cognitive mechanisms rather than brittle spurious reasoning shortcuts or memorization, opening new directions for both improving model capabilities and testing theories of human cognition at scale.

</details>
