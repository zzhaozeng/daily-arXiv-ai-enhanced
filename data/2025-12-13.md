<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 2]
- [cs.AI](#cs.AI) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Quantifying Emotional Tone in Tolkien's The Hobbit: Dialogue Sentiment Analysis with RegEx, NRC-VAD, and Python](https://arxiv.org/abs/2512.10865)
*Lilin Qiu*

Main category: cs.CL

TL;DR: 本研究使用计算文本分析技术，分析了《霍比特人》对话中的情感变化，发现其情感节奏保持积极和平静，并随着故事进展逐渐增强主导性。


<details>
  <summary>Details</summary>
Motivation: 通过计算文本分析方法，探索文学作品中的情感结构，以揭示《霍比特人》的情感节奏和故事叙述中的情感调节。

Method: 提取对话，并使用正则表达式进行预处理，然后使用NRC-VAD词典对情感维度进行量化评分，并进行可视化展示。

Result: 对话整体保持积极（高情绪价值）和冷静（低唤醒度）的语调，并随着故事进展主导感（支配性）逐渐增强。

Conclusion: 结合计算工具和文学解读，该研究展示了数字方法如何揭示文学中的微妙情感结构，从而揭示《霍比特人》中的稳定节奏和情感调节。

Abstract: This study analyzes the emotional tone of dialogue in J. R. R. Tolkien's The Hobbit (1937) using computational text analysis. Dialogue was extracted with regular expressions, then preprocessed, and scored using the NRC-VAD lexicon to quantify emotional dimensions. The results show that the dialogue maintains a generally positive (high valence) and calm (low arousal) tone, with a gradually increasing sense of agency (dominance) as the story progresses. These patterns reflect the novel's emotional rhythm: moments of danger and excitement are regularly balanced by humor, camaraderie, and relief. Visualizations -- including emotional trajectory graphs and word clouds -- highlight how Tolkien's language cycles between tension and comfort. By combining computational tools with literary interpretation, this study demonstrates how digital methods can uncover subtle emotional structures in literature, revealing the steady rhythm and emotional modulation that shape the storytelling in The Hobbit.

</details>


### [2] [Computational emotion analysis with multimodal LLMs: Current evidence on an emerging methodological opportunity](https://arxiv.org/abs/2512.10882)
*Hauke Licht*

Main category: cs.CL

TL;DR: 该论文评估了多模态大语言模型（mLLMs）在基于视频的情感唤起分析中的有效性。


<details>
  <summary>Details</summary>
Motivation: 分析情感在政治交流中的作用有悠久传统，随着研究越来越多地利用视听材料来分析情感展示，多模态生成AI的出现带来了巨大进展。然而，缺乏关于多模态AI在情感分析中有效性的证据。

Method: 通过评估当前多模态大语言模型（mLLMs）在两个互补的人类标注视频数据集上的情感唤起分析表现。

Result: 在理想情况下，mLLMs的情感唤起评分高度可靠，几乎没有人口统计学偏见的迹象。但在真实世界议会辩论的录音中，mLLMs的唤起评分未能实现这种可靠性，可能对下游统计推断产生负面影响。

Conclusion: 该研究强调需要继续深入评估新兴生成AI方法在政治分析中的表现，并贡献了一个可复制的评估框架。

Abstract: Emotions are central to politics and analyzing their role in political communication has a long tradition. As research increasingly leverages audio-visual materials to analyze the display of emotions, the emergence of multimodal generative AI promises great advances. However, we lack evidence about the effectiveness of multimodal AI in emotion analysis. This paper addresses this gap by evaluating current multimodal large language models (mLLMs) in video-based analysis of emotional arousal in two complementary data sets of human-labeled video recordings. I find that under ideal circumstances, mLLMs' emotional arousal ratings are highly reliable and show little to know indication of demographic bias. However, in recordings of speakers in real-world parliamentary debates, mLLMs' arousal ratings fail to deliver on this promise with potential negative consequences for downstream statistical inferences. This study therefore underscores the need for continued, thorough evaluation of emerging generative AI methods in political analysis and contributes a suitable replicable framework.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [3] [LLMs Can Assist with Proposal Selection at Large User Facilities](https://arxiv.org/abs/2512.10895)
*Lijie Ding,Janell Thomson,Jon Taylor,Changwoo Do*

Main category: cs.AI

TL;DR: 本文探讨了大语言模型（LLMs）如何以可扩展、一致且经济高效的方式，增强大型用户设施的提案选择过程。


<details>
  <summary>Details</summary>
Motivation: 传统的人工提案评审存在相关性弱、评审偏见和不一致的问题，虽然两两比较方法在逻辑上更优，但其工作量巨大，难以实际应用。因此，研究者们探索使用LLMs来解决这些问题。

Method: 利用来自散裂中子源（SNS）三个光束线的高质量的提案和发表记录，通过LLMs进行提案排名，并与人工排名进行比较。此外，还使用嵌入模型进行提案相似性的量化评估。

Result: LLM排名与人工排名之间有很强的相关性（Spearman $ρ\simeq 0.2-0.8$，在去除10%的异常值后提高到$\geq 0.5$）。LLM在识别具有高发表潜力的提案方面表现不逊于人工评审，且成本更低。

Conclusion: LLMs不仅能提供与人工评审相当甚至更好的排名效果，还能进行一些对人类而言较为困难的高级分析，例如通过嵌入模型量化评估提案的相似性。因此，LLMs在提案选择过程中具有巨大潜力。

Abstract: We explore how large language models (LLMs) can enhance the proposal selection process at large user facilities, offering a scalable, consistent, and cost-effective alternative to traditional human review. Proposal selection depends on assessing the relative strength among submitted proposals; however, traditional human scoring often suffers from weak inter-proposal correlations and is subject to reviewer bias and inconsistency. A pairwise preference-based approach is logically superior, providing a more rigorous and internally consistent basis for ranking, but its quadratic workload makes it impractical for human reviewers. We address this limitation using LLMs. Leveraging the uniquely well-curated proposals and publication records from three beamlines at the Spallation Neutron Source (SNS), Oak Ridge National Laboratory (ORNL), we show that the LLM rankings correlate strongly with the human rankings (Spearman $ρ\simeq 0.2-0.8$, improving to $\geq 0.5$ after 10\% outlier removal). Moreover, LLM performance is no worse than that of human reviewers in identifying proposals with high publication potential, while costing over two orders of magnitude less. Beyond ranking, LLMs enable advanced analyses that are challenging for humans, such as quantitative assessment of proposal similarity via embedding models, which provides information crucial for review committees.

</details>


### [4] [Multi-Granular Node Pruning for Circuit Discovery](https://arxiv.org/abs/2512.10903)
*Muhammad Umair Haider,Hammad Rizwan,Hassan Sajjad,A. B. Siddique*

Main category: cs.AI

TL;DR: 提出了一种新的节点级剪枝框架，用于在大语言模型中发现更小、更高效的电路。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖边剪枝，计算成本高且粒度粗糙，忽略了单个神经元等更细粒度的结构。

Method: 引入可学习的多粒度掩码，通过粒度特定的稀疏惩罚，在统一优化目标下进行剪枝。

Result: 该方法在节点数量上优于以前的方法，识别出更小的电路，并显著降低内存占用5-10倍。

Conclusion: 许多以前方法认为是重要的神经元实际上并不相关，而本方法仍能保持任务性能。

Abstract: Circuit discovery aims to identify minimal subnetworks that are responsible for specific behaviors in large language models (LLMs). Existing approaches primarily rely on iterative edge pruning, which is computationally expensive and limited to coarse-grained units such as attention heads or MLP blocks, overlooking finer structures like individual neurons. We propose a node-level pruning framework for circuit discovery that addresses both scalability and granularity limitations. Our method introduces learnable masks across multiple levels of granularity, from entire blocks to individual neurons, within a unified optimization objective. Granularity-specific sparsity penalties guide the pruning process, allowing a comprehensive compression in a single fine-tuning run. Empirically, our approach identifies circuits that are smaller in nodes than those discovered by prior methods; moreover, we demonstrate that many neurons deemed important by coarse methods are actually irrelevant, while still maintaining task performance. Furthermore, our method has a significantly lower memory footprint, 5-10x, as it does not require keeping intermediate activations in the memory to work.

</details>
