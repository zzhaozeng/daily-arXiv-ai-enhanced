<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 14]
- [cs.AI](#cs.AI) [Total: 22]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Segment, Embed, and Align: A Universal Recipe for Aligning Subtitles to Signing](https://arxiv.org/abs/2512.08094)
*Zifan Jiang,Youngjoon Jang,Liliane Momeni,Gül Varol,Sarah Ebling,Andrew Zisserman*

Main category: cs.CL

TL;DR: 本文提出了一种用于将字幕与连续手语视频对齐的通用方法SEA，该方法跨语言、跨领域，且无需端到端训练。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖于特定语言或数据集进行端到端训练，这限制了其通用性。为此，需要一种灵活且高效的方法来处理多语言和不同领域的手语数据。

Method: SEA方法结合了两个预训练模型：一个用于将视频帧序列分割为单独的手势，另一个用于将每个手势的视频片段嵌入到与文本共享的潜在空间。对齐过程采用轻量级动态规划程序，可在CPU上高效运行。

Result: 在四个手语数据集上的实验表明，SEA方法实现了最先进的对齐性能，并且能够生成高质量的并行数据。

Conclusion: SEA方法灵活且高效，适用于从小型词汇表到大型连续语料库的各种场景，具有推动手语处理发展的潜力。

Abstract: The goal of this work is to develop a universal approach for aligning subtitles (i.e., spoken language text with corresponding timestamps) to continuous sign language videos. Prior approaches typically rely on end-to-end training tied to a specific language or dataset, which limits their generality. In contrast, our method Segment, Embed, and Align (SEA) provides a single framework that works across multiple languages and domains. SEA leverages two pretrained models: the first to segment a video frame sequence into individual signs and the second to embed the video clip of each sign into a shared latent space with text. Alignment is subsequently performed with a lightweight dynamic programming procedure that runs efficiently on CPUs within a minute, even for hour-long episodes. SEA is flexible and can adapt to a wide range of scenarios, utilizing resources from small lexicons to large continuous corpora. Experiments on four sign language datasets demonstrate state-of-the-art alignment performance, highlighting the potential of SEA to generate high-quality parallel data for advancing sign language processing. SEA's code and models are openly available.

</details>


### [2] [Universal Adversarial Suffixes Using Calibrated Gumbel-Softmax Relaxation](https://arxiv.org/abs/2512.08123)
*Sampriti Soor,Suklav Ghosh,Arijit Sur*

Main category: cs.CL

TL;DR: 该论文研究了通用对抗性后缀，这些后缀是短标记序列，附加到任何输入后能广泛降低语言模型在各种任务上的准确性。


<details>
  <summary>Details</summary>
Motivation: 语言模型作为零样本或少样本分类器时容易受到对抗性提示的影响，以往的方法通常优化特定任务或模型的触发器，导致结果难以比较且迁移性差。

Method: 论文提出了一种学习通用对抗性后缀的方法，使用Gumbel-Softmax松弛以可微分“软”形式学习后缀，然后将其离散化用于推理。训练时最大化标签区域上的校准交叉熵，并通过熵正则化避免崩溃。

Result: 单个后缀在一个模型上训练后能有效迁移到其他模型，持续降低准确性和校准置信度。实验涵盖了情感分析、自然语言推理、释义检测、常识问答和物理推理等任务，验证了攻击的有效性。

Conclusion: 通用对抗性后缀能在不同任务和模型家族之间迁移，有效降低语言模型的分类性能和置信度。

Abstract: Language models (LMs) are often used as zero-shot or few-shot classifiers by scoring label words, but they remain fragile to adversarial prompts. Prior work typically optimizes task- or model-specific triggers, making results difficult to compare and limiting transferability. We study universal adversarial suffixes: short token sequences (4-10 tokens) that, when appended to any input, broadly reduce accuracy across tasks and models. Our approach learns the suffix in a differentiable "soft" form using Gumbel-Softmax relaxation and then discretizes it for inference. Training maximizes calibrated cross-entropy on the label region while masking gold tokens to prevent trivial leakage, with entropy regularization to avoid collapse. A single suffix trained on one model transfers effectively to others, consistently lowering both accuracy and calibrated confidence. Experiments on sentiment analysis, natural language inference, paraphrase detection, commonsense QA, and physical reasoning with Qwen2-1.5B, Phi-1.5, and TinyLlama-1.1B demonstrate consistent attack effectiveness and transfer across tasks and model families.

</details>


### [3] [Universal Adversarial Suffixes for Language Models Using Reinforcement Learning with Calibrated Reward](https://arxiv.org/abs/2512.08131)
*Sampriti Soor,Suklav Ghosh,Arijit Sur*

Main category: cs.CL

TL;DR: 本文提出了一种使用强化学习框架来发现可跨任务和模型迁移的对抗性后缀的方法。


<details>
  <summary>Details</summary>
Motivation: 语言模型容易受到能够改变预测的短对抗性后缀影响，现有方法通常依赖于梯度搜索或基于规则的方法，但这些方法较为脆弱，并且通常与特定任务或模型绑定。

Method: 采用强化学习框架，将后缀视为策略，并使用近端策略优化（PPO）进行训练，以冻结模型作为奖励预言机，并使用校准的交叉熵塑造奖励，消除标签偏差并聚合不同形式的表达以提高可迁移性。

Result: 在涵盖情感分析、自然语言推理、释义和常识推理的五个不同NLP基准数据集上，使用Qwen2-1.5B Instruct、TinyLlama-1.1B Chat和Phi-1.5三种不同的语言模型进行评估，结果表明RL训练的后缀始终降低准确率，并且在任务和模型间具有更好的迁移能力。

Conclusion: 本文的方法在生成可迁移的对抗性后缀方面优于以往的方法，展示了强化学习在对抗攻击中的有效性。

Abstract: Language models are vulnerable to short adversarial suffixes that can reliably alter predictions. Previous works usually find such suffixes with gradient search or rule-based methods, but these are brittle and often tied to a single task or model. In this paper, a reinforcement learning framework is used where the suffix is treated as a policy and trained with Proximal Policy Optimization against a frozen model as a reward oracle. Rewards are shaped using calibrated cross-entropy, removing label bias and aggregating across surface forms to improve transferability. The proposed method is evaluated on five diverse NLP benchmark datasets, covering sentiment, natural language inference, paraphrase, and commonsense reasoning, using three distinct language models: Qwen2-1.5B Instruct, TinyLlama-1.1B Chat, and Phi-1.5. Results show that RL-trained suffixes consistently degrade accuracy and transfer more effectively across tasks and models than previous adversarial triggers of similar genres.

</details>


### [4] [ClinicalTrialsHub: Bridging Registries and Literature for Comprehensive Clinical Trial Access](https://arxiv.org/abs/2512.08193)
*Jiwoo Park,Ruoqi Liu,Avani Jagdale,Andrew Srisuwananukorn,Jing Zhao,Lang Li,Ping Zhang,Sachin Kumar*

Main category: cs.CL

TL;DR: ClinicalTrialsHub是一个整合ClinicalTrials.gov和PubMed数据的交互式搜索平台，利用大语言模型提升结构化临床试验数据访问效率83.8%。


<details>
  <summary>Details</summary>
Motivation: 解决现有临床数据分散、结构化程度低的问题，提升患者、医生、研究人员等群体获取证据医学数据的效率。

Method: 使用GPT-5.1和Gemini-3-Pro等LLM模型，自动解析全文文献提取结构化信息，实现用户查询的结构化转换和溯源式问答系统。

Result: 相比单独使用ClinicalTrials.gov，结构化数据访问量提升83.8%，经临床医生、研究员等用户测试验证了信息抽取和问答能力。

Conclusion: 该平台显著增强了临床试验数据的可及性，通过多源数据融合和LLM技术推动了循证医学发展。

Abstract: We present ClinicalTrialsHub, an interactive search-focused platform that consolidates all data from ClinicalTrials.gov and augments it by automatically extracting and structuring trial-relevant information from PubMed research articles. Our system effectively increases access to structured clinical trial data by 83.8% compared to relying on ClinicalTrials.gov alone, with potential to make access easier for patients, clinicians, researchers, and policymakers, advancing evidence-based medicine. ClinicalTrialsHub uses large language models such as GPT-5.1 and Gemini-3-Pro to enhance accessibility. The platform automatically parses full-text research articles to extract structured trial information, translates user queries into structured database searches, and provides an attributed question-answering system that generates evidence-grounded answers linked to specific source sentences. We demonstrate its utility through a user study involving clinicians, clinical researchers, and PhD students of pharmaceutical sciences and nursing, and a systematic automatic evaluation of its information extraction and question answering capabilities.

</details>


### [5] [Are generative AI text annotations systematically biased?](https://arxiv.org/abs/2512.08404)
*Sjoerd B. Stolwijk,Mark Boukes,Damian Trilling*

Main category: cs.CL

TL;DR: 该论文研究了GLLM（大语言模型）注释中的偏见，通过复制Boukes（2024）的手工注释，评估了不同GLLM和提示组合在五个概念上的表现。


<details>
  <summary>Details</summary>
Motivation: 理解GLLM注释的偏见，并比较其与人工注释的差异，尤其是在不同概念和提示条件下的系统性偏差。

Method: 使用多种GLLM（Llama3.1:8b, Llama3.3:70b, GPT4o, Qwen2.5:72b）和五种提示，对五个概念（政治内容、互动性、理性、不文明和意识形态）进行注释，并与手工注释比较。

Result: GLLM在F1分数上表现良好，但在流行率、实质下游结果和与手工注释的重叠方面存在系统性偏差。F1分数的差异未能完全解释偏见的程度。

Conclusion: GLLM注释虽然在某些指标上表现良好，但与人工注释之间存在显著差异，提示需要更多关注GLLM注释中的偏见问题。

Abstract: This paper investigates bias in GLLM annotations by conceptually replicating manual annotations of Boukes (2024). Using various GLLMs (Llama3.1:8b, Llama3.3:70b, GPT4o, Qwen2.5:72b) in combination with five different prompts for five concepts (political content, interactivity, rationality, incivility, and ideology). We find GLLMs perform adequate in terms of F1 scores, but differ from manual annotations in terms of prevalence, yield substantively different downstream results, and display systematic bias in that they overlap more with each other than with manual annotations. Differences in F1 scores fail to account for the degree of bias.

</details>


### [6] [What Triggers my Model? Contrastive Explanations Inform Gender Choices by Translation Models](https://arxiv.org/abs/2512.08440)
*Janiça Hackenbuchner,Arda Tezcan,Joke Daems*

Main category: cs.CL

TL;DR: 该研究旨在通过分析性别模糊的源数据，探索机器翻译模型中性别偏见的来源，使用对比解释和显著性归因来研究输入内容如何影响目标语言中的性别选择。


<details>
  <summary>Details</summary>
Motivation: 当前对模型中性别偏见的理解有限，研究动机是超越简单测量偏见，探索其根本来源，以便更好地理解和缓解这一问题。

Method: 研究使用对比解释和计算显著性归因的方法，分析源句子中输入标记对翻译模型在目标语言中选择性别的影响，并与人类性别感知进行比较。

Result: 研究发现，在性别决策中，模型归因和人类的感知之间存在明显重叠。此外，研究还对显著性词进行了语言分析。

Conclusion: 该研究强调理解模型在翻译中性别决策的重要性，并表明这些信息与人类决策的比较有助于减少性别偏见。

Abstract: Interpretability can be implemented as a means to understand decisions taken by (black box) models, such as machine translation (MT) or large language models (LLMs). Yet, research in this area has been limited in relation to a manifested problem in these models: gender bias. With this research, we aim to move away from simply measuring bias to exploring its origins. Working with gender-ambiguous natural source data, this study examines which context, in the form of input tokens in the source sentence, influences (or triggers) the translation model choice of a certain gender inflection in the target language. To analyse this, we use contrastive explanations and compute saliency attribution. We first address the challenge of a lacking scoring threshold and specifically examine different attribution levels of source words on the model gender decisions in the translation. We compare salient source words with human perceptions of gender and demonstrate a noticeable overlap between human perceptions and model attribution. Additionally, we provide a linguistic analysis of salient words. Our work showcases the relevance of understanding model translation decisions in terms of gender, how this compares to human decisions and that this information should be leveraged to mitigate gender bias.

</details>


### [7] [Soft Inductive Bias Approach via Explicit Reasoning Perspectives in Inappropriate Utterance Detection Using Large Language Models](https://arxiv.org/abs/2512.08480)
*Ju-Young Kim,Ji-Hong Park,Se-Yeon Lee,Sujin Park,Gun-Woo Kim*

Main category: cs.CL

TL;DR: 本文提出一种软性归纳偏置方法，通过明确推理视角来提升韩语大模型在不当言论检测中的表现。


<details>
  <summary>Details</summary>
Motivation: 匿名环境下不当言论频发，需研究检测对话中不当言论的技术以构建更安全的交流环境。

Method: 提出软性归纳偏置方法，明确推理视角，微调韩语大模型，并进行定量和定性评估。

Result: Kanana-1.5模型的平均准确率达到87.0046，比标准监督学习提高了约3.89%。

Conclusion: 该方法通过约束推理视角，使大模型能进行更精确和一致的判断，有效提升了不当言论检测的效果。

Abstract: Recent incidents in certain online games and communities, where anonymity is guaranteed, show that unchecked inappropriate remarks frequently escalate into verbal abuse and even criminal behavior, raising significant social concerns. Consequently, there is a growing need for research on techniques that can detect inappropriate utterances within conversational texts to help build a safer communication environment. Although large-scale language models trained on Korean corpora and chain-of-thought reasoning have recently gained attention, research applying these approaches to inappropriate utterance detection remains limited. In this study, we propose a soft inductive bias approach that explicitly defines reasoning perspectives to guide the inference process, thereby promoting rational decision-making and preventing errors that may arise during reasoning. We fine-tune a Korean large language model using the proposed method and conduct both quantitative performance comparisons and qualitative evaluations across different training strategies. Experimental results show that the Kanana-1.5 model achieves an average accuracy of 87.0046, improving by approximately 3.89 percent over standard supervised learning. These findings indicate that the proposed method goes beyond simple knowledge imitation by large language models and enables more precise and consistent judgments through constrained reasoning perspectives, demonstrating its effectiveness for inappropriate utterance detection.

</details>


### [8] [HealthcareNLP: where are we and what is next?](https://arxiv.org/abs/2512.08617)
*Lifeng Han,Paul Rayson,Suzan Verberne,Andrew Moore,Goran Nenadic*

Main category: cs.CL

TL;DR: 本教程介绍了医疗健康领域自然语言处理（Healthcare NLP）的应用、现有成果及未来挑战。


<details>
  <summary>Details</summary>
Motivation: 现有综述忽略了重要任务，如解决隐私问题的合成数据生成、可解释临床NLP、检索增强生成和LLMs与KGs的神经符号集成方法。因此，本教程旨在提供以患者和资源为导向的Healthcare NLP重要子领域的概述。

Method: 教程涵盖三层架构：数据/资源层（标注指南、伦理审批、治理、合成数据），NLP-评估层（如NER、RE、情感分析、链接/编码等任务，导致可解释性HealthAI），患者层（PPIE、健康素养、翻译、简化、总结及支持共享决策）。教程还包括实践环节，供参与者实际操作Healthcare NLP应用。

Result: 提供了一个全面且层次分明的Healthcare NLP教程，涵盖数据层、NLP任务层和患者参与层，并包含实践环节。

Conclusion: 该教程适合医疗应用领域的NLP从业者、对此领域感兴趣的研究者、医疗研究人员和NLP领域的学生，无需事先具备相关知识即可参加。

Abstract: This proposed tutorial focuses on Healthcare Domain Applications of NLP, what we have achieved around HealthcareNLP, and the challenges that lie ahead for the future. Existing reviews in this domain either overlook some important tasks, such as synthetic data generation for addressing privacy concerns, or explainable clinical NLP for improved integration and implementation, or fail to mention important methodologies, including retrieval augmented generation and the neural symbolic integration of LLMs and KGs. In light of this, the goal of this tutorial is to provide an introductory overview of the most important sub-areas of a patient- and resource-oriented HealthcareNLP, with three layers of hierarchy: data/resource layer: annotation guidelines, ethical approvals, governance, synthetic data; NLP-Eval layer: NLP tasks such as NER, RE, sentiment analysis, and linking/coding with categorised methods, leading to explainable HealthAI; patients layer: Patient Public Involvement and Engagement (PPIE), health literacy, translation, simplification, and summarisation (also NLP tasks), and shared decision-making support. A hands-on session will be included in the tutorial for the audience to use HealthcareNLP applications. The target audience includes NLP practitioners in the healthcare application domain, NLP researchers who are interested in domain applications, healthcare researchers, and students from NLP fields. The type of tutorial is "Introductory to CL/NLP topics (HealthcareNLP)" and the audience does not need prior knowledge to attend this. Tutorial materials: https://github.com/4dpicture/HealthNLP

</details>


### [9] [QSTN: A Modular Framework for Robust Questionnaire Inference with Large Language Models](https://arxiv.org/abs/2512.08646)
*Maximilian Kreutner,Jens Rupprecht,Georg Ahnert,Ahmed Salem,Markus Strohmaier*

Main category: cs.CL

TL;DR: QSTN是一个用于从问卷式提示系统生成响应的开源Python框架，支持LLMs的模拟调查和注释任务。


<details>
  <summary>Details</summary>
Motivation: 为了支持大规模语言模型（LLMs）在模拟调查和注释任务中的应用，需要一种能够系统生成问卷响应的工具。

Method: 引入QSTN框架，通过评估问卷展示、提示扰动和响应生成方法，进行大规模实验（超过4000万次调查响应）。

Result: 问题结构和响应生成方法对生成的调查响应与人类答案的一致性有显著影响，并且可以以较低的计算成本实现。

Conclusion: QSTN支持LLM研究的再现性和可靠性，并提供无需代码的用户界面，方便研究人员进行实验。

Abstract: We introduce QSTN, an open-source Python framework for systematically generating responses from questionnaire-style prompts to support in-silico surveys and annotation tasks with large language models (LLMs). QSTN enables robust evaluation of questionnaire presentation, prompt perturbations, and response generation methods. Our extensive evaluation ($>40 $ million survey responses) shows that question structure and response generation methods have a significant impact on the alignment of generated survey responses with human answers, and can be obtained for a fraction of the compute cost. In addition, we offer a no-code user interface that allows researchers to set up robust experiments with LLMs without coding knowledge. We hope that QSTN will support the reproducibility and reliability of LLM-based research in the future.

</details>


### [10] [Automatic Essay Scoring and Feedback Generation in Basque Language Learning](https://arxiv.org/abs/2512.08713)
*Ekhi Azurmendi,Xabier Arregi,Oier Lopez de Lacalle*

Main category: cs.CL

TL;DR: 本文介绍了首个面向巴斯克语C1水平自动作文评分（AES）和反馈生成的公开数据集，包含3200篇HABE文章，每篇都由专家评分并提供详细反馈。


<details>
  <summary>Details</summary>
Motivation: 解决巴斯克语等低资源语言在自动作文评分和反馈生成方面的数据缺乏问题，并提升模型在该任务上的表现。

Method: 使用RoBERTa-EusCrawl和Latxa 8B/70B等开源模型进行微调，结合自动一致性和专家验证的评估方法，对反馈生成进行评估。

Result: 微调后的Latxa模型在评分一致性和反馈质量方面超越了GPT-5和Claude Sonnet 4.5等先进闭源系统，能够生成更有教学意义的反馈。

Conclusion: 该数据集和基准测试为透明、可复现和基于教育的低资源语言NLP研究奠定了基础，特别是在巴斯克语方面。

Abstract: This paper introduces the first publicly available dataset for Automatic Essay Scoring (AES) and feedback generation in Basque, targeting the CEFR C1 proficiency level. The dataset comprises 3,200 essays from HABE, each annotated by expert evaluators with criterion specific scores covering correctness, richness, coherence, cohesion, and task alignment enriched with detailed feedback and error examples. We fine-tune open-source models, including RoBERTa-EusCrawl and Latxa 8B/70B, for both scoring and explanation generation. Our experiments show that encoder models remain highly reliable for AES, while supervised fine-tuning (SFT) of Latxa significantly enhances performance, surpassing state-of-the-art (SoTA) closed-source systems such as GPT-5 and Claude Sonnet 4.5 in scoring consistency and feedback quality. We also propose a novel evaluation methodology for assessing feedback generation, combining automatic consistency metrics with expert-based validation of extracted learner errors. Results demonstrate that the fine-tuned Latxa model produces criterion-aligned, pedagogically meaningful feedback and identifies a wider range of error types than proprietary models. This resource and benchmark establish a foundation for transparent, reproducible, and educationally grounded NLP research in low-resource languages such as Basque.

</details>


### [11] [Fluent Alignment with Disfluent Judges: Post-training for Lower-resource Languages](https://arxiv.org/abs/2512.08777)
*David Samuel,Lilja Øvrelid,Erik Velldal,Andrey Kutuzov*

Main category: cs.CL

TL;DR: 提出了一种针对低资源语言的训练后方法，能够在通过不流利的奖励模型进行对齐时保持语言模型的流畅性。


<details>
  <summary>Details</summary>
Motivation: 低资源语言缺乏由母语者撰写的数据集和能够生成流畅合成数据的语言模型，因此需要一种不依赖目标语言指令微调数据的流畅性偏好对齐方法。

Method: 使用一种on-policy训练方法，并与监督微调和机器翻译数据上的多语言微调两种常见方法进行比较。

Result: 在挪威书面语Bokmål上的案例研究表明，on-policy方法在母语者评估中显著优于其他方法。

Conclusion: on-policy训练方法在对齐低资源语言模型时至关重要，并且不依赖难以获取的数据。

Abstract: We propose a post-training method for lower-resource languages that preserves fluency of language models even when aligned by disfluent reward models. Preference-optimization is now a well-researched topic, but previous work has mostly addressed models for English and Chinese. Lower-resource languages lack both datasets written by native speakers and language models capable of generating fluent synthetic data. Thus, in this work, we focus on developing a fluent preference-aligned language model without any instruction-tuning data in the target language. Our approach uses an on-policy training method, which we compare with two common approaches: supervised finetuning on machine-translated data and multilingual finetuning. We conduct a case study on Norwegian Bokmål and evaluate fluency through native-speaker assessments. The results show that the on-policy aspect is crucial and outperforms the alternatives without relying on any hard-to-obtain data.

</details>


### [12] [A Systematic Evaluation of Preference Aggregation in Federated RLHF for Pluralistic Alignment of LLMs](https://arxiv.org/abs/2512.08786)
*Mahmoud Srewa,Tianyu Zhao,Salma Elmalaki*

Main category: cs.CL

TL;DR: 本文提出一种新颖的评估框架和自适应方案，以在联邦学习环境中更好地对齐大型语言模型与多样化的人类偏好。


<details>
  <summary>Details</summary>
Motivation: 在联邦学习中，标准方法往往无法充分代表多样化的观点，因此需要解决语言模型在多样化人类偏好下的对齐问题。

Method: 引入了一个全面评估框架，评估不同聚合策略下对齐质量和公平性之间的权衡。提出了一种自适应方案，基于群体的历史对齐表现动态调整偏好权重。

Result: 实验证明，自适应方法在保持竞争对齐分数的同时，始终实现更优的公平性。

Conclusion: 该研究为多样化人群中的LLM行为评估提供了稳健方法，并为开发真正多元化和公平对齐的模型提供了实用解决方案。

Abstract: This paper addresses the challenge of aligning large language models (LLMs) with diverse human preferences within federated learning (FL) environments, where standard methods often fail to adequately represent diverse viewpoints. We introduce a comprehensive evaluation framework that systematically assesses the trade-off between alignment quality and fairness when using different aggregation strategies for human preferences. In our federated setting, each group locally evaluates rollouts and produces reward signals, and the server aggregates these group-level rewards without accessing any raw data. Specifically, we evaluate standard reward aggregation techniques (min, max, and average) and introduce a novel adaptive scheme that dynamically adjusts preference weights based on a group's historical alignment performance. Our experiments on question-answering (Q/A) tasks using a PPO-based RLHF pipeline demonstrate that our adaptive approach consistently achieves superior fairness while maintaining competitive alignment scores. This work offers a robust methodology for evaluating LLM behavior across diverse populations and provides a practical solution for developing truly pluralistic and fairly aligned models.

</details>


### [13] [Do Depth-Grown Models Overcome the Curse of Depth? An In-Depth Analysis](https://arxiv.org/abs/2512.08819)
*Ferdinand Kapl,Emmanouil Angelis,Tobias Höppe,Kaitlin Maile,Johannes von Oswald,Nino Scherrer,Stefan Bauer*

Main category: cs.CL

TL;DR: 逐步增加Transformer的深度可以降低训练成本并提高推理性能。本文揭示了这种现象背后的机制，并提出了一种MIDAS的轻量级改进。


<details>
  <summary>Details</summary>
Motivation: 理解逐步增加深度带来的性能提升的机制，并解决传统非增长模型中深度利用不足的问题。

Method: 通过深度分析，研究逐步增加中间层对模型深度利用的影响，并改进MIDAS。

Result: 逐步增加深度提高了模型深度的利用效率，改变了残差流结构，促进了可置换计算块的形成。

Conclusion: 模型深度的逐步增长能够形成独特的计算电路，克服传统非增长模型的深度利用限制。

Abstract: Gradually growing the depth of Transformers during training can not only reduce training cost but also lead to improved reasoning performance, as shown by MIDAS (Saunshi et al., 2024). Thus far, however, a mechanistic understanding of these gains has been missing. In this work, we establish a connection to recent work showing that layers in the second half of non-grown, pre-layernorm Transformers contribute much less to the final output distribution than those in the first half - also known as the Curse of Depth (Sun et al., 2025, Csordás et al., 2025). Using depth-wise analyses, we demonstrate that growth via gradual middle stacking yields more effective utilization of model depth, alters the residual stream structure, and facilitates the formation of permutable computational blocks. In addition, we propose a lightweight modification of MIDAS that yields further improvements in downstream reasoning benchmarks. Overall, this work highlights how the gradual growth of model depth can lead to the formation of distinct computational circuits and overcome the limited depth utilization seen in standard non-grown models.

</details>


### [14] [Toward Faithful Retrieval-Augmented Generation with Sparse Autoencoders](https://arxiv.org/abs/2512.08892)
*Guangzhi Xiong,Zhenghao He,Bohan Liu,Sanchit Sinha,Aidong Zhang*

Main category: cs.CL

TL;DR: 该论文介绍了RAGLens，一种利用稀疏自动编码器(SAEs)识别大型语言模型内部激活特征以检测RAG幻觉的轻量级方法。


<details>
  <summary>Details</summary>
Motivation: RAG在提高LLMs事实性的同时，依然存在faithfulness failures的问题。现有的幻觉检测方法要么需要大量标注数据，要么依赖外部LLM判断，成本高且准确率有限。

Method: 利用稀疏自动编码器(SAEs)分离LLM内部激活，通过信息性特征选择及加性特征建模，开发出RAGLens，一个轻量级的幻觉检测器。

Result: RAGLens在检测性能上优于现有方法，并为决策提供可解释性依据，有效缓解RAG不忠实问题。

Conclusion: RAGLens利用LLM内部表示，不仅提高了幻觉检测的准确性，而且提供了可解释性，并揭示了LLM中幻觉相关信号的分布特征。

Abstract: Retrieval-Augmented Generation (RAG) improves the factuality of large language models (LLMs) by grounding outputs in retrieved evidence, but faithfulness failures, where generations contradict or extend beyond the provided sources, remain a critical challenge. Existing hallucination detection methods for RAG often rely either on large-scale detector training, which requires substantial annotated data, or on querying external LLM judges, which leads to high inference costs. Although some approaches attempt to leverage internal representations of LLMs for hallucination detection, their accuracy remains limited. Motivated by recent advances in mechanistic interpretability, we employ sparse autoencoders (SAEs) to disentangle internal activations, successfully identifying features that are specifically triggered during RAG hallucinations. Building on a systematic pipeline of information-based feature selection and additive feature modeling, we introduce RAGLens, a lightweight hallucination detector that accurately flags unfaithful RAG outputs using LLM internal representations. RAGLens not only achieves superior detection performance compared to existing methods, but also provides interpretable rationales for its decisions, enabling effective post-hoc mitigation of unfaithful RAG. Finally, we justify our design choices and reveal new insights into the distribution of hallucination-related signals within LLMs. The code is available at https://github.com/Teddy-XiongGZ/RAGLens.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [15] [Impact of Data-Oriented and Object-Oriented Design on Performance and Cache Utilization with Artificial Intelligence Algorithms in Multi-Threaded CPUs](https://arxiv.org/abs/2512.07841)
*Gabriel M. Arantes,Richard F. Pinto,Bruno L. Dalmazo,Eduardo N. Borges,Giancarlo Lucca,Viviane L. D. de Mattos,Fabian C. Cardoso,Rafael A. Berri*

Main category: cs.AI

TL;DR: 该研究分析了多核CPU与内存之间性能差距，评估了数据导向设计（DOD）与面向对象设计（OOD）在多线程环境下的性能表现。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于硬件性能与软件设计之间的差距，特别是在多核CPU和内存之间的性能差距，需要优化缓存利用率和效率。

Method: 开发了四种版本的A*搜索算法：单线程OOD（ST-OOD）、单线程DOD（ST-DOD）、多线程OOD（MT-OOD）和多线程DOD（MT-DOD）。评估指标包括执行时间、内存使用和CPU缓存未命中次数。

Result: 在多线程测试中，DOD实现了更快的执行时间和较少的原始系统调用和缓存未命中。单线程版本在任务管理开销方面优于多线程版本。

Conclusion: 尽管在简单算法中性能差异可能看起来微小，但DOD在关键指标上的持续优势突显了其架构上的优越性，表明DOD在复杂、大规模AI和并行计算任务中更为有效。

Abstract: The growing performance gap between multi-core CPUs and main memory necessitates hardware-aware software design paradigms. This study provides a comprehensive performance analysis of Data Oriented Design (DOD) versus the traditional Object-Oriented Design (OOD), focusing on cache utilization and efficiency in multi-threaded environments. We developed and compared four distinct versions of the A* search algorithm: single-threaded OOD (ST-OOD), single-threaded DOD (ST-DOD), multi-threaded OOD (MT-OOD), and multi-threaded DOD (MT-DOD). The evaluation was based on metrics including execution time, memory usage, and CPU cache misses. In multi-threaded tests, the DOD implementation demonstrated considerable performance gains, with faster execution times and a lower number of raw system calls and cache misses. While OOD occasionally showed marginal advantages in memory usage or percentage-based cache miss rates, DOD's efficiency in data-intensive operations was more evident. Furthermore, our findings reveal that for a fine-grained task like the A* algorithm, the overhead associated with thread management led to single-threaded versions significantly outperforming their multi-threaded counterparts in both paradigms. We conclude that even when performance differences appear subtle in simple algorithms, the consistent advantages of DOD in critical metrics highlight its foundational architectural superiority, suggesting it is a more effective approach for maximizing hardware efficiency in complex, large-scale AI and parallel computing tasks.

</details>


### [16] [SkipKV: Selective Skipping of KV Generation and Storage for Efficient Inference with Large Reasoning Models](https://arxiv.org/abs/2512.07993)
*Jiayi Tian,Seyedarmin Azizi,Yequan Zhao,Erfan Baghaei Potraghloo,Sean McPherson,Sharath Nittur Sridhar,Zhengyang Wang,Zheng Zhang,Massoud Pedram,Souvik Kundu*

Main category: cs.AI

TL;DR: SkipKV是一种无需训练、粗粒度句子级别KV缓存压缩方法，通过句子评分和动态调整隐藏激活状态，提升CoT推理效率。


<details>
  <summary>Details</summary>
Motivation: 现有KV缓存驱逐方法在CoT推理中由于不稳定的token级评分和填充token导致的KV预算减少，难以维持多批次推理的准确性，并常生成更长的序列。

Method: SkipKV引入了句子评分指标以识别和删除高相似度句子，同时动态调整steering vector以更新隐藏激活状态，实现选择性的驱逐和生成。

Result: 在多个推理基准上，SkipKV相比其他方法在相似压缩预算下能保持最高26.7%的准确率，生成长度减少最多1.6倍，吞吐量提高最多1.7倍。

Conclusion: SkipKV通过粗粒度句子级别的KV压缩和动态调整策略，有效提升了LRMs在CoT推理中的效率，减少了冗余生成，同时保持了语义连贯性。

Abstract: Large reasoning models (LRMs) often cost significant key-value (KV) cache overhead, due to their linear growth with the verbose chain-of-thought (CoT) reasoning process. This costs both memory and throughput bottleneck limiting their efficient deployment. Towards reducing KV cache size during inference, we first investigate the effectiveness of existing KV cache eviction methods for CoT reasoning. Interestingly, we find that due to unstable token-wise scoring and the reduced effective KV budget caused by padding tokens, state-of-the-art (SoTA) eviction methods fail to maintain accuracy in the multi-batch setting. Additionally, these methods often generate longer sequences than the original model, as semantic-unaware token-wise eviction leads to repeated revalidation during reasoning. To address these issues, we present \textbf{SkipKV}, a \textbf{\textit{training-free}} KV compression method for selective \textit{eviction} and \textit{generation} operating at a coarse-grained sentence-level sequence removal for efficient CoT reasoning. In specific, it introduces a \textit{sentence-scoring metric} to identify and remove highly similar sentences while maintaining semantic coherence. To suppress redundant generation, SkipKV dynamically adjusts a steering vector to update the hidden activation states during inference enforcing the LRM to generate concise response. Extensive evaluations on multiple reasoning benchmarks demonstrate the effectiveness of SkipKV in maintaining up to $\mathbf{26.7}\%$ improved accuracy compared to the alternatives, at a similar compression budget. Additionally, compared to SoTA, SkipKV yields up to $\mathbf{1.6}\times$ fewer generation length while improving throughput up to $\mathbf{1.7}\times$.

</details>


### [17] [Toward an AI Reasoning-Enabled System for Patient-Clinical Trial Matching](https://arxiv.org/abs/2512.08026)
*Caroline N. Leach,Mitchell A. Klusty,Samuel E. Armstrong,Justine C. Pickarski,Kristen L. Hankins,Emily B. Collier,Maya Shah,Aaron D. Mullen,V. K. Cody Bumgardner*

Main category: cs.AI

TL;DR: 该论文介绍了一种利用AI增强的患者与临床试验匹配系统，旨在解决当前手动筛选过程耗时和资源密集的问题。


<details>
  <summary>Details</summary>
Motivation: 筛选临床试验合格患者目前是一个手动、耗时和资源密集的过程，存在整合异构电子健康记录（EHR）数据、促进专家审查和维护严格安全标准的挑战。

Method: 该系统利用开源、支持推理的大语言模型（LLMs），超越了二分类方法，生成带有可解释推理链的结构化资格评估，支持人机协作审查。

Result: 系统将资格表示为动态状态，而不是固定判定，识别现有匹配并提供可操作的建议，可能使患者在未来符合资格。

Conclusion: 该系统的目标是减少协调员的工作负担，智能扩展每例患者考虑的试验范围，并保证所有AI生成输出的全面可审计性。

Abstract: Screening patients for clinical trial eligibility remains a manual, time-consuming, and resource-intensive process. We present a secure, scalable proof-of-concept system for Artificial Intelligence (AI)-augmented patient-trial matching that addresses key implementation challenges: integrating heterogeneous electronic health record (EHR) data, facilitating expert review, and maintaining rigorous security standards. Leveraging open-source, reasoning-enabled large language models (LLMs), the system moves beyond binary classification to generate structured eligibility assessments with interpretable reasoning chains that support human-in-the-loop review. This decision support tool represents eligibility as a dynamic state rather than a fixed determination, identifying matches when available and offering actionable recommendations that could render a patient eligible in the future. The system aims to reduce coordinator burden, intelligently broaden the set of trials considered for each patient and guarantee comprehensive auditability of all AI-generated outputs.

</details>


### [18] [Large Language Models for Education and Research: An Empirical and User Survey-based Analysis](https://arxiv.org/abs/2512.08057)
*Md Mostafizer Rahman,Ariful Islam Shiplu,Md Faizul Ibne Amin,Yutaka Watanobe,Lu Peng*

Main category: cs.AI

TL;DR: 本研究评估了ChatGPT和DeepSeek在大语言模型（LLM）应用于教育和研究中的表现，通过背景技术分析和实验比较了模型准确性、计算效率和用户体验。


<details>
  <summary>Details</summary>
Motivation: 随着预训练大语言模型在多个领域取得成功，特别是在教育和研究中的重要性日益增加，有必要对当前主流模型在不同任务中的表现进行综合评估。

Method: 通过背景技术分析和实证实验，结合真实用户的调查，评估了ChatGPT和DeepSeek在文本生成、编程和专门问题解决方面的表现。

Result: ChatGPT在通用语言理解和文本生成方面表现出色，而DeepSeek在编程任务中表现更优，因其注重效率的设计。两个模型在医学诊断输出和复杂数学问题解决方面均表现良好。

Conclusion: 该研究通过实验和用户调查揭示了ChatGPT和DeepSeek在实际教育和研究中的优势与局限，为模型选择和应用提供了重要参考。

Abstract: Pretrained Large Language Models (LLMs) have achieved remarkable success across diverse domains, with education and research emerging as particularly impactful areas. Among current state-of-the-art LLMs, ChatGPT and DeepSeek exhibit strong capabilities in mathematics, science, medicine, literature, and programming. In this study, we present a comprehensive evaluation of these two LLMs through background technology analysis, empirical experiments, and a real-world user survey. The evaluation explores trade-offs among model accuracy, computational efficiency, and user experience in educational and research affairs. We benchmarked these LLMs performance in text generation, programming, and specialized problem-solving. Experimental results show that ChatGPT excels in general language understanding and text generation, while DeepSeek demonstrates superior performance in programming tasks due to its efficiency- focused design. Moreover, both models deliver medically accurate diagnostic outputs and effectively solve complex mathematical problems. Complementing these quantitative findings, a survey of students, educators, and researchers highlights the practical benefits and limitations of these models, offering deeper insights into their role in advancing education and research.

</details>


### [19] [Scalable Back-End for an AI-Based Diabetes Prediction Application](https://arxiv.org/abs/2512.08147)
*Henry Anand Septian Radityo,Bernardus Willson,Reynard Tanadi,Latifa Dwiyanti,Saiful Akbar*

Main category: cs.AI

TL;DR: 本文开发并评估了一个用于移动糖尿病预测应用的可扩展后端系统，实现了低于5%的故障率和低于1000ms的平均延迟。


<details>
  <summary>Details</summary>
Motivation: 由于糖尿病全球患病率上升，早期检测变得至关重要。AI驱动的预测应用需要一个响应迅速且可扩展的后端架构来服务大量用户。

Method: 该架构采用了水平扩展、数据库分片和通过消息队列的异步通信。

Result: 性能评估显示，系统24个功能中的20个（83%）达到了指定的性能目标。系统能够处理多达10,000名并发用户，验证了其可扩展性。

Conclusion: 使用RabbitMQ实现异步通信被证明对最小化计算密集型预测请求的错误率至关重要，通过排队请求并在高负载下防止数据丢失，确保了系统可靠性。

Abstract: The rising global prevalence of diabetes necessitates early detection to prevent severe complications. While AI-powered prediction applications offer a promising solution, they require a responsive and scalable back-end architecture to serve a large user base effectively. This paper details the development and evaluation of a scalable back-end system designed for a mobile diabetes prediction application. The primary objective was to maintain a failure rate below 5% and an average latency of under 1000 ms. The architecture leverages horizontal scaling, database sharding, and asynchronous communication via a message queue. Performance evaluation showed that 83% of the system's features (20 out of 24) met the specified performance targets. Key functionalities such as user profile management, activity tracking, and read-intensive prediction operations successfully achieved the desired performance. The system demonstrated the ability to handle up to 10,000 concurrent users without issues, validating its scalability. The implementation of asynchronous communication using RabbitMQ proved crucial in minimizing the error rate for computationally intensive prediction requests, ensuring system reliability by queuing requests and preventing data loss under heavy load.

</details>


### [20] [Beyond Traditional Diagnostics: Transforming Patient-Side Information into Predictive Insights with Knowledge Graphs and Prototypes](https://arxiv.org/abs/2512.08261)
*Yibowen Zhao,Yinan Zhang,Zhixiang Su,Lizhen Cui,Chunyan Miao*

Main category: cs.AI

TL;DR: 提出了一种新的框架KPI，通过整合医学知识图谱、疾病原型和对比学习，增强疾病预测的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在疾病预测中存在疾病分布不平衡和缺乏可解释性等挑战，导致预测结果有偏或不可靠。

Method: KPI框架通过整合结构化医学知识构建疾病知识图谱，建立疾病原型，并使用对比学习提高预测准确性，同时利用大语言模型生成个性化医学解释。

Result: 在真实世界数据集上的广泛实验表明，KPI在预测准确性方面优于现有方法，并提供与患者叙述高度一致的临床有效解释。

Conclusion: KPI框架在提高预测准确性和可解释性方面表现出色，具有在患者中心医疗中实际应用的潜力。

Abstract: Predicting diseases solely from patient-side information, such as demographics and self-reported symptoms, has attracted significant research attention due to its potential to enhance patient awareness, facilitate early healthcare engagement, and improve healthcare system efficiency. However, existing approaches encounter critical challenges, including imbalanced disease distributions and a lack of interpretability, resulting in biased or unreliable predictions. To address these issues, we propose the Knowledge graph-enhanced, Prototype-aware, and Interpretable (KPI) framework. KPI systematically integrates structured and trusted medical knowledge into a unified disease knowledge graph, constructs clinically meaningful disease prototypes, and employs contrastive learning to enhance predictive accuracy, which is particularly important for long-tailed diseases. Additionally, KPI utilizes large language models (LLMs) to generate patient-specific, medically relevant explanations, thereby improving interpretability and reliability. Extensive experiments on real-world datasets demonstrate that KPI outperforms state-of-the-art methods in predictive accuracy and provides clinically valid explanations that closely align with patient narratives, highlighting its practical value for patient-centered healthcare delivery.

</details>


### [21] [Reasoning Models Ace the CFA Exams](https://arxiv.org/abs/2512.08270)
*Jaisal Patel,Yunzhe Chen,Kaiwen He,Keyi Wang,David Li,Kairong Xiao,Xiao-Yang Liu*

Main category: cs.AI

TL;DR: 最新推理模型在CFA模拟考试中表现优异，多数模型通过所有三个级别。


<details>
  <summary>Details</summary>
Motivation: 以往研究表明大语言模型在CFA考试中表现不佳，但最新推理模型在其他专业考试中表现强劲，因此有必要重新评估其在CFA考试中的表现。

Method: 在包含980个问题的CFA模拟考试（涵盖三个级别）上评估了当前最先进的推理模型，并使用先前研究中的通过/未通过标准进行比较。

Result: 多数模型通过所有三个级别，其中Gemini 3.0 Pro在Level I中得分97.6%，GPT-5在Level II中得分94.3%，Gemini 2.5 Pro在Level III选择题中得分86.4%，Gemini 3.0 Pro在Level III建构题中得分92.0%。

Conclusion: 最新推理模型在CFA考试中表现突出，显著优于以往的大语言模型。

Abstract: Previous research has reported that large language models (LLMs) demonstrate poor performance on the Chartered Financial Analyst (CFA) exams. However, recent reasoning models have achieved strong results on graduate-level academic and professional examinations across various disciplines. In this paper, we evaluate state-of-the-art reasoning models on a set of mock CFA exams consisting of 980 questions across three Level I exams, two Level II exams, and three Level III exams. Using the same pass/fail criteria from prior studies, we find that most models clear all three levels. The models that pass, ordered by overall performance, are Gemini 3.0 Pro, Gemini 2.5 Pro, GPT-5, Grok 4, Claude Opus 4.1, and DeepSeek-V3.1. Specifically, Gemini 3.0 Pro achieves a record score of 97.6% on Level I. Performance is also strong on Level II, led by GPT-5 at 94.3%. On Level III, Gemini 2.5 Pro attains the highest score with 86.4% on multiple-choice questions while Gemini 3.0 Pro achieves 92.0% on constructed-response questions.

</details>


### [22] [Towards a Science of Scaling Agent Systems](https://arxiv.org/abs/2512.08296)
*Yubin Kim,Ken Gu,Chanwoo Park,Chunjong Park,Samuel Schmidgall,A. Ali Heydari,Yao Yan,Zhihan Zhang,Yuchen Zhuang,Mark Malhotra,Paul Pu Liang,Hae Won Park,Yuzhe Yang,Xuhai Xu,Yilun Du,Shwetak Patel,Tim Althoff,Daniel McDuff,Xin Liu*

Main category: cs.AI

TL;DR: 本文通过实证方法研究了基于语言模型的多智能体系统的性能扩展原则，提出了可预测的协调策略框架。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统已成为AI应用的主流范式，但其性能决定因素尚未被充分探索，实践者往往依赖启发式方法而非原则性设计选择。

Method: 在四个不同的基准测试（Finance-Agent, BrowseComp-Plus, PlanCraft, Workbench）上，使用五种典型架构（Single, Independent, Centralized, Decentralized, Hybrid）和三个LLM家族，进行了180种配置的控制性评估。通过效率、开销、误差放大和冗余等实证协调指标，建立了一个预测模型。

Result: 1. 工具-协调权衡：固定计算预算下，工具密集型任务更易受多智能体开销影响；2. 能力饱和：当单智能体基线超过约45%时，协调收益递减或变为负值；3. 拓扑依赖的误差放大：独立智能体误差放大17.2倍，而集中式协调限制为4.4倍。集中式协调在并行任务上提升性能80.9%，分散式协调在动态网页导航上表现更佳。

Conclusion: 该框架能预测87%的留出配置的最优协调策略，为基于可测量任务特性的智能体扩展提供了预测原则。

Abstract: Agents, language model (LM)-based systems that are capable of reasoning, planning, and acting are becoming the dominant paradigm for real-world AI applications. Despite this widespread adoption, the principles that determine their performance remain underexplored, leaving practitioners to rely on heuristics rather than principled design choices. We address this gap by deriving quantitative scaling principles for agent systems. We evaluate this across four diverse benchmarks: Finance-Agent, BrowseComp-Plus, PlanCraft, and Workbench. Using five canonical architectures (Single, Independent, Centralized, Decentralized, Hybrid) instantiated across three LLM families, we perform a controlled evaluation spanning 180 configurations with standardized tools and token budgets. We derive a predictive model using empirical coordination metrics, including efficiency, overhead, error amplification, and redundancy, that achieves cross-validated R^2=0.513. We identify three dominant effects: (1) a tool-coordination trade-off: under fixed computational budgets, tool-heavy tasks suffer disproportionately from multi-agent overhead. (2) a capability saturation: coordination yields diminishing or negative returns (beta=-0.408, p<0.001) once single-agent baselines exceed ~45%. (3) topology-dependent error amplification: independent agents amplify errors 17.2x through unchecked propagation, while centralized coordination contains this to 4.4x. Centralized coordination improves performance by 80.9% on parallelizable tasks like financial reasoning, while decentralized coordination excels on dynamic web navigation (+9.2% vs. +0.2%). Yet for sequential reasoning tasks, all multi-agent variants degraded performance by 39-70%. The framework predicts the optimal coordination strategy for 87% of held-out configurations, providing a predictive principle of agentic scaling based on measurable task properties.

</details>


### [23] [rSIM: Incentivizing Reasoning Capabilities of LLMs via Reinforced Strategy Injection](https://arxiv.org/abs/2512.08300)
*Sijia Chen,Baochun Li,Di Niu*

Main category: cs.AI

TL;DR: 该论文提出了一种新的强化策略注入机制（rSIM），通过多智能体强化学习训练一个小型规划器，引导大语言模型的思维链自适应注入推理策略，从而将其转变为推理语言模型（RLM）。


<details>
  <summary>Details</summary>
Motivation: 大语言模型通过强化学习进化为具有‘顿悟’时刻的推理语言模型，这启发了研究者开发一种机制，使任何大语言模型都能通过注入推理策略成为推理语言模型。

Method: 论文提出rSIM机制，采用领导者-追随者框架，通过多智能体强化学习联合训练一个小型规划器（领导者）和大语言模型（追随者），并采用基于规则的奖励。

Result: rSIM使Qwen2.5-0.5B成为推理语言模型，显著优于Qwen2.5-14B。规划器具有良好的泛化能力，只需训练一次即可作为插件提升现有大语言模型的推理能力，并支持持续学习。

Conclusion: rSIM机制通过小型规划器引导大语言模型进行推理策略注入，不仅提升了模型性能，还具有良好的泛化性和持续学习能力，为提升大语言模型推理能力提供了一种有效途径。

Abstract: Large language models (LLMs) are post-trained through reinforcement learning (RL) to evolve into Reasoning Language Models (RLMs), where the hallmark of this advanced reasoning is ``aha'' moments when they start to perform strategies, such as self-reflection and deep thinking, within chain of thoughts (CoTs). Motivated by this, this paper proposes a novel reinforced strategy injection mechanism (rSIM), that enables any LLM to become an RLM by employing a small planner to guide the LLM's CoT through the adaptive injection of reasoning strategies. To achieve this, the planner (leader agent) is jointly trained with an LLM (follower agent) using multi-agent RL (MARL), based on a leader-follower framework and straightforward rule-based rewards. Experimental results show that rSIM enables Qwen2.5-0.5B to become an RLM and significantly outperform Qwen2.5-14B. Moreover, the planner is generalizable: it only needs to be trained once and can be applied as a plug-in to substantially improve the reasoning capabilities of existing LLMs. In addition, the planner supports continual learning across various tasks, allowing its planning abilities to gradually improve and generalize to a wider range of problems.

</details>


### [24] [Predicting California Bearing Ratio with Ensemble and Neural Network Models: A Case Study from Türkiye](https://arxiv.org/abs/2512.08340)
*Abdullah Hulusi Kökçam,Uğur Dağdeviren,Talas Fikret Kurnaz,Alparslan Serhat Demir,Caner Erden*

Main category: cs.AI

TL;DR: 该研究利用机器学习（ML）技术，提出了一个用于预测加州承载比（CBR）的综合框架，使用从土耳其不同地理气候区域收集的382个土壤样本数据集。


<details>
  <summary>Details</summary>
Motivation: 传统的CBR测定方法耗时且成本高，尤其是在大规模或多样化的土壤剖面上，因此需要一种更高效和精确的替代方法。

Method: 研究测试了12种ML算法，包括决策树、随机森林、极端树、梯度提升、xgboost等，并在监督学习环境中利用土壤的物理化学特性进行多维特征表示。

Result: 随机森林回归器表现最佳，训练、验证和测试的R2分数分别为0.95、0.76和0.83，显示出强大的非线性映射能力。

Conclusion: 该研究支持将智能、以数据为中心的模型集成到岩土工程中，为传统方法提供了有效的替代，并推动基础设施分析和设计的数字化转型。

Abstract: The California Bearing Ratio (CBR) is a key geotechnical indicator used to assess the load-bearing capacity of subgrade soils, especially in transportation infrastructure and foundation design. Traditional CBR determination relies on laboratory penetration tests. Despite their accuracy, these tests are often time-consuming, costly, and can be impractical, particularly for large-scale or diverse soil profiles. Recent progress in artificial intelligence, especially machine learning (ML), has enabled data-driven approaches for modeling complex soil behavior with greater speed and precision. This study introduces a comprehensive ML framework for CBR prediction using a dataset of 382 soil samples collected from various geoclimatic regions in Türkiye. The dataset includes physicochemical soil properties relevant to bearing capacity, allowing multidimensional feature representation in a supervised learning context. Twelve ML algorithms were tested, including decision tree, random forest, extra trees, gradient boosting, xgboost, k-nearest neighbors, support vector regression, multi-layer perceptron, adaboost, bagging, voting, and stacking regressors. Each model was trained, validated, and evaluated to assess its generalization and robustness. Among them, the random forest regressor performed the best, achieving strong R2 scores of 0.95 (training), 0.76 (validation), and 0.83 (test). These outcomes highlight the model's powerful nonlinear mapping ability, making it a promising tool for predictive geotechnical tasks. The study supports the integration of intelligent, data-centric models in geotechnical engineering, offering an effective alternative to traditional methods and promoting digital transformation in infrastructure analysis and design.

</details>


### [25] [Soil Compaction Parameters Prediction Based on Automated Machine Learning Approach](https://arxiv.org/abs/2512.08343)
*Caner Erden,Alparslan Serhat Demir,Abdullah Hulusi Kokcam,Talas Fikret Kurnaz,Ugur Dagdeviren*

Main category: cs.AI

TL;DR: 该论文提出了一种自动机器学习（AutoML）方法来预测土壤的最佳含水量（OMC）和最大干密度（MDD），并发现XGBoost算法在预测中表现最好。


<details>
  <summary>Details</summary>
Motivation: 传统实验室实验方法劳动强度大，经验回归模型在不同土壤类型上的适用性和准确性有限，现有ML模型在预测准确性和泛化能力方面存在问题。

Method: 采用自动机器学习（AutoML）方法自动选择算法和优化超参数，通过广泛实验评估不同算法的性能，最终选择XGBoost算法。

Result: XGBoost算法在独立数据集上预测MDD的R平方值为80.4%，预测OMC的R平方值为89.1%，表现最佳。

Conclusion: AutoML方法在预测不同土壤类型的压实参数方面非常有效，且使用异质数据集可以提高ML模型的泛化和性能，从而提升建筑实践的效率和可靠性。

Abstract: Soil compaction is critical in construction engineering to ensure the stability of structures like road embankments and earth dams. Traditional methods for determining optimum moisture content (OMC) and maximum dry density (MDD) involve labor-intensive laboratory experiments, and empirical regression models have limited applicability and accuracy across diverse soil types. In recent years, artificial intelligence (AI) and machine learning (ML) techniques have emerged as alternatives for predicting these compaction parameters. However, ML models often struggle with prediction accuracy and generalizability, particularly with heterogeneous datasets representing various soil types. This study proposes an automated machine learning (AutoML) approach to predict OMC and MDD. AutoML automates algorithm selection and hyperparameter optimization, potentially improving accuracy and scalability. Through extensive experimentation, the study found that the Extreme Gradient Boosting (XGBoost) algorithm provided the best performance, achieving R-squared values of 80.4% for MDD and 89.1% for OMC on a separate dataset. These results demonstrate the effectiveness of AutoML in predicting compaction parameters across different soil types. The study also highlights the importance of heterogeneous datasets in improving the generalization and performance of ML models. Ultimately, this research contributes to more efficient and reliable construction practices by enhancing the prediction of soil compaction parameters.

</details>


### [26] [DeepFeature: Iterative Context-aware Feature Generation for Wearable Biosignals](https://arxiv.org/abs/2512.08379)
*Kaiwei Liu,Yuting He,Bufang Yang,Mu Yuan,Chun Man Victor Wong,Ho Pong Andrew Sze,Zhenyu Yan,Hongkai Chen*

Main category: cs.AI

TL;DR: 提出了一种新颖的框架DeepFeature，利用大语言模型生成可穿戴生物信号的特征。


<details>
  <summary>Details</summary>
Motivation: 当前的特征提取方法缺乏任务特定的上下文知识，难以在高维特征空间中确定最佳设置，并容易产生代码生成和自动化错误。

Method: DeepFeature引入多源特征生成机制，整合专家知识和任务设置，并通过迭代特征精炼过程，使用基于特征评估的反馈进行特征重选。同时采用多层过滤和验证方法，实现稳健的特征到代码的转换。

Result: 在八个不同任务中，DeepFeature相比基线方法实现了4.21-9.67%的AUROC平均提升，并在五个任务上优于最先进的方法，其余任务性能相当。

Conclusion: DeepFeature是一个有效的、上下文感知的特征生成框架，能显著提升可穿戴生物信号在医疗应用中的性能。

Abstract: Biosignals collected from wearable devices are widely utilized in healthcare applications. Machine learning models used in these applications often rely on features extracted from biosignals due to their effectiveness, lower data dimensionality, and wide compatibility across various model architectures. However, existing feature extraction methods often lack task-specific contextual knowledge, struggle to identify optimal feature extraction settings in high-dimensional feature space, and are prone to code generation and automation errors. In this paper, we propose DeepFeature, the first LLM-empowered, context-aware feature generation framework for wearable biosignals. DeepFeature introduces a multi-source feature generation mechanism that integrates expert knowledge with task settings. It also employs an iterative feature refinement process that uses feature assessment-based feedback for feature re-selection. Additionally, DeepFeature utilizes a robust multi-layer filtering and verification approach for robust feature-to-code translation to ensure that the extraction functions run without crashing. Experimental evaluation results show that DeepFeature achieves an average AUROC improvement of 4.21-9.67% across eight diverse tasks compared to baseline methods. It outperforms state-of-the-art approaches on five tasks while maintaining comparable performance on the remaining tasks.

</details>


### [27] [Using reinforcement learning to probe the role of feedback in skill acquisition](https://arxiv.org/abs/2512.08463)
*Antonio Terpin,Raffaello D'Andrea*

Main category: cs.AI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Many high-performance human activities are executed with little or no external feedback: think of a figure skater landing a triple jump, a pitcher throwing a curveball for a strike, or a barista pouring latte art. To study the process of skill acquisition under fully controlled conditions, we bypass human subjects. Instead, we directly interface a generalist reinforcement learning agent with a spinning cylinder in a tabletop circulating water channel to maximize or minimize drag. This setup has several desirable properties. First, it is a physical system, with the rich interactions and complex dynamics that only the physical world has: the flow is highly chaotic and extremely difficult, if not impossible, to model or simulate accurately. Second, the objective -- drag minimization or maximization -- is easy to state and can be captured directly in the reward, yet good strategies are not obvious beforehand. Third, decades-old experimental studies provide recipes for simple, high-performance open-loop policies. Finally, the setup is inexpensive and far easier to reproduce than human studies. In our experiments we find that high-dimensional flow feedback lets the agent discover high-performance drag-control strategies with only minutes of real-world interaction. When we later replay the same action sequences without any feedback, we obtain almost identical performance. This shows that feedback, and in particular flow feedback, is not needed to execute the learned policy. Surprisingly, without flow feedback during training the agent fails to discover any well-performing policy in drag maximization, but still succeeds in drag minimization, albeit more slowly and less reliably. Our studies show that learning a high-performance skill can require richer information than executing it, and learning conditions can be kind or wicked depending solely on the goal, not on dynamics or policy complexity.

</details>


### [28] [Principles2Plan: LLM-Guided System for Operationalising Ethical Principles into Plans](https://arxiv.org/abs/2512.08536)
*Tammy Zhong,Yang Song,Maurice Pagnucco*

Main category: cs.AI

TL;DR: 介绍了一个名为 Principles2Plan 的系统，该系统通过人和大型语言模型（LLM）协作生成情境敏感的伦理规则，以指导自动化规划。


<details>
  <summary>Details</summary>
Motivation: 现有自动化规划工具缺乏对伦理意识的支持，而手动指定伦理规则既耗时又高度依赖情境。因此，需要一种更实用的方法来实现伦理自动化规划。

Method: 提出 Principles2Plan，一个交互式研究原型，通过领域专家提供规划领域、问题细节和高层次伦理原则，系统生成可操作的伦理规则，用户可以审查、优化这些规则，并提交给规划器生成符合伦理的计划。

Result: 展示了 Principles2Plan 能够通过人和 LLM 协作生成基于原则的规则，从而支持经典规划情境下的伦理规则生成。

Conclusion: Principles2Plan 展示了人和 LLM 协作在伦理自动化规划中的潜力，使这一过程变得更加实用和可行。

Abstract: Ethical awareness is critical for robots operating in human environments, yet existing automated planning tools provide little support. Manually specifying ethical rules is labour-intensive and highly context-specific. We present Principles2Plan, an interactive research prototype demonstrating how a human and a Large Language Model (LLM) can collaborate to produce context-sensitive ethical rules and guide automated planning. A domain expert provides the planning domain, problem details, and relevant high-level principles such as beneficence and privacy. The system generates operationalisable ethical rules consistent with these principles, which the user can review, prioritise, and supply to a planner to produce ethically-informed plans. To our knowledge, no prior system supports users in generating principle-grounded rules for classical planning contexts. Principles2Plan showcases the potential of human-LLM collaboration for making ethical automated planning more practical and feasible.

</details>


### [29] [CogMCTS: A Novel Cognitive-Guided Monte Carlo Tree Search Framework for Iterative Heuristic Evolution with Large Language Models](https://arxiv.org/abs/2512.08609)
*Hui Wang,Yang Liu,Xiaoyu Zhang,Chaoxu Mu*

Main category: cs.AI

TL;DR: 本文提出了一种新颖的认知引导MCTS框架（CogMCTS），用于自动启发式优化。


<details>
  <summary>Details</summary>
Motivation: 现有的基于LLM的进化方法易陷入局部最优，而结合MCTS虽能改善探索与利用的平衡，但在多轮认知整合和搜索多样性方面仍有限制。

Method: CogMCTS将LLMs的认知指导机制与MCTS紧密结合，采用多轮认知反馈、双轨节点扩展、精英启发式管理和策略性变异等技术，动态改进启发式生成。

Result: 实验结果表明，CogMCTS在稳定性、效率和解决方案质量方面优于现有的基于LLM的AHD方法。

Conclusion: CogMCTS通过紧密整合认知指导和MCTS，有效提升了自动启发式优化的性能。

Abstract: Automatic Heuristic Design (AHD) is an effective1 framework for solving complex optimization prob-2 lems. The development of large language mod-3 els (LLMs) enables the automated generation of4 heuristics. Existing LLM-based evolutionary meth-5 ods rely on population strategies and are prone6 to local optima. Integrating LLMs with Monte7 Carlo Tree Search (MCTS) improves the trade-off8 between exploration and exploitation, but multi-9 round cognitive integration remains limited and10 search diversity is constrained. To overcome these11 limitations, this paper proposes a novel cognitive-12 guided MCTS framework (CogMCTS). CogMCTS13 tightly integrates the cognitive guidance mecha-14 nism of LLMs with MCTS to achieve efficient au-15 tomated heuristic optimization. The framework16 employs multi-round cognitive feedback to incor-17 porate historical experience, node information, and18 negative outcomes, dynamically improving heuris-19 tic generation. Dual-track node expansion com-20 bined with elite heuristic management balances the21 exploration of diverse heuristics and the exploita-22 tion of high-quality experience. In addition, strate-23 gic mutation modifies the heuristic forms and pa-24 rameters to further enhance the diversity of the so-25 lution and the overall optimization performance.26 The experimental results indicate that CogMCTS27 outperforms existing LLM-based AHD methods in28 stability, efficiency, and solution quality.

</details>


### [30] [Protein Secondary Structure Prediction Using Transformers](https://arxiv.org/abs/2512.08613)
*Manzi Kevin Maxime*

Main category: cs.AI

TL;DR: 提出了一种基于Transformer的模型，利用注意力机制预测蛋白质二级结构。


<details>
  <summary>Details</summary>
Motivation: 预测蛋白质二级结构对于理解蛋白质功能至关重要。

Method: 采用滑动窗口数据增强技术和Transformer模型，在CB513数据集上进行训练。

Result: 模型在可变长度序列上表现出色，能有效捕捉局部和长程残基相互作用。

Conclusion: Transformer模型在蛋白质二级结构预测中展示了强大的泛化能力。

Abstract: Predicting protein secondary structures such as alpha helices, beta sheets, and coils from amino acid sequences is essential for understanding protein function. This work presents a transformer-based model that applies attention mechanisms to protein sequence data to predict structural motifs. A sliding-window data augmentation technique is used on the CB513 dataset to expand the training samples. The transformer shows strong ability to generalize across variable-length sequences while effectively capturing both local and long-range residue interactions.

</details>


### [31] [Towards Foundation Models with Native Multi-Agent Intelligence](https://arxiv.org/abs/2512.08743)
*Shuyue Hu,Haoyang Yan,Yiqun Zhang,Yang Chen,Dongzhan Zhou,Lei Bai*

Main category: cs.AI

TL;DR: 本文探讨了基础模型在多智能体环境中的核心能力，并提出需专门研究以弥补单智能体与多智能体智能之间的差距。


<details>
  <summary>Details</summary>
Motivation: 尽管基础模型在单智能体能力方面取得进展，但在多智能体智能方面仍存在差距，需要专门的研究来提升其能力。

Method: 通过分析41种大型语言模型的实证证据，识别出多智能体环境中的四个核心能力：理解、规划、高效沟通和适应。

Result: 强有力的单智能体性能并不自动转化为强大的多智能体智能，需要进一步的研究来构建具备这些能力的模型。

Conclusion: 提出了构建具有原生多智能体智能的基础模型的关键研究方向，包括数据集构建、评估、训练范式和安全考虑。

Abstract: Foundation models (FMs) are increasingly assuming the role of the "brain" of AI agents. While recent efforts have begun to equip FMs with native single-agent abilities -- such as GUI interaction or integrated tool use -- we argue that the next frontier is endowing FMs with native multi-agent intelligence. We identify four core capabilities of FMs in multi-agent contexts: understanding, planning, efficient communication, and adaptation. Contrary to assumptions about the spontaneous emergence of such abilities, we provide extensive empirical evidence across 41 large language models showing that strong single-agent performance alone does not automatically yield robust multi-agent intelligence. To address this gap, we outline key research directions -- spanning dataset construction, evaluation, training paradigms, and safety considerations -- for building FMs with native multi-agent intelligence.

</details>


### [32] [A Practical Guide for Designing, Developing, and Deploying Production-Grade Agentic AI Workflows](https://arxiv.org/abs/2512.08769)
*Eranga Bandara,Ross Gore,Peter Foytik,Sachin Shetty,Ravi Mukkamala,Abdul Rahman,Xueping Liang,Safdar H. Bouk,Amin Hass,Sachini Rajapakse,Ng Wee Keong,Kasun De Zoysa,Aruna Withanage,Nilaan Loganathan*

Main category: cs.AI

TL;DR: 本文提出了一个关于如何设计、开发和部署生产级Agentic AI系统的端到端指南，介绍了结构化工程生命周期和九项核心最佳实践。


<details>
  <summary>Details</summary>
Motivation: Agentic AI在自主系统推理、规划和执行多步骤任务方面标志着重大转变，但在实际应用中，组织面临如何设计可靠、可观察、可维护且符合安全和治理要求的生产级Agentic AI工作流的挑战。

Method: 引入了一种结构化工程生命周期，包括工作流分解、多智能体设计模式、模型上下文协议（MCP）和工具集成、确定性编排、责任AI考虑以及环境感知部署策略，并提出了九项核心最佳实践。

Result: 通过一个多模态新闻分析和媒体生成工作流的综合案例研究，展示了这些原则的实际应用。

Conclusion: 本文通过架构指导、操作模式和实际实施见解，为构建稳健、可扩展且生产就绪的Agentic AI工作流提供了基础参考。

Abstract: Agentic AI marks a major shift in how autonomous systems reason, plan, and execute multi-step tasks. Unlike traditional single model prompting, agentic workflows integrate multiple specialized agents with different Large Language Models(LLMs), tool-augmented capabilities, orchestration logic, and external system interactions to form dynamic pipelines capable of autonomous decision-making and action. As adoption accelerates across industry and research, organizations face a central challenge: how to design, engineer, and operate production-grade agentic AI workflows that are reliable, observable, maintainable, and aligned with safety and governance requirements. This paper provides a practical, end-to-end guide for designing, developing, and deploying production-quality agentic AI systems. We introduce a structured engineering lifecycle encompassing workflow decomposition, multi-agent design patterns, Model Context Protocol(MCP), and tool integration, deterministic orchestration, Responsible-AI considerations, and environment-aware deployment strategies. We then present nine core best practices for engineering production-grade agentic AI workflows, including tool-first design over MCP, pure-function invocation, single-tool and single-responsibility agents, externalized prompt management, Responsible-AI-aligned model-consortium design, clean separation between workflow logic and MCP servers, containerized deployment for scalable operations, and adherence to the Keep it Simple, Stupid (KISS) principle to maintain simplicity and robustness. To demonstrate these principles in practice, we present a comprehensive case study: a multimodal news-analysis and media-generation workflow. By combining architectural guidance, operational patterns, and practical implementation insights, this paper offers a foundational reference to build robust, extensible, and production-ready agentic AI workflows.

</details>


### [33] [CARLoS: Retrieval via Concise Assessment Representation of LoRAs at Scale](https://arxiv.org/abs/2512.08826)
*Shahar Sarfaty,Adi Haviv,Uri Hacohen,Niva Elkin-Koren,Roi Livni,Amit H. Bermano*

Main category: cs.AI

TL;DR: CARLoS是一个用于描述和检索LoRAs的框架，通过分析650多个LoRAs，提出了一种无需额外元数据即可表征LoRAs的方法，并开发了一种高效的检索框架。


<details>
  <summary>Details</summary>
Motivation: 现有的LoRAs发现方法依赖不可靠的用户描述或有偏的流行度指标，影响了可用性。需要一个更可靠和高效的方法来表征和检索LoRAs。

Method: 通过在各种提示和种子下进行图像生成来评估LoRAs的行为，使用CLIP嵌入及其与基础模型生成的差异，定义了三个部分表示：方向（Directions）、强度（Strength）和一致性（Consistency）。

Result: 开发了一种高效的检索框架，可以根据文本查询语义匹配相关的LoRAs，并在自动化和人工评估中优于文本基线。

Conclusion: CARLoS不仅是一个实用的LoRAs检索系统，还能通过强度和一致性分析支持与版权相关的法律概念，具有广泛的LoRAs分析应用价值。

Abstract: The rapid proliferation of generative components, such as LoRAs, has created a vast but unstructured ecosystem. Existing discovery methods depend on unreliable user descriptions or biased popularity metrics, hindering usability. We present CARLoS, a large-scale framework for characterizing LoRAs without requiring additional metadata. Analyzing over 650 LoRAs, we employ them in image generation over a variety of prompts and seeds, as a credible way to assess their behavior. Using CLIP embeddings and their difference to a base-model generation, we concisely define a three-part representation: Directions, defining semantic shift; Strength, quantifying the significance of the effect; and Consistency, quantifying how stable the effect is. Using these representations, we develop an efficient retrieval framework that semantically matches textual queries to relevant LoRAs while filtering overly strong or unstable ones, outperforming textual baselines in automated and human evaluations. While retrieval is our primary focus, the same representation also supports analyses linking Strength and Consistency to legal notions of substantiality and volition, key considerations in copyright, positioning CARLoS as a practical system with broader relevance for LoRA analysis.

</details>


### [34] [Interpolation in Knowledge Representation](https://arxiv.org/abs/2512.08833)
*Jean Christoph Jung,Patrick Koopmann,Matthias Knorr*

Main category: cs.AI

TL;DR: 本文探讨了知识表示中Craig插值和均匀插值的应用和挑战，重点分析描述逻辑和逻辑编程两种形式体系的插值计算理论和实践方法。


<details>
  <summary>Details</summary>
Motivation: Craig插值和均匀插值在知识表示中具有广泛的应用，如可解释性、遗忘、模块化和重用，甚至是学习。然而，许多知识表示形式体系通常不具备这些插值性质，且实际插值计算具有挑战性。

Method: 研究聚焦于描述逻辑和逻辑编程这两种重要的知识表示形式体系，详细讨论插值计算的理论结果和实践方法。

Result: 提供了关于描述逻辑和逻辑编程形式体系中插值计算的理论成果和实际计算方法。

Conclusion: 通过深入研究描述逻辑和逻辑编程的插值计算，为知识表示中的插值问题提供了理论和实践参考。

Abstract: Craig interpolation and uniform interpolation have many applications in knowledge representation, including explainability, forgetting, modularization and reuse, and even learning. At the same time, many relevant knowledge representation formalisms do in general not have Craig or uniform interpolation, and computing interpolants in practice is challenging. We have a closer look at two prominent knowledge representation formalisms, description logics and logic programming, and discuss theoretical results and practical methods for computing interpolants.

</details>


### [35] [EcomBench: Towards Holistic Evaluation of Foundation Agents in E-commerce](https://arxiv.org/abs/2512.08868)
*Rui Min,Zile Qiao,Ze Xu,Jiawen Zhai,Wenyu Gao,Xuanzhong Chen,Haozhen Sun,Zhen Zhang,Xinyu Wang,Hong Zhou,Wenbiao Yin,Xuan Zhou,Yong Jiang,Haicheng Liu,Liang Ding,Ling Zou,Yi R.,Fung,Yalong Li,Pengjun Xie*

Main category: cs.AI

TL;DR: EcomBench是一个为在现实电子商务环境中评估agent性能而设计的全方位基准测试。


<details>
  <summary>Details</summary>
Motivation: 当前很多基准测试集中于学术或人为设计场景，忽视了现实应用中的挑战，而电子商务领域具有大量多样化的用户互动、动态市场条件和与真实决策过程相关的任务，因此需要一个更实际的评估环境。

Method: EcomBench从全球主要电子商务生态系统中提取真实用户需求，并通过人类专家进行精心策划和注释，以确保清晰性、准确性和领域相关性。它涵盖多个电子商务场景任务类别，并定义了三个难度级别。

Result: EcomBench为agent在深度信息检索、多步推理和跨源知识整合等关键能力上提供了严格的、动态的测试平台。

Conclusion: 通过在真实电子商务环境中进行评估，EcomBench为衡量agent在现代电子商务中的实际能力提供了一个有效的基准。

Abstract: Foundation agents have rapidly advanced in their ability to reason and interact with real environments, making the evaluation of their core capabilities increasingly important. While many benchmarks have been developed to assess agent performance, most concentrate on academic settings or artificially designed scenarios while overlooking the challenges that arise in real applications. To address this issue, we focus on a highly practical real-world setting, the e-commerce domain, which involves a large volume of diverse user interactions, dynamic market conditions, and tasks directly tied to real decision-making processes. To this end, we introduce EcomBench, a holistic E-commerce Benchmark designed to evaluate agent performance in realistic e-commerce environments. EcomBench is built from genuine user demands embedded in leading global e-commerce ecosystems and is carefully curated and annotated through human experts to ensure clarity, accuracy, and domain relevance. It covers multiple task categories within e-commerce scenarios and defines three difficulty levels that evaluate agents on key capabilities such as deep information retrieval, multi-step reasoning, and cross-source knowledge integration. By grounding evaluation in real e-commerce contexts, EcomBench provides a rigorous and dynamic testbed for measuring the practical capabilities of agents in modern e-commerce.

</details>


### [36] [Same Content, Different Answers: Cross-Modal Inconsistency in MLLMs](https://arxiv.org/abs/2512.08923)
*Angela van Sprang,Laurens Samson,Ana Lucic,Erman Acar,Sennay Ghebreab,Yuki M. Asano*

Main category: cs.AI

TL;DR: 引入了两个新的基准测试REST和REST+，用于系统评估多模态大型语言模型（MLLMs）中的跨模态不一致性。


<details>
  <summary>Details</summary>
Motivation: MLLMs被训练为在相同的嵌入空间中表现视觉和语言，但它们在这两种模态中不能执行相同的任务。需要系统评估这种不一致性。

Method: 设计了包含三种模态（图像、文本、混合）样本的基准，并评估了15个MLLMs在不同模态上的一致性。

Result: 发现模态不一致程度在不同模型间有显著差异，视觉特征（如文本颜色和分辨率）和视觉令牌的数量影响模型性能。

Conclusion: 一致性分数与文本和图像之间的模态差距相关，揭示了MLLMs跨模态不一致的机制解释。

Abstract: We introduce two new benchmarks REST and REST+(Render-Equivalence Stress Tests) to enable systematic evaluation of cross-modal inconsistency in multimodal large language models (MLLMs). MLLMs are trained to represent vision and language in the same embedding space, yet they cannot perform the same tasks in both modalities. Our benchmarks contain samples with the same semantic information in three modalities (image, text, mixed) and we show that state-of-the-art MLLMs cannot consistently reason over these different modalities. We evaluate 15 MLLMs and find that the degree of modality inconsistency varies substantially, even when accounting for problems with text recognition (OCR). Neither rendering text as image nor rendering an image as text solves the inconsistency. Even if OCR is correct, we find that visual characteristics (text colour and resolution, but not font) and the number of vision tokens have an impact on model performance. Finally, we find that our consistency score correlates with the modality gap between text and images, highlighting a mechanistic interpretation of cross-modal inconsistent MLLMs.

</details>
