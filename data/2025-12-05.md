<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 24]
- [cs.AI](#cs.AI) [Total: 29]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [On GRPO Collapse in Search-R1: The Lazy Likelihood-Displacement Death Spiral](https://arxiv.org/abs/2512.04220)
*Wenlong Deng,Yushu Li,Boying Gong,Yi Ren,Christos Thrampoulidis,Xiaoxiao Li*

Main category: cs.CL

TL;DR: 本文分析了工具集成强化学习中GRPO算法的训练崩溃问题，提出了一种新的轻量级正则化方法LLDS来解决该问题。


<details>
  <summary>Details</summary>
Motivation: GRPO在工具集成强化学习中表现出快速收敛和无值函数优势，但存在训练崩溃问题，需要解决这一限制其应用的关键瓶颈。

Method: 识别出Lazy Likelihood Displacement (LLD)是导致训练崩溃的核心机制，并提出了一种细粒度的、只针对下降轨迹激活的轻量级正则化方法LLDS。

Result: 在七个开放域和多跳QA基准测试中，新方法稳定了训练过程，防止梯度爆炸，在Qwen2.5-3B和Qwen2.5-7B上分别实现了+37.8%和+32.0%的性能提升。

Conclusion: LLD是GRPO-based TIRL中的基本瓶颈，提出的LLDS方法为解决该问题提供了实用路径，能够实现稳定、可扩展的工具集成LLM训练。

Abstract: Tool-integrated (TI) reinforcement learning (RL) enables large language models (LLMs) to perform multi-step reasoning by interacting with external tools such as search engines and retrievers. Group Relative Policy Optimization (GRPO), exemplified by the recent Search-R1, offers fast convergence and a value-free formulation that makes it appealing for this setting, yet consistently suffers from training collapse. We identify Lazy Likelihood Displacement (LLD), a systematic reduction or stagnation in the likelihood of both correct and incorrect responses, as the core mechanism driving this failure. LLD emerges early and triggers a self-reinforcing LLD Death Spiral, where declining likelihood leads to low-confidence responses, inflating gradients, and ultimately causing collapse. We empirically characterize this process across models on a Search-R1-style, search-integrated question answering task, revealing a consistent three-phase trajectory: early stagnation, steady decay, and accelerated collapse. To address this, we propose a lightweight likelihood-preserving regularization LLDS for GRPO that activates only when a trajectory's likelihood decreases, and regularizes only the tokens responsible. This fine-grained structure mitigates LLD with minimal interference to optimization. Across seven open-domain and multi-hop QA benchmarks, our method stabilizes training, prevents gradient explosion, and yields substantial performance improvements, including +37.8% gains on Qwen2.5-3B and +32.0% gains on Qwen2.5-7B. Our results establish LLD as a fundamental bottleneck in GRPO-based TIRL and provide a practical path toward stable, scalable training of tool-integrated LLM.

</details>


### [2] [Computational Linguistics Meets Libyan Dialect: A Study on Dialect Identification](https://arxiv.org/abs/2512.04257)
*Mansour Essgaer,Khamis Massud,Rabia Al Mamlook,Najah Ghmaid*

Main category: cs.CL

TL;DR: 该研究评估了多种机器学习模型在利比亚方言分类中的表现，发现多项式朴素贝叶斯（MNB）结合特定n-gram特征效果最佳。


<details>
  <summary>Details</summary>
Motivation: 利比亚方言在社交媒体（如Twitter）上存在大量非标准拼写和正字法变异，研究旨在解决方言分类的预处理和特征选择挑战。

Method: 使用QADI语料库的54万条句子，通过卡方检验筛选特征，并比较逻辑回归、线性支持向量机和两类朴素贝叶斯模型在不同n-gram表示下的性能。

Result: MNB模型结合(1,2)词和(1,5)字符n-gram时表现最佳（准确率85.89%，F1=0.85741），优于逻辑回归（84.41%）和线性SVM（84.73%）。

Conclusion: 精心设计的n-gram表示和模型选择能显著提升方言分类效果，为阿拉伯语方言NLP研究提供了实证基准。

Abstract: This study investigates logistic regression, linear support vector machine, multinomial Naive Bayes, and Bernoulli Naive Bayes for classifying Libyan dialect utterances gathered from Twitter. The dataset used is the QADI corpus, which consists of 540,000 sentences across 18 Arabic dialects. Preprocessing challenges include handling inconsistent orthographic variations and non-standard spellings typical of the Libyan dialect. The chi-square analysis revealed that certain features, such as email mentions and emotion indicators, were not significantly associated with dialect classification and were thus excluded from further analysis. Two main experiments were conducted: (1) evaluating the significance of meta-features extracted from the corpus using the chi-square test and (2) assessing classifier performance using different word and character n-gram representations. The classification experiments showed that Multinomial Naive Bayes (MNB) achieved the highest accuracy of 85.89% and an F1-score of 0.85741 when using a (1,2) word n-gram and (1,5) character n-gram representation. In contrast, Logistic Regression and Linear SVM exhibited slightly lower performance, with maximum accuracies of 84.41% and 84.73%, respectively. Additional evaluation metrics, including log loss, Cohen kappa, and Matthew correlation coefficient, further supported the effectiveness of MNB in this task. The results indicate that carefully selected n-gram representations and classification models play a crucial role in improving the accuracy of Libyan dialect identification. This study provides empirical benchmarks and insights for future research in Arabic dialect NLP applications.

</details>


### [3] [SQuARE: Structured Query & Adaptive Retrieval Engine For Tabular Formats](https://arxiv.org/abs/2512.04292)
*Chinmay Gondhalekar,Urjitkumar Patel,Fang-Chun Yeh*

Main category: cs.CL

TL;DR: SQuARE是一种混合检索框架，能根据电子表格的复杂度自动选择最佳检索路径，解决了多行标题、合并单元格等问题，提高了问答准确性。


<details>
  <summary>Details</summary>
Motivation: 由于多行标题、合并单元格和单位注释等问题，现有的基于文本块或SQL的检索方法在处理真实电子表格时表现不佳，需要一个更灵活的解决方案。

Method: SQuARE采用表级复杂感知路由，基于标题深度和合并密度计算连续分数，将查询通过保结构文本块检索或自动构建的关系型SQL表示两种路径之一处理，并在置信度低时由轻量级智能体监督结果整合。

Result: 在多种复杂电子表格数据集上的评估显示，SQuARE在检索精度和端到端答案准确性方面始终优于单一策略基线及ChatGPT-4o，同时保持可预测的延迟。

Conclusion: SQuARE通过解耦检索与模型选择，不仅提升了当前表格理解的效果，还为未来表格基础模型的接入提供了实用桥梁，是迈向更健壮表格理解的重要进展。

Abstract: Accurate question answering over real spreadsheets remains difficult due to multirow headers, merged cells, and unit annotations that disrupt naive chunking, while rigid SQL views fail on files lacking consistent schemas. We present SQuARE, a hybrid retrieval framework with sheet-level, complexity-aware routing. It computes a continuous score based on header depth and merge density, then routes queries either through structure-preserving chunk retrieval or SQL over an automatically constructed relational representation. A lightweight agent supervises retrieval, refinement, or combination of results across both paths when confidence is low. This design maintains header hierarchies, time labels, and units, ensuring that returned values are faithful to the original cells and straightforward to verify. Evaluated on multi-header corporate balance sheets, a heavily merged World Bank workbook, and diverse public datasets, SQuARE consistently surpasses single-strategy baselines and ChatGPT-4o on both retrieval precision and end-to-end answer accuracy while keeping latency predictable. By decoupling retrieval from model choice, the system is compatible with emerging tabular foundation models and offers a practical bridge toward a more robust table understanding.

</details>


### [4] [ClusterFusion: Hybrid Clustering with Embedding Guidance and LLM Adaptation](https://arxiv.org/abs/2512.04350)
*Yiming Xu,Yuan Yuan,Vijay Viswanathan,Graham Neubig*

Main category: cs.CL

TL;DR: 提出了一种新颖的混合聚类框架ClusterFusion，利用大语言模型作为聚类核心，结合轻量级嵌入方法，在领域特定上下文中实现高效聚类。


<details>
  <summary>Details</summary>
Motivation: 传统聚类算法在领域特定任务中表现不佳，需要昂贵的微调。大语言模型虽具强上下文推理能力，但现有方法仅将其作为辅助模块，未能充分发挥其潜力。

Method: ClusterFusion框架分为三个阶段：嵌入引导子集划分、LLM驱动主题摘要和LLM主题分配，通过这种设计直接结合领域知识和用户偏好。

Result: 在三个公共基准和两个新领域特定数据集上的实验表明，ClusterFusion不仅能在标准任务中实现最先进性能，还能在专业领域中显著提升性能。

Conclusion: ClusterFusion通过有效结合LLM和嵌入方法，实现了在领域特定上下文中的高效聚类，为未来研究提供了新数据集和基准结果。

Abstract: Text clustering is a fundamental task in natural language processing, yet traditional clustering algorithms with pre-trained embeddings often struggle in domain-specific contexts without costly fine-tuning. Large language models (LLMs) provide strong contextual reasoning, yet prior work mainly uses them as auxiliary modules to refine embeddings or adjust cluster boundaries. We propose ClusterFusion, a hybrid framework that instead treats the LLM as the clustering core, guided by lightweight embedding methods. The framework proceeds in three stages: embedding-guided subset partition, LLM-driven topic summarization, and LLM-based topic assignment. This design enables direct incorporation of domain knowledge and user preferences, fully leveraging the contextual adaptability of LLMs. Experiments on three public benchmarks and two new domain-specific datasets demonstrate that ClusterFusion not only achieves state-of-the-art performance on standard tasks but also delivers substantial gains in specialized domains. To support future work, we release our newly constructed dataset and results on all benchmarks.

</details>


### [5] [LangSAT: A Novel Framework Combining NLP and Reinforcement Learning for SAT Solving](https://arxiv.org/abs/2512.04374)
*Muyu Pan,Matthew Walter,Dheeraj Kodakandla,Mahfuza Farooque*

Main category: cs.CL

TL;DR: 提出了一种新颖的基于强化学习（RL）的框架LangSAT，通过优化CDCL过程中的启发式选择，提高布尔可满足性（SAT）求解的效率。


<details>
  <summary>Details</summary>
Motivation: 解决传统SAT求解平台需要CNF作为输入，不够用户友好的问题，使得用户可以用标准英语描述输入，从而让SAT求解更加易于访问。

Method: 该框架包含两个关键组件：Lang2Logic，将英文句子翻译成CNF表达式；SmartSAT，一个基于强化学习的SAT求解器。SmartSAT将子句-变量关系编码为结构化图表示，并提取特定SAT问题的全局特征。

Result: Lang2Logic在多种自然语言输入上进行了评估，处理长达450字的描述。SmartSAT在求解时间方面表现与传统CDCL启发式相当。

Conclusion: LangSAT框架为SAT求解任务提供了更易访问和可扩展的解决方案，适用于推理、形式验证和调试等领域。

Abstract: Our work presents a novel reinforcement learning (RL) based framework to optimize heuristic selection within the conflict-driven clause learning (CDCL) process, improving the efficiency of Boolean satisfia- bility (SAT) solving. The proposed system, LangSAT, bridges the gap between natural language inputs and propositional logic by converting English descriptions into Conjunctive Normal Form (CNF) expressions and solving them using an RL-enhanced CDCL SAT solver. Unlike existing SAT-solving platforms that require CNF as input, LangSAT enables users to input standard English descriptions, making SAT-solving more accessible. The framework comprises two key components: Lang2Logic, which translates English sentences into CNF expressions, and SmartSAT, an RL-based SAT solver. SmartSAT encodes clause-variable relationships as structured graph representations and extracts global features specific to the SAT problem. This implementation provides the RL agent with deeper contextual information, enabling SAT problems to be solved more efficiently. Lang2Logic was evaluated on diverse natural language inputs, processing descriptions up to 450 words. The generated CNFs were solved by SmartSAT, which demonstrated comparable performance to traditional CDCL heuristics with respect to solving time. The combined LangSAT framework offers a more accessible and scalable solution for SAT-solving tasks across reasoning, formal verification, and debugging.

</details>


### [6] [RapidUn: Influence-Driven Parameter Reweighting for Efficient Large Language Model Unlearning](https://arxiv.org/abs/2512.04457)
*Guoshenghui Zhao,Huawei Lin,Weijie Zhao*

Main category: cs.CL

TL;DR: 提出RapidUn，一种高效、基于影响力驱动的LLM数据遗忘框架，通过快速估计样本影响力并映射为自适应权重，实现参数高效更新。


<details>
  <summary>Details</summary>
Motivation: 现有LLM遗忘方法存在计算成本高、稳定性差、对数据分布敏感等问题，尤其在小或类别不平衡遗忘集上效果不佳。

Method: RapidUn框架包含：(1) 快速样本影响力估计模块；(2) 将影响力分数映射为自适应更新权重；(3) 选择性参数更新策略，兼顾遗忘有害行为与保留通用知识。

Result: 在Mistral-7B和Llama-3-8B上，RapidUn比全参数重训练高效100倍，在Dolly-15k和Alpaca-57k数据集上，对分布内/外遗忘均优于Fisher、GA和LoReUn方法。

Conclusion: 影响力引导的参数重加权是一种可扩展、可解释的LLM遗忘新范式。

Abstract: Removing specific data influence from large language models (LLMs) remains challenging, as retraining is costly and existing approximate unlearning methods are often unstable. The challenge is exacerbated when the forget set is small or imbalanced. We introduce RapidUn, an influence-driven and parameter-efficient unlearning framework. It first estimates per-sample influence through a fast estimation module, then maps these scores into adaptive update weights that guide selective parameter updates -- forgetting harmful behavior while retaining general knowledge. On Mistral-7B and Llama-3-8B across Dolly-15k and Alpaca-57k, RapidUn achieves up to 100 times higher efficiency than full retraining and consistently outperforms Fisher, GA, and LoReUn on both in-distribution and out-of-distribution forgetting. These results establish influence-guided parameter reweighting as a scalable and interpretable paradigm for LLM unlearning.

</details>


### [7] [UW-BioNLP at ChemoTimelines 2025: Thinking, Fine-Tuning, and Dictionary-Enhanced LLM Systems for Chemotherapy Timeline Extraction](https://arxiv.org/abs/2512.04518)
*Tianmai M. Zhang,Zhaoyi Sun,Sihang Zeng,Chenxi Li,Neil F. Abernethy,Barbara D. Lam,Fei Xia,Meliha Yetisgen*

Main category: cs.CL

TL;DR: 本文介绍了在 ChemoTimelines 共享任务中，从癌症患者的电子健康记录中生成患者化疗时间线的方法。


<details>
  <summary>Details</summary>
Motivation: 旨在评估和优化从临床笔记中提取化疗事件并生成时间线的多种策略，以提高时间线提取的准确性。

Method: 采用了包括思维链、监督微调、直接偏好优化和基于字典的查找等策略，遵循两步工作流程：首先从临床笔记中提取化疗事件，然后算法将这些事件标准化并汇总成患者级时间线。

Result: 多种方法在测试集上表现出色，其中微调的 Qwen3-14B 模型取得了 0.678 的最佳官方得分。

Conclusion: 本文的结果和分析为未来在该任务及类似任务的设计提供了有价值的见解。

Abstract: The ChemoTimelines shared task benchmarks methods for constructing timelines of systemic anticancer treatment from electronic health records of cancer patients. This paper describes our methods, results, and findings for subtask 2 -- generating patient chemotherapy timelines from raw clinical notes. We evaluated strategies involving chain-of-thought thinking, supervised fine-tuning, direct preference optimization, and dictionary-based lookup to improve timeline extraction. All of our approaches followed a two-step workflow, wherein an LLM first extracted chemotherapy events from individual clinical notes, and then an algorithm normalized and aggregated events into patient-level timelines. Each specific method differed in how the associated LLM was utilized and trained. Multiple approaches yielded competitive performances on the test set leaderboard, with fine-tuned Qwen3-14B achieving the best official score of 0.678. Our results and analyses could provide useful insights for future attempts on this task as well as the design of similar tasks.

</details>


### [8] [EvoEdit: Lifelong Free-Text Knowledge Editing through Latent Perturbation Augmentation and Knowledge-driven Parameter Fusion](https://arxiv.org/abs/2512.04545)
*Pengfei Cao,Zeao Ji,Daojian Zeng,Jun Zhao,Kang Liu*

Main category: cs.CL

TL;DR: 提出了一种新的终身自由文本知识编辑任务（LF-Edit），并设计了一个大规模基准测试MRLF-Bench，以及一个名为EvoEdit的新方法，以解决现有知识编辑方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有知识编辑方法存在两个局限：1) 依赖结构化三元组，与LLM预训练的自由文本性质不一致；2) 通常只支持一次性知识更新，缺乏对序列或终身编辑的研究。

Method: 提出LF-Edit任务，允许模型以自然语言进行持续编辑；设计了MRLF-Bench基准测试，并提出多等级评估框架；引入EvoEdit方法，通过潜在扰动增强知识注入，并通过知识驱动的参数融合保留先验信息。

Result: 实验结果表明，EvoEdit在提出的LF-Edit任务上显著优于现有知识编辑方法。

Conclusion: LF-Edit任务、MRLF-Bench基准测试和EvoEdit方法共同为终身自由文本知识编辑提供了新的研究方向和解决方案。

Abstract: Adjusting the outdated knowledge of large language models (LLMs) after deployment remains a major challenge. This difficulty has spurred the development of knowledge editing, which seeks to accurately and efficiently modify a model's internal (parametric) knowledge without retraining it from scratch. However, existing methods suffer from two limitations. First, they depend on structured triplets that are misaligned with the free-text nature of LLM pretraining and fail to capture the nuanced relationships among facts. Second, they typically support one-time knowledge updates, with relatively limited research on the problem of sequential or lifelong editing. To address these gaps, we propose a new task, Lifelong Free-text Knowledge Editing (LF-Edit), which enables models to incorporate updates expressed in natural language and supports continual editing over time. Despite its promise, LF-Edit faces the dual challenge of integrating new knowledge while mitigating the forgetting of prior information. To foster research on this new task, we construct a large-scale benchmark, Multi-Rank Lifelong Free-text Editing Benchmark (MRLF-Bench), containing 16,835 free-text edit requests. We further design a cognitively inspired multi-rank evaluation framework encompassing four levels: memorization, understanding, constrained comprehension, and reasoning. To tackle the challenges inherent in LF-Edit, we introduce a novel approach named EvoEdit that enhances knowledge injection through Latent Perturbation Augmentation and preserves prior information via Knowledge-driven Parameter Fusion. Experimental results demonstrate that EvoEdit substantially outperforms existing knowledge editing methods on the proposed LF-Edit task.

</details>


### [9] [AdmTree: Compressing Lengthy Context with Adaptive Semantic Trees](https://arxiv.org/abs/2512.04550)
*Yangning Li,Shaoshen Chen,Yinghui Li,Yankai Chen,Hai-Tao Zheng,Hui Wang,Wenhao Jiang,Philip S. Yu*

Main category: cs.CL

TL;DR: 提出AdmTree框架，以解决LLMs在处理长上下文时自注意力机制的二次复杂度问题。


<details>
  <summary>Details</summary>
Motivation: 自注意力机制的二次复杂度限制了LLMs在处理长上下文时的能力，现有方法在局部细节和语义信息保持方面存在问题。

Method: AdmTree通过动态分割输入、利用信息密度、使用gist tokens总结不同长度片段，并通过轻量级聚合机制与冻结主干LLM进行高效层次抽象。

Result: AdmTree在保持细粒度细节的同时，保留了全局语义连贯性，减轻了位置偏差，并动态适应内容。

Conclusion: AdmTree是一个新颖的自适应层次上下文压缩框架，能够有效处理长上下文，同时保持高效率和语义保真度。

Abstract: The quadratic complexity of self-attention constrains Large Language Models (LLMs) in processing long contexts, a capability essential for many advanced applications. Context compression aims to alleviate this computational bottleneck while retaining critical semantic information. However, existing approaches often fall short: explicit methods may compromise local detail, whereas implicit methods can suffer from positional biases, information degradation, or an inability to capture long-range semantic dependencies. We propose AdmTree, a novel framework for adaptive, hierarchical context compression with a central focus on preserving high semantic fidelity while maintaining efficiency. AdmTree dynamically segments input based on information density, utilizing gist tokens to summarize variable-length segments as the leaves of a semantic binary tree. This structure, together with a lightweight aggregation mechanism and a frozen backbone LLM (thereby minimizing new trainable parameters), enables efficient hierarchical abstraction of the context. By preserving fine-grained details alongside global semantic coherence, mitigating positional bias, and dynamically adapting to content, AdmTree robustly retains the semantic information of long contexts.

</details>


### [10] [ADAPT: Learning Task Mixtures for Budget-Constrained Instruction Tuning](https://arxiv.org/abs/2512.04555)
*Pritam Kadasi,Abhishek Upperwal,Mayank SIngh*

Main category: cs.CL

TL;DR: 提出ADAPT元学习算法，通过显式token预算自动学习多任务指令调优的任务采样比例。


<details>
  <summary>Details</summary>
Motivation: 解决多任务学习中人工设定任务权重不灵活、易导致训练效率低和性能瓶颈的问题。

Method: 采用连续任务分布和元梯度优化，基于平滑最坏验证目标动态调整任务采样比例，实现自适应课程学习。

Result: 在3种1B参数LLMs和20个任务上，ADAPT在11个基准测试中匹配或超越最优静态混合方法，且使用更少训练token。

Conclusion: ADAPT能自动将计算资源分配给更难且与评测对齐的任务，提升训练效率和下游性能。

Abstract: We propose ADAPT, a meta-learning algorithm that \emph{learns} task sampling proportions under an explicit token budget for multi-task instruction tuning. Instead of fixing task weights by hand, \adapt{} maintains a continuous distribution over tasks and updates it via meta-gradients of a smooth worst-case validation objective, inducing an adaptive curriculum that allocates more tokens to useful tasks while avoiding collapse. We instantiate ADAPT on three $\sim$1B-parameter open-weight LLMs (Gemma-3-1B, LLaMA-3.2-1B, Qwen-0.6B), training on 20 Natural Instructions task types under budgets of $1\%$, $5\%$, and $10\%$ of the available supervised tokens, and compare against strong supervised fine-tuning baselines with uniform and size-proportional mixing. We conduct evaluations on 11 out-of-domain benchmarks spanning reasoning, reading comprehension, code generation, and instruction following, we find that ADAPT matches or slightly improves average downstream performance relative to the best static mixture, while using fewer effective training tokens and reallocating budget toward harder, benchmark-aligned tasks.

</details>


### [11] [LexGenius: An Expert-Level Benchmark for Large Language Models in Legal General Intelligence](https://arxiv.org/abs/2512.04578)
*Wenjin Liu,Haoran Luo,Xin Feng,Xiang Ji,Lijuan Zhou,Rui Mao,Jiapu Wang,Shirui Pan,Erik Cambria*

Main category: cs.CL

TL;DR: 提出LexGenius，一个专家级中文法律智能评估基准，用于评估大型语言模型的法律智能。


<details>
  <summary>Details</summary>
Motivation: 现有的法律智能评估基准以结果为导向，无法系统评估大型语言模型的法律智能，阻碍了法律通用智能的发展。

Method: 采用Dimension-Task-Ability框架，涵盖7个维度、11项任务和20种能力，利用近期法律案例和考试题目创建选择题，通过人工和LLM审查减少数据泄漏风险，并多次检查确保准确性和可靠性。

Result: 评估了12个最先进的LLM，发现这些模型在法律智能能力方面存在显著差异，即使是最好的LLM也落后于人类法律专业人士。

Conclusion: LexGenius能够评估LLM的法律智能能力，并促进法律通用智能的发展。

Abstract: Legal general intelligence (GI) refers to artificial intelligence (AI) that encompasses legal understanding, reasoning, and decision-making, simulating the expertise of legal experts across domains. However, existing benchmarks are result-oriented and fail to systematically evaluate the legal intelligence of large language models (LLMs), hindering the development of legal GI. To address this, we propose LexGenius, an expert-level Chinese legal benchmark for evaluating legal GI in LLMs. It follows a Dimension-Task-Ability framework, covering seven dimensions, eleven tasks, and twenty abilities. We use the recent legal cases and exam questions to create multiple-choice questions with a combination of manual and LLM reviews to reduce data leakage risks, ensuring accuracy and reliability through multiple rounds of checks. We evaluate 12 state-of-the-art LLMs using LexGenius and conduct an in-depth analysis. We find significant disparities across legal intelligence abilities for LLMs, with even the best LLMs lagging behind human legal professionals. We believe LexGenius can assess the legal intelligence abilities of LLMs and enhance legal GI development. Our project is available at https://github.com/QwenQKing/LexGenius.

</details>


### [12] [Geschlechtsübergreifende Maskulina im Sprachgebrauch Eine korpusbasierte Untersuchung zu lexemspezifischen Unterschieden](https://arxiv.org/abs/2512.04683)
*Carolin Mueller-Spitzer,Samira Ochs,Jan Oliver Ruediger,Sascha Wolfer*

Main category: cs.CL

TL;DR: 本文研究了现代德语新闻文本中通用阳性（GM）的分布和语言特征，发现其在不同个人名词之间存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 通用阳性（GM）在学术界和公众中被广泛讨论，尤其是在其性别中立性方面存在争议。心理语言学研究表明，GM更容易与男性指代相关联，但基于语料库的实际使用分析仍较少。

Method: 研究团队在一个大型新闻文本语料库中调查了GM，重点关注不同个人名词类型的词汇特定差异，并对21个个人名词的全部屈折范式进行了手动标注，总共标注了6,195个标记。

Result: 研究发现，不同词汇项之间存在显著差异，特别是在被动角色名词和与声望相关的个人名词之间。在语法层面上，GM主要出现在复数形式和不定名词短语中，并且并不主要用于表示整个人类类别。

Conclusion: 研究提供了对真实书面语言中GM使用的实证见解，有助于更细致地理解其形式和表现。研究结果还为在心理语言学研究中更好地调整语言刺激与真实语言使用之间的一致性提供了坚实基础。

Abstract: This study examines the distribution and linguistic characteristics of generic masculines (GM) in contemporary German press texts. The use of masculine personal nouns to refer to mixed-gender groups or unspecified individuals has been widely debated in academia and the public, with con-flicting perspectives on its gender-neutrality. While psycholinguistic studies suggest that GM is more readily associated with male referents, corpus-based analyses of its actual use remain scarce. We investigate GM in a large corpus of press texts, focusing on lexeme-specific differences across dif-ferent types of personal nouns. We conducted manual annotations of the whole inflectional para-digm of 21 personal nouns, resulting in 6,195 annotated tokens. Our findings reveal considerable differences between lexical items, especially between passive role nouns and prestige-related per-sonal nouns. On a grammatical level, we find that GM occurs predominantly in the plural and in indefinite noun phrases. Furthermore, our data shows that GM is not primarily used to denote entire classes of people, as has been previously claimed. By providing an empirical insight into the use of GM in authentic written language, we contribute to a more nuanced understanding of its forms and manifestations. These findings provide a solid basis for aligning linguistic stimuli in psy-cholinguistic studies more closely with real-world language use.

</details>


### [13] [SignRoundV2: Closing the Performance Gap in Extremely Low-Bit Post-Training Quantization for LLMs](https://arxiv.org/abs/2512.04746)
*Wenhua Cheng,Weiwei Zhang,Heng Guo,Haihao Shen*

Main category: cs.CL

TL;DR: 提出了一种新的后训练量化框架SignRoundV2，用于低比特量化大型语言模型，以在不使用混合精度的情况下提高性能。


<details>
  <summary>Details</summary>
Motivation: 极低比特量化对于高效部署大型语言模型至关重要，但在2位和4位（如MXFP4）时常常导致性能严重退化。

Method: SignRoundV2引入了快速灵敏度指标，结合梯度信息和量化引起的偏差来指导层间比特分配，并使用轻量级预调搜索量化尺度。

Result: 该方法在4-5比特下实现了接近全精度模型的性能，在2比特下也表现出强结果，准确度与全精度模型相差约1%。

Conclusion: SignRoundV2是一个有效的量化框架，可以在极低比特下实现生产级性能，并且代码已开源。

Abstract: Extreme low-bit quantization is critical for efficiently deploying Large Language Models (LLMs), yet it often leads to severe performance degradation at 2-bits and even 4-bits (e.g., MXFP4). We present SignRoundV2, a post-training quantization framework that is highly effective even without mixed-precision. SignRoundV2 introduces (1) a fast sensitivity metric that combines gradient information with quantization-induced deviations to guide layer-wise bit allocation, and (2) a lightweight pre-tuning search for quantization scales to improve extremely low-bit quantization. These components allow SignRoundV2 to close the gap with full-precision models. Extensive experiments indicate that our method sustains competitive accuracy for LLMs, achieving production-grade performance with about 1 percent variance at 4-5 bits and strong results even at 2 bits. The implementation is available at https://github.com/intel/auto-round.

</details>


### [14] [Model Whisper: Steering Vectors Unlock Large Language Models' Potential in Test-time](https://arxiv.org/abs/2512.04748)
*Xinyue Kang,Diwei Shi,Li Chen*

Main category: cs.CL

TL;DR: 提出一种轻量级组件TTSV，通过优化测试数据上的输出熵来引导LLM，提升推理能力而不需调整模型参数。


<details>
  <summary>Details</summary>
Motivation: 现有测试时适应方法需要调整模型参数，计算成本高且可能降低模型已有能力。因此，需要一种轻量级、高效的方法来提升LLM在特定任务上的表现。

Method: 引入测试时引导向量（TTSV），该向量加在输入前，通过优化测试数据上的输出熵，引导模型到更高置信度的内部状态。

Result: TTSV在基础模型和推理增强模型上均有效。例如，在MATH500任务上，TTSV在Qwen2.5-Math-7B模型上实现了45.88%的相对性能提升，在Qwen3-4B模型上实现了16.22%的提升。

Conclusion: TTSV是一种轻量级、高效、即插即用的增强方法，具有良好的泛化能力，其引导向量在多种任务间高度可迁移。

Abstract: It is a critical challenge to efficiently unlock the powerful reasoning potential of Large Language Models (LLMs) for specific tasks or new distributions. Existing test-time adaptation methods often require tuning model parameters, which is not only computationally expensive but also risks degrading the model's pre-existing abilities.To address this, we introduce a lightweight component, Test-Time Steering Vectors (TTSV), which is prepended to the input while keeping the LLM's parameters entirely frozen. By optimizing the TTSV on test data to minimize the model's output entropy, we steer the model towards an internal state of higher confidence, activating its inherent abilities most relevant to the current task. TTSV is both lightweight and highly efficient to optimize, making it a true plug-and-play enhancement. Extensive experiments validate our approach's effectiveness on both base models and reasoning-enhanced models. For instance, on the MATH500 task, TTSV achieves a 45.88% relative performance gain on the Qwen2.5-Math-7B model and a 16.22% relative gain on the Qwen3-4B model. Furthermore, our approach exhibits robust generalization, with its steering vectors proving highly transferable across diverse tasks.

</details>


### [15] [EtCon: Edit-then-Consolidate for Reliable Knowledge Editing](https://arxiv.org/abs/2512.04753)
*Ruilin Li,Yibin Wang,Wenhong Zhu,Chenglin Li,Jinghao Zhang,Chenliang Li,Junchi Yan,Jiaqi Wang*

Main category: cs.CL

TL;DR: 本文提出了一种新的知识编辑范式Edit-then-Consolidate，以减少在大型语言模型中进行知识编辑时出现的过拟合和知识整合不足的问题。


<details>
  <summary>Details</summary>
Motivation: 以往的知识编辑方法在真实世界终身学习场景下的表现远不如在控制环境中的表现，这限制了它们的实际应用。

Method: 该文提出的Edit-then-Consolidate框架通过目标近端监督微调（TPSFT）来减少过拟合，再通过组相对策略优化（GRPO）来整合新知识，从而改进编辑效果。

Result: 广泛的实验表明，该框架在真实世界评估下显著提高了编辑的可靠性和泛化能力，同时更好地保持了模型的局部性和预训练能力。

Conclusion: Edit-then-Consolidate范式有效弥合了理论方法与实际应用之间的差距，提高了知识编辑在大型语言模型中的实用价值。

Abstract: Knowledge editing aims to update specific facts in large language models (LLMs) without full retraining. Prior efforts sought to tune the knowledge layers of LLMs, proving effective for making selective edits. However, a significant gap exists between their performance in controlled, teacher-forcing evaluations and their real-world effectiveness in lifelong learning scenarios, which greatly limits their practical applicability. This work's empirical analysis reveals two recurring issues associated with this gap: (1) Most traditional methods lead the edited model to overfit to the new fact, thereby degrading pre-trained capabilities; (2) There is a critical absence of a knowledge consolidation stage, leaving new facts insufficiently integrated into LLMs' inference-time behavior under autoregressive generation, thereby leading to a mismatch between parametric knowledge and actual generation behavior. To this end, we propose Edit-then-Consolidate, a novel knowledge editing paradigm that aims to bridge the gap between theoretical knowledge editing methods and their real-world applicability. Specifically, (1) our framework mitigates overfitting via Targeted Proximal Supervised Fine-Tuning (TPSFT) that localizes the edit via a trust-region objective to limit policy drift; (2) Then, a consolidation stage using Group Relative Policy Optimization (GRPO) aligns the edited knowledge with CoT-based inference policy by optimizing trajectory-level behavior under comprehensive reward signals. Extensive experiments demonstrate our framework consistently improves editing reliability and generalization under real-world evaluations, while better preserving locality and pre-trained capabilities.

</details>


### [16] [Challenging the Abilities of Large Language Models in Italian: a Community Initiative](https://arxiv.org/abs/2512.04759)
*Malvina Nissim,Danilo Croce,Viviana Patti,Pierpaolo Basile,Giuseppe Attanasio,Elio Musacchio,Matteo Rinaldi,Federico Borazio,Maria Francis,Jacopo Gili,Daniel Scalena,Begoña Altuna,Ekhi Azurmendi,Valerio Basile,Luisa Bentivogli,Arianna Bisazza,Marianna Bolognesi,Dominique Brunato,Tommaso Caselli,Silvia Casola,Maria Cassese,Mauro Cettolo,Claudia Collacciani,Leonardo De Cosmo,Maria Pia Di Buono,Andrea Esuli,Julen Etxaniz,Chiara Ferrando,Alessia Fidelangeli,Simona Frenda,Achille Fusco,Marco Gaido,Andrea Galassi,Federico Galli,Luca Giordano,Mattia Goffetti,Itziar Gonzalez-Dios,Lorenzo Gregori,Giulia Grundler,Sandro Iannaccone,Chunyang Jiang,Moreno La Quatra,Francesca Lagioia,Soda Marem Lo,Marco Madeddu,Bernardo Magnini,Raffaele Manna,Fabio Mercorio,Paola Merlo,Arianna Muti,Vivi Nastase,Matteo Negri,Dario Onorati,Elena Palmieri,Sara Papi,Lucia Passaro,Giulia Pensa,Andrea Piergentili,Daniele Potertì,Giovanni Puccetti,Federico Ranaldi,Leonardo Ranaldi,Andrea Amelio Ravelli,Martina Rosola,Elena Sofia Ruzzetti,Giuseppe Samo,Andrea Santilli,Piera Santin,Gabriele Sarti,Giovanni Sartor,Beatrice Savoldi,Antonio Serino,Andrea Seveso,Lucia Siciliani,Paolo Torroni,Rossella Varvara,Andrea Zaninello,Asya Zanollo,Fabio Massimo Zanzotto,Kamyar Zeinalipour,Andrea Zugarini*

Main category: cs.CL

TL;DR: CALAMITA是意大利语的大规模协作基准测试，涵盖多种任务，旨在系统化评估大型语言模型（LLMs）在意大利语上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs的评估主要聚焦于英语，对于其他语言（如意大利语）的评估较为有限，因此需要系统化的基准测试。

Method: CALAMITA联合了来自学术界、工业界和公共部门的80多位贡献者，设计、记录并评估了涵盖语言能力、常识推理、事实一致性、公平性、摘要、翻译和代码生成的20多个任务及其子任务，并建立了集中式评估流程。

Result: 报告了四个开放权重LLMs的评估结果，突显了各模型在不同能力上的系统强弱，并指出了任务特定评估的挑战。

Conclusion: CALAMITA不仅是一个资源，也是一个可持续的、社区驱动的评估框架，为其他语言和社区提供了包容性和严格的LLM评估实践范例。

Abstract: The rapid progress of Large Language Models (LLMs) has transformed natural language processing and broadened its impact across research and society. Yet, systematic evaluation of these models, especially for languages beyond English, remains limited. "Challenging the Abilities of LAnguage Models in ITAlian" (CALAMITA) is a large-scale collaborative benchmarking initiative for Italian, coordinated under the Italian Association for Computational Linguistics. Unlike existing efforts that focus on leaderboards, CALAMITA foregrounds methodology: it federates more than 80 contributors from academia, industry, and the public sector to design, document, and evaluate a diverse collection of tasks, covering linguistic competence, commonsense reasoning, factual consistency, fairness, summarization, translation, and code generation. Through this process, we not only assembled a benchmark of over 20 tasks and almost 100 subtasks, but also established a centralized evaluation pipeline that supports heterogeneous datasets and metrics. We report results for four open-weight LLMs, highlighting systematic strengths and weaknesses across abilities, as well as challenges in task-specific evaluation. Beyond quantitative results, CALAMITA exposes methodological lessons: the necessity of fine-grained, task-representative metrics, the importance of harmonized pipelines, and the benefits and limitations of broad community engagement. CALAMITA is conceived as a rolling benchmark, enabling continuous integration of new tasks and models. This makes it both a resource -- the most comprehensive and diverse benchmark for Italian to date -- and a framework for sustainable, community-driven evaluation. We argue that this combination offers a blueprint for other languages and communities seeking inclusive and rigorous LLM evaluation practices.

</details>


### [17] [AdiBhashaa: A Community-Curated Benchmark for Machine Translation into Indian Tribal Languages](https://arxiv.org/abs/2512.04765)
*Pooja Singh,Sandeep Kumar*

Main category: cs.CL

TL;DR: AdiBhashaa是一个社区驱动的项目，旨在为四种印度部落语言创建首个开放平行语料库和基线机器翻译系统，并推动更公平的AI研究。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型和多语言机器翻译系统日益普及，但部落社区的语言在这些技术中仍然被忽视，这加剧了教育、治理和数字参与方面的结构性不平等。

Method: 该项目结合了参与式数据创建、母语者参与、人机协同验证，并系统评估了编码器-解码器机器翻译模型和大型语言模型。

Result: 成功构建了四种印度部落语言（Bhili, Mundari, Gondi, 和 Santali）的平行语料库和基线机器翻译系统。

Conclusion: AdiBhashaa展示了以本地专业知识为中心、培养边缘化社区早期职业研究人员能力，并在语言技术开发中优先考虑人类验证的更公平AI研究模式。

Abstract: Large language models and multilingual machine translation (MT) systems increasingly drive access to information, yet many languages of the tribal communities remain effectively invisible in these technologies. This invisibility exacerbates existing structural inequities in education, governance, and digital participation. We present AdiBhashaa, a community-driven initiative that constructs the first open parallel corpora and baseline MT systems for four major Indian tribal languages-Bhili, Mundari, Gondi, and Santali. This work combines participatory data creation with native speakers, human-in-the-loop validation, and systematic evaluation of both encoder-decoder MT models and large language models. In addition to reporting technical findings, we articulate how AdiBhashaa illustrates a possible model for more equitable AI research: it centers local expertise, builds capacity among early-career researchers from marginalized communities, and foregrounds human validation in the development of language technologies.

</details>


### [18] [DaLA: Danish Linguistic Acceptability Evaluation Guided by Real World Errors](https://arxiv.org/abs/2512.04799)
*Gianluca Barmina,Nathalie Carmen Hau Norman,Peter Schneider-Kamp,Lukas Galke*

Main category: cs.CL

TL;DR: 本文提出了一种用于评估丹麦语语言可接受性的增强基准。


<details>
  <summary>Details</summary>
Motivation: 分析书面丹麦语中最常见的错误，以建立一个更全面的语言可接受性评估基准。

Method: 引入十四种错误函数，通过系统地向正确的丹麦语句子中引入错误来生成不正确的句子，并使用手动和自动方法评估这些错误的有效性。

Result: 该基准在评估大型语言模型的语言可接受性判断任务中表现出更广泛的覆盖面和更高的综合性，增加了任务难度，并且具有更高的判别力。

Conclusion: 该基准可以更好地区分性能良好的模型与性能较低的模型，从而提供更严格的语言可接受性评估。

Abstract: We present an enhanced benchmark for evaluating linguistic acceptability in Danish. We first analyze the most common errors found in written Danish. Based on this analysis, we introduce a set of fourteen corruption functions that generate incorrect sentences by systematically introducing errors into existing correct Danish sentences. To ensure the accuracy of these corruptions, we assess their validity using both manual and automatic methods. The results are then used as a benchmark for evaluating Large Language Models on a linguistic acceptability judgement task. Our findings demonstrate that this extension is both broader and more comprehensive than the current state of the art. By incorporating a greater variety of corruption types, our benchmark provides a more rigorous assessment of linguistic acceptability, increasing task difficulty, as evidenced by the lower performance of LLMs on our benchmark compared to existing ones. Our results also suggest that our benchmark has a higher discriminatory power which allows to better distinguish well-performing models from low-performing ones.

</details>


### [19] [DAMASHA: Detecting AI in Mixed Adversarial Texts via Segmentation with Human-interpretable Attribution](https://arxiv.org/abs/2512.04838)
*L. D. M. S. Sai Teja,N. Siva Gopala Krishna,Ufaq Khan,Muhammad Haris Khan,Partha Pakray,Atul Mishra*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的框架Info-Mask，用于检测混合作者文本中的过渡点，并引入了对抗性基准数据集MAS以评估系统的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在大型语言模型（LLMs）时代，人类和AI生成文本之间的界限越来越模糊，识别混合作者文本中的过渡点对于真实性、信任和人类监督具有重要意义。

Method: Info-Mask框架结合了风格特征、困惑度驱动信号和结构化边界建模，以准确地分割人类和AI的协作内容。此外，引入了人类可解释归属（HIA）覆盖，以突出风格特征如何影响边界预测。

Result: 在多个架构上，Info-Mask显著提高了对抗条件下的段落级别鲁棒性，建立了新的基线，并揭示了剩余的挑战。

Conclusion: 该研究强调了对抗性鲁棒、可解释的混合作者检测的潜力和局限性，对人类-AI共同创作的信任和监督具有重要意义。

Abstract: In the age of advanced large language models (LLMs), the boundaries between human and AI-generated text are becoming increasingly blurred. We address the challenge of segmenting mixed-authorship text, that is identifying transition points in text where authorship shifts from human to AI or vice-versa, a problem with critical implications for authenticity, trust, and human oversight. We introduce a novel framework, called Info-Mask for mixed authorship detection that integrates stylometric cues, perplexity-driven signals, and structured boundary modeling to accurately segment collaborative human-AI content. To evaluate the robustness of our system against adversarial perturbations, we construct and release an adversarial benchmark dataset Mixed-text Adversarial setting for Segmentation (MAS), designed to probe the limits of existing detectors. Beyond segmentation accuracy, we introduce Human-Interpretable Attribution (HIA overlays that highlight how stylometric features inform boundary predictions, and we conduct a small-scale human study assessing their usefulness. Across multiple architectures, Info-Mask significantly improves span-level robustness under adversarial conditions, establishing new baselines while revealing remaining challenges. Our findings highlight both the promise and limitations of adversarially robust, interpretable mixed-authorship detection, with implications for trust and oversight in human-AI co-authorship.

</details>


### [20] [Mitigating Catastrophic Forgetting in Target Language Adaptation of LLMs via Source-Shielded Updates](https://arxiv.org/abs/2512.04844)
*Atsuki Yamaguchi,Terufumi Morishita,Aline Villavicencio,Nikolaos Aletras*

Main category: cs.CL

TL;DR: 提出了一种在低资源条件下，仅使用未标注目标语言数据来扩展指令大型语言模型（LLMs）语言多样性的方法，称为源屏蔽更新（SSU）。


<details>
  <summary>Details</summary>
Motivation: 当前扩展多语言LLMs的主要障碍是依赖于昂贵的特定目标语言标注数据和适应过程中出现的灾难性遗忘问题。

Method: 引入SSU策略，通过源数据和参数重要性评分方法，选择性地更新参数，以保护关键的源知识。应用列级冻结策略在适应之前保护这些参数。

Result: 在五种不同类型语言和7B及13B模型上的实验表明，SSU有效减轻了灾难性遗忘，源语言任务性能下降分别仅为3.4%（7B）和2.8%（13B）。

Conclusion: SSU在保持源语言能力的同时，目标语言性能与全量微调相当，甚至在某些情况下优于全量微调。

Abstract: Expanding the linguistic diversity of instruct large language models (LLMs) is crucial for global accessibility but is often hindered by the reliance on costly specialized target language labeled data and catastrophic forgetting during adaptation. We tackle this challenge under a realistic, low-resource constraint: adapting instruct LLMs using only unlabeled target language data. We introduce Source-Shielded Updates (SSU), a selective parameter update strategy that proactively preserves source knowledge. Using a small set of source data and a parameter importance scoring method, SSU identifies parameters critical to maintaining source abilities. It then applies a column-wise freezing strategy to protect these parameters before adaptation. Experiments across five typologically diverse languages and 7B and 13B models demonstrate that SSU successfully mitigates catastrophic forgetting. It reduces performance degradation on monolingual source tasks to just 3.4% (7B) and 2.8% (13B) on average, a stark contrast to the 20.3% and 22.3% from full fine-tuning. SSU also achieves target-language performance highly competitive with full fine-tuning, outperforming it on all benchmarks for 7B models and the majority for 13B models.

</details>


### [21] [LLMs Know More Than Words: A Genre Study with Syntax, Metaphor & Phonetics](https://arxiv.org/abs/2512.04957)
*Weiye Shi,Zhaowei Zhang,Shaoheng Yan,Yaodong Yang*

Main category: cs.CL

TL;DR: 本文介绍了一种新的多语言类型分类数据集，并探讨了大型语言模型从文本中学习语言特性的能力。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型是否能从原始文本中捕捉深层语言属性，如句法结构、语音线索和韵律模式。

Method: 引入了一个从Project Gutenberg获取的多语言类型分类数据集，并增加了三种语言特性（句法树结构、隐喻计数和语音指标）来评估其对分类性能的影响。

Result: 实验表明，尽管LLM分类器能从原始文本或明确提供的特性中学习潜在的语言结构，但不同特性在不同任务中的贡献不均衡。

Conclusion: 强调了模型训练中纳入更复杂语言信号的重要性。

Abstract: Large language models (LLMs) demonstrate remarkable potential across diverse language related tasks, yet whether they capture deeper linguistic properties, such as syntactic structure, phonetic cues, and metrical patterns from raw text remains unclear. To analysis whether LLMs can learn these features effectively and apply them to important nature language related tasks, we introduce a novel multilingual genre classification dataset derived from Project Gutenberg, a large-scale digital library offering free access to thousands of public domain literary works, comprising thousands of sentences per binary task (poetry vs. novel;drama vs. poetry;drama vs. novel) in six languages (English, French, German, Italian, Spanish, and Portuguese). We augment each with three explicit linguistic feature sets (syntactic tree structures, metaphor counts, and phonetic metrics) to evaluate their impact on classification performance. Experiments demonstrate that although LLM classifiers can learn latent linguistic structures either from raw text or from explicitly provided features, different features contribute unevenly across tasks, which underscores the importance of incorporating more complex linguistic signals during model training.

</details>


### [22] [Factuality and Transparency Are All RAG Needs! Self-Explaining Contrastive Evidence Re-ranking](https://arxiv.org/abs/2512.05012)
*Francielle Vargas,Daniel Pedronette*

Main category: cs.CL

TL;DR: CER是一种通过对比学习微调和生成标记级归因证据来重构检索的方法，提升了检索准确性并减少了幻觉。


<details>
  <summary>Details</summary>
Motivation: 提高检索系统的可靠性，特别是在安全性至关重要的领域，通过证据对齐减少主观或误导性解释的影响。

Method: 通过对比学习微调嵌入，并为每个检索段落生成标记级归因证据，自动选择硬性负样本。

Result: 在临床试验报告上评估，CER提高了检索准确性，减少了RAG系统中的幻觉，并提供了透明的、基于证据的检索。

Conclusion: 该方法创建了一个明确与证据推理对齐的嵌入空间，提高了安全性关键领域的检索可靠性。

Abstract: This extended abstract introduces Self-Explaining Contrastive Evidence Re-Ranking (CER), a novel method that restructures retrieval around factual evidence by fine-tuning embeddings with contrastive learning and generating token-level attribution rationales for each retrieved passage. Hard negatives are automatically selected using a subjectivity-based criterion, forcing the model to pull factual rationales closer while pushing subjective or misleading explanations apart. As a result, the method creates an embedding space explicitly aligned with evidential reasoning. We evaluated our method on clinical trial reports, and initial experimental results show that CER improves retrieval accuracy, mitigates the potential for hallucinations in RAG systems, and provides transparent, evidence-based retrieval that enhances reliability, especially in safety-critical domains.

</details>


### [23] [Arbitrage: Efficient Reasoning via Advantage-Aware Speculation](https://arxiv.org/abs/2512.05033)
*Monishwaran Maheswaran,Rishabh Tiwari,Yuezhou Hu,Kerem Dilmen,Coleman Hooper,Haocheng Xi,Nicholas Lee,Mehrdad Farajtabar,Michael W. Mahoney,Kurt Keutzer,Amir Gholami*

Main category: cs.CL

TL;DR: 提出了一种新的逐步级投机生成框架Arbitrage，通过动态路由机制提高推理效率。


<details>
  <summary>Details</summary>
Motivation: 现代大型语言模型在推理任务中表现出色，但推理过程计算成本高，传统的投机解码在语义等价步骤上存在不必要的拒绝问题。

Method: Arbitrage框架引入轻量级路由器，根据草稿模型和目标模型的相对优势动态选择生成步骤，避免了固定接受阈值的局限性。

Result: 在多个数学推理基准测试中，Arbitrage显著优于先前的逐步级投机解码基线，推理延迟降低了约2倍。

Conclusion: Arbitrage通过动态路由机制实现了接近最优的效率-准确性权衡，提升了推理效率。

Abstract: Modern Large Language Models achieve impressive reasoning capabilities with long Chain of Thoughts, but they incur substantial computational cost during inference, and this motivates techniques to improve the performance-cost ratio. Among these techniques, Speculative Decoding accelerates inference by employing a fast but inaccurate draft model to autoregressively propose tokens, which are then verified in parallel by a more capable target model. However, due to unnecessary rejections caused by token mismatches in semantically equivalent steps, traditional token-level Speculative Decoding struggles in reasoning tasks. Although recent works have shifted to step-level semantic verification, which improve efficiency by accepting or rejecting entire reasoning steps, existing step-level methods still regenerate many rejected steps with little improvement, wasting valuable target compute. To address this challenge, we propose Arbitrage, a novel step-level speculative generation framework that routes generation dynamically based on the relative advantage between draft and target models. Instead of applying a fixed acceptance threshold, Arbitrage uses a lightweight router trained to predict when the target model is likely to produce a meaningfully better step. This routing approximates an ideal Arbitrage Oracle that always chooses the higher-quality step, achieving near-optimal efficiency-accuracy trade-offs. Across multiple mathematical reasoning benchmarks, Arbitrage consistently surpasses prior step-level Speculative Decoding baselines, reducing inference latency by up to $\sim2\times$ at matched accuracy.

</details>


### [24] [Structured Document Translation via Format Reinforcement Learning](https://arxiv.org/abs/2512.05100)
*Haiyue Song,Johannes Eschbach-Dymanus,Hour Kaing,Sumire Honda,Hideki Tanaka,Bianka Buschbeck,Masao Utiyama*

Main category: cs.CL

TL;DR: 提出FormatRL，通过结构化奖励函数优化文档级XML/HTML翻译。


<details>
  <summary>Details</summary>
Motivation: 现有结构化文本翻译局限于句子级，难以处理复杂文档结构。

Method: 采用GRPO优化结构感知奖励（TreeSim、Node-chrF），结合StrucAUC细粒度评估。

Result: 在SAP基准测试中，6项指标均有提升。

Conclusion: 结构感知奖励函数可同步提升翻译质量和结构准确性。

Abstract: Recent works on structured text translation remain limited to the sentence level, as they struggle to effectively handle the complex document-level XML or HTML structures. To address this, we propose \textbf{Format Reinforcement Learning (FormatRL)}, which employs Group Relative Policy Optimization on top of a supervised fine-tuning model to directly optimize novel structure-aware rewards: 1) TreeSim, which measures structural similarity between predicted and reference XML trees and 2) Node-chrF, which measures translation quality at the level of XML nodes. Additionally, we apply StrucAUC, a fine-grained metric distinguishing between minor errors and major structural failures. Experiments on the SAP software-documentation benchmark demonstrate improvements across six metrics and an analysis further shows how different reward functions contribute to improvements in both structural and translation quality.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [25] [Solving N-Queen Problem using Las Vegas Algorithm with State Pruning](https://arxiv.org/abs/2512.04139)
*Susmita Sharma,Aayush Shrestha,Sitasma Thapa,Prashant Timalsina,Prakash Poudyal*

Main category: cs.AI

TL;DR: 本文提出了一种基于拉斯维加斯算法的混合算法，通过迭代剪枝减少搜索空间，以高效解决N皇后问题。


<details>
  <summary>Details</summary>
Motivation: N皇后问题是指在一个N x N的棋盘上放置N个皇后，使它们互不攻击，是约束满足算法的经典问题。传统的回溯法虽然保证找到解，但指数级时间复杂度使其在大规模实例中不实用。因此，随机方法如拉斯维加斯算法更受青睐，但随机性导致性能差异大。

Method: 研究提出了一种混合算法，在标准拉斯维加斯框架的基础上，通过迭代剪枝动态消除随机赋值阶段的无效位置，从而有效减少搜索空间。

Result: 分析结果表明，传统回溯法在N增加时扩展性较差，而所提出的技术能更快速地生成有效解。虽然大N值会导致一些性能变化，但算法在计算成本和解决方案保真度之间展示了有效的权衡。

Conclusion: 该算法特别适用于资源受限的计算环境，在需要及时获得单个解决方案时，是比传统方法更优的选择。

Abstract: The N-Queens problem, placing all N queens in a N x N chessboard where none attack the other, is a classic problem for constraint satisfaction algorithms. While complete methods like backtracking guarantee a solution, their exponential time complexity makes them impractical for large-scale instances thus, stochastic approaches, such as Las Vegas algorithm, are preferred. While it offers faster approximate solutions, it suffers from significant performance variance due to random placement of queens on the board. This research introduces a hybrid algorithm built on top of the standard Las Vegas framework through iterative pruning, dynamically eliminating invalid placements during the random assignment phase, thus this method effectively reduces the search space. The analysis results that traditional backtracking scales poorly with increasing N. In contrast, the proposed technique consistently generates valid solutions more rapidly, establishing it as a superior alternative to use where a single, timely solution is preferred over completeness. Although large N causes some performance variability, the algorithm demonstrates a highly effective trade-off between computational cost and solution fidelity, making it particularly suited for resource-constrained computing environments.

</details>


### [26] [RippleBench: Capturing Ripple Effects Using Existing Knowledge Repositories](https://arxiv.org/abs/2512.04144)
*Roy Rinberg,Usha Bhalla,Igor Shilov,Flavio P. Calmon,Rohit Gandikota*

Main category: cs.AI

TL;DR: 提出RippleBench-Maker，一种自动工具，用于生成Q&A数据集以测量模型编辑任务中的涟漪效应。


<details>
  <summary>Details</summary>
Motivation: 语言模型的针对性干预（如遗忘、去偏或模型编辑）常会引发涟漪效应，影响模型在相关但非预期领域的表现。因此，需要一个工具来量化和评估这些涟漪效应。

Method: 基于Wikipedia-based RAG pipeline (WikiRAG)，开发RippleBench-Maker生成多选题，构建RippleBench-Bio基准，并在WMDP数据集上评估了八种最先进的遗忘方法。

Result: 所有评估的遗忘方法在非目标领域都表现出显著的准确率下降，且各自有不同的传播特征。

Conclusion: RippleBench-Maker和RippleBench-Bio为研究模型编辑任务中的涟漪效应提供了有效工具和数据基准，支持持续的研究进展。

Abstract: Targeted interventions on language models, such as unlearning, debiasing, or model editing, are a central method for refining model behavior and keeping knowledge up to date. While these interventions aim to modify specific information within models (e.g., removing virology content), their effects often propagate to related but unintended areas (e.g., allergies); these side-effects are commonly referred to as the ripple effect. In this work, we present RippleBench-Maker, an automatic tool for generating Q&A datasets that allow for the measurement of ripple effects in any model-editing task. RippleBench-Maker builds on a Wikipedia-based RAG pipeline (WikiRAG) to generate multiple-choice questions at varying semantic distances from the target concept (e.g., the knowledge being unlearned). Using this framework, we construct RippleBench-Bio, a benchmark derived from the WMDP (Weapons of Mass Destruction Paper) dataset, a common unlearning benchmark. We evaluate eight state-of-the-art unlearning methods and find that all exhibit non-trivial accuracy drops on topics increasingly distant from the unlearned knowledge, each with distinct propagation profiles. To support ongoing research, we release our codebase for on-the-fly ripple evaluation, along with the benchmark, RippleBench-Bio.

</details>


### [27] [Orchestrator Multi-Agent Clinical Decision Support System for Secondary Headache Diagnosis in Primary Care](https://arxiv.org/abs/2512.04207)
*Xizhi Wu,Nelly Estefanie Garduno-Rapp,Justin F Rousseau,Mounika Thakkallapally,Hang Zhang,Yuelyu Ji,Shyam Visweswaran,Yifan Peng,Yanshan Wang*

Main category: cs.AI

TL;DR: 本文提出了一种基于多智能体的大型语言模型临床决策支持系统，旨在通过可解释的方式诊断继发性头痛。


<details>
  <summary>Details</summary>
Motivation: 继发性头痛需要专业护理，但临床医生在初级保健环境中常常面临诊断困难，尤其是在时间和信息有限的情况下。

Method: 构建了一个基于 orchestrator-specialist 架构的多智能体系统，将诊断分解为七个专门领域的智能体，并使用中心 orchestrator 进行任务分解和智能体协调。

Result: 在90例经专家验证的继发性头痛病例上评估，多智能体系统在与基于指南的提示（GPrompt）结合时，始终实现了最高的F1分数，尤其在较小的模型上表现更佳。

Conclusion: 结构化的多智能体推理不仅提升了诊断准确性，还提供了一种透明且与临床实践一致的可解释决策支持方法。

Abstract: Unlike most primary headaches, secondary headaches need specialized care and can have devastating consequences if not treated promptly. Clinical guidelines highlight several 'red flag' features, such as thunderclap onset, meningismus, papilledema, focal neurologic deficits, signs of temporal arteritis, systemic illness, and the 'worst headache of their life' presentation. Despite these guidelines, determining which patients require urgent evaluation remains challenging in primary care settings. Clinicians often work with limited time, incomplete information, and diverse symptom presentations, which can lead to under-recognition and inappropriate care. We present a large language model (LLM)-based multi-agent clinical decision support system built on an orchestrator-specialist architecture, designed to perform explicit and interpretable secondary headache diagnosis from free-text clinical vignettes. The multi-agent system decomposes diagnosis into seven domain-specialized agents, each producing a structured and evidence-grounded rationale, while a central orchestrator performs task decomposition and coordinates agent routing. We evaluated the multi-agent system using 90 expert-validated secondary headache cases and compared its performance with a single-LLM baseline across two prompting strategies: question-based prompting (QPrompt) and clinical practice guideline-based prompting (GPrompt). We tested five open-source LLMs (Qwen-30B, GPT-OSS-20B, Qwen-14B, Qwen-8B, and Llama-3.1-8B), and found that the orchestrated multi-agent system with GPrompt consistently achieved the highest F1 scores, with larger gains in smaller models. These findings demonstrate that structured multi-agent reasoning improves accuracy beyond prompt engineering alone and offers a transparent, clinically aligned approach for explainable decision support in secondary headache diagnosis.

</details>


### [28] [Balancing Safety and Helpfulness in Healthcare AI Assistants through Iterative Preference Alignment](https://arxiv.org/abs/2512.04210)
*Huy Nghiem,Swetasudha Panda,Devashish Khatwani,Huy V. Nguyen,Krishnaram Kenthapadi,Hal Daumé*

Main category: cs.AI

TL;DR: 提出了一个迭代式部署后对齐框架，结合KTO和DPO优化医疗领域LLM的安全性。


<details>
  <summary>Details</summary>
Motivation: 医疗对话助手需平衡安全合规与良性请求的响应，避免过度拒绝或危险服从。

Method: 使用KTO和DPO方法，基于CARES-18K基准对4种LLM进行多轮优化，并分析架构相关偏差。

Result: 有害查询检测的安全指标提升42%，发现模型架构与错误拒绝间的权衡关系。

Conclusion: 医疗对话助手需结合自评估与外部评判，以实现患者安全、用户信任和临床效用的平衡。

Abstract: Large Language Models (LLMs) are increasingly used in healthcare, yet ensuring their safety and trustworthiness remains a barrier to deployment. Conversational medical assistants must avoid unsafe compliance without over-refusing benign queries. We present an iterative post-deployment alignment framework that applies Kahneman-Tversky Optimization (KTO) and Direct Preference Optimization (DPO) to refine models against domain-specific safety signals. Using the CARES-18K benchmark for adversarial robustness, we evaluate four LLMs (Llama-3B/8B, Meditron-8B, Mistral-7B) across multiple cycles. Our results show up to 42% improvement in safety-related metrics for harmful query detection, alongside interesting trade-offs against erroneous refusals, thereby exposing architecture-dependent calibration biases. We also perform ablation studies to identify when self-evaluation is reliable and when external or finetuned judges are necessary to maximize performance gains. Our findings underscore the importance of adopting best practices that balance patient safety, user trust, and clinical utility in the design of conversational medical assistants.

</details>


### [29] [Educational Cone Model in Embedding Vector Spaces](https://arxiv.org/abs/2512.04227)
*Yo Ehara*

Main category: cs.AI

TL;DR: 本文提出了一种教育锥模型，用于评估不同嵌入方法在分析文本难度方面的适用性。


<details>
  <summary>Details</summary>
Motivation: 智能教育系统需要带有明确难度评级的人工标注数据集，而选择合适的嵌入方法是一个挑战。

Method: 提出一种基于几何框架的教育锥模型，假设简单文本在嵌入空间中多样性较低，而困难文本多样性较高，从而形成锥形分布。通过设计特定的损失函数，将嵌入评估转化为优化问题，并获得高效的解析解。

Result: 在真实数据集上的实验验证了该模型在识别与难度标注教育文本最对齐的嵌入空间方面的有效性和速度。

Conclusion: 教育锥模型能够有效地评估和选择最合适的嵌入方法，以分析文本难度，提高智能教育系统的性能。

Abstract: Human-annotated datasets with explicit difficulty ratings are essential in intelligent educational systems. Although embedding vector spaces are widely used to represent semantic closeness and are promising for analyzing text difficulty, the abundance of embedding methods creates a challenge in selecting the most suitable method. This study proposes the Educational Cone Model, which is a geometric framework based on the assumption that easier texts are less diverse (focusing on fundamental concepts), whereas harder texts are more diverse. This assumption leads to a cone-shaped distribution in the embedding space regardless of the embedding method used. The model frames the evaluation of embeddings as an optimization problem with the aim of detecting structured difficulty-based patterns. By designing specific loss functions, efficient closed-form solutions are derived that avoid costly computation. Empirical tests on real-world datasets validated the model's effectiveness and speed in identifying the embedding spaces that are best aligned with difficulty-annotated educational texts.

</details>


### [30] [Addressing Logical Fallacies In Scientific Reasoning From Large Language Models: Towards a Dual-Inference Training Framework](https://arxiv.org/abs/2512.04228)
*Peter B. Walker,Hannah Davidson,Aiden Foster,Matthew Lienert,Thomas Pardue,Dale Russell*

Main category: cs.AI

TL;DR: 本文揭示了大型语言模型在科学领域推理中的逻辑缺陷，并提出了一种结合肯定生成与结构化反事实否定的双重推理训练框架。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然在自然语言处理上表现突出，但在面对科学领域的否定、反例和错误前提时，存在逻辑漏洞和推理弱点，尤其是在因果推理和对抗性操作方面。

Method: 引入了一种双重推理训练框架，将肯定生成与结构化反事实否定相结合，基于形式逻辑、认知科学和对抗训练，通过计算上的“否定前提”机制来增强模型的推理和鲁棒性。

Result: 实验表明，当前主流平台的大型语言模型在科学推理中确实表现出系统性的弱点，而新的训练框架能提升模型对无效推理的识别和拒绝能力。

Conclusion: 通过结合生成合成和显式否定感知目标，该框架使模型不仅能确认有效推理，还能拒绝无效推理，从而提升模型的鲁棒性和可解释性，并使其更接近人类的推理方式。

Abstract: Large Language Models (LLMs) have transformed natural language processing and hold growing promise for advancing science, healthcare, and decision-making. Yet their training paradigms remain dominated by affirmation-based inference, akin to \textit{modus ponens}, where accepted premises yield predicted consequents. While effective for generative fluency, this one-directional approach leaves models vulnerable to logical fallacies, adversarial manipulation, and failures in causal reasoning. This paper makes two contributions. First, it demonstrates how existing LLMs from major platforms exhibit systematic weaknesses when reasoning in scientific domains with negation, counterexamples, or faulty premises \footnote{Code to recreate these experiments are at https://github.com/hannahdavidsoncollege-maker/ScientificReasoningForEnvironment-MedicineWithLLMs. Second, it introduces a dual-reasoning training framework that integrates affirmative generation with structured counterfactual denial. Grounded in formal logic, cognitive science, and adversarial training, this training paradigm formalizes a computational analogue of ``denying the antecedent'' as a mechanism for disconfirmation and robustness. By coupling generative synthesis with explicit negation-aware objectives, the framework enables models that not only affirm valid inferences but also reject invalid ones, yielding systems that are more resilient, interpretable, and aligned with human reasoning.

</details>


### [31] [The Geometry of Benchmarks: A New Path Toward AGI](https://arxiv.org/abs/2512.04276)
*Przemyslaw Chojecki*

Main category: cs.AI

TL;DR: 本文提出了一个几何框架，将AI智能体的心理测量电池视为结构化模空间中的点，并通过能力函数来描述其表现。引入了自主AI（AAI）量表、模空间电池、GVU操作符和自我改进系数κ。


<details>
  <summary>Details</summary>
Motivation: 当前AI评估依赖于孤立的测试套件，缺乏对泛化和自主自我改进的推理指导，需要新的框架来理解AI进步。

Method: 引入几何框架，定义AAI量表和模空间电池，提出GVU操作符，并定义自我改进系数κ，使用Lie导数进行描述。

Result: 通过密集电池家族可以认证整个任务空间区域的表现，并提出了生成器-验证器-更新器（GVU）操作符，涵盖强化学习、自我博弈、辩论和基于验证器的微调。

Conclusion: AI进步应理解为在模空间中由GVU动力学驱动的流程，而不是在单个排行榜上的得分。

Abstract: Benchmarks are the primary tool for assessing progress in artificial intelligence (AI), yet current practice evaluates models on isolated test suites and provides little guidance for reasoning about generality or autonomous self-improvement. Here we introduce a geometric framework in which all psychometric batteries for AI agents are treated as points in a structured moduli space, and agent performance is described by capability functionals over this space. First, we define an Autonomous AI (AAI) Scale, a Kardashev-style hierarchy of autonomy grounded in measurable performance on batteries spanning families of tasks (for example reasoning, planning, tool use and long-horizon control). Second, we construct a moduli space of batteries, identifying equivalence classes of benchmarks that are indistinguishable at the level of agent orderings and capability inferences. This geometry yields determinacy results: dense families of batteries suffice to certify performance on entire regions of task space. Third, we introduce a general Generator-Verifier-Updater (GVU) operator that subsumes reinforcement learning, self-play, debate and verifier-based fine-tuning as special cases, and we define a self-improvement coefficient $κ$ as the Lie derivative of a capability functional along the induced flow. A variance inequality on the combined noise of generation and verification provides sufficient conditions for $κ> 0$. Our results suggest that progress toward artificial general intelligence (AGI) is best understood as a flow on moduli of benchmarks, driven by GVU dynamics rather than by scores on individual leaderboards.

</details>


### [32] [Artificial Intelligence Applications in Horizon Scanning for Infectious Diseases](https://arxiv.org/abs/2512.04287)
*Ian Miles,Mayumi Wakimoto,Wagner Meira,Daniela Paula,Daylene Ticiane,Bruno Rosa,Jane Biddulph,Stelios Georgiou,Valdir Ermida*

Main category: cs.AI

TL;DR: 本文探讨了人工智能在Horizon Scanning中的应用，特别是在识别和应对传染病新兴威胁和机会方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 研究如何AI工具可以增强信号检测、数据监测、场景分析和决策支持，并解决AI采用的风险。

Method: 审查AI工具在Horizon Scanning中的整合，分析其在公共卫生准备中的应用和限制。

Result: 展示了AI在公共卫生准备中的潜力和局限性，为前瞻性文献体系贡献了重要发现。

Conclusion: AI在识别和应对传染病威胁方面具有重要作用，但需有效实施和治理策略以应对相关风险。

Abstract: This review explores the integration of Artificial Intelligence into Horizon Scanning, focusing on identifying and responding to emerging threats and opportunities linked to Infectious Diseases. We examine how AI tools can enhance signal detection, data monitoring, scenario analysis, and decision support. We also address the risks associated with AI adoption and propose strategies for effective implementation and governance. The findings contribute to the growing body of Foresight literature by demonstrating the potential and limitations of AI in Public Health preparedness.

</details>


### [33] [Towards better dense rewards in Reinforcement Learning Applications](https://arxiv.org/abs/2512.04302)
*Shuyuan Zhang*

Main category: cs.AI

TL;DR: 该论文探讨了强化学习中设计有效密集奖励函数的问题，提出多种方法以改善奖励构建的有效性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 密集奖励函数可以改善强化学习中智能体的学习效率，但设计不当会导致意外行为或奖励篡改，尤其在复杂环境中更难手工设计奖励。

Method: 论文提出了多种方法，包括逆向强化学习、从人类偏好建模奖励，以及自监督学习的内在奖励。

Result: 这些方法为密集奖励的设计提供了有希望的方向，但各自在通用性、可扩展性和与人类意图对齐方面存在权衡。

Conclusion: 论文旨在探索不同强化学习应用中，解决密集奖励构建问题并提升其有效性和可靠性的方法。

Abstract: Finding meaningful and accurate dense rewards is a fundamental task in the field of reinforcement learning (RL) that enables agents to explore environments more efficiently. In traditional RL settings, agents learn optimal policies through interactions with an environment guided by reward signals. However, when these signals are sparse, delayed, or poorly aligned with the intended task objectives, agents often struggle to learn effectively. Dense reward functions, which provide informative feedback at every step or state transition, offer a potential solution by shaping agent behavior and accelerating learning. Despite their benefits, poorly crafted reward functions can lead to unintended behaviors, reward hacking, or inefficient exploration. This problem is particularly acute in complex or high-dimensional environments where handcrafted rewards are difficult to specify and validate. To address this, recent research has explored a variety of approaches, including inverse reinforcement learning, reward modeling from human preferences, and self-supervised learning of intrinsic rewards. While these methods offer promising directions, they often involve trade-offs between generality, scalability, and alignment with human intent. This proposal explores several approaches to dealing with these unsolved problems and enhancing the effectiveness and reliability of dense reward construction in different RL applications.

</details>


### [34] [Efficient Reinforcement Learning with Semantic and Token Entropy for LLM Reasoning](https://arxiv.org/abs/2512.04359)
*Hongye Cao,Zhixin Bai,Ziyue Peng,Boyan Wang,Tianpei Yang,Jing Huo,Yuyao Zhang,Yang Gao*

Main category: cs.AI

TL;DR: 提出一种利用语义和词元熵信号的高效强化学习框架，以缓解熵崩溃并增强大语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 强化学习在提升大语言模型推理能力方面表现出色，但准确率导向的学习模式容易导致熵崩溃，降低策略探索能力。

Method: 从数据角度出发，引入语义熵引导的课程学习，对训练数据按语义熵从低到高排序，以指导从易到难的优化。在算法设计上，采用非均匀词元处理，对低熵词元施加KL正则化，并对这些词元内的高协方差部分施加更强的约束。

Result: 在6个基准测试和3个不同参数规模的基础模型上，该方法在提升推理能力方面优于其他基于熵的方法。

Conclusion: 通过联合优化数据组织和算法设计，该方法有效缓解了熵崩溃，并增强了大语言模型的推理能力。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has demonstrated superior performance in enhancing the reasoning capability of large language models (LLMs). However, this accuracy-oriented learning paradigm often suffers from entropy collapse, which reduces policy exploration and limits reasoning capabilities. To address this challenge, we propose an efficient reinforcement learning framework that leverages entropy signals at both the semantic and token levels to improve reasoning. From the data perspective, we introduce semantic entropy-guided curriculum learning, organizing training data from low to high semantic entropy to guide progressive optimization from easier to more challenging tasks. For the algorithmic design, we adopt non-uniform token treatment by imposing KL regularization on low-entropy tokens that critically impact policy exploration and applying stronger constraints on high-covariance portions within these tokens. By jointly optimizing data organization and algorithmic design, our method effectively mitigates entropy collapse and enhances LLM reasoning. Experimental results across 6 benchmarks with 3 different parameter-scale base models demonstrate that our method outperforms other entropy-based approaches in improving reasoning.

</details>


### [35] [GovBench: Benchmarking LLM Agents for Real-World Data Governance Workflows](https://arxiv.org/abs/2512.04416)
*Zhou Liu,Zhaoyang Han,Guochen Yan,Hao Liang,Bohan Zeng,Xing Chen,Yuanfeng Song,Wentao Zhang*

Main category: cs.AI

TL;DR: 本文介绍了GovBench，一个用于自动化数据治理的基准测试，并提出了一个名为DataGovAgent的框架，以提高数据治理任务的执行效果。


<details>
  <summary>Details</summary>
Motivation: 数据治理对数据质量、安全性和合规性至关重要，但现有自动化数据科学基准测试未能捕捉到数据治理的独特挑战，因此需要专门的基准和工具。

Method: 引入了GovBench，一个基于真实场景和数据的基准，以及DataGovAgent，一个采用Planner-Executor-Evaluator架构的框架，集成了基于约束的规划、检索增强生成和沙盒调试。

Result: DataGovAgent在复杂任务上的平均任务得分（ATS）从39.7提高到54.9，调试迭代次数减少了77.9%。

Conclusion: GovBench填补了自动化数据治理基准的空白，DataGovAgent通过其创新架构显著提升了任务执行效果和效率。

Abstract: Data governance ensures data quality, security, and compliance through policies and standards, a critical foundation for scaling modern AI development. Recently, large language models (LLMs) have emerged as a promising solution for automating data governance by translating user intent into executable transformation code. However, existing benchmarks for automated data science often emphasize snippet-level coding or high-level analytics, failing to capture the unique challenge of data governance: ensuring the correctness and quality of the data itself. To bridge this gap, we introduce GovBench, a benchmark featuring 150 diverse tasks grounded in real-world scenarios, built on data from actual cases. GovBench employs a novel "reversed-objective" methodology to synthesize realistic noise and utilizes rigorous metrics to assess end-to-end pipeline reliability. Our analysis on GovBench reveals that current models struggle with complex, multi-step workflows and lack robust error-correction mechanisms. Consequently, we propose DataGovAgent, a framework utilizing a Planner-Executor-Evaluator architecture that integrates constraint-based planning, retrieval-augmented generation, and sandboxed feedback-driven debugging. Experimental results show that DataGovAgent significantly boosts the Average Task Score (ATS) on complex tasks from 39.7 to 54.9 and reduces debugging iterations by over 77.9 percent compared to general-purpose baselines.

</details>


### [36] [Solving LLM Repetition Problem in Production: A Comprehensive Study of Multiple Solutions](https://arxiv.org/abs/2512.04419)
*Weiwei Wang,Weijie Zou,Jiyong Min*

Main category: cs.AI

TL;DR: 本文研究了LLMs在批量代码解释任务中的重复生成问题，并提出了三种解决方案。


<details>
  <summary>Details</summary>
Motivation: 重复生成问题严重影响LLMs在生产环境中的性能，导致系统性能下降和停滞，需要解决。

Method: 识别了三种重复模式，并使用马尔可夫模型进行理论分析，提出三种解决方案：(1) Beam Search解码，(2) presence_penalty超参数，(3) DPO微调。

Result: 实验验证显示，Beam Search解码适用于所有重复模式，presence_penalty对特定模式有效，DPO微调是通用的模型级解决方案。

Conclusion: 结合生产经验和实验验证，提出了系统化的理论分析和多种解决方案，为生产环境提供了实用且经过验证的方法。

Abstract: The repetition problem, where Large Language Models (LLMs) continuously generate repetitive content without proper termination, poses a critical challenge in production deployments, causing severe performance degradation and system stalling. This paper presents a comprehensive investigation and multiple practical solutions for the repetition problem encountered in real-world batch code interpretation tasks.
  We identify three distinct repetition patterns: (1) business rule generation repetition, (2) method call relationship analysis repetition, and (3) PlantUML diagram syntax generation repetition. Through rigorous theoretical analysis based on Markov models, we establish that the root cause lies in greedy decoding's inability to escape repetitive loops, exacerbated by self-reinforcement effects.
  Our comprehensive experimental evaluation demonstrates three viable solutions: (1) Beam Search decoding with early_stopping=True serves as a universal post-hoc mechanism that effectively resolves all three repetition patterns; (2) presence_penalty hyperparameter provides an effective solution specifically for BadCase 1; and (3) Direct Preference Optimization (DPO) fine-tuning offers a universal model-level solution for all three BadCases.
  The primary value of this work lies in combining first-hand production experience with extensive experimental validation. Our main contributions include systematic theoretical analysis of repetition mechanisms, comprehensive evaluation of multiple solutions with task-specific applicability mapping, identification of early_stopping as the critical parameter for Beam Search effectiveness, and practical production-ready solutions validated in real deployment environments.

</details>


### [37] [TaskEval: Synthesised Evaluation for Foundation-Model Tasks](https://arxiv.org/abs/2512.04442)
*Dilani Widanapathiranage,Scott Barnett,Stefanus Kurniawan,Wannita Takerngsaksiri*

Main category: cs.AI

TL;DR: 提出了一种针对基础模型（FM）任务特定评估器的合成方法，以实现自动化和捕获反馈的自定义用户界面。


<details>
  <summary>Details</summary>
Motivation: 幻觉是基础模型应用中的关键问题，现有方法缺乏针对特定任务的评估指标和数据集，需要自动化和深度集成人类洞察的方法。

Method: 提出了一种包含三个核心创新的方法：(1) 任务无关的元模型，(2) 有效利用人类反馈的交互协议，(3) 评估合成器。

Result: 在两个不同的FM任务（图表数据提取和文档问答）上验证了该方法，并实现了93%和90%的评估准确率。

Conclusion: 该方法解决了工程团队如何评估和审查FM任务输出的问题，为任务特定评估器的合成提供了有效途径。

Abstract: Hallucinations are a key concern when creating applications that rely on Foundation models (FMs). Understanding where and how these subtle failures occur in an application relies on evaluation methods known as \textit{evals}. Prior work focuses on defining new eval methods or benchmark datasets for specific tasks. However, neither helps a software team with a task-specific FM application when there is no metric or dataset. The demand for both automated approaches and deep integration of human insight makes this a challenging problem. We address this gap by proposing an approach to synthesise a FM task-specific evaluator program that provides automation and a custom UI for capturing feedback. The core novelty of our approach lies in: (1) a task-agnostic meta-model that captures properties of any FM task, (2) an interaction protocol for efficient use of human feedback, and (3) an eval synthesiser that selects or generates an appropriate set of evals. We implement our approach in \toolname and demonstrate the concept on two diverse FM tasks: chart data extraction and document question answering. A preliminary evaluation on the quality of our selected evals shows 93\% and 90\% accuracy respectively. Our research tackles a growing problem facing engineering teams, how to evaluate and review outputs from FM tasks.

</details>


### [38] [MARL Warehouse Robots](https://arxiv.org/abs/2512.04463)
*Price Allman,Lian Thang,Dre Simmons,Salmon Riaz*

Main category: cs.AI

TL;DR: 本文比较了多智能体强化学习算法在合作仓储机器人中的表现，发现QMIX在特定环境下表现优于IPPO，但需要大量超参数调整。


<details>
  <summary>Details</summary>
Motivation: 研究旨在评估不同多智能体强化学习算法在仓储机器人任务中的有效性，并探讨其在实际应用中的可行性。

Method: 在Robotic Warehouse环境和Unity 3D模拟中对QMIX和IPPO进行评估，并进行超参数调整。

Result: QMIX的性能显著优于独立学习方法（平均回报3.25对比IPPO的0.38），并在Unity ML-Agents中成功部署，实现了一百万步训练后的稳定包裹递送。

Conclusion: QMIX在小型部署（2-4个机器人）中表现良好，但在大规模扩展方面仍面临挑战。

Abstract: We present a comparative study of multi-agent reinforcement learning (MARL) algorithms for cooperative warehouse robotics. We evaluate QMIX and IPPO on the Robotic Warehouse (RWARE) environment and a custom Unity 3D simulation. Our experiments reveal that QMIX's value decomposition significantly outperforms independent learning approaches (achieving 3.25 mean return vs. 0.38 for advanced IPPO), but requires extensive hyperparameter tuning -- particularly extended epsilon annealing (5M+ steps) for sparse reward discovery. We demonstrate successful deployment in Unity ML-Agents, achieving consistent package delivery after 1M training steps. While MARL shows promise for small-scale deployments (2-4 robots), significant scaling challenges remain. Code and analyses: https://pallman14.github.io/MARL-QMIX-Warehouse-Robots/

</details>


### [39] [Persona-based Multi-Agent Collaboration for Brainstorming](https://arxiv.org/abs/2512.04488)
*Nate Straub,Saara Khan,Kat Jay,Brian Cabral,Oskar Linde*

Main category: cs.AI

TL;DR: 本文展示了基于角色的的多智能体头脑风暴在多样主题和学科思想中的重要性，并提出了一个角色选择框架来提升头脑风暴的效果。


<details>
  <summary>Details</summary>
Motivation: 以往的研究表明，广义的多智能体协作通常比单个智能体提供更好的推理。因此，作者提出通过角色领域策展来改善头脑风暴结果。

Method: 通过多种实验设置，评估不同角色配对（如医生与虚拟现实工程师）和A2A（智能体对智能体）动态（分离、共同、分离-然后共同）的头脑风暴输出。

Result: 研究发现角色选择影响思想领域，协作模式改变思想生成的多样性，多智能体角色驱动头脑风暴产生思想深度和跨领域覆盖。

Conclusion: 基于角色的的多智能体头脑风暴可以显著提高思想的深度和多样性，并且角色选择和协作模式对结果有重要影响。

Abstract: We demonstrate the importance of persona-based multi-agents brainstorming for both diverse topics and subject matter ideation. Prior work has shown that generalized multi-agent collaboration often provides better reasoning than a single agent alone. In this paper, we propose and develop a framework for persona-based agent selection, showing how persona domain curation can improve brainstorming outcomes. Using multiple experimental setups, we evaluate brainstorming outputs across different persona pairings (e.g., Doctor vs VR Engineer) and A2A (agent-to-agent) dynamics (separate, together, separate-then-together). Our results show that (1) persona choice shapes idea domains, (2) collaboration mode shifts diversity of idea generation, and (3) multi-agent persona-driven brainstorming produces idea depth and cross-domain coverage.

</details>


### [40] [A Modular Cognitive Architecture for Assisted Reasoning: The Nemosine Framework](https://arxiv.org/abs/2512.04500)
*Edervaldo Melo*

Main category: cs.AI

TL;DR: 提出了一种模块化认知架构Nemosine Framework，用于辅助推理和决策支持。


<details>
  <summary>Details</summary>
Motivation: 支持辅助推理、结构化思维和系统分析，为符号-模块化推理架构的研究提供基础。

Method: 通过功能性认知模块（'personas'）组织任务，结合元认知、分布式认知和模块化认知系统的原理，并采用形式化规范、内部一致性标准和可复现的结构组件进行架构记录。

Result: 提供了一个清晰的未来计算实现的概念基础。

Conclusion: Nemosine Framework为辅助问题解决和决策支持提供了操作性结构，并为符号-模块化架构的研究做出了贡献。

Abstract: This paper presents the Nemosine Framework, a modular cognitive architecture designed to support assisted reasoning, structured thinking, and systematic analysis. The model operates through functional cognitive modules ("personas") that organize tasks such as planning, evaluation, cross-checking, and narrative synthesis. The framework combines principles from metacognition, distributed cognition, and modular cognitive systems to offer an operational structure for assisted problem-solving and decision support. The architecture is documented through formal specification, internal consistency criteria, and reproducible structural components. The goal is to provide a clear conceptual basis for future computational implementations and to contribute to the study of symbolic-modular architectures for reasoning.

</details>


### [41] [BiTAgent: A Task-Aware Modular Framework for Bidirectional Coupling between Multimodal Large Language Models and World Models](https://arxiv.org/abs/2512.04513)
*Yu-Wei Zhan,Xin Wang,Pengzhe Mao,Tongtong Feng,Ren Wang,Wenwu Zhu*

Main category: cs.AI

TL;DR: 提出了一种名为BiTAgent的框架，通过双向耦合多模态大语言模型（MLLMs）和世界模型（WMs）以实现更稳定的多任务和跨环境泛化。


<details>
  <summary>Details</summary>
Motivation: 解决MLLMs与WMs结合中的关键挑战，即建立语义意图与动态状态表示之间的紧密耦合，以及实现支持多任务学习和跨环境泛化的任务感知适应性。

Method: 提出了BiTAgent，一个任务感知的动态联合框架，通过三个组件实现MLLMs和WMs之间的双向交互：任务感知动态联合学习、任务感知行为学习和MLLM-WM联合优化。

Result: 在多任务和跨环境设置中，BiTAgent相较于最先进的基线方法表现出优越的稳定性和泛化能力。

Conclusion: BiTAgent为开放式的具身学习提供了一个有前景的方向，通过双向耦合机制有效协调了语义推理和动态预测。

Abstract: Building generalist embodied agents requires a unified system that can interpret multimodal goals, model environment dynamics, and execute reliable actions across diverse real-world tasks. Multimodal large language models (MLLMs) offer strong semantic priors and cross-modal generalization, while world models (WMs) provide actionable latent dynamics for prediction and control. Their combination holds promise for open-ended embodied intelligence, yet introduces two key challenges: (1) establishing a tight coupling between the semantic intent from MLLMs and the dynamic state representations within the WM's latent space, and (2) achieving task-aware adaptability that supports multi-task learning and cross-environment generalization. To address these limitations, we propose BiTAgent, a task-aware dynamic joint framework that enables bidirectional coupling between MLLMs and WMs. BiTAgent establishes two complementary pathways: a forward path that injects MLLM representations into the WM's latent space for semantically guided imagination, and a backward path where WM-generated feedback refines the MLLM's semantic space via dense text-conditioned rewards. This bidirectional interaction is realized through three synergistic components: Task-Aware Dynamic Joint Learning, Task-Aware Behavior Learning, and MLLM-WM Joint Optimization, which together harmonize semantic reasoning and dynamic prediction. Extensive experiments across multi-task and cross-environment settings demonstrate superior stability and generalization over state-of-the-art baselines, marking a step toward open-ended embodied learning.

</details>


### [42] [The Ethics of Generative AI](https://arxiv.org/abs/2512.04598)
*Michael Klenk*

Main category: cs.AI

TL;DR: 本章讨论生成式人工智能的伦理问题，包括技术入门、责任、隐私、偏见和公平、异化和剥削，以及生成式AI特有的伦理问题。


<details>
  <summary>Details</summary>
Motivation: 生成式AI使得技术可以像人类一样被体验，这为AI伦理哲学提供了一个富有成效的研究方向。

Method: 通过技术入门和伦理分析，探讨生成式AI如何加剧和缓解AI伦理中的常见关切，并特别分析生成式AI的模仿生成性引发的伦理问题。

Result: 生成式AI既加剧了AI伦理中的某些问题，也缓解了其他问题，并引发了一系列特有的伦理讨论。

Conclusion: 生成式AI的伦理问题需要综合考虑其技术特性和社会影响，特别是在作者身份、信用、机器与人的社会关系以及影响、说服和操纵等方面。

Abstract: This chapter discusses the ethics of generative AI. It provides a technical primer to show how generative AI affords experiencing technology as if it were human, and this affordance provides a fruitful focus for the philosophical ethics of generative AI. It then shows how generative AI can both aggravate and alleviate familiar ethical concerns in AI ethics, including responsibility, privacy, bias and fairness, and forms of alienation and exploitation. Finally, the chapter examines ethical questions that arise specifically from generative AI's mimetic generativity, such as debates about authorship and credit, the emergence of as-if social relationships with machines, and new forms of influence, persuasion, and manipulation.

</details>


### [43] [Neural Decoding of Overt Speech from ECoG Using Vision Transformers and Contrastive Representation Learning](https://arxiv.org/abs/2512.04618)
*Mohamed Baha Ben Ticha,Xingchen Ran,Guillaume Saldanha,Gaël Le Godais,Philémon Roussel,Marc Aubert,Amina Fontanell,Thomas Costecalde,Lucas Struber,Serpil Karakas,Shaomin Zhang,Philippe Kahane,Guillaume Charvet,Stéphan Chabardès,Blaise Yvert*

Main category: cs.AI

TL;DR: 本文提出了一种基于编码器-解码器深度神经架构的离线语音解码流程，结合视觉变换器和对比学习，以增强从ECoG信号直接回归语音。


<details>
  <summary>Details</summary>
Motivation: 语音脑机接口（BCIs）为严重瘫痪患者提供了沟通的解决方案。当前挑战在于通过表面ECoG记录直接回归皮层信号实现流式语音重建，并优化神经解码器。

Method: 提出的解码流程采用编码器-解码器深度神经架构，整合了视觉变换器和对比学习，以增强从ECoG信号直接回归语音。

Result: 该方法在两个数据集上进行了评估，分别使用临床硬膜下电极和完全可植入的WIMAGINE硬膜外系统，展示了从完全可植入和无线硬膜外记录系统解码语音的初步尝试。

Conclusion: 该研究为长期使用的完全可植入和无线硬膜外记录系统解码语音提供了前景。

Abstract: Speech Brain Computer Interfaces (BCIs) offer promising solutions to people with severe paralysis unable to communicate. A number of recent studies have demonstrated convincing reconstruction of intelligible speech from surface electrocorticographic (ECoG) or intracortical recordings by predicting a series of phonemes or words and using downstream language models to obtain meaningful sentences. A current challenge is to reconstruct speech in a streaming mode by directly regressing cortical signals into acoustic speech. While this has been achieved recently using intracortical data, further work is needed to obtain comparable results with surface ECoG recordings. In particular, optimizing neural decoders becomes critical in this case. Here we present an offline speech decoding pipeline based on an encoder-decoder deep neural architecture, integrating Vision Transformers and contrastive learning to enhance the direct regression of speech from ECoG signals. The approach is evaluated on two datasets, one obtained with clinical subdural electrodes in an epileptic patient, and another obtained with the fully implantable WIMAGINE epidural system in a participant of a motor BCI trial. To our knowledge this presents a first attempt to decode speech from a fully implantable and wireless epidural recording system offering perspectives for long-term use.

</details>


### [44] [Turbo-Muon: Accelerating Orthogonality-Based Optimization with Pre-Conditioning](https://arxiv.org/abs/2512.04632)
*Thibaut Boissin,Thomas Massena,Franck Mamalet,Mathieu Serrurier*

Main category: cs.AI

TL;DR: 提出一种加速Newton-Schulz收敛并降低计算成本的新预处理方法，在保持模型性能的同时提高训练速度。


<details>
  <summary>Details</summary>
Motivation: 基于正交性的优化器（如Muon）在大规模训练中表现出色，但其依赖昂贵的梯度正交化步骤，影响了效率。

Method: 引入预处理程序以加速Newton-Schulz收敛，减少计算成本，并在不降低近似质量的前提下减少迭代次数。

Result: 在Newton-Schulz近似中实现高达2.8倍的加速，并在端到端训练中实现5-10%的运行时间改进。

Conclusion: 该方法在不需超参数调整的情况下，能作为简单插入式替代，提升训练效率并保持模型性能。

Abstract: Orthogonality-based optimizers, such as Muon, have recently shown strong performance across large-scale training and community-driven efficiency challenges. However, these methods rely on a costly gradient orthogonalization step. Even efficient iterative approximations such as Newton-Schulz remain expensive, typically requiring dozens of matrix multiplications to converge. We introduce a preconditioning procedure that accelerates Newton-Schulz convergence and reduces its computational cost. We evaluate its impact and show that the overhead of our preconditioning can be made negligible. Furthermore, the faster convergence it enables allows us to remove one iteration out of the usual five without degrading approximation quality. Our publicly available implementation achieves up to a 2.8x speedup in the Newton-Schulz approximation. We also show that this has a direct impact on end-to-end training runtime with 5-10% improvement in realistic training scenarios across two efficiency-focused tasks. On challenging language or vision tasks, we validate that our method maintains equal or superior model performance while improving runtime. Crucially, these improvements require no hyperparameter tuning and can be adopted as a simple drop-in replacement. Our code is publicly available on github.

</details>


### [45] [Towards Ethical Multi-Agent Systems of Large Language Models: A Mechanistic Interpretability Perspective](https://arxiv.org/abs/2512.04691)
*Jae Hee Lee,Anne Lauscher,Stefano V. Albrecht*

Main category: cs.AI

TL;DR: 这篇论文提出了一个研究议程，旨在通过机制可解释性确保多智能体大型语言模型（MALMs）的伦理行为。


<details>
  <summary>Details</summary>
Motivation: 多智能体大型语言模型在各种应用中表现出巨大潜力，但同时也带来了显著的伦理挑战。因此，需要确保这些系统的伦理行为。

Method: 论文确定了三个关键研究挑战：(i) 开发全面评估框架以在个体、交互和系统层面评估伦理行为；(ii) 通过机制可解释性阐明导致新兴行为的内部机制；(iii) 实施有针对性的参数高效对齐技术，引导MALMs朝向伦理行为而不影响其性能。

Result: 论文提出了一个研究议程，为解决MALMs的伦理问题提供了一个系统的方法。

Conclusion: 通过机制可解释性，可以更好地理解和引导MALMs的行为，以确保其在复杂应用中的伦理合规性。

Abstract: Large language models (LLMs) have been widely deployed in various applications, often functioning as autonomous agents that interact with each other in multi-agent systems. While these systems have shown promise in enhancing capabilities and enabling complex tasks, they also pose significant ethical challenges. This position paper outlines a research agenda aimed at ensuring the ethical behavior of multi-agent systems of LLMs (MALMs) from the perspective of mechanistic interpretability. We identify three key research challenges: (i) developing comprehensive evaluation frameworks to assess ethical behavior at individual, interactional, and systemic levels; (ii) elucidating the internal mechanisms that give rise to emergent behaviors through mechanistic interpretability; and (iii) implementing targeted parameter-efficient alignment techniques to steer MALMs towards ethical behaviors without compromising their performance.

</details>


### [46] [Playing the Player: A Heuristic Framework for Adaptive Poker AI](https://arxiv.org/abs/2512.04714)
*Andrew Paterson,Carl Sanders*

Main category: cs.AI

TL;DR: 本文挑战了扑克AI以不可被剥削的完美玩法为主导的传统观念，提出了一种名为Patrick的AI，它基于最大化剥削对手的理念，通过专门设计的架构和新的预测锚定学习方法，针对人类对手的心理和非理性行为进行优化，在64,267手牌的测试中取得了盈利表现。


<details>
  <summary>Details</summary>
Motivation: 传统的扑克AI研究专注于创建不可被剥削的策略，即追求机器完美玩法，但这忽略了人类玩家的非理性和可预测性。本文旨在探索一种新范式，即通过最大化剥削人类对手的心理和认知偏差来赢得比赛。

Method: Patrick采用了一种专门设计的架构，专注于理解和攻击人类对手的缺陷，并引入了新颖的预测锚定学习方法，通过分析对手的行为模式进行针对性调整。

Result: 在64,267手牌的试验中，Patrick展示了其盈利能力，证明了剥削策略在实战中的有效性。

Conclusion: 追求不可被剥削的“完美”策略是一种误导，真正的挑战在于开发能够掌握人类不完美艺术的AI，这为扑克AI的研究开辟了新的方向。

Abstract: For years, the discourse around poker AI has been dominated by the concept of solvers and the pursuit of unexploitable, machine-perfect play. This paper challenges that orthodoxy. It presents Patrick, an AI built on the contrary philosophy: that the path to victory lies not in being unexploitable, but in being maximally exploitative. Patrick's architecture is a purpose-built engine for understanding and attacking the flawed, psychological, and often irrational nature of human opponents. Through detailed analysis of its design, its novel prediction-anchored learning method, and its profitable performance in a 64,267-hand trial, this paper makes the case that the solved myth is a distraction from the real, far more interesting challenge: creating AI that can master the art of human imperfection.

</details>


### [47] [Are LLMs Truly Multilingual? Exploring Zero-Shot Multilingual Capability of LLMs for Information Retrieval: An Italian Healthcare Use Case](https://arxiv.org/abs/2512.04834)
*Vignesh Kumar Kembu,Pierandrea Morandini,Marta Bianca Maria Ranzini,Antonino Nocera*

Main category: cs.AI

TL;DR: 本文探讨了开源多语言LLMs在意大利语电子健康记录（EHRs）信息提取方面的能力，特别是在共病提取任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 临床记录中的信息提取是数字医疗中的关键任务，但传统NLP技术因临床语言的复杂性和高内部语义而表现不佳。LLMs的出现为解决这一问题提供了新工具。

Method: 通过在意大利语EHRs上进行详细实验，评估了不同开源多语言LLMs在共病提取任务中的性能，并与本地模式匹配和手动注释进行了比较。

Result: 实验显示，一些LLMs在零样本和本地设置下表现不佳，其他模型则在不同疾病间性能差异显著，难以泛化。

Conclusion: 尽管LLMs在理解生成自然语言方面表现出色，但在临床信息提取任务中，特别是在零样本和泛化能力方面仍存在挑战。

Abstract: Large Language Models (LLMs) have become a key topic in AI and NLP, transforming sectors like healthcare, finance, education, and marketing by improving customer service, automating tasks, providing insights, improving diagnostics, and personalizing learning experiences. Information extraction from clinical records is a crucial task in digital healthcare. Although traditional NLP techniques have been used for this in the past, they often fall short due to the complexity, variability of clinical language, and high inner semantics in the free clinical text. Recently, Large Language Models (LLMs) have become a powerful tool for better understanding and generating human-like text, making them highly effective in this area. In this paper, we explore the ability of open-source multilingual LLMs to understand EHRs (Electronic Health Records) in Italian and help extract information from them in real-time. Our detailed experimental campaign on comorbidity extraction from EHR reveals that some LLMs struggle in zero-shot, on-premises settings, and others show significant variation in performance, struggling to generalize across various diseases when compared to native pattern matching and manual annotations.

</details>


### [48] [STELLA: Guiding Large Language Models for Time Series Forecasting with Semantic Abstractions](https://arxiv.org/abs/2512.04871)
*Junjie Fan,Hongye Zhao,Linduo Wei,Jiayu Rao,Guijia Li,Jiaxin Yuan,Wenqi Xu,Yong Qi*

Main category: cs.AI

TL;DR: STELLA框架通过动态语义抽象和分层语义锚点，提升LLMs在时间序列预测中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在时间序列预测中未能充分利用其推理能力，且现有提示策略缺乏全局和特定实例的上下文信息。

Method: STELLA框架通过动态语义抽象机制将输入序列分解为趋势、季节性和残差成分，并将这些成分的行为特征转化为分层语义锚点（CSP和FBP），作为LLMs的前缀提示。

Result: 在八个基准数据集上的实验表明，STELLA在长期和短期预测中均优于现有方法，且在零样本和少样本设置中具有更强的泛化能力。

Conclusion: 动态生成的语义锚点有效提升了LLMs在时间序列预测中的性能，消融研究进一步验证了其有效性。

Abstract: Recent adaptations of Large Language Models (LLMs) for time series forecasting often fail to effectively enhance information for raw series, leaving LLM reasoning capabilities underutilized. Existing prompting strategies rely on static correlations rather than generative interpretations of dynamic behavior, lacking critical global and instance-specific context. To address this, we propose STELLA (Semantic-Temporal Alignment with Language Abstractions), a framework that systematically mines and injects structured supplementary and complementary information. STELLA employs a dynamic semantic abstraction mechanism that decouples input series into trend, seasonality, and residual components. It then translates intrinsic behavioral features of these components into Hierarchical Semantic Anchors: a Corpus-level Semantic Prior (CSP) for global context and a Fine-grained Behavioral Prompt (FBP) for instance-level patterns. Using these anchors as prefix-prompts, STELLA guides the LLM to model intrinsic dynamics. Experiments on eight benchmark datasets demonstrate that STELLA outperforms state-of-the-art methods in long- and short-term forecasting, showing superior generalization in zero-shot and few-shot settings. Ablation studies further validate the effectiveness of our dynamically generated semantic anchors.

</details>


### [49] [Algorithmic Thinking Theory](https://arxiv.org/abs/2512.04923)
*MohammadHossein Bateni,Vincent Cohen-Addad,Yuzhou Gu,Silvio Lattanzi,Simon Meierhans,Christopher Mohri*

Main category: cs.AI

TL;DR: 大型语言模型（LLMs）通过迭代生成和组合解决方案来提高复杂推理任务的效果。本文提出了一种分析此类推理算法的理论框架。


<details>
  <summary>Details</summary>
Motivation: LLMs在复杂推理任务中表现出高效性，通过迭代改进先前的解决方案，可以进一步提升其能力。

Method: 引入一个理论框架，形式化迭代改进和答案聚合的原则，为设计新的更强大的推理方法提供基础。

Result: 该模型不依赖于架构细节，而是基于实验证据，提供了一个通用的视角，可以应用于各种当前和未来的推理oracle。

Conclusion: 该框架为理解LLMs的推理过程提供了一个通用且基于实验证据的理论基础，可能对未来推理算法的设计产生重要影响。

Abstract: Large language models (LLMs) have proven to be highly effective for solving complex reasoning tasks. Surprisingly, their capabilities can often be improved by iterating on previously generated solutions. In this context, a reasoning plan for generating and combining a set of solutions can be thought of as an algorithm for reasoning using a probabilistic oracle.
  We introduce a theoretical framework for analyzing such reasoning algorithms. This framework formalizes the principles underlying popular techniques for iterative improvement and answer aggregation, providing a foundation for designing a new generation of more powerful reasoning methods. Unlike approaches for understanding models that rely on architectural specifics, our model is grounded in experimental evidence. As a result, it offers a general perspective that may extend to a wide range of current and future reasoning oracles.

</details>


### [50] [Model-Based and Sample-Efficient AI-Assisted Math Discovery in Sphere Packing](https://arxiv.org/abs/2512.04829)
*Rasul Tutunov,Alexandre Maraval,Antoine Grosnit,Xihan Li,Jun Wang,Haitham Bou-Ammar*

Main category: cs.AI

TL;DR: 本文提出了一种新方法，通过将半定规划（SDP）构建形式化为顺序决策过程，结合贝叶斯优化和蒙特卡洛树搜索，为n维球堆积问题提供了新的最佳上界。


<details>
  <summary>Details</summary>
Motivation: 球堆积问题在密码学、晶体学和医学成像等领域具有重要意义，但在大多数维度上仍未解决。现有的三点法虽然有效，但计算复杂，标准AI方法因需大量数据而不适用。

Method: 将SDP构建过程视为顺序决策过程（SDP游戏），使用结合贝叶斯优化和蒙特卡洛树搜索的基于模型的框架，从可接受的组件集合中组装SDP公式。

Result: 在维度4到16中获得了新的最佳上界，证明了基于模型的搜索在计算几何问题中的有效性。

Conclusion: 高效的基于模型的搜索方法能够在数学严格且评估受限的问题上取得实质性进展，为AI辅助发现提供了新的方向，超越了大规模LLM驱动的探索。

Abstract: Sphere packing, Hilbert's eighteenth problem, asks for the densest arrangement of congruent spheres in n-dimensional Euclidean space. Although relevant to areas such as cryptography, crystallography, and medical imaging, the problem remains unresolved: beyond a few special dimensions, neither optimal packings nor tight upper bounds are known. Even a major breakthrough in dimension $n=8$, later recognised with a Fields Medal, underscores its difficulty. A leading technique for upper bounds, the three-point method, reduces the problem to solving large, high-precision semidefinite programs (SDPs). Because each candidate SDP may take days to evaluate, standard data-intensive AI approaches are infeasible. We address this challenge by formulating SDP construction as a sequential decision process, the SDP game, in which a policy assembles SDP formulations from a set of admissible components. Using a sample-efficient model-based framework that combines Bayesian optimisation with Monte Carlo Tree Search, we obtain new state-of-the-art upper bounds in dimensions $4-16$, showing that model-based search can advance computational progress in longstanding geometric problems. Together, these results demonstrate that sample-efficient, model-based search can make tangible progress on mathematically rigid, evaluation limited problems, pointing towards a complementary direction for AI-assisted discovery beyond large-scale LLM-driven exploration.

</details>


### [51] [From Task Executors to Research Partners: Evaluating AI Co-Pilots Through Workflow Integration in Biomedical Research](https://arxiv.org/abs/2512.04854)
*Lukas Weidener,Marko Brkić,Chiara Bacci,Mihailo Jovanović,Emre Ulgac,Alex Dobrin,Johannes Weniger,Martin Vlas,Ritvik Singh,Aakaash Meduri*

Main category: cs.AI

TL;DR: 本文综述了生物医学研究中人工智能系统的评估实践，提出了现有基准测试的不足，并设计了一个新的面向过程评估框架。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统在生物医学研究中的应用日益增多，但现有的评估框架未能充分评估其作为研究合作者的实际效果，因此需要更全面的评估方法。

Method: 通过快速综述方法，检索了2018年1月1日至2025年10月31日间三个主要数据库和两个预印本服务器的数据，确定了14个评估AI能力的基准，并提出了一个新的过程导向的评估框架。

Result: 现有基准仅评估孤立的组件能力，而缺乏对集成工作流、上下文记忆、自适应对话和约束传播等方面的评估。新框架提出了对话质量、工作流编排、会话连续性和研究人员经验四个关键维度。

Conclusion: 为有效评估AI系统作为研究合作者的实际能力，需要引入过程导向的评估框架，以弥补现有基准测试的不足，并确保AI系统能够在实际研究环境中有效协作。

Abstract: Artificial intelligence systems are increasingly deployed in biomedical research. However, current evaluation frameworks may inadequately assess their effectiveness as research collaborators. This rapid review examines benchmarking practices for AI systems in preclinical biomedical research. Three major databases and two preprint servers were searched from January 1, 2018 to October 31, 2025, identifying 14 benchmarks that assess AI capabilities in literature understanding, experimental design, and hypothesis generation. The results revealed that all current benchmarks assess isolated component capabilities, including data analysis quality, hypothesis validity, and experimental protocol design. However, authentic research collaboration requires integrated workflows spanning multiple sessions, with contextual memory, adaptive dialogue, and constraint propagation. This gap implies that systems excelling on component benchmarks may fail as practical research co-pilots. A process-oriented evaluation framework is proposed that addresses four critical dimensions absent from current benchmarks: dialogue quality, workflow orchestration, session continuity, and researcher experience. These dimensions are essential for evaluating AI systems as research co-pilots rather than as isolated task executors.

</details>


### [52] [Toward Continuous Neurocognitive Monitoring: Integrating Speech AI with Relational Graph Transformers for Rare Neurological Diseases](https://arxiv.org/abs/2512.04938)
*Raquel Norel,Michele Merler,Pavitra Modi*

Main category: cs.AI

TL;DR: 通过智能手机语音分析和RELGT架构实现对罕见神经系统疾病患者的持续性神经认知监测。


<details>
  <summary>Details</summary>
Motivation: 传统认知测试无法捕捉罕见神经系统疾病患者的‘脑雾’症状，因此需要一种新的监测方法。

Method: 采用智能手机语音分析与关系图变换器（RELGT）架构相结合的方法，在苯丙酮尿症（PKU）患者中进行验证。

Result: 语音分析的‘话语熟练度’与血苯丙氨酸水平显著相关（p = -0.50, p < 0.005），但与传统认知测试无关（|r| < 0.35）。RELGT可提前数周预测病情恶化。

Conclusion: 成功将转变神经系统疾病的间歇性诊疗为持续性个性化监测，但需解决多疾病验证、临床整合和语言公平性等挑战。

Abstract: Patients with rare neurological diseases report cognitive symptoms -"brain fog"- invisible to traditional tests. We propose continuous neurocognitive monitoring via smartphone speech analysis integrated with Relational Graph Transformer (RELGT) architectures. Proof-of-concept in phenylketonuria (PKU) shows speech-derived "Proficiency in Verbal Discourse" correlates with blood phenylalanine (p = -0.50, p < 0.005) but not standard cognitive tests (all |r| < 0.35). RELGT could overcome information bottlenecks in heterogeneous medical data (speech, labs, assessments), enabling predictive alerts weeks before decompensation. Key challenges: multi-disease validation, clinical workflow integration, equitable multilingual deployment. Success would transform episodic neurology into continuous personalized monitoring for millions globally.

</details>


### [53] [Detecting Perspective Shifts in Multi-agent Systems](https://arxiv.org/abs/2512.05013)
*Eric Bridgeford,Hayden Helm*

Main category: cs.AI

TL;DR: 本文提出了TDKPS，用于多智能体系统行为变化的动态监测。


<details>
  <summary>Details</summary>
Motivation: 随着智能体使用的扩展，需要监测多智能体系统的行为变化，尤其是在黑箱环境下。

Method: 引入了Temporal Data Kernel Perspective Space（TDKPS），并提出了几种新的假设检验方法，用于检测智能体及群体层面的行为变化。

Result: 通过模拟实验和真实事件验证了所提出方法的有效性，展示了其敏感性和显著性。

Conclusion: TDKPS是首个用于监测黑箱多智能体系统行为动态的原则性框架，对大规模生成性智能体部署具有重要意义。

Abstract: Generative models augmented with external tools and update mechanisms (or \textit{agents}) have demonstrated capabilities beyond intelligent prompting of base models. As agent use proliferates, dynamic multi-agent systems have naturally emerged. Recent work has investigated the theoretical and empirical properties of low-dimensional representations of agents based on query responses at a single time point. This paper introduces the Temporal Data Kernel Perspective Space (TDKPS), which jointly embeds agents across time, and proposes several novel hypothesis tests for detecting behavioral change at the agent- and group-level in black-box multi-agent systems. We characterize the empirical properties of our proposed tests, including their sensitivity to key hyperparameters, in simulations motivated by a multi-agent system of evolving digital personas. Finally, we demonstrate via natural experiment that our proposed tests detect changes that correlate sensitively, specifically, and significantly with a real exogenous event. As far as we are aware, TDKPS is the first principled framework for monitoring behavioral dynamics in black-box multi-agent systems -- a critical capability as generative agent deployment continues to scale.

</details>
