<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 6]
- [cs.AI](#cs.AI) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Auxiliary Metrics Help Decoding Skill Neurons in the Wild](https://arxiv.org/abs/2511.21610)
*Yixiu Zhao,Xiaozhi Wang,Zijun Yao,Lei Hou,Juanzi Li*

Main category: cs.CL

TL;DR: 本文介绍了一种简单、轻量级且广泛适用的方法，用于隔离编码特定技能的神经元，通过软提示训练和多技能复杂场景分析，关联神经元激活与辅助指标，无需手动标记即可揭示可解释且任务特定的行为。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在各种任务中表现出卓越能力，但其内部机制仍不透明。作者旨在探索模型中编码特定技能的神经元。

Method: 在先前通过软提示训练识别“技能神经元”的基础上，扩展分析到涉及多种技能的复杂场景。通过关联神经元激活与辅助指标（如外部标签和模型自身置信度分数），无需手动标记。

Result: 在开放文本生成和自然语言推理等任务上验证了该方法，能检测驱动已知技能的神经元，并揭示了BigBench算术推理中的新捷径。

Conclusion: 该方法能够有效检测并揭示大型语言模型中特定任务的神经元行为，具有广泛的适用性和解释性。

Abstract: Large language models (LLMs) exhibit remarkable capabilities across a wide range of tasks, yet their internal mechanisms remain largely opaque. In this paper, we introduce a simple, lightweight, and broadly applicable method with a focus on isolating neurons that encode specific skills. Building upon prior work that identified "skill neurons" via soft prompt training on classification tasks, our approach extends the analysis to complex scenarios involving multiple skills. We correlate neuron activations with auxiliary metrics -- such as external labels and the model's own confidence score -- thereby uncovering interpretable and task-specific behaviors without the need for manual token aggregation. We empirically validate our method on tasks spanning open-ended text generation and natural language inference, demonstrating its ability to detect neurons that not only drive known skills but also reveal previously unidentified shortcuts in arithmetic reasoning on BigBench.

</details>


### [2] [Beyond URLs: Metadata Diversity and Position for Efficient LLM Pretraining](https://arxiv.org/abs/2511.21613)
*Dongyang Fan,Diba Hashemi,Sai Praneeth Karimireddy,Martin Jaggi*

Main category: cs.CL

TL;DR: 该论文探索了在大型语言模型预训练中引入多种元数据以提升训练速度和质量的方法。


<details>
  <summary>Details</summary>
Motivation: 先前的研究仅强调了URL这一种元数据的有效性，本文则探索更多类型的元数据，尤其是文档质量的细粒度指标，以期获得更好的预训练效果。

Method: 研究分析了多种元数据类型，识别出细粒度信息编码的元数据，并引入了元数据附加和辅助任务预测来提升训练效率。同时，通过可学习的元标记和掩码损失来诱导质量感知的潜在结构。

Result: 发现多种元数据，尤其是细粒度文档质量指标，在预训练中有效。通过元数据附加和辅助任务预测，训练速度得到提升，可学习元标记也恢复了部分加速效果。

Conclusion: 多种元数据可以显著提升大型语言模型预训练的效率，细粒度信息编码是有效元数据的关键特征，这为实际应用提供了指导。

Abstract: Incorporating metadata in Large Language Models (LLMs) pretraining has recently emerged as a promising approach to accelerate training. However prior work highlighted only one useful signal-URLs, leaving open the question of whether other forms of metadata could yield greater benefits. In this study, we investigate a wider range of metadata types and find other types of metadata, such as fine-grained indicators of document quality that can also accelerate pretraining when prepended. We identify a common feature among effective metadata: they encode information at a finer granularity. We further introduce metadata appending as a means of improving training efficiency, where predicting an appropriate metadata as auxiliary task can help speed up pretraining. In addition, learnable meta-tokens trained with masked loss can recover part of the speedup by inducing quality-aware latent structure. Using probing, we analyze latent representations to understand how metadata shapes learning. Together, these results yield practical guidelines for integrating metadata to improve both the efficiency and effectiveness of LLM pretraining.

</details>


### [3] [The author is dead, but what if they never lived? A reception experiment on Czech AI- and human-authored poetry](https://arxiv.org/abs/2511.21629)
*Anna Marklová,Ondřej Vinš,Martina Vokáčová,Jiří Milička*

Main category: cs.CL

TL;DR: 本文研究了捷克母语者对AI生成和人类创作捷克诗歌的辨别和审美评价，发现AI生成的诗歌与人类的难以区分，但作者身份会影响审美评价。


<details>
  <summary>Details</summary>
Motivation: 大多数关于AI生成诗歌的研究集中在英语，而本研究关注在训练数据中代表性较低的捷克语，以探索AI在复杂形态语言中的表现。

Method: 研究通过让捷克母语者猜测诗歌的作者身份（AI或人类），并对其进行审美评价，使用逻辑回归模型分析喜好与作者身份识别之间的关系。

Result: 参与者在作者身份识别方面表现随机（平均45.8%正确），审美评价显示身份偏见：被认定为AI创作的诗评价较低。诗歌的受欢迎程度与准确识别作者身份的概率呈负相关。

Conclusion: AI在捷克语这样的复杂形态、低资源语言中能够令人信服地生成诗歌，读者对作者身份的信念与审美评价相互关联。

Abstract: Large language models are increasingly capable of producing creative texts, yet most studies on AI-generated poetry focus on English -- a language that dominates training data. In this paper, we examine the perception of AI- and human-written Czech poetry. We ask if Czech native speakers are able to identify it and how they aesthetically judge it. Participants performed at chance level when guessing authorship (45.8\% correct on average), indicating that Czech AI-generated poems were largely indistinguishable from human-written ones. Aesthetic evaluations revealed a strong authorship bias: when participants believed a poem was AI-generated, they rated it as less favorably, even though AI poems were in fact rated equally or more favorably than human ones on average. The logistic regression model uncovered that the more the people liked a poem, the less probable was that they accurately assign the authorship. Familiarity with poetry or literary background had no effect on recognition accuracy. Our findings show that AI can convincingly produce poetry even in a morphologically complex, low-resource (with respect of the training data of AI models) Slavic language such as Czech. The results suggest that readers' beliefs about authorship and the aesthetic evaluation of the poem are interconnected.

</details>


### [4] [Matrix: Peer-to-Peer Multi-Agent Synthetic Data Generation Framework](https://arxiv.org/abs/2511.21686)
*Dong Wang,Yang Li,Ansong Ni,Ching-Feng Yeh,Youssef Emad,Xinjie Lei,Liam Robbins,Karthik Padthe,Hu Xu,Xian Li,Asli Celikyilmaz,Ramya Raghavendra,Lifei Huang,Carole-Jean Wu,Shang-Wen Li*

Main category: cs.CL

TL;DR: Matrix是一个去中心化的框架，通过分布式队列传递序列化消息，以支持多智能体协作合成数据，提高数据生成的质量和多样性。


<details>
  <summary>Details</summary>
Motivation: 现有框架多依赖于中心化协调器，造成扩展性瓶颈，或针对特定领域硬编码，限制灵活性。因此需要一种灵活且可扩展的解决方案。

Method: Matrix采用去中心化的设计，将控制和数据流表示为通过分布式队列传递的序列化消息。每个任务由轻量级智能体独立处理，计算密集型操作由分布式服务处理，基于Ray实现高扩展性和模块化设计。

Result: 在多种合成场景下，Matrix在相同硬件资源下实现了2-15倍更高的数据生成吞吐量，同时不降低输出质量。

Conclusion: Matrix通过其去中心化和模块化设计，为多智能体数据合成任务提供了灵活、可扩展的解决方案，在各种应用场景中表现出色。

Abstract: Synthetic data has become increasingly important for training large language models, especially when real data is scarce, expensive, or privacy-sensitive. Many such generation tasks require coordinated multi-agent workflows, where specialized agents collaborate to produce data that is higher quality, more diverse, and structurally richer. However, existing frameworks for multi-agent synthesis often depend on a centralized orchestrator, creating scalability bottlenecks, or are hardcoded for specific domains, limiting flexibility. We present \textbf{Matrix}, a decentralized framework that represents both control and data flow as serialized messages passed through distributed queues. This peer-to-peer design eliminates the central orchestrator. Each task progresses independently through lightweight agents, while compute-intensive operations, such as LLM inference or containerized environments, are handled by distributed services. Built on Ray, Matrix scales to tens of thousands of concurrent agentic workflows and provides a modular, configurable design that enables easy adaptation to a wide range of data generation workflows. We evaluate Matrix across diverse synthesis scenarios, such as multi-agent collaborative dialogue, web-based reasoning data extraction, and tool-use trajectory generation in customer service environments. In all cases, Matrix achieves $2$--$15\times$ higher data generation throughput under identical hardware resources, without compromising output quality.

</details>


### [5] [ToolOrchestra: Elevating Intelligence via Efficient Model and Tool Orchestration](https://arxiv.org/abs/2511.21689)
*Hongjin Su,Shizhe Diao,Ximing Lu,Mingjie Liu,Jiacheng Xu,Xin Dong,Yonggan Fu,Peter Belcak,Hanrong Ye,Hongxu Yin,Yi Dong,Evelina Bakhturina,Tao Yu,Yejin Choi,Jan Kautz,Pavlo Molchanov*

Main category: cs.CL

TL;DR: ToolOrchestra 是一种通过训练小型协调器来管理其他模型和工具，以提升解决复杂问题的效率和准确性的方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽然功能强大，但在解决复杂问题时仍面临概念和计算上的挑战。小型协调器管理其他模型和工具可以提升智能上限并改善效率。

Method: 引入 ToolOrchestra 方法，利用强化学习，结合结果、效率和用户偏好的奖励，训练小型协调器来协调智能工具的使用。

Result: 使用 ToolOrchestra 方法训练的 8B 模型 Orchestrator，在 HLE 上实现了 37.1% 的准确率，超过 GPT-5 (35.1%)，且效率提高了 2.5 倍；在 tau2-Bench 和 FRAMES 上，性能超过 GPT-5，但成本仅约 30%。

Conclusion: ToolOrchestra 方法通过组合多种工具与轻量级协调模型，实现了性能和成本的最佳权衡，展示了比现有方法更高效和有效的解决方案，为可扩展的工具增强推理系统铺平了道路。

Abstract: Large language models are powerful generalists, yet solving deep and complex problems such as those of the Humanity's Last Exam (HLE) remains both conceptually challenging and computationally expensive. We show that small orchestrators managing other models and a variety of tools can both push the upper bound of intelligence and improve efficiency in solving difficult agentic tasks. We introduce ToolOrchestra, a method for training small orchestrators that coordinate intelligent tools. ToolOrchestra explicitly uses reinforcement learning with outcome-, efficiency-, and user-preference-aware rewards. Using ToolOrchestra, we produce Orchestrator, an 8B model that achieves higher accuracy at lower cost than previous tool-use agents while aligning with user preferences on which tools are to be used for a given query. On HLE, Orchestrator achieves a score of 37.1%, outperforming GPT-5 (35.1%) while being 2.5x more efficient. On tau2-Bench and FRAMES, Orchestrator surpasses GPT-5 by a wide margin while using only about 30% of the cost. Extensive analysis shows that Orchestrator achieves the best trade-off between performance and cost under multiple metrics, and generalizes robustly to unseen tools. These results demonstrate that composing diverse tools with a lightweight orchestration model is both more efficient and more effective than existing methods, paving the way for practical and scalable tool-augmented reasoning systems.

</details>


### [6] [Revisiting Generalization Across Difficulty Levels: It's Not So Easy](https://arxiv.org/abs/2511.21692)
*Yeganeh Kordi,Nihal V. Nayak,Max Zuo,Ilana Nguyen,Stephen H. Bach*

Main category: cs.CL

TL;DR: 大型语言模型在不同任务难度上的泛化能力有限，训练数据难度与测试数据难度之间的一致性影响学习效果。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型在不同任务难度下的泛化能力，以优化数据管理和评估方法。

Method: 通过系统评估模型、数据集和细粒度示例难度组，使用数千个不同LLM的输出和项目反应理论（IRT）对示例进行排序。

Result: 训练在简单或困难数据上并不能在整个难度范围内实现一致的改进，交叉难度泛化能力有限。

Conclusion: 训练和评估数据应包含各种难度，针对难度的捷径是不可取的。

Abstract: We investigate how well large language models (LLMs) generalize across different task difficulties, a key question for effective data curation and evaluation. Existing research is mixed regarding whether training on easier or harder data leads to better results, and whether those gains come on easier or harder test data. We address this question by conducting a systematic evaluation of LLMs' generalization across models, datasets, and fine-grained groups of example difficulty. We rank examples in six datasets using the outputs of thousands of different LLMs and Item Response Theory (IRT), a well-established difficulty metric in educational testing. Unlike prior work, our difficulty ratings are therefore determined solely by the abilities of many different LLMs, excluding human opinions of difficulty. With a more objective, larger-scale, and finer-grained analysis, we show that cross-difficulty generalization is often limited; training on either easy or hard data cannot achieve consistent improvements across the full range of difficulties. These results show the importance of having a range of difficulties in both training and evaluation data for LLMs, and that taking shortcuts with respect to difficulty is risky.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [7] [On the Limits of Innate Planning in Large Language Models](https://arxiv.org/abs/2511.21591)
*Charles Schepanowski,Charles Ling*

Main category: cs.AI

TL;DR: 大型语言模型（LLMs）在规划及状态推理能力方面仍存在局限，特别是在没有外部工具的情况下。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在许多基准测试中表现出色，但其规划和状态推理能力仍不清楚。因此，本文通过经典8数码问题评估这些能力。

Method: 使用8数码问题测试了四种模型，在零样本、思维链和算法思维等提示条件下，以及分级纠正反馈下的表现，并引入了外部移动验证器。

Result: 纠正反馈提高了某些模型的成功率，但许多成功的运行冗长且计算成本高。引入外部移动验证器后，所有模型均无法解决任何问题。

Conclusion: 当前的LLMs在缺乏外部工具的情况下，规划能力存在重大局限，需要进一步开发用于维护明确状态和执行结构化搜索的机制。

Abstract: Large language models (LLMs) achieve impressive results on many benchmarks, yet their capacity for planning and stateful reasoning remains unclear. We study these abilities directly, without code execution or other tools, using the 8-puzzle: a classic task that requires state tracking and goal-directed planning while allowing precise, step-by-step evaluation. Four models are tested under common prompting conditions (Zero-Shot, Chain-of-Thought, Algorithm-of-Thought) and with tiered corrective feedback. Feedback improves success rates for some model-prompt combinations, but many successful runs are long, computationally expensive, and indirect. We then examine the models with an external move validator that provides only valid moves. Despite this level of assistance, none of the models solve any puzzles in this setting. Qualitative analysis reveals two dominant deficits across all models: (1) brittle internal state representations, leading to frequent invalid moves, and (2) weak heuristic planning, with models entering loops or selecting actions that do not reduce the distance to the goal state. These findings indicate that, in the absence of external tools such as code interpreters, current LLMs have substantial limitations in planning and that further progress may require mechanisms for maintaining explicit state and performing structured search.

</details>


### [8] [Bridging the Unavoidable A Priori: A Framework for Comparative Causal Modeling](https://arxiv.org/abs/2511.21636)
*Peter S. Hovmand,Kari O'Donnell,Callie Ogland-Hand,Brian Biroscak,Douglas D. Gunzler*

Main category: cs.AI

TL;DR: 本文提出了一种将系统动力学和结构方程建模结合的统一数学框架，以解决AI/ML模型中的人类偏见问题。


<details>
  <summary>Details</summary>
Motivation: AI/ML模型在解决未解问题和放大人类偏见方面表现出创新性。责任AI/ML倡导者希望借助系统动力学的因果模型来更好地开发责任AI/ML。然而，一个主要障碍是不同方法基于不同的假设。

Method: 本文将系统动力学和结构方程建模结合进一个共同的数学框架，用于从分布生成系统、开发方法，并比较结果，以说明系统动力学在数据科学和AI/ML应用中的基本认识论。

Result: 该框架可以生成系统、开发方法，并比较结果，以更好地理解系统动力学的认识论。

Conclusion: 通过将系统动力学和结构方程建模结合，可以更好地开发负责任的AI/ML模型，并克服不同方法之间的障碍。

Abstract: AI/ML models have rapidly gained prominence as innovations for solving previously unsolved problems and their unintended consequences from amplifying human biases. Advocates for responsible AI/ML have sought ways to draw on the richer causal models of system dynamics to better inform the development of responsible AI/ML. However, a major barrier to advancing this work is the difficulty of bringing together methods rooted in different underlying assumptions (i.e., Dana Meadow's "the unavoidable a priori"). This paper brings system dynamics and structural equation modeling together into a common mathematical framework that can be used to generate systems from distributions, develop methods, and compare results to inform the underlying epistemology of system dynamics for data science and AI/ML applications.

</details>
