<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 54]
- [cs.AI](#cs.AI) [Total: 40]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Omnilingual ASR: Open-Source Multilingual Speech Recognition for 1600+ Languages](https://arxiv.org/abs/2511.09690)
*Omnilingual ASR team,Gil Keren,Artyom Kozhevnikov,Yen Meng,Christophe Ropers,Matthew Setzler,Skyler Wang,Ife Adebara,Michael Auli,Can Balioglu,Kevin Chan,Chierh Cheng,Joe Chuang,Caley Droof,Mark Duppenthaler,Paul-Ambroise Duquenne,Alexander Erben,Cynthia Gao,Gabriel Mejia Gonzalez,Kehan Lyu,Sagar Miglani,Vineel Pratap,Kaushik Ram Sadagopan,Safiyyah Saleem,Arina Turkatenko,Albert Ventayol-Boada,Zheng-Xin Yong,Yu-An Chung,Jean Maillard,Rashel Moritz,Alexandre Mourachko,Mary Williamson,Shireen Yates*

Main category: cs.CL

TL;DR: Omnilingual ASR 是首个为可扩展性设计的大规模自动语音识别（ASR）系统，使社区能够通过少量数据样本引入未被服务到的语言。


<details>
  <summary>Details</summary>
Motivation: 当前 ASR 技术在大多数世界语言中仍未被支持，扩展语言覆盖范围成本高且受限于架构。此外，缺乏社区协作也带来了伦理问题。

Method: Omnilingual ASR 采用自监督预训练扩展至7B参数以学习鲁棒语音表示，引入LLM启发的编码器-解码器架构以实现零样本泛化，并通过结合公共资源和社区录音进行训练。

Result: Omnilingual ASR 扩展覆盖至1600多种语言，包括500多种此前从未被ASR服务过的语言，并在低资源条件下表现出显著的性能提升和强大的泛化能力。

Conclusion: 通过开源模型和工具，Omnilingual ASR 降低了研究人员和社区参与的技术门槛，并探讨了其在伦理和社会层面的影响。

Abstract: Automatic speech recognition (ASR) has advanced in high-resource languages, but most of the world's 7,000+ languages remain unsupported, leaving thousands of long-tail languages behind. Expanding ASR coverage has been costly and limited by architectures that restrict language support, making extension inaccessible to most--all while entangled with ethical concerns when pursued without community collaboration. To transcend these limitations, we introduce Omnilingual ASR, the first large-scale ASR system designed for extensibility. Omnilingual ASR enables communities to introduce unserved languages with only a handful of data samples. It scales self-supervised pre-training to 7B parameters to learn robust speech representations and introduces an encoder-decoder architecture designed for zero-shot generalization, leveraging a LLM-inspired decoder. This capability is grounded in a massive and diverse training corpus; by combining breadth of coverage with linguistic variety, the model learns representations robust enough to adapt to unseen languages. Incorporating public resources with community-sourced recordings gathered through compensated local partnerships, Omnilingual ASR expands coverage to over 1,600 languages, the largest such effort to date--including over 500 never before served by ASR. Automatic evaluations show substantial gains over prior systems, especially in low-resource conditions, and strong generalization. We release Omnilingual ASR as a family of models, from 300M variants for low-power devices to 7B for maximum accuracy. We reflect on the ethical considerations shaping this design and conclude by discussing its societal impact. In particular, we highlight how open-sourcing models and tools can lower barriers for researchers and communities, inviting new forms of participation. Open-source artifacts are available at https://github.com/facebookresearch/omnilingual-asr.

</details>


### [2] [Order Matters: Rethinking Prompt Construction in In-Context Learning](https://arxiv.org/abs/2511.09700)
*Warren Li,Yiqian Wang,Zihan Wang,Jingbo Shang*

Main category: cs.CL

TL;DR: 本文通过实验证明了在上下文学习（ICL）中，示例的顺序对性能的影响与选择不同的示例集的影响相当，并强调了示例顺序的重要性。


<details>
  <summary>Details</summary>
Motivation: 先前的研究认为示例的选择对性能的影响远大于示例的顺序，因此研究重点一直放在示例选择上。本文重新审视了这一假设，并系统性地比较了示例选择和顺序对性能的影响。

Method: 通过在分类和生成任务上进行控制实验，使用多个开源模型家族（0.5B到27B参数）和GPT-5，评估不同示例顺序和选择对性能的影响。

Result: 实验发现，不同示例顺序导致性能差异与不同示例集导致的性能差异相当。此外，仅使用开发集即可识别出有效的顺序，其性能接近于基于测试标签选择的最佳顺序。

Conclusion: 示例选择和顺序在提示设计中具有同等且相互交织的重要性，因此有必要重新审视ICL中的假设。

Abstract: In-context learning (ICL) enables large language models to perform new tasks by conditioning on a sequence of examples. Most prior work reasonably and intuitively assumes that which examples are chosen has a far greater effect on performance than how those examples are ordered, leading to a focus on example selection. We revisit this assumption and conduct a systematic comparison between the effect of selection and ordering. Through controlled experiments on both classification and generation tasks, using multiple open-source model families (0.5B to 27B parameters) and GPT-5, we find that the variance in performance due to different example orderings is comparable to that from using entirely different example sets. Furthermore, we show that strong orderings can be identified using only a development set, achieving performance close to an oracle that selects the best ordering based on test labels. Our findings highlight the equal and intertwined importance of example selection and ordering in prompt design, calling for a reexamination of the assumptions held in ICL.

</details>


### [3] [Contextual morphologically-guided tokenization for Latin encoder models](https://arxiv.org/abs/2511.09709)
*Marisa Hudspeth,Patrick J. Burns,Brendan O'Connor*

Main category: cs.CL

TL;DR: 本文研究拉丁语的形态感知分词，发现其能提升下游任务性能，尤其在跨领域文本中表现更佳。


<details>
  <summary>Details</summary>
Motivation: 标准分词方法通常关注信息论目标（如高压缩率和低生育率），而非语言学目标（如形态对齐），导致在形态丰富的语言中表现不佳。拉丁语是一个中等资源语言，但在词汇资源方面是高资源语言，这为研究提供了契机。

Method: 研究采用形态学指导的分词方法，并评估其在四种下游任务中的性能，特别关注跨领域文本的表现。

Result: 形态学指导的分词方法在四个下游任务中提升了整体性能，特别是在跨领域文本中性能提升最为显著。

Conclusion: 语言资源可以有效提升形态复杂语言的语言模型性能，对于缺乏大规模预训练数据的低资源语言，开发和使用语言资源是一种可行的改进方案。

Abstract: Tokenization is a critical component of language model pretraining, yet standard tokenization methods often prioritize information-theoretical goals like high compression and low fertility rather than linguistic goals like morphological alignment. In fact, they have been shown to be suboptimal for morphologically rich languages, where tokenization quality directly impacts downstream performance. In this work, we investigate morphologically-aware tokenization for Latin, a morphologically rich language that is medium-resource in terms of pretraining data, but high-resource in terms of curated lexical resources -- a distinction that is often overlooked but critical in discussions of low-resource language modeling. We find that morphologically-guided tokenization improves overall performance on four downstream tasks. Performance gains are most pronounced for out of domain texts, highlighting our models' improved generalization ability. Our findings demonstrate the utility of linguistic resources to improve language modeling for morphologically complex languages. For low-resource languages that lack large-scale pretraining data, the development and incorporation of linguistic resources can serve as a feasible alternative to improve LM performance.

</details>


### [4] [Assessing the Applicability of Natural Language Processing to Traditional Social Science Methodology: A Case Study in Identifying Strategic Signaling Patterns in Presidential Directives](https://arxiv.org/abs/2511.09738)
*C. LeMay,A. Lane,J. Seales,M. Winstead,S. Baty*

Main category: cs.CL

TL;DR: 该研究探讨了自然语言处理（NLP）在大规模文本数据中识别主要主题的能力，并以里根至克林顿时期的总统指令为例进行应用。


<details>
  <summary>Details</summary>
Motivation: 研究旨在评估NLP在社会科学研究中识别大规模文本主题的有效性，尤其是在总统指令中识别信号主题。

Method: 通过NLP和人工分析识别相关文档，并比较两者结果。

Result: NLP和人工分析均识别出相关文档，但两者结果存在差异，表明NLP在该应用场景中尚需进一步研究以验证其有效性。

Conclusion: 研究展示了现有NLP工具在社会科学应用中的能力，同时指出了由于AI工具快速发展，需要持续研究以评估NLP在相关领域的有效性。

Abstract: Our research investigates how Natural Language Processing (NLP) can be used to extract main topics from a larger corpus of written data, as applied to the case of identifying signaling themes in Presidential Directives (PDs) from the Reagan through Clinton administrations. Analysts and NLP both identified relevant documents, demonstrating the potential utility of NLPs in research involving large written corpuses. However, we also identified discrepancies between NLP and human-labeled results that indicate a need for more research to assess the validity of NLP in this use case. The research was conducted in 2023, and the rapidly evolving landscape of AIML means existing tools have improved and new tools have been developed; this research displays the inherent capabilities of a potentially dated AI tool in emerging social science applications.

</details>


### [5] [How Small Can You Go? Compact Language Models for On-Device Critical Error Detection in Machine Translation](https://arxiv.org/abs/2511.09748)
*Muskaan Chopra,Lorenz Sparrenberg,Sarthak Khanna,Rafet Sifa*

Main category: cs.CL

TL;DR: 本文研究了小型语言模型在英语到德语关键错误检测（CED）任务中的表现，发现约10亿参数的模型（如Gemma-3-1B）在性能和计算成本之间达到最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在机器翻译评估中表现出色，但其规模和成本阻碍了在边缘设备和隐私敏感工作流中的部署。研究者们希望找到在检测意义改变的翻译错误时，模型可以做到多小。

Method: 在标准英语到德语CED任务上对参数少于2B的模型进行基准测试，采用标准化提示、轻量级logit-bias校准和多数投票的方法，并报告语义质量（MCC, F1-ERR/F1-NOT）和计算指标（VRAM, 延迟, 吞吐量）。

Result: 约10亿参数的Gemma-3-1B在性能与效率之间达到最佳平衡，在SynCED-EnDe-2025上MCC=0.77，F1-ERR=0.98。Qwen-3-1.7B在性能上更优但计算成本更高，超小型模型（0.6B）在使用少量样本校准后可用，但对实体和数字错误的检测能力较弱。

Conclusion: 通过轻量级校准和小样本监督，小型指令调整LLMs能够在设备上实现可信、低成本的机器翻译CED，为现实世界中的翻译流程提供私密且低成本的错误筛查。

Abstract: Large Language Models (LLMs) excel at evaluating machine translation (MT), but their scale and cost hinder deployment on edge devices and in privacy-sensitive workflows. We ask: how small can you get while still detecting meaning-altering translation errors? Focusing on English->German Critical Error Detection (CED), we benchmark sub-2B models (LFM2-350M, Qwen-3-0.6B/1.7B, Llama-3.2-1B-Instruct, Gemma-3-1B) across WMT21, WMT22, and SynCED-EnDe-2025. Our framework standardizes prompts, applies lightweight logit-bias calibration and majority voting, and reports both semantic quality (MCC, F1-ERR/F1-NOT) and compute metrics (VRAM, latency, throughput). Results reveal a clear sweet spot around one billion parameters: Gemma-3-1B provides the best quality-efficiency trade-off, reaching MCC=0.77 with F1-ERR=0.98 on SynCED-EnDe-2025 after merged-weights fine-tuning, while maintaining 400 ms single-sample latency on a MacBook Pro M4 Pro (24 GB). At larger scale, Qwen-3-1.7B attains the highest absolute MCC (+0.11 over Gemma) but with higher compute cost. In contrast, ultra-small models (0.6B) remain usable with few-shot calibration yet under-detect entity and number errors. Overall, compact, instruction-tuned LLMs augmented with lightweight calibration and small-sample supervision can deliver trustworthy, on-device CED for MT, enabling private, low-cost error screening in real-world translation pipelines. All datasets, prompts, and scripts are publicly available at our GitHub repository.

</details>


### [6] [Predicate-Argument Structure Divergences in Chinese and English Parallel Sentences and their Impact on Language Transfer](https://arxiv.org/abs/2511.09796)
*Rocco Tripodi,Xiaoyu Liu*

Main category: cs.CL

TL;DR: 本文分析汉英平行句子的谓词-论元结构，探讨语言迁移的不对称性，强调迁移学习中源语言选择的重要性。


<details>
  <summary>Details</summary>
Motivation: 跨语言NLP虽在低资源环境中应用广泛，但语言类型差异限制了语言间的知识迁移，需深入研究其不对称性。

Method: 分析汉英平行句子的谓词-论元结构，进行标注投影实验，并定性和定量分析结构差异。

Result: 语言迁移具有不对称性，源语言选择对迁移学习应用至关重要。

Conclusion: 在提出跨语言NLP科学主张前，必须仔细选择源语言并研究迁移的不对称性。

Abstract: Cross-lingual Natural Language Processing (NLP) has gained significant traction in recent years, offering practical solutions in low-resource settings by transferring linguistic knowledge from resource-rich to low-resource languages. This field leverages techniques like annotation projection and model transfer for language adaptation, supported by multilingual pre-trained language models. However, linguistic divergences hinder language transfer, especially among typologically distant languages. In this paper, we present an analysis of predicate-argument structures in parallel Chinese and English sentences. We explore the alignment and misalignment of predicate annotations, inspecting similarities and differences and proposing a categorization of structural divergences. The analysis and the categorization are supported by a qualitative and quantitative analysis of the results of an annotation projection experiment, in which, in turn, one of the two languages has been used as source language to project annotations into the corresponding parallel sentences. The results of this analysis show clearly that language transfer is asymmetric. An aspect that requires attention when it comes to selecting the source language in transfer learning applications and that needs to be investigated before any scientific claim about cross-lingual NLP is proposed.

</details>


### [7] [TARG: Training-Free Adaptive Retrieval Gating for Efficient RAG](https://arxiv.org/abs/2511.09803)
*Yufeng Wang,Lu wei,Haibin Ling*

Main category: cs.CL

TL;DR: 提出一种无需训练的自适应检索门控(TARG)方法，通过轻量级不确定性评分决定何时进行检索，以平衡RAG的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: RAG虽然能提高事实准确性，但每次查询都检索会降低质量并增加延迟和tokens开销。

Method: TARG使用基模型生成的无上下文短草稿，通过三种方式计算不确定性分数：平均token熵、基于top-1/top-2 logit差距的边缘信号、少量随机前缀的小N方差，仅在分数超过阈值时触发检索。

Result: 在NQ-Open、TriviaQA和PopQA上，相比Always-RAG，TARG在保持或提高EM/F1的同时减少70-90%检索量，降低端到端延迟，且开销接近Never-RAG。

Conclusion: 现代指令调优LLM中，边缘信号是稳健默认选择(熵随模型优化而压缩)，小N方差提供保守预算优先替代方案；通过门控类型和前缀长度消融实验及delta延迟视图验证了方法有效性。

Abstract: Retrieval-Augmented Generation (RAG) improves factuality but retrieving for every query often hurts quality while inflating tokens and latency. We propose Training-free Adaptive Retrieval Gating (TARG), a single-shot policy that decides when to retrieve using only a short, no-context draft from the base model. From the draft's prefix logits, TARG computes lightweight uncertainty scores: mean token entropy, a margin signal derived from the top-1/top-2 logit gap via a monotone link, or small-N variance across a handful of stochastic prefixes, and triggers retrieval only when the score exceeds a threshold. The gate is model agnostic, adds only tens to hundreds of draft tokens, and requires no additional training or auxiliary heads. On NQ-Open, TriviaQA, and PopQA, TARG consistently shifts the accuracy-efficiency frontier: compared with Always-RAG, TARG matches or improves EM/F1 while reducing retrieval by 70-90% and cutting end-to-end latency, and it remains close to Never-RAG in overhead. A central empirical finding is that under modern instruction-tuned LLMs the margin signal is a robust default (entropy compresses as backbones sharpen), with small-N variance offering a conservative, budget-first alternative. We provide ablations over gate type and prefix length and use a delta-latency view to make budget trade-offs explicit.

</details>


### [8] [Khmer Spellchecking: A Holistic Approach](https://arxiv.org/abs/2511.09812)
*Marry Kong,Rina Buoy,Sovisal Chenda,Nguonly Taing*

Main category: cs.CL

TL;DR: 该论文提出了一种综合方法来解决高棉语拼写检查中的挑战，并公开相关数据集。


<details>
  <summary>Details</summary>
Motivation: 高棉语拼写检查面临词分割模型与词典不匹配、词形变化、复合词频繁出现以及专有名词识别等挑战，现有解决方案不足以应对这些问题。

Method: 论文提出了一种综合方法，整合了高棉语的子词分割、命名实体识别（NER）、字素到音素（G2P）转换和语言模型，以识别并排列最佳拼写修正候选项。

Result: 实验结果表明，该方法的高棉语拼写检查准确率达到了94.4%，超越了现有解决方案，为当前最佳水平。

Conclusion: 该综合方法有效地解决了高棉语拼写检查的多个挑战，并计划公开相关基准数据集，以促进进一步的研究。

Abstract: Compared to English and other high-resource languages, spellchecking for Khmer remains an unresolved problem due to several challenges. First, there are misalignments between words in the lexicon and the word segmentation model. Second, a Khmer word can be written in different forms. Third, Khmer compound words are often loosely and easily formed, and these compound words are not always found in the lexicon. Fourth, some proper nouns may be flagged as misspellings due to the absence of a Khmer named-entity recognition (NER) model. Unfortunately, existing solutions do not adequately address these challenges. This paper proposes a holistic approach to the Khmer spellchecking problem by integrating Khmer subword segmentation, Khmer NER, Khmer grapheme-to-phoneme (G2P) conversion, and a Khmer language model to tackle these challenges, identify potential correction candidates, and rank the most suitable candidate. Experimental results show that the proposed approach achieves a state-of-the-art Khmer spellchecking accuracy of up to 94.4%, compared to existing solutions. The benchmark datasets for Khmer spellchecking and NER tasks in this study will be made publicly available.

</details>


### [9] [Improving Graduate Outcomes by Identifying Skills Gaps and Recommending Courses Based on Career Interests](https://arxiv.org/abs/2511.09819)
*Rahul Soni,Basem Suleiman,Sonit Singh*

Main category: cs.CL

TL;DR: 本文设计并开发了一种课程推荐系统，利用数据分析和机器学习算法，为学生推荐符合行业趋势和需求的课程。


<details>
  <summary>Details</summary>
Motivation: 解决学生在选择相关课程时的困难，填补大学学习与行业期望之间的差距，促进终身学习和职业发展。

Method: 系统采用了数据挖掘和协同过滤技术，结合用户偏好和学术标准，设计了一个综合算法框架，并注重易于使用的前端界面开发。

Result: 经过用户反馈的反复优化和系统改进，确保了系统满足用户需求，为学生、教师和职业顾问提供有效工具。

Conclusion: 该课程推荐系统有望帮助学生做出基于数据和行业需求的课程决策，提高大学毕业生的就业结果。

Abstract: This paper aims to address the challenge of selecting relevant courses for students by proposing the design and development of a course recommendation system. The course recommendation system utilises a combination of data analytics techniques and machine learning algorithms to recommend courses that align with current industry trends and requirements. In order to provide customised suggestions, the study entails the design and implementation of an extensive algorithmic framework that combines machine learning methods, user preferences, and academic criteria. The system employs data mining and collaborative filtering techniques to examine past courses and individual career goals in order to provide course recommendations. Moreover, to improve the accessibility and usefulness of the recommendation system, special attention is given to the development of an easy-to-use front-end interface. The front-end design prioritises visual clarity, interaction, and simplicity through iterative prototyping and user input revisions, guaranteeing a smooth and captivating user experience. We refined and optimised the proposed system by incorporating user feedback, ensuring that it effectively meets the needs and preferences of its target users. The proposed course recommendation system could be a useful tool for students, instructors, and career advisers to use in promoting lifelong learning and professional progression as it fills the gap between university learning and industry expectations. We hope that the proposed course recommendation system will help university students in making data-drive and industry-informed course decisions, in turn, improving graduate outcomes for the university sector.

</details>


### [10] [Answering Students' Questions on Course Forums Using Multiple Chain-of-Thought Reasoning and Finetuning RAG-Enabled LLM](https://arxiv.org/abs/2511.09831)
*Neo Wang,Sonit Singh*

Main category: cs.CL

TL;DR: 本文提出了一种基于开源大语言模型和检索增强生成（RAG）的问答系统，以解决课程论坛中学生问题响应不及时和重复提问的问题。


<details>
  <summary>Details</summary>
Motivation: 课程论坛中学生数量增加导致问题响应不及时和教师面临大量重复提问，需要一个自动化的问答系统来缓解这些问题。

Method: 设计并实现了一个基于开源大语言模型的问答系统，通过微调相关课程数据集，并使用本地知识库和RAG方法检索与学生问题相关的文档。此外，引入多链思维推理来减少大语言模型的幻觉。

Result: 在HotpotQA数据集上实验表明，带有RAG方法的微调大语言模型在问答任务上表现出强大的性能。

Conclusion: 该问答系统能够有效处理课程论坛中的学生问题，减少教师负担，并提升响应速度和准确性。

Abstract: The course forums are increasingly significant and play vital role in facilitating student discussions and answering their questions related to the course. It provides a platform for students to post their questions related to the content and admin issues related to the course. However, there are several challenges due to the increase in the number of students enrolled in the course. The primary challenge is that students' queries cannot be responded immediately and the instructors have to face lots of repetitive questions. To mitigate these issues, we propose a question answering system based on large language model with retrieval augmented generation (RAG) method. This work focuses on designing a question answering system with open source Large Language Model (LLM) and fine-tuning it on the relevant course dataset. To further improve the performance, we use a local knowledge base and applied RAG method to retrieve relevant documents relevant to students' queries, where the local knowledge base contains all the course content. To mitigate the hallucination of LLMs, We also integrate it with multi chain-of-thought reasoning to overcome the challenge of hallucination in LLMs. In this work, we experiment fine-tuned LLM with RAG method on the HotpotQA dataset. The experimental results demonstrate that the fine-tuned LLM with RAG method has a strong performance on question answering task.

</details>


### [11] [TermGPT: Multi-Level Contrastive Fine-Tuning for Terminology Adaptation in Legal and Financial Domain](https://arxiv.org/abs/2511.09854)
*Yidan Sun,Mengying Zhu,Feiyue Chen,Yangyang Wu,Xiaolei Dan,Mengyuan Yang,Xiaolin Zheng,Shenglin Ben*

Main category: cs.CL

TL;DR: 提出TermGPT，一个多层次对比微调框架，以解决法律和金融等领域中术语嵌入的各向同性问题，提高术语级别表示的判别能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在文本生成中表现出色，但其嵌入空间常受各向同性问题困扰，导致在需要细微语义区分的专业领域（如法律和金融）表现不佳。

Method: 构建句子图以捕获语义和结构关系，利用上下文和拓扑线索生成正负样本，并设计句子级和标记级的多层次对比学习方法。

Result: TermGPT在金融和法律领域的术语判别任务中优于现有基线。

Conclusion: 通过多层次对比微调，TermGPT有效提升了专业术语的表示能力，为下游任务如法律判决预测和金融风险分析提供了支持。

Abstract: Large language models (LLMs) have demonstrated impressive performance in text generation tasks; however, their embedding spaces often suffer from the isotropy problem, resulting in poor discrimination of domain-specific terminology, particularly in legal and financial contexts. This weakness in terminology-level representation can severely hinder downstream tasks such as legal judgment prediction or financial risk analysis, where subtle semantic distinctions are critical. To address this problem, we propose TermGPT, a multi-level contrastive fine-tuning framework designed for terminology adaptation. We first construct a sentence graph to capture semantic and structural relations, and generate semantically consistent yet discriminative positive and negative samples based on contextual and topological cues. We then devise a multi-level contrastive learning approach at both the sentence and token levels, enhancing global contextual understanding and fine-grained terminology discrimination. To support robust evaluation, we construct the first financial terminology dataset derived from official regulatory documents. Experiments show that TermGPT outperforms existing baselines in term discrimination tasks within the finance and legal domains.

</details>


### [12] [In-Token Rationality Optimization: Towards Accurate and Concise LLM Reasoning via Self-Feedback](https://arxiv.org/abs/2511.09865)
*Mingye Zhu,Yi Liu,Zheren Fu,Quan Wang,Yongdong Zhang*

Main category: cs.CL

TL;DR: 提出了一种新的框架InTRO，通过token级探索和自我反馈优化大语言模型的思维链推理能力。


<details>
  <summary>Details</summary>
Motivation: 监督微调限制了模型的泛化能力，而强化学习在可验证奖励方面存在信用分配问题和计算成本高。因此，需要一种新的方法来提高模型的推理准确性和简洁性。

Method: InTRO利用校正因子，即生成策略和答案条件策略之间的信息差异，估计token-wise的重要性权重，实现token级探索和自我反馈。

Result: 在六个数学推理基准测试中，InTRO始终优于其他基线方法，解决方案的准确性提高了20%，思维链更简洁。

Conclusion: InTRO不仅提高了推理的准确性和简洁性，还展现了跨领域迁移能力，具有强大的泛化能力。

Abstract: Training Large Language Models (LLMs) for chain-of-thought reasoning presents a significant challenge: supervised fine-tuning on a single "golden" rationale hurts generalization as it penalizes equally valid alternatives, whereas reinforcement learning with verifiable rewards struggles with credit assignment and prohibitive computational cost. To tackle these limitations, we introduce InTRO (In-Token Rationality Optimization), a new framework that enables both token-level exploration and self-feedback for accurate and concise reasoning. Instead of directly optimizing an intractable objective over all valid reasoning paths, InTRO leverages correction factors-token-wise importance weights estimated by the information discrepancy between the generative policy and its answer-conditioned counterpart, for informative next token selection. This approach allows the model to perform token-level exploration and receive self-generated feedback within a single forward pass, ultimately encouraging accurate and concise rationales. Across six math-reasoning benchmarks, InTRO consistently outperforms other baselines, raising solution accuracy by up to 20% relative to the base model. Its chains of thought are also notably more concise, exhibiting reduced verbosity. Beyond this, InTRO enables cross-domain transfer, successfully adapting to out-of-domain reasoning tasks that extend beyond the realm of mathematics, demonstrating robust generalization.

</details>


### [13] [EnchTable: Unified Safety Alignment Transfer in Fine-tuned Large Language Models](https://arxiv.org/abs/2511.09880)
*Jialin Wu,Kecen Li,Zhicong Huang,Xinfeng Li,Xiaofeng Wang,Cheng Hong*

Main category: cs.CL

TL;DR: EnchTable是一个新颖的框架，通过NTK-based安全向量蒸馏和干扰感知合并技术，能够在不进行广泛再训练的情况下，转移和保持下游LLMs的安全对齐。


<details>
  <summary>Details</summary>
Motivation: 微调大型语言模型（LLMs）在特定领域（如代码生成、生物医学分析和数学问题解决）时，常常会降低安全对齐性，从而增加有害输出的风险。因此，有必要在不影响性能的前提下，增强和保持模型的安全对齐。

Method: EnchTable采用基于神经切线核（NTK）的安全向量蒸馏方法，将安全约束与任务特定推理解耦，并使用干扰感知合并技术平衡安全性和实用性。实验涵盖三个任务领域和三种LLM架构，在十一个数据集上评估其性能和安全性。

Result: EnchTable在减少不安全输出、提高实用性评分方面表现出色，并展示了对静态和动态越狱攻击的强大抵抗力。与六种参数修改方法和两种推理时对齐基线相比，EnchTable具有更低的危险率和更高的实用性评分，且能跨不同任务领域通用。

Conclusion: EnchTable能够有效保持和转移LLMs的安全对齐，且无需大量再训练，能无缝集成到各种部署流程中，具有广泛的适用性和实用性。

Abstract: Many machine learning models are fine-tuned from large language models (LLMs) to achieve high performance in specialized domains like code generation, biomedical analysis, and mathematical problem solving. However, this fine-tuning process often introduces a critical vulnerability: the systematic degradation of safety alignment, undermining ethical guidelines and increasing the risk of harmful outputs. Addressing this challenge, we introduce EnchTable, a novel framework designed to transfer and maintain safety alignment in downstream LLMs without requiring extensive retraining. EnchTable leverages a Neural Tangent Kernel (NTK)-based safety vector distillation method to decouple safety constraints from task-specific reasoning, ensuring compatibility across diverse model architectures and sizes. Additionally, our interference-aware merging technique effectively balances safety and utility, minimizing performance compromises across various task domains. We implemented a fully functional prototype of EnchTable on three different task domains and three distinct LLM architectures, and evaluated its performance through extensive experiments on eleven diverse datasets, assessing both utility and model safety. Our evaluations include LLMs from different vendors, demonstrating EnchTable's generalization capability. Furthermore, EnchTable exhibits robust resistance to static and dynamic jailbreaking attacks, outperforming vendor-released safety models in mitigating adversarial prompts. Comparative analyses with six parameter modification methods and two inference-time alignment baselines reveal that EnchTable achieves a significantly lower unsafe rate, higher utility score, and universal applicability across different task domains. Additionally, we validate EnchTable can be seamlessly integrated into various deployment pipelines without significant overhead.

</details>


### [14] [HI-TransPA: Hearing Impairments Translation Personal Assistant](https://arxiv.org/abs/2511.09915)
*Zhiming Ma,Shiyu Gan,Junhao Zhao,Xianming Li,Qingyun Pan,Peidong Wang,Mingjun Pan,Yuhao Mo,Jiajie Cheng,Chengxin Chen,Zhonglun Cao,Chonghan Liu,Shi Cheng*

Main category: cs.CL

TL;DR: 引入Omni-Model范式，提出HI-TransPA，一个指令驱动的视听个人助理，为听力障碍者提供统一且灵活的解决方案。


<details>
  <summary>Details</summary>
Motivation: 解决听力障碍者日常交流的问题，尤其是现有Omni-Models在嘈杂和异构数据上的适应性差。

Method: 构建全面的数据预处理和质量评估流程，采用SigLIP编码器和Unified 3D-Resampler，实施课程学习策略。

Result: 在自建HI-Dialogue数据集上，HI-TransPA在字面准确率和语义保真度上实现了最先进的性能。

Conclusion: 为Omni-Model在辅助通信技术中的应用奠定基础，提供一个端到端建模框架和必要的处理工具。

Abstract: To provide a unified and flexible solution for daily communication among hearing-impaired individuals, we introduce the Omni-Model paradigm into assistive technology and present HI-TransPA, an instruction-driven audio-visual personal assistant. The model fuses indistinct speech with high-frame-rate lip dynamics, enabling both translation and dialogue within a single multimodal framework. To tackle the challenges of noisy and heterogeneous raw data and the limited adaptability of existing Omni-Models to hearing-impaired speech, we construct a comprehensive preprocessing and curation pipeline that detects facial landmarks, isolates and stabilizes the lip region, and quantitatively assesses multimodal sample quality. These quality scores guide a curriculum learning strategy that first trains on clean, high-confidence samples and progressively incorporates harder cases to strengthen model robustness. We further adopt a SigLIP encoder combined with a Unified 3D-Resampler to efficiently encode high-frame-rate lip motion. Experiments on our purpose-built HI-Dialogue dataset show that HI-TransPA achieves state-of-the-art performance in both literal accuracy and semantic fidelity. This work establishes a foundation for applying Omni-Models to assistive communication technology, providing an end-to-end modeling framework and essential processing tools for future research.

</details>


### [15] [Leveraging Large Language Models for Identifying Knowledge Components](https://arxiv.org/abs/2511.09935)
*Canwen Wang,Jionghao Lin,Kenneth R. Koedinger*

Main category: cs.CL

TL;DR: 该研究通过扩大模拟教材的LLM提示策略，并结合基于余弦相似度的合并方法，解决了知识组件（KCs）自动化识别中的冗余问题。


<details>
  <summary>Details</summary>
Motivation: 手动识别知识组件（KCs）是一个瓶颈，虽然LLM提供了自动化的可能性，但之前的研究受限于小数据集并生成过多冗余KC标签。

Method: 研究扩展了LLM提示策略（使用GPT-4o-mini）到更大的数据集，并提出了基于余弦相似度的合并方法来合并语义相似的KC标签。

Result: 初始自动化方法表现不如专家设计的KC模型，但通过合并策略显著改善了性能，使用0.8的余弦相似度阈值，KCs数量减少到428，RMSE改善至0.4259。

Conclusion: 尽管单独使用扩展的LLM生成不足以达到最优效果，但结合语义合并技术为自动化和优化KC识别提供了可行路径。

Abstract: Knowledge Components (KCs) are foundational to adaptive learning systems, but their manual identification by domain experts is a significant bottleneck. While Large Language Models (LLMs) offer a promising avenue for automating this process, prior research has been limited to small datasets and has been shown to produce superfluous, redundant KC labels. This study addresses these limitations by first scaling a "simulated textbook" LLM prompting strategy (using GPT-4o-mini) to a larger dataset of 646 multiple-choice questions. We found that this initial automated approach performed significantly worse than an expert-designed KC model (RMSE 0.4285 vs. 0.4206) and generated an excessive number of KCs (569 vs. 101). To address the issue of redundancy, we proposed and evaluated a novel method for merging semantically similar KC labels based on their cosine similarity. This merging strategy significantly improved the model's performance; a model using a cosine similarity threshold of 0.8 achieved the best result, reducing the KC count to 428 and improving the RMSE to 0.4259. This demonstrates that while scaled LLM generation alone is insufficient, combining it with a semantic merging technique offers a viable path toward automating and refining KC identification.

</details>


### [16] [REAP: Enhancing RAG with Recursive Evaluation and Adaptive Planning for Multi-Hop Question Answering](https://arxiv.org/abs/2511.09966)
*Yijie Zhu,Haojie Zhou,Wanting Hong,Tailin Liu,Ning Wang*

Main category: cs.CL

TL;DR: 提出了一种递归评估和自适应规划（REAP）方法，以改进多跳推理任务中的全局规划和细粒度分析。


<details>
  <summary>Details</summary>
Motivation: 现有的多跳推理方法缺乏全局规划，导致容易陷入局部推理困境，且未能充分利用检索内容，忽略潜在线索，影响推理准确性。

Method: REAP方法包括子任务规划器（SP）和事实提取器（FE）模块，SP维护全局视角指导推理方向，FE进行细粒度分析，提取可靠答案和线索。

Result: 在多个公共多跳数据集上的实验结果表明，REAP在域内和域外设置中显著优于现有RAG方法。

Conclusion: 该方法有效提升了多跳推理任务的可靠性和可追溯性，验证了其在复杂任务中的有效性。

Abstract: Retrieval-augmented generation (RAG) has been extensively employed to mitigate hallucinations in large language models (LLMs). However, existing methods for multi-hop reasoning tasks often lack global planning, increasing the risk of falling into local reasoning impasses. Insufficient exploitation of retrieved content and the neglect of latent clues fail to ensure the accuracy of reasoning outcomes. To overcome these limitations, we propose Recursive Evaluation and Adaptive Planning (REAP), whose core idea is to explicitly maintain structured sub-tasks and facts related to the current task through the Sub-task Planner (SP) and Fact Extractor (FE) modules. SP maintains a global perspective, guiding the overall reasoning direction and evaluating the task state based on the outcomes of FE, enabling dynamic optimization of the task-solving trajectory. FE performs fine-grained analysis over retrieved content to extract reliable answers and clues. These two modules incrementally enrich a logically coherent representation of global knowledge, enhancing the reliability and the traceability of the reasoning process. Furthermore, we propose a unified task paradigm design that enables effective multi-task fine-tuning, significantly enhancing SP's performance on complex, data-scarce tasks. We conduct extensive experiments on multiple public multi-hop datasets, and the results demonstrate that our method significantly outperforms existing RAG methods in both in-domain and out-of-domain settings, validating its effectiveness in complex multi-hop reasoning tasks.

</details>


### [17] [NumPert: Numerical Perturbations to Probe Language Models for Veracity Prediction](https://arxiv.org/abs/2511.09971)
*Peter Røysland Aarnes,Vinay Setty*

Main category: cs.CL

TL;DR: 大型语言模型在知识密集型任务中表现优异，但在数值推理方面表现不佳。本文对最新模型在数值主张和证据对上的真实性预测进行了系统评估，发现即使在扰动条件下，模型的准确性也会大幅下降。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在数值推理和事实核查任务中表现不稳定，本文旨在通过控制扰动测试模型的鲁棒性，揭示其在数值事实核查中的局限性。

Method: 使用控制扰动（如标签翻转探针）对最先进的模型进行系统评估，测试其在数值主张和证据对上的真实性预测的鲁棒性，并分析不同上下文长度和扰动演示对模型性能的影响。

Result: 在特定扰动条件下，即使是领先的专有系统，其准确性也会下降高达62%。增加上下文长度通常会降低准确性，但加入扰动演示后，大多数模型能显著恢复性能。

Conclusion: 当前语言模型在数值事实核查中存在关键局限性，鲁棒性仍然是一个未解决的挑战，需要进一步研究以提高其在数值推理任务中的表现。

Abstract: Large language models show strong performance on knowledge intensive tasks such as fact-checking and question answering, yet they often struggle with numerical reasoning. We present a systematic evaluation of state-of-the-art models for veracity prediction on numerical claims and evidence pairs using controlled perturbations, including label-flipping probes, to test robustness. Our results indicate that even leading proprietary systems experience accuracy drops of up to 62\% under certain perturbations. No model proves to be robust across all conditions. We further find that increasing context length generally reduces accuracy, but when extended context is enriched with perturbed demonstrations, most models substantially recover. These findings highlight critical limitations in numerical fact-checking and suggest that robustness remains an open challenge for current language models.

</details>


### [18] [Modeling Uncertainty Trends for Timely Retrieval in Dynamic RAG](https://arxiv.org/abs/2511.09980)
*Bo Li,Tian Tian,Zhenghua Xu,Hao Cheng,Shikun Zhang,Wei Ye*

Main category: cs.CL

TL;DR: 提出了一种无需训练的熵趋势约束（ETC）方法，通过建模标记级不确定性动态来确定动态检索增强生成（RAG）中的最佳检索时机。


<details>
  <summary>Details</summary>
Motivation: 动态RAG中一个核心挑战是如何确定最佳检索时机，现有方法基于低标记级置信度触发检索，可能导致错误传播后的延迟干预。

Method: 引入熵趋势约束（ETC），利用熵序列的一阶和二阶差分来检测新出现的不确定性趋势，从而实现更早更精确的检索。

Result: 在六个QA基准测试中，ETC始终优于强基线方法，同时降低了检索频率，在特定领域场景中表现尤为出色，展示了强大的泛化能力。

Conclusion: 趋势感知的不确定性建模能产生更有效的检索时机，ETC方法即插即用、模型无关，易于集成到现有解码流程中。

Abstract: Dynamic retrieval-augmented generation (RAG) allows large language models (LLMs) to fetch external knowledge on demand, offering greater adaptability than static RAG. A central challenge in this setting lies in determining the optimal timing for retrieval. Existing methods often trigger retrieval based on low token-level confidence, which may lead to delayed intervention after errors have already propagated. We introduce Entropy-Trend Constraint (ETC), a training-free method that determines optimal retrieval timing by modeling the dynamics of token-level uncertainty. Specifically, ETC utilizes first- and second-order differences of the entropy sequence to detect emerging uncertainty trends, enabling earlier and more precise retrieval. Experiments on six QA benchmarks with three LLM backbones demonstrate that ETC consistently outperforms strong baselines while reducing retrieval frequency. ETC is particularly effective in domain-specific scenarios, exhibiting robust generalization capabilities. Ablation studies and qualitative analyses further confirm that trend-aware uncertainty modeling yields more effective retrieval timing. The method is plug-and-play, model-agnostic, and readily integrable into existing decoding pipelines. Implementation code is included in the supplementary materials.

</details>


### [19] [Language Drift in Multilingual Retrieval-Augmented Generation: Characterization and Decoding-Time Mitigation](https://arxiv.org/abs/2511.09984)
*Bo Li,Zhenghua Xu,Rui Xie*

Main category: cs.CL

TL;DR: 本文研究了多语言RAG中的语言漂移问题，并提出了一种新的解码策略SCD来缓解这一问题。


<details>
  <summary>Details</summary>
Motivation: 多语言RAG在处理知识密集型任务时，由于检索到的证据与用户查询和上下文范例语言不一致，模型常常产生非预期语言的响应，特别是在推理密集型解码过程中。

Method: 通过系统研究多个数据集、语言和LLM架构上的输出语言漂移现象，提出了一种轻量级、无需训练的Soft Constrained Decoding (SCD)策略，通过惩罚非目标语言标记来引导生成目标语言。

Result: 实验表明，SCD在三种多语言数据集和多种语言上始终改善了语言对齐和任务性能。

Conclusion: SCD是一种有效且通用的解决多语言RAG中语言漂移问题的方法，能够在不修改模型结构或增加数据的情况下应用。

Abstract: Multilingual Retrieval-Augmented Generation (RAG) enables large language models (LLMs) to perform knowledge-intensive tasks in multilingual settings by leveraging retrieved documents as external evidence. However, when the retrieved evidence differs in language from the user query and in-context exemplars, the model often exhibits language drift by generating responses in an unintended language. This phenomenon is especially pronounced during reasoning-intensive decoding, such as Chain-of-Thought (CoT) generation, where intermediate steps introduce further language instability. In this paper, we systematically study output language drift in multilingual RAG across multiple datasets, languages, and LLM backbones. Our controlled experiments reveal that the drift results not from comprehension failure but from decoder-level collapse, where dominant token distributions and high-frequency English patterns dominate the intended generation language. We further observe that English serves as a semantic attractor under cross-lingual conditions, emerging as both the strongest interference source and the most frequent fallback language.
  To mitigate this, we propose Soft Constrained Decoding (SCD), a lightweight, training-free decoding strategy that gently steers generation toward the target language by penalizing non-target-language tokens. SCD is model-agnostic and can be applied to any generation algorithm without modifying the architecture or requiring additional data. Experiments across three multilingual datasets and multiple typologically diverse languages show that SCD consistently improves language alignment and task performance, providing an effective and generalizable solution in multilingual RAG.

</details>


### [20] [FinNuE: Exposing the Risks of Using BERTScore for Numerical Semantic Evaluation in Finance](https://arxiv.org/abs/2511.09997)
*Yu-Shiang Huang,Yun-Yu Lee,Tzu-Hsin Chou,Che Lin,Chuan-Ju Wang*

Main category: cs.CL

TL;DR: 本文指出了BERTScore在金融文本中数字变化敏感性不足的问题，并提出了包含受控数字扰动的金融数据集FinNuE来验证这一局限。


<details>
  <summary>Details</summary>
Motivation: 金融文本中的数字精度对语义至关重要，但现有的BERTScore在评估金融文本时对数字变化不敏感，这可能导致错误的语义相似性判断。

Method: 构建了一个名为FinNuE的诊断数据集，该数据集包含受控的数字扰动，并覆盖财报电话、监管文件、社交媒体和新闻文章等多种金融文本。

Result: 使用FinNuE验证了BERTScore在金融文本中无法区分关键的数字差异，常常为语义上差异很大的文本对分配高相似性分数。

Conclusion: 本文揭示了基于嵌入的度量在金融文本中的根本局限性，并提出了需要针对金融NLP设计对数字敏感的评估框架。

Abstract: BERTScore has become a widely adopted metric for evaluating semantic similarity between natural language sentences. However, we identify a critical limitation: BERTScore exhibits low sensitivity to numerical variation, a significant weakness in finance where numerical precision directly affects meaning (e.g., distinguishing a 2% gain from a 20% loss). We introduce FinNuE, a diagnostic dataset constructed with controlled numerical perturbations across earnings calls, regulatory filings, social media, and news articles. Using FinNuE, demonstrate that BERTScore fails to distinguish semantically critical numerical differences, often assigning high similarity scores to financially divergent text pairs. Our findings reveal fundamental limitations of embedding-based metrics for finance and motivate numerically-aware evaluation frameworks for financial NLP.

</details>


### [21] [PustakAI: Curriculum-Aligned and Interactive Textbooks Using Large Language Models](https://arxiv.org/abs/2511.10002)
*Shivam Sharma,Riya Naik,Tejas Gawas,Heramb Patil,Kunal Korgaonkar*

Main category: cs.CL

TL;DR: 本文提出了PustakAI框架和NCERT-QA数据集，专为印度NCERT课程设计，用于评估和优化大语言模型在6-8年级英语和科学科目的问答表现。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在教育领域有广泛应用潜力，特别是在教学资源有限的地区，但如何将其有效适配到特定课程（如印度NCERT课程）仍面临准确性、对齐性和教学相关性的挑战。

Method: 构建了与NCERT课程对齐的NCERT-QA问答数据集，分类为事实性、推理性及其他类型，并采用元提示、少样本和思维链（CoT）等多种提示技术，结合多种评估指标对数据集进行评估。

Result: 评估了包括开源模型（Gemma3:1b, Llama3.2:3b, Nemotron-mini:4b）和高性能模型（Llama-4-Scout-17B, Deepseek-r1-70B）的表现，分析了这些模型在正式教育系统中的优势和局限性。

Conclusion: PustakAI框架和NCERT-QA数据集为将大语言模型适配到特定课程提供了有效的方法，不同提示技术和模型在课程问答任务中表现各异，强调了进一步优化的必要性。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in understanding and generating human-like content. This has revolutionized various sectors such as healthcare, software development, and education. In education, LLMs offer potential for personalized and interactive learning experiences, especially in regions with limited teaching resources. However, adapting these models effectively to curriculum-specific content, such as the National Council of Educational Research and Training (NCERT) syllabus in India, presents unique challenges in terms of accuracy, alignment, and pedagogical relevance. In this paper, we present the framework "PustakAI"\footnote{Pustak means `book' in many Indian languages.} for the design and evaluation of a novel question-answering dataset "NCERT-QA" aligned with the NCERT curriculum for English and Science subjects of grades 6 to 8. We classify the curated QA pairs as Factoid, Inferential, and Others (evaluative and reasoning). We evaluate the dataset with various prompting techniques, such as meta-prompt, few-shot, and CoT-style prompting, using diverse evaluation metrics to understand which approach aligns more efficiently with the structure and demands of the curriculum. Along with the usability of the dataset, we analyze the strengths and limitations of current open-source LLMs (Gemma3:1b, Llama3.2:3b, and Nemotron-mini:4b) and high-end LLMs (Llama-4-Scout-17B and Deepseek-r1-70B) as AI-based learning tools in formal education systems.

</details>


### [22] [ScaleFormer: Span Representation Cumulation for Long-Context Transformer](https://arxiv.org/abs/2511.10029)
*Jiangshu Du,Wenpeng Yin,Philip Yu*

Main category: cs.CL

TL;DR: 提出了一种名为ScaleFormer的即插即用框架，无需结构修改即可让预训练的编码器-解码器模型处理长序列。


<details>
  <summary>Details</summary>
Motivation: 标准自注意力的二次复杂度限制了Transformer模型在长上下文任务中的应用，现有高效Transformer变体通常需要架构更改和昂贵的从头预训练。

Method: 将长输入分割成重叠块，并生成压缩的、上下文感知的表示供解码器使用；核心是一种新颖的无参数融合机制，通过累积上下文向量增强每个块的边界表示。

Result: 在长文档摘要实验中，该方法在不需架构修改或外部检索机制的情况下，表现极具竞争力，经常优于最先进的方法。

Conclusion: ScaleFormer是一个简单有效的解决方案，可以让预训练模型高效处理长序列，同时保持线性复杂度和强大的文档叙述流信号。

Abstract: The quadratic complexity of standard self-attention severely limits the application of Transformer-based models to long-context tasks. While efficient Transformer variants exist, they often require architectural changes and costly pre-training from scratch. To circumvent this, we propose ScaleFormer(Span Representation Cumulation for Long-Context Transformer) - a simple and effective plug-and-play framework that adapts off-the-shelf pre-trained encoder-decoder models to process long sequences without requiring architectural modifications. Our approach segments long inputs into overlapping chunks and generates a compressed, context-aware representation for the decoder. The core of our method is a novel, parameter-free fusion mechanism that endows each chunk's representation with structural awareness of its position within the document. It achieves this by enriching each chunk's boundary representations with cumulative context vectors from all preceding and succeeding chunks. This strategy provides the model with a strong signal of the document's narrative flow, achieves linear complexity, and enables pre-trained models to reason effectively over long-form text. Experiments on long-document summarization show that our method is highly competitive with and often outperforms state-of-the-art approaches without requiring architectural modifications or external retrieval mechanisms.

</details>


### [23] [Do Language Models Associate Sound with Meaning? A Multimodal Study of Sound Symbolism](https://arxiv.org/abs/2511.10045)
*Jinhong Jeong,Sunghyun Lee,Jaeyoung Lee,Seonah Han,Youngjae Yu*

Main category: cs.CL

TL;DR: 该论文探讨了多模态大型语言模型（MLLMs）如何在不同输入形式下处理语音象征性，并提出了LEX-ICON数据集用于分析。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于理解MLLMs如何解释人类语言中的听觉信息，并探索声音象征性在模型中的表现。

Method: 通过构建LEX-ICON数据集，包括8,052个自然语言词和2,930个伪词，分析MLLMs在文本（正字法和IPA）和听觉输入下的音位象征性表现，并测量音素级注意分数。

Result: 研究发现MLLMs在多个语义维度上表现出与语言学现有研究一致的音感直觉，并突出了模型在象征性音素上的注意模式。

Conclusion: 这些结果为人工智能和认知语言学领域之间架起了桥梁，为MLLMs的可解释性提供了大规模、定量的音感象征分析。

Abstract: Sound symbolism is a linguistic concept that refers to non-arbitrary associations between phonetic forms and their meanings. We suggest that this can be a compelling probe into how Multimodal Large Language Models (MLLMs) interpret auditory information in human languages. We investigate MLLMs' performance on phonetic iconicity across textual (orthographic and IPA) and auditory forms of inputs with up to 25 semantic dimensions (e.g., sharp vs. round), observing models' layer-wise information processing by measuring phoneme-level attention fraction scores. To this end, we present LEX-ICON, an extensive mimetic word dataset consisting of 8,052 words from four natural languages (English, French, Japanese, and Korean) and 2,930 systematically constructed pseudo-words, annotated with semantic features applied across both text and audio modalities. Our key findings demonstrate (1) MLLMs' phonetic intuitions that align with existing linguistic research across multiple semantic dimensions and (2) phonosemantic attention patterns that highlight models' focus on iconic phonemes. These results bridge domains of artificial intelligence and cognitive linguistics, providing the first large-scale, quantitative analyses of phonetic iconicity in terms of MLLMs' interpretability.

</details>


### [24] [ADI-20: Arabic Dialect Identification dataset and models](https://arxiv.org/abs/2511.10070)
*Haroun Elleuch,Salima Mdhaffar,Yannick Estève,Fethi Bougares*

Main category: cs.CL

TL;DR: 本文介绍了ADI-20，一个扩展的阿拉伯语方言识别（ADI）数据集，涵盖了所有阿拉伯语国家的方言。


<details>
  <summary>Details</summary>
Motivation: 为了改进和扩展先前发布的ADI-17数据集，使其覆盖所有阿拉伯语国家的方言，并用于训练和评估先进的ADI系统。

Method: 使用ADI-20数据集训练和评估各种先进的ADI系统，探索了微调的ECAPA-TDNN模型和Whisper编码器块结合注意力池化层和分类密集层的方法，并研究了训练数据量和模型参数对方言识别性能的影响。

Result: 结果显示，在使用仅30%的原始训练数据时，F1分数仅有轻微下降。

Conclusion: 研究团队开源了收集的数据和训练模型，以支持ADI领域的进一步研究和工作的重现。

Abstract: We present ADI-20, an extension of the previously published ADI-17 Arabic Dialect Identification (ADI) dataset. ADI-20 covers all Arabic-speaking countries' dialects. It comprises 3,556 hours from 19 Arabic dialects in addition to Modern Standard Arabic (MSA). We used this dataset to train and evaluate various state-of-the-art ADI systems. We explored fine-tuning pre-trained ECAPA-TDNN-based models, as well as Whisper encoder blocks coupled with an attention pooling layer and a classification dense layer. We investigated the effect of (i) training data size and (ii) the model's number of parameters on identification performance. Our results show a small decrease in F1 score while using only 30% of the original training data. We open-source our collected data and trained models to enable the reproduction of our work, as well as support further research in ADI.

</details>


### [25] [Format Matters: The Robustness of Multimodal LLMs in Reviewing Evidence from Tables and Charts](https://arxiv.org/abs/2511.10075)
*Xanh Ho,Yun-Ang Wu,Sunisth Kumar,Florian Boudin,Atsuhiro Takasu,Akiko Aizawa*

Main category: cs.CL

TL;DR: 本文评估了多模态大语言模型在验证科学主张方面的能力，发现模型在处理表格证据时表现优于图表证据，而人类在这两种格式下均保持较强性能。


<details>
  <summary>Details</summary>
Motivation: 随着科学论文数量的增长，需要系统协助审稿人评估研究主张。实验结果作为科学工作的核心部分，常以表格或图表形式呈现，因此需要研究多模态大模型在不同证据格式下的科学主张验证能力。

Method: 设计了一系列实验，通过调整两个现有科学论文数据集，加入多模态主张验证任务所需的标注和结构，评估了12个多模态大模型的表现，并进行人工评估以对比。

Result: 当前模型在表格证据下表现更好，但在图表证据下表现不佳。人类在这两种格式下均保持较强性能。此外，小型多模态模型（低于8B）在表格和图表任务之间表现相关性较弱，表明跨模态泛化能力有限。

Conclusion: 当前多模态大模型在多模态推理能力上存在差距，未来的多模态大模型应更重视提高对图表的理解，以更好地支持科学主张验证。

Abstract: With the growing number of submitted scientific papers, there is an increasing demand for systems that can assist reviewers in evaluating research claims. Experimental results are a core component of scientific work, often presented in varying formats such as tables or charts. Understanding how robust current multimodal large language models (multimodal LLMs) are at verifying scientific claims across different evidence formats remains an important and underexplored challenge. In this paper, we design and conduct a series of experiments to assess the ability of multimodal LLMs to verify scientific claims using both tables and charts as evidence. To enable this evaluation, we adapt two existing datasets of scientific papers by incorporating annotations and structures necessary for a multimodal claim verification task. Using this adapted dataset, we evaluate 12 multimodal LLMs and find that current models perform better with table-based evidence while struggling with chart-based evidence. We further conduct human evaluations and observe that humans maintain strong performance across both formats, unlike the models. Our analysis also reveals that smaller multimodal LLMs (under 8B) show weak correlation in performance between table-based and chart-based tasks, indicating limited cross-modal generalization. These findings highlight a critical gap in current models' multimodal reasoning capabilities. We suggest that future multimodal LLMs should place greater emphasis on improving chart understanding to better support scientific claim verification.

</details>


### [26] [ELYADATA & LIA at NADI 2025: ASR and ADI Subtasks](https://arxiv.org/abs/2511.10090)
*Haroun Elleuch,Youssef Saidi,Salima Mdhaffar,Yannick Estève,Fethi Bougares*

Main category: cs.CL

TL;DR: 本文介绍了Elyadata与LIA联合提交的NADI多方言阿拉伯语语音处理2025参赛方案，在ADI任务中获第一，ASR任务中获第二。


<details>
  <summary>Details</summary>
Motivation: 展示大型预训练语音模型在阿拉伯语语音处理中的有效性，尤其是在多方言环境下的表现。

Method: 在ADI任务中，采用微调Whisper-large-v3编码器并结合数据增强；在ASR任务中，对SeamlessM4T-v2 Large模型进行各方言的独立微调。

Result: 在官方测试集上，ADI任务取得了79.83%的准确率，ASR任务在测试集上的平均WER和CER分别为38.54%和14.53%。

Conclusion: 大型预训练语音模型结合有针对性的微调在阿拉伯语语音处理任务中表现出显著效果。

Abstract: This paper describes Elyadata \& LIA's joint submission to the NADI multi-dialectal Arabic Speech Processing 2025. We participated in the Spoken Arabic Dialect Identification (ADI) and multi-dialectal Arabic ASR subtasks. Our submission ranked first for the ADI subtask and second for the multi-dialectal Arabic ASR subtask among all participants. Our ADI system is a fine-tuned Whisper-large-v3 encoder with data augmentation. This system obtained the highest ADI accuracy score of \textbf{79.83\%} on the official test set. For multi-dialectal Arabic ASR, we fine-tuned SeamlessM4T-v2 Large (Egyptian variant) separately for each of the eight considered dialects. Overall, we obtained an average WER and CER of \textbf{38.54\%} and \textbf{14.53\%}, respectively, on the test set. Our results demonstrate the effectiveness of large pre-trained speech models with targeted fine-tuning for Arabic speech processing.

</details>


### [27] [On the Military Applications of Large Language Models](https://arxiv.org/abs/2511.10093)
*Satu Johansson,Taneli Riihonen*

Main category: cs.CL

TL;DR: 本文探讨了自然语言处理和大型语言模型在军事领域的应用，通过分析GPT模型和商用云服务（如Microsoft Azure）的可行性，评估了它们在军事应用中的潜力。


<details>
  <summary>Details</summary>
Motivation: 随着GPT和OpenAI等基础模型的出现，自然语言处理技术在多个领域取得了显著进展。本文旨在探讨这些技术在军事领域的具体应用及其实现方式。

Method: 首先，通过询问基于GPT的语言模型（如Microsoft Copilot）来揭示其自身关于潜在军事应用的认识，并对这些信息进行批判性评估。其次，研究如何利用商用云服务（如Microsoft Azure）来构建这些应用，并评估其可行性。

Result: 研究发现，语言模型的摘要和生成特性直接促进了多种应用，而其他特性也可能在特定用途中找到应用。

Conclusion: 语言模型的多种特性使其在军事应用中有广泛的潜力，特别是在信息摘要和生成方面。商用云服务的利用进一步增强了这些应用的可行性。

Abstract: In this paper, military use cases or applications and implementation thereof are considered for natural language processing and large language models, which have broken into fame with the invention of the generative pre-trained transformer (GPT) and the extensive foundation model pretraining done by OpenAI for ChatGPT and others. First, we interrogate a GPT-based language model (viz. Microsoft Copilot) to make it reveal its own knowledge about their potential military applications and then critically assess the information. Second, we study how commercial cloud services (viz. Microsoft Azure) could be used readily to build such applications and assess which of them are feasible. We conclude that the summarization and generative properties of language models directly facilitate many applications at large and other features may find particular uses.

</details>


### [28] [Generalizing to Unseen Disaster Events: A Causal View](https://arxiv.org/abs/2511.10120)
*Philipp Seeberger,Steffen Freisinger,Tobias Bocklet,Korbinian Riedhammer*

Main category: cs.CL

TL;DR: 本文提出了一种通过因果视角减轻事件和领域相关偏差的方法，以提升在灾难事件中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 社交媒体平台在灾难事件中信息监测的重要性，以及现有系统面临的事件相关偏差问题。

Method: 采用因果学习方法来减轻事件和领域相关偏差。

Result: 在三个灾难分类任务中，该方法优于多个基线，F1得分提高达1.9%，显著提升了PLM分类器性能。

Conclusion: 该方法有效提升了模型在灾难事件中的泛化能力，为未来事件提供了更好的适应性。

Abstract: Due to the rapid growth of social media platforms, these tools have become essential for monitoring information during ongoing disaster events. However, extracting valuable insights requires real-time processing of vast amounts of data. A major challenge in existing systems is their exposure to event-related biases, which negatively affects their ability to generalize to emerging events. While recent advancements in debiasing and causal learning offer promising solutions, they remain underexplored in the disaster event domain. In this work, we approach bias mitigation through a causal lens and propose a method to reduce event- and domain-related biases, enhancing generalization to future events. Our approach outperforms multiple baselines by up to +1.9% F1 and significantly improves a PLM-based classifier across three disaster classification tasks.

</details>


### [29] [Beyond the Black Box: Demystifying Multi-Turn LLM Reasoning with VISTA](https://arxiv.org/abs/2511.10182)
*Yiran Zhang,Mingyang Lin,Mark Dras,Usman Naseem*

Main category: cs.CL

TL;DR: 该论文介绍了VISTA，一个用于多轮对话推理分析的基于Web的可视化交互系统。


<details>
  <summary>Details</summary>
Motivation: 当前研究关注大型语言模型（LLMs）在多轮交互中的推理能力，但分析这些交互的复杂推理过程面临挑战，因为缺乏专门的工具，导致研究人员认知负荷高。

Method: 论文提出VISTA系统，允许用户可视化上下文对模型决策的影响，并交互式修改对话历史进行“假设”分析。平台能自动解析会话并生成推理依赖树，提供模型逐步逻辑路径的透明视图。

Result: VISTA通过提供统一和交互式框架，显著降低了分析推理链的复杂性，帮助研究人员更深入地理解现有LLMs的能力和局限性。平台开源，支持集成自定义基准和本地模型。

Conclusion: VISTA解决了多轮交互中LLMs推理分析的可视化问题，为研究人员提供了一个强大且易于使用的工具，有助于推动对LLMs推理能力的理解。

Abstract: Recent research has increasingly focused on the reasoning capabilities of Large Language Models (LLMs) in multi-turn interactions, as these scenarios more closely mirror real-world problem-solving. However, analyzing the intricate reasoning processes within these interactions presents a significant challenge due to complex contextual dependencies and a lack of specialized visualization tools, leading to a high cognitive load for researchers. To address this gap, we present VISTA, an web-based Visual Interactive System for Textual Analytics in multi-turn reasoning tasks. VISTA allows users to visualize the influence of context on model decisions and interactively modify conversation histories to conduct "what-if" analyses across different models. Furthermore, the platform can automatically parse a session and generate a reasoning dependency tree, offering a transparent view of the model's step-by-step logical path. By providing a unified and interactive framework, VISTA significantly reduces the complexity of analyzing reasoning chains, thereby facilitating a deeper understanding of the capabilities and limitations of current LLMs. The platform is open-source and supports easy integration of custom benchmarks and local models.

</details>


### [30] [Text2SQL-Flow: A Robust SQL-Aware Data Augmentation Framework for Text-to-SQL](https://arxiv.org/abs/2511.10192)
*Qifeng Cai,Hao Liang,Chang Xu,Tao Xie,Wentao Zhang,Bin Cui*

Main category: cs.CL

TL;DR: 为解决Text-to-SQL任务中的数据稀缺、简单和多样性不足的问题，本文提出了Text2SQL-Flow框架，通过六个增强维度生成大规模、语义有效和结构多样的Text-to-SQL数据对，并构建了包含89,544个标注样本的高质量数据集SQLFlow。


<details>
  <summary>Details</summary>
Motivation: Text-to-SQL任务受限于数据的稀缺性、简单性和低多样性。因此，作者提出了一种数据增强框架，以生成更多高质量的Text-to-SQL数据对，从而提升模型性能。

Method: Text2SQL-Flow框架包括SQL执行验证、自然语言问题生成、思维链推理轨迹和数据分类的端到端流程，并采用模块化的数据库管理器以确保跨数据库的兼容性和可扩展性。此外，引入了掩码对齐检索方法，将SQLFlow作为知识库和训练数据。

Result: 在开源和闭源大语言模型上，使用SQLFlow数据集进行微调或检索均显著提升了性能。SQLFlow在相同数据预算下，性能优于现有方法。

Conclusion: 本文的工作为Text-to-SQL系统建立了一个可扩展的数据中心基础，强调了高质量结构化数据在现代AI中的关键作用。

Abstract: The data-centric paradigm has become pivotal in AI, especially for Text-to-SQL, where performance is limited by scarce, simplistic, and low-diversity datasets. To address this, we propose Text2SQL-Flow, a SQL-aware data augmentation framework that generates large-scale, semantically valid, and structurally diverse Text-to-SQL pairs from minimal seed data. It operates across six augmentation dimensions and integrates an end-to-end pipeline featuring SQL execution verification, natural language question generation, chain-of-thought reasoning traces, and data classification. A modular Database Manager ensures cross-database compatibility and scalability. Using this framework, we build SQLFlow, a high-quality dataset of 89,544 annotated examples. We evaluate SQLFlow in two settings: (1) For open-source LLMs, fine-tuning on SQLFlow consistently improves performance across benchmarks under the same data budget. (2) For closed-source LLMs, we introduce a masked alignment retrieval method that treats SQLFlow as both knowledge base and training data for the retriever. This enables structure-aware example matching by modeling fine-grained alignments between questions and SQL queries. Experiments show our retrieval strategy outperforms existing methods, underscoring the value of SQLFlow's high-fidelity data and our novel technique. Our work establishes a scalable, data-centric foundation for advancing Text-to-SQL systems and highlights the critical role of high-quality structured data in modern AI.

</details>


### [31] [EffiReason-Bench: A Unified Benchmark for Evaluating and Advancing Efficient Reasoning in Large Language Models](https://arxiv.org/abs/2511.10201)
*Junquan Huang,Haotian Wu,Yubo Gao,Yibo Yan,Junyan Zhang,Yonghua Hei,Song Dai,Jie Zhang,Puay Siew Tan,Xuming Hu*

Main category: cs.CL

TL;DR: 提出EffiReason-Bench统一基准和E3-Score指标，系统性评估三类高效推理方法在不同模型和数据集上的表现，发现最优方法因模型规模、任务复杂度而异。


<details>
  <summary>Details</summary>
Motivation: 大模型思维链推理存在冗长低效问题，且现有效率优化方法缺乏标准化评估体系，导致横向比较困难。

Method: 构建含标准化CoT标注的CommonsenseQA/LogiQA数据集；设计涵盖三大类（蓝图/动态/后处理）的基准测试；提出融合经济权衡思想的E3-Score连续评估指标。

Result: 在4类任务6种模型(1B-70B)上评估7种方法，揭示不同场景下的最优方法选择规律，如小规模模型更适合动态执行类方法。

Conclusion: 高效推理方法需根据模型架构、规模及任务类型定制，提出的评估体系为领域建立了可复现的标准化测试框架。

Abstract: Large language models (LLMs) with Chain-of-Thought (CoT) prompting achieve strong reasoning but often produce unnecessarily long explanations, increasing cost and sometimes reducing accuracy. Fair comparison of efficiency-oriented approaches is hindered by fragmented evaluation practices. We introduce EffiReason-Bench, a unified benchmark for rigorous cross-paradigm evaluation of efficient reasoning methods across three categories: Reasoning Blueprints, Dynamic Execution, and Post-hoc Refinement. To enable step-by-step evaluation, we construct verified CoT annotations for CommonsenseQA and LogiQA via a pipeline that enforces standardized reasoning structures, comprehensive option-wise analysis, and human verification. We evaluate 7 methods across 6 open-source LLMs (1B-70B) on 4 datasets spanning mathematics, commonsense, and logic, and propose the E3-Score, a principled metric inspired by economic trade-off modeling that provides smooth, stable evaluation without discontinuities or heavy reliance on heuristics. Experiments show that no single method universally dominates; optimal strategies depend on backbone scale, task complexity, and architecture.

</details>


### [32] [Persona-Aware Alignment Framework for Personalized Dialogue Generation](https://arxiv.org/abs/2511.10215)
*Guanrong Li,Xinyu Liu,Zhen Wu,Xinyu Dai*

Main category: cs.CL

TL;DR: 提出了一种新颖的个性化对话生成框架PAL，通过两阶段训练和易于使用的推理策略来提升对话生成的角色相关性和一致性。


<details>
  <summary>Details</summary>
Motivation: 主流模型在个性化对话生成中往往忽视给定的角色信息，导致生成通用回复。为了解决这个问题，作者提出了PAL框架，将角色对齐作为明确的训练目标。

Method: PAL采用了两阶段训练方法，包括角色感知学习和角色对齐，并配备了一个易于使用的推理策略Select then Generate，以在语义层面上提高角色敏感性。

Result: 通过大量实验，PAL框架在个性化对话生成任务中优于许多最新的方法和大型语言模型。

Conclusion: PAL框架通过直接优化角色对齐，能够生成更具角色相关性和一致性的对话回复，为个性化对话生成提供了新的解决方案。

Abstract: Personalized dialogue generation aims to leverage persona profiles and dialogue history to generate persona-relevant and consistent responses. Mainstream models typically rely on token-level language model training with persona dialogue data, such as Next Token Prediction, to implicitly achieve personalization, making these methods tend to neglect the given personas and generate generic responses. To address this issue, we propose a novel Persona-Aware Alignment Framework (PAL), which directly treats persona alignment as the training objective of dialogue generation. Specifically, PAL employs a two-stage training method including Persona-aware Learning and Persona Alignment, equipped with an easy-to-use inference strategy Select then Generate, to improve persona sensitivity and generate more persona-relevant responses at the semantics level. Through extensive experiments, we demonstrate that our framework outperforms many state-of-the-art personalized dialogue methods and large language models.

</details>


### [33] [LangGPS: Language Separability Guided Data Pre-Selection for Joint Multilingual Instruction Tuning](https://arxiv.org/abs/2511.10229)
*Yangfan Ye,Xiaocheng Feng,Xiachong Feng,Lei Huang,Weitao Ma,Qichen Hong,Yunfei Lu,Duyu Tang,Dandan Tu,Bing Qin*

Main category: cs.CL

TL;DR: 提出了一种基于语言可分性的两阶段预筛选框架LangGPS，用于提升多语言训练数据选择效果。


<details>
  <summary>Details</summary>
Motivation: 现有多语言数据选择方法忽视了数据的内在语言结构，导致多语言能力对训练数据组成和选择高度敏感。

Method: 设计了LangGPS框架，通过语言可分性分数先过滤数据，再结合现有选择方法精炼子集。

Result: 在六个基准和22种语言上的实验显示，LangGPS提升了现有选择方法在多语言训练中的有效性和泛化性，尤其对于理解任务和低资源语言。

Conclusion: 语言可分性可作为多语言课程学习的有效信号，交替使用不同可分性样本可带来稳定且泛化的性能提升。希望该工作能为多语言环境中的数据效用提供新视角，支持更懂语言的LLMs开发。

Abstract: Joint multilingual instruction tuning is a widely adopted approach to improve the multilingual instruction-following ability and downstream performance of large language models (LLMs), but the resulting multilingual capability remains highly sensitive to the composition and selection of the training data. Existing selection methods, often based on features like text quality, diversity, or task relevance, typically overlook the intrinsic linguistic structure of multilingual data. In this paper, we propose LangGPS, a lightweight two-stage pre-selection framework guided by language separability which quantifies how well samples in different languages can be distinguished in the model's representation space. LangGPS first filters training data based on separability scores and then refines the subset using existing selection methods. Extensive experiments across six benchmarks and 22 languages demonstrate that applying LangGPS on top of existing selection methods improves their effectiveness and generalizability in multilingual training, especially for understanding tasks and low-resource languages. Further analysis reveals that highly separable samples facilitate the formation of clearer language boundaries and support faster adaptation, while low-separability samples tend to function as bridges for cross-lingual alignment. Besides, we also find that language separability can serve as an effective signal for multilingual curriculum learning, where interleaving samples with diverse separability levels yields stable and generalizable gains. Together, we hope our work offers a new perspective on data utility in multilingual contexts and support the development of more linguistically informed LLMs.

</details>


### [34] [VocalNet-M2: Advancing Low-Latency Spoken Language Modeling via Integrated Multi-Codebook Tokenization and Multi-Token Prediction](https://arxiv.org/abs/2511.10232)
*Yuhao Wang,Ziyang Cheng,Heyang Liu,Ronghua Wu,Qunshan Gu,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: VocalNet-M2是一种新型低延迟口语语言模型，通过引入多码本标记化和多标记预测策略，显著降低了响应时间。


<details>
  <summary>Details</summary>
Motivation: 当前端到端口语语言模型存在较大响应延迟，主要源于自回归生成和复杂流匹配模型，因此需要降低延迟以提高实时交互性能。

Method: VocalNet-M2集成了多码本标记器和多标记预测（MTP）策略，直接生成多码本语音标记，无需流匹配模型。

Result: 实验表明，VocalNet-M2将首段延迟从725ms降低到350ms，同时在主流口语语言模型中保持竞争力。

Conclusion: 该研究不仅显著减少了延迟，还通过单码本与多码本策略的对比，为开发高效、高性能SLM提供了重要见解。

Abstract: Current end-to-end spoken language models (SLMs) have made notable progress, yet they still encounter considerable response latency. This delay primarily arises from the autoregressive generation of speech tokens and the reliance on complex flow-matching models for speech synthesis. To overcome this, we introduce VocalNet-M2, a novel low-latency SLM that integrates a multi-codebook tokenizer and a multi-token prediction (MTP) strategy. Our model directly generates multi-codebook speech tokens, thus eliminating the need for a latency-inducing flow-matching model. Furthermore, our MTP strategy enhances generation efficiency and improves overall performance. Extensive experiments demonstrate that VocalNet-M2 achieves a substantial reduction in first chunk latency (from approximately 725ms to 350ms) while maintaining competitive performance across mainstream SLMs. This work also provides a comprehensive comparison of single-codebook and multi-codebook strategies, offering valuable insights for developing efficient and high-performance SLMs for real-time interactive applications.

</details>


### [35] [MTR-DuplexBench: Towards a Comprehensive Evaluation of Multi-Round Conversations for Full-Duplex Speech Language Models](https://arxiv.org/abs/2511.10262)
*He Zhang,Wenqian Cui,Haoning Xu,Xiaohui Li,Lei Zhu,Shaohua Ma,Irwin King*

Main category: cs.CL

TL;DR: 提出了一个新的基准测试MTR-DuplexBench，用于评估全双工语言模型在多轮对话中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试主要集中在单轮对话和会话特征，忽略了多轮对话的复杂性，以及指令遵循和安全性等关键能力。

Method: 引入了MTR-DuplexBench，将连续的全双工对话分割成离散的轮次，从而实现对对话质量、会话动态、指令遵循和安全性的逐轮全面评估。

Result: 实验结果表明，当前的全双工语言模型在多轮对话和不同评估维度上难以保持稳定的性能。

Conclusion: MTR-DuplexBench揭示了现有全双工语言模型的不足，并突显了新基准的必要性和有效性。

Abstract: Full-Duplex Speech Language Models (FD-SLMs) enable real-time, overlapping conversational interactions, offering a more dynamic user experience compared to traditional half-duplex models. However, existing benchmarks primarily focus on evaluating single-round interactions and conversational features, neglecting the complexities of multi-round communication and critical capabilities such as instruction following and safety. Evaluating FD-SLMs in multi-round settings poses significant challenges, including blurred turn boundaries in communication and context inconsistency during model inference. To address these gaps, we introduce MTR-DuplexBench, a novel benchmark that segments continuous full-duplex dialogues into discrete turns, enabling comprehensive, turn-by-turn evaluation of FD-SLMs across dialogue quality, conversational dynamics, instruction following, and safety. Experimental results reveal that current FD-SLMs face difficulties in maintaining consistent performance across multiple rounds and evaluation dimensions, highlighting the necessity and effectiveness of our proposed benchmark. The benchmark and code will be available in the future.

</details>


### [36] [Local Hybrid Retrieval-Augmented Document QA](https://arxiv.org/abs/2511.10297)
*Paolo Astrino*

Main category: cs.CL

TL;DR: 提出了一个在本地基础设施上运行的问答系统，结合了语义理解和关键词精确匹配，以在不牺牲数据隐私的前提下提供高准确性的答案。


<details>
  <summary>Details</summary>
Motivation: 组织在处理敏感文档时面临选择：采用云端AI系统可能会影响数据隐私，而本地处理虽然安全但准确性差。本文旨在解决这一两难问题。

Method: 通过结合语义理解和关键词精确匹配，系统完全在本地运行，无需互联网连接，平衡两种互补的检索策略，并使用消费级硬件加速。

Result: 系统在法律、科学和对话文档的复杂查询中表现出有竞争力的准确性，同时保证数据完全保留在本地。

Conclusion: 该工作证明，在企业AI部署中，隐私和性能不必互相排斥，组织可以在不牺牲安全性的前提下获得高性能的文档AI系统。

Abstract: Organizations handling sensitive documents face a critical dilemma: adopt cloud-based AI systems that offer powerful question-answering capabilities but compromise data privacy, or maintain local processing that ensures security but delivers poor accuracy. We present a question-answering system that resolves this trade-off by combining semantic understanding with keyword precision, operating entirely on local infrastructure without internet access. Our approach demonstrates that organizations can achieve competitive accuracy on complex queries across legal, scientific, and conversational documents while keeping all data on their machines. By balancing two complementary retrieval strategies and using consumer-grade hardware acceleration, the system delivers reliable answers with minimal errors, letting banks, hospitals, and law firms adopt conversational document AI without transmitting proprietary information to external providers. This work establishes that privacy and performance need not be mutually exclusive in enterprise AI deployment.

</details>


### [37] [Rectify Evaluation Preference: Improving LLMs' Critique on Math Reasoning via Perplexity-aware Reinforcement Learning](https://arxiv.org/abs/2511.10303)
*Changyuan Tian,Zhicong Lu,Shuang Qian,Nayu Liu,Peiguang Li,Li Jin,Leiyi Hu,Zhizhao Zeng,Sirui Wang,Ke Zeng,Zhi Guo*

Main category: cs.CL

TL;DR: 本文提出了一种新的算法，通过感知困惑度的强化学习来纠正大型语言模型在多步数学推理中的不平衡评估偏好，从而提高其批判能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多步数学推理中批判能力不足，现有方法忽视了深入分析导致这种能力差的根本原因，因此本文旨在探索并解决这个问题。

Method: 本文首先构建了一个 One-to-many Problem-Solution (OPS) 基准来量化LLMs在评估自己与他人生成的解答时的行为差异，并通过统计偏好分析揭示了LLMs倾向于将低困惑度解答判断为正确的现象。接着，提出了一种新的感知困惑度的强化学习算法，利用Group Relative Policy Optimization来纠正这种不平衡的评估偏好。

Result: 大量的实验结果表明，在自建的OPS和现有的批判性基准测试中，提出的方法有效提高了LLMs的批判能力。

Conclusion: 通过纠正LLMs的评估偏好，本文提出的算法显著提升了其在多步数学推理中的批判能力，为改进LLMs的推理能力提供了新的视角和方法。

Abstract: To improve Multi-step Mathematical Reasoning (MsMR) of Large Language Models (LLMs), it is crucial to obtain scalable supervision from the corpus by automatically critiquing mistakes in the reasoning process of MsMR and rendering a final verdict of the problem-solution. Most existing methods rely on crafting high-quality supervised fine-tuning demonstrations for critiquing capability enhancement and pay little attention to delving into the underlying reason for the poor critiquing performance of LLMs. In this paper, we orthogonally quantify and investigate the potential reason -- imbalanced evaluation preference, and conduct a statistical preference analysis. Motivated by the analysis of the reason, a novel perplexity-aware reinforcement learning algorithm is proposed to rectify the evaluation preference, elevating the critiquing capability. Specifically, to probe into LLMs' critiquing characteristics, a One-to-many Problem-Solution (OPS) benchmark is meticulously constructed to quantify the behavior difference of LLMs when evaluating the problem solutions generated by itself and others. Then, to investigate the behavior difference in depth, we conduct a statistical preference analysis oriented on perplexity and find an intriguing phenomenon -- ``LLMs incline to judge solutions with lower perplexity as correct'', which is dubbed as \textit{imbalanced evaluation preference}. To rectify this preference, we regard perplexity as the baton in the algorithm of Group Relative Policy Optimization, supporting the LLMs to explore trajectories that judge lower perplexity as wrong and higher perplexity as correct. Extensive experimental results on our built OPS and existing available critic benchmarks demonstrate the validity of our method.

</details>


### [38] [BhashaKritika: Building Synthetic Pretraining Data at Scale for Indic Languages](https://arxiv.org/abs/2511.10338)
*Guduru Manoj,Neel Prabhanjan Rachamalla,Ashish Kulkarni,Gautam Rajeev,Jay Piplodiya,Arul Menezes,Shaharukh Khan,Souvik Rana,Manya Sah,Chandra Khatri,Shubham Agarwal*

Main category: cs.CL

TL;DR: 本文系统研究了为印度语言生成和评估合成多语言预训练数据的方法，构建了包含540B tokens的大规模合成数据集BhashaKritika，并提出了模块化质量评估流程。


<details>
  <summary>Details</summary>
Motivation: 在低资源语言环境中，大型语言模型（LLMs）的效益分布不均，合成数据成为生成高质量预训练数据的替代方案。

Method: 研究使用了5种不同技术生成10种印度语言的合成数据，探讨了文档、角色和主题接地对数据质量的影响，比较了英语内容翻译与本地生成的效果，并引入了模块化质量评估流程，包括脚本和语言检测、元数据一致性检查、n-gram重复分析和基于困惑度的过滤。

Result: 通过模型实验揭示了不同生成策略的权衡，并突出了构建有效多语言语料库的最佳实践。

Conclusion: 该研究为印度语言的多语言预训练数据生成和评估提供了系统的方法和最佳实践，强调了合成数据在低资源语言环境中的重要性。

Abstract: In the context of pretraining of Large Language Models (LLMs), synthetic data has emerged as an alternative for generating high-quality pretraining data at scale. This is particularly beneficial in low-resource language settings where the benefits of recent LLMs have been unevenly distributed across languages. In this work, we present a systematic study on the generation and evaluation of synthetic multilingual pretraining data for Indic languages, where we construct a large-scale synthetic dataset BhashaKritika, comprising 540B tokens using 5 different techniques for 10 languages. We explore the impact of grounding generation in documents, personas, and topics. We analyze how language choice, both in the prompt instructions and document grounding, affects data quality, and we compare translations of English content with native generation in Indic languages. To support scalable and language-sensitive evaluation, we introduce a modular quality evaluation pipeline that integrates script and language detection, metadata consistency checks, n-gram repetition analysis, and perplexity-based filtering using KenLM models. Our framework enables robust quality control across diverse scripts and linguistic contexts. Empirical results through model runs reveal key trade-offs in generation strategies and highlight best practices for constructing effective multilingual corpora.

</details>


### [39] [Knowledge Graphs Generation from Cultural Heritage Texts: Combining LLMs and Ontological Engineering for Scholarly Debates](https://arxiv.org/abs/2511.10354)
*Andrea Schimmenti,Valentina Pasqual,Fabio Vitali,Marieke van Erp*

Main category: cs.CL

TL;DR: 提出ATR4CH方法，用大模型从文化遗产文本提取知识构建图谱


<details>
  <summary>Details</summary>
Motivation: 文化遗产文本知识丰富但难以系统化查询，需将非结构化文本转为结构化知识图谱

Method: 五步法：基础分析、标注方案开发、流水线架构、集成优化、全面评估，结合标注模型、本体框架和LLM提取

Result: 在维基百科争议物品文章上验证，元数据提取F1 0.96-0.99，实体识别0.7-0.8，假设提取0.65-0.75，证据提取0.95-0.97，话语表示G-EVAL 0.62，小模型表现好

Conclusion: ATR4CH是首个协调LLM提取与文化遗产本体的方法，为文化遗产机构提供可复用框架，支持文本知识转可查询图谱，但需人工后期监督，目前限于维基百科数据

Abstract: Cultural Heritage texts contain rich knowledge that is difficult to query systematically due to the challenges of converting unstructured discourse into structured Knowledge Graphs (KGs). This paper introduces ATR4CH (Adaptive Text-to-RDF for Cultural Heritage), a systematic five-step methodology for Large Language Model-based Knowledge Extraction from Cultural Heritage documents. We validate the methodology through a case study on authenticity assessment debates. Methodology - ATR4CH combines annotation models, ontological frameworks, and LLM-based extraction through iterative development: foundational analysis, annotation schema development, pipeline architecture, integration refinement, and comprehensive evaluation. We demonstrate the approach using Wikipedia articles about disputed items (documents, artifacts...), implementing a sequential pipeline with three LLMs (Claude Sonnet 3.7, Llama 3.3 70B, GPT-4o-mini). Findings - The methodology successfully extracts complex Cultural Heritage knowledge: 0.96-0.99 F1 for metadata extraction, 0.7-0.8 F1 for entity recognition, 0.65-0.75 F1 for hypothesis extraction, 0.95-0.97 for evidence extraction, and 0.62 G-EVAL for discourse representation. Smaller models performed competitively, enabling cost-effective deployment. Originality - This is the first systematic methodology for coordinating LLM-based extraction with Cultural Heritage ontologies. ATR4CH provides a replicable framework adaptable across CH domains and institutional resources. Research Limitations - The produced KG is limited to Wikipedia articles. While the results are encouraging, human oversight is necessary during post-processing. Practical Implications - ATR4CH enables Cultural Heritage institutions to systematically convert textual knowledge into queryable KGs, supporting automated metadata enrichment and knowledge discovery.

</details>


### [40] [TruthfulRAG: Resolving Factual-level Conflicts in Retrieval-Augmented Generation with Knowledge Graphs](https://arxiv.org/abs/2511.10375)
*Shuyi Liu,Yuming Shang,Xi Zhang*

Main category: cs.CL

TL;DR: 提出TruthfulRAG框架，利用知识图谱解决RAG系统中的事实级知识冲突。


<details>
  <summary>Details</summary>
Motivation: 随着外部知识库不断扩大和模型参数知识变得过时，RAG系统面临的关键挑战是解决检索到的外部信息与LLMs内部知识之间的冲突，这显著影响了生成内容的准确性和可靠性。

Method: TruthfulRAG通过系统从检索内容中提取三元组构建知识图谱，利用基于查询的图谱检索识别相关知识，并采用基于熵的过滤机制精确定位冲突元素，减轻事实不一致性。

Result: 广泛的实验表明，TruthfulRAG优于现有方法，有效缓解了知识冲突，提高了RAG系统的稳健性和可信度。

Conclusion: TruthfulRAG是首个利用知识图谱解决RAG系统事实级知识冲突的框架，显著提升了生成内容的可信度和准确性。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a powerful framework for enhancing the capabilities of Large Language Models (LLMs) by integrating retrieval-based methods with generative models. As external knowledge repositories continue to expand and the parametric knowledge within models becomes outdated, a critical challenge for RAG systems is resolving conflicts between retrieved external information and LLMs' internal knowledge, which can significantly compromise the accuracy and reliability of generated content. However, existing approaches to conflict resolution typically operate at the token or semantic level, often leading to fragmented and partial understanding of factual discrepancies between LLMs' knowledge and context, particularly in knowledge-intensive tasks. To address this limitation, we propose TruthfulRAG, the first framework that leverages Knowledge Graphs (KGs) to resolve factual-level knowledge conflicts in RAG systems. Specifically, TruthfulRAG constructs KGs by systematically extracting triples from retrieved content, utilizes query-based graph retrieval to identify relevant knowledge, and employs entropy-based filtering mechanisms to precisely locate conflicting elements and mitigate factual inconsistencies, thereby enabling LLMs to generate faithful and accurate responses. Extensive experiments reveal that TruthfulRAG outperforms existing methods, effectively alleviating knowledge conflicts and improving the robustness and trustworthiness of RAG systems.

</details>


### [41] [Position: On the Methodological Pitfalls of Evaluating Base LLMs for Reasoning](https://arxiv.org/abs/2511.10381)
*Jason Chan,Zhixue Zhao,Robert Gaizauskas*

Main category: cs.CL

TL;DR: 本文探讨了评估基础大型语言模型（LLMs）推理能力时存在的方法论问题。


<details>
  <summary>Details</summary>
Motivation: 现有研究评估基础LLMs的推理能力，以揭示其局限性、类人偏见和潜在过程，但这些研究忽视了基础LLMs预训练目标和推理评估标准之间不匹配的问题。

Method: 通过分析基础LLMs生成逻辑有效或无效结论的过程，指出这些结论只是符合语言统计模式的偶然副产品。

Result: 基础LLMs的输出不能被视为它们真正试图得出的正确答案或结论，且关于基础LLMs推理的结论不能推广到经过指令优化训练后的LLMs。

Conclusion: 需要对依赖于这些假设的现有研究进行重新审视，并在未来研究中考虑这些方法论陷阱。

Abstract: Existing work investigates the reasoning capabilities of large language models (LLMs) to uncover their limitations, human-like biases and underlying processes. Such studies include evaluations of base LLMs (pre-trained on unlabeled corpora only) for this purpose. Our position paper argues that evaluating base LLMs' reasoning capabilities raises inherent methodological concerns that are overlooked in such existing studies. We highlight the fundamental mismatch between base LLMs' pretraining objective and normative qualities, such as correctness, by which reasoning is assessed. In particular, we show how base LLMs generate logically valid or invalid conclusions as coincidental byproducts of conforming to purely linguistic patterns of statistical plausibility. This fundamental mismatch challenges the assumptions that (a) base LLMs' outputs can be assessed as their bona fide attempts at correct answers or conclusions; and (b) conclusions about base LLMs' reasoning can generalize to post-trained LLMs optimized for successful instruction-following. We call for a critical re-examination of existing work that relies implicitly on these assumptions, and for future work to account for these methodological pitfalls.

</details>


### [42] [DELICATE: Diachronic Entity LInking using Classes And Temporal Evidence](https://arxiv.org/abs/2511.10404)
*Cristian Santini,Sebastian Barzaghi,Paolo Sernani,Emanuele Frontoni,Mehwish Alam*

Main category: cs.CL

TL;DR: 本文提出两种针对历史意大利语文本中实体链接（EL）的创新方法：DELICATE（结合BERT编码器与Wikidata上下文信息的神经符号方法）和ENEIDE（半自动构建的多领域EL语料库），以解决复杂文档类型、领域特定数据集和模型的缺乏以及长尾实体等问题。


<details>
  <summary>Details</summary>
Motivation: 尽管自然语言处理领域取得了显著进展，但由于复杂文档类型、缺乏领域特定数据集和模型以及长尾实体的存在，人文学科中的实体链接仍然具有挑战性。

Method: 本文提出了DELICATE，一种新颖的神经符号方法，将基于BERT的编码器与Wikidata的上下文信息相结合，通过时间合理性和实体类型一致性选择合适的知识库实体；以及ENEIDE，一个半自动构建的历史意大利语多领域EL语料库。

Result: 结果表明，DELICATE在历史意大利语上的表现优于其他EL模型，即使与拥有数十亿参数的大型架构相比也是如此。此外，进一步分析显示DELICATE的置信度分数和特征敏感性提供了比纯神经方法更具解释性和可解释性的结果。

Conclusion: DELICATE和ENEIDE的提出有效解决了人文学科领域中的实体链接挑战，尤其是在历史意大利语文本中，不仅提高了性能，还增强了模型的可解释性。

Abstract: In spite of the remarkable advancements in the field of Natural Language Processing, the task of Entity Linking (EL) remains challenging in the field of humanities due to complex document typologies, lack of domain-specific datasets and models, and long-tail entities, i.e., entities under-represented in Knowledge Bases (KBs). The goal of this paper is to address these issues with two main contributions. The first contribution is DELICATE, a novel neuro-symbolic method for EL on historical Italian which combines a BERT-based encoder with contextual information from Wikidata to select appropriate KB entities using temporal plausibility and entity type consistency. The second contribution is ENEIDE, a multi-domain EL corpus in historical Italian semi-automatically extracted from two annotated editions spanning from the 19th to the 20th century and including literary and political texts. Results show how DELICATE outperforms other EL models in historical Italian even if compared with larger architectures with billions of parameters. Moreover, further analyses reveal how DELICATE confidence scores and features sensitivity provide results which are more explainable and interpretable than purely neural methods.

</details>


### [43] [Analogical Structure, Minimal Contextual Cues and Contrastive Distractors: Input Design for Sample-Efficient Linguistic Rule Induction](https://arxiv.org/abs/2511.10441)
*Chunyang Jiang,Paola Merlo*

Main category: cs.CL

TL;DR: 通过类比范式组织，轻量模型可以用极少数据达到大型模型的性能。


<details>
  <summary>Details</summary>
Motivation: 探讨是否可以通过类比范式组织，使轻量模型在极少数据下达到大型模型的性能。

Method: 实现三种认知启发原则：类比结构、对比学习和最小上下文线索，使用结构化完成任务的轻量模型（BERT+CNN，0.5M参数）。

Result: 仅用一百个英语使动/非使动转换的结构化样本训练的轻量模型F1=0.95，优于零样本GPT-o3（F1=0.87）。

Conclusion: 类比范式组织使轻量模型能够以比常规方法少得多的数据学习语言规则，并达到竞争性能。

Abstract: Large language models achieve strong performance through training on vast datasets. Can analogical paradigm organization enable lightweight models to match this performance with minimal data? We develop a computational approach implementing three cognitive-inspired principles: analogical structure, contrastive learning, and minimal contextual cues. We test this approach with structured completion tasks where models identify correct sentence completions from analogical patterns with contrastive alternatives. Training lightweight models (BERT+CNN, $0.5M$ parameters) on only one hundred structured examples of English causative/inchoative alternations achieves $F1=0.95$, outperforming zero-shot \texttt{GPT-o3} ($F1=0.87$). Ablation studies confirm that analogical organization and contrastive structure improve performance, consistently surpassing randomly shuffled baselines across architectures. Cross-phenomenon validation using unspecified object alternations replicates these efficiency gains, confirming approach robustness. Our results show that analogical paradigm organization enables competitive linguistic rule learning with orders of magnitude less data than conventional approaches require.

</details>


### [44] [Reasoning About Intent for Ambiguous Requests](https://arxiv.org/abs/2511.10453)
*Irina Saparina,Mirella Lapata*

Main category: cs.CL

TL;DR: 为解决大型语言模型对模糊请求的单一解释问题，本文提出生成多种解释-答案对的方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型对模糊请求的单一解释可能导致用户不满和安全风险，需要更透明和高效的方法。

Method: 使用强化学习和自定义奖励函数训练模型，生成多种解释-答案对，并以结构化响应呈现。

Result: 在对话问答和语义解析任务中，该方法比基线方法具有更高的有效答案覆盖率，人工评估显示预测解释与答案高度一致。

Conclusion: 该方法通过明确的解释提高透明度，仅需一次生成步骤实现高效，并因其结构化输出格式支持下游应用。

Abstract: Large language models often respond to ambiguous requests by implicitly committing to one interpretation. Intent misunderstandings can frustrate users and create safety risks. To address this, we propose generating multiple interpretation-answer pairs in a single structured response to ambiguous requests. Our models are trained with reinforcement learning and customized reward functions using multiple valid answers as supervision. Experiments on conversational question answering and semantic parsing demonstrate that our method achieves higher coverage of valid answers than baseline approaches. Human evaluation confirms that predicted interpretations are highly aligned with their answers. Our approach promotes transparency with explicit interpretations, achieves efficiency by requiring only one generation step, and supports downstream applications through its structured output format.

</details>


### [45] [Exploring State Tracking Capabilities of Large Language Models](https://arxiv.org/abs/2511.10457)
*Kiamehr Rezaee,Jose Camacho-Collados,Mohammad Taher Pilehvar*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型在状态跟踪任务中的表现，提出了专门基准测试并发现GPT-4和Llama3等新一代模型结合思维链机制能有效跟踪状态，而前代模型在步骤增多时表现下降。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂任务中表现出色，但状态跟踪作为需要持续追踪多个实体状态的问题尚未被深入研究，因此作者希望独立评估模型在纯状态跟踪任务上的能力。

Method: 提出包含三个明确定义状态跟踪任务的基准测试，在不同场景下分析模型表现，特别比较了不同代际LLM（GPT-4/Llama3 vs 前代模型）的表现差异。

Result: 最新一代LLM（GPT-4/Llama3）能有效跟踪状态，尤其是结合思维链（CoT）机制时；前代模型虽能理解任务并在初期解决，但步骤增多后表现显著下降。

Conclusion: 模型状态跟踪能力存在代际差异，最新LLM具备可靠的状态跟踪潜力，但前代模型的长程推理存在局限性，提示未来改进方向需关注持续推理能力。

Abstract: Large Language Models (LLMs) have demonstrated impressive capabilities in solving complex tasks, including those requiring a certain level of reasoning. In this paper, we focus on state tracking, a problem where models need to keep track of the state governing a number of entities. To isolate the state tracking component from other factors, we propose a benchmark based on three well-defined state tracking tasks and analyse the performance of LLMs in different scenarios. The results indicate that the recent generation of LLMs (specifically, GPT-4 and Llama3) are capable of tracking state, especially when integrated with mechanisms such as Chain of Thought. However, models from the former generation, while understanding the task and being able to solve it at the initial stages, often fail at this task after a certain number of steps.

</details>


### [46] [LocalBench: Benchmarking LLMs on County-Level Local Knowledge and Reasoning](https://arxiv.org/abs/2511.10459)
*Zihan Gao,Yifei Xu,Jacob Thebault-Spieker*

Main category: cs.CL

TL;DR: 本文介绍了LocalBench，这是首个系统性评估大型语言模型在美国县级本地知识表现的基准，揭示了当前模型在本地知识任务上的不足。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在宏观地理任务上已被广泛评估，但在处理超本地知识方面的能力仍不明确。这对需要AI系统理解社区特定动态、文化叙述和地方治理的实际应用至关重要。

Method: 提出LocalBench基准，基于Localness概念框架，包括14,782个经过验证的问题-答案对，覆盖49个州的526个县，整合了人口普查数据、本地subreddit讨论和区域新闻等多种来源，评估了13种最先进的LLMs。

Result: 即使是最优模型在叙述性问题上的准确率也只有56.8%，在数值推理上的表现低于15.5%。模型大小和网页增强不能保证更好的性能，例如，搜索使Gemini的准确率提高了+13.6%，但使GPT系列性能降低了-11.4%。

Conclusion: 这些结果强调了对能够支持公平、具有地方意识的AI系统的语言模型的迫切需求，这些模型应能够处理地方社区在地理和文化背景下的多样化、细粒度的现实。

Abstract: Large language models (LLMs) have been widely evaluated on macro-scale geographic tasks, such as global factual recall, event summarization, and regional reasoning. Yet, their ability to handle hyper-local knowledge remains poorly understood. This gap is increasingly consequential as real-world applications, from civic platforms to community journalism, demand AI systems that can reason about neighborhood-specific dynamics, cultural narratives, and local governance. Existing benchmarks fall short in capturing this complexity, often relying on coarse-grained data or isolated references. We present LocalBench, the first benchmark designed to systematically evaluate LLMs on county-level local knowledge across the United States. Grounded in the Localness Conceptual Framework, LocalBench includes 14,782 validated question-answer pairs across 526 U.S. counties in 49 states, integrating diverse sources such as Census statistics, local subreddit discourse, and regional news. It spans physical, cognitive, and relational dimensions of locality. Using LocalBench, we evaluate 13 state-of-the-art LLMs under both closed-book and web-augmented settings. Our findings reveal critical limitations: even the best-performing models reach only 56.8% accuracy on narrative-style questions and perform below 15.5% on numerical reasoning. Moreover, larger model size and web augmentation do not guarantee better performance, for example, search improves Gemini's accuracy by +13.6%, but reduces GPT-series performance by -11.4%. These results underscore the urgent need for language models that can support equitable, place-aware AI systems: capable of engaging with the diverse, fine-grained realities of local communities across geographic and cultural contexts.

</details>


### [47] [Beyond Elicitation: Provision-based Prompt Optimization for Knowledge-Intensive Tasks](https://arxiv.org/abs/2511.10465)
*Yunzhe Xu,Zhuosheng Zhang,Zhe Liu*

Main category: cs.CL

TL;DR: 提出了一种基于知识提供的提示优化框架KPPO，通过系统性知识整合而非传统的激活模型能力的方法，解决了现有提示优化方法在知识密集型任务中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有提示优化方法主要关注如何激活模型已有能力，但在知识密集型任务中存在局限，因为它们不能提供特定领域所需的实际知识、术语精确性和推理模式。

Method: KPPO框架包含三个创新：1) 知识差距识别和针对性补救的知识填补机制；2) 考虑性能提升和分布稳定性的批量候选评估方法；3) 平衡性能和标记效率的自适应知识剪枝策略。

Result: 在15个知识密集型基准测试中，KPPO相比最强的基线方法平均性能提升约6%，同时标记使用量减少29%，达到相当或更低的标记消耗。

Conclusion: KPPO通过系统性知识整合的方式，显著优于传统的基于激活的提示优化方法，为知识密集型任务提供了更有效的解决方案。

Abstract: While prompt optimization has emerged as a critical technique for enhancing language model performance, existing approaches primarily focus on elicitation-based strategies that search for optimal prompts to activate models' capabilities. These methods exhibit fundamental limitations when addressing knowledge-intensive tasks, as they operate within fixed parametric boundaries rather than providing the factual knowledge, terminology precision, and reasoning patterns required in specialized domains. To address these limitations, we propose Knowledge-Provision-based Prompt Optimization (KPPO), a framework that reformulates prompt optimization as systematic knowledge integration rather than potential elicitation. KPPO introduces three key innovations: 1) a knowledge gap filling mechanism for knowledge gap identification and targeted remediation; 2) a batch-wise candidate evaluation approach that considers both performance improvement and distributional stability; 3) an adaptive knowledge pruning strategy that balances performance and token efficiency, reducing up to 29% token usage. Extensive evaluation on 15 knowledge-intensive benchmarks from various domains demonstrates KPPO's superiority over elicitation-based methods, with an average performance improvement of ~6% over the strongest baseline while achieving comparable or lower token consumption. Code at: https://github.com/xyz9911/KPPO.

</details>


### [48] [Rubric-Based Benchmarking and Reinforcement Learning for Advancing LLM Instruction Following](https://arxiv.org/abs/2511.10507)
*Yun He,Wenzhe Li,Hejia Zhang,Songlin Li,Karishma Mandyam,Sopan Khosla,Yuanhao Xiong,Nanshu Wang,Selina Peng,Beibin Li,Shengjie Bi,Shishir G. Patil,Qi Qi,Shengyu Feng,Julian Katz-Samuels,Richard Yuanzhe Pang,Sujan Gonugondla,Hunter Lang,Yue Yu,Yundi Qian,Maryam Fazel-Zarandi,Licheng Yu,Amine Benhalloum,Hany Awadalla,Manaal Faruqui*

Main category: cs.CL

TL;DR: 本文介绍了AdvancedIF基准测试和RIFL训练方法，以提高大型语言模型在复杂、多轮和系统级指令跟随任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在复杂指令跟随任务中仍面临挑战，且缺乏高质量的人类标注基准测试和可靠的奖励信号。

Method: 提出了AdvancedIF，一个包含1600多个提示和专家策划评分标准的基准测试，并引入了RIFL，一个基于评分标准的训练流程，包括评分标准生成、评分验证和奖励塑造。

Result: RIFL显著提升了模型在AdvancedIF上的表现，绝对增益达6.7%，并在公共基准测试中取得了良好结果。

Conclusion: 本工作确立了评分标准作为训练和评估大型语言模型复杂指令跟随能力的重要工具，为更可靠和能干的AI系统铺平了道路。

Abstract: Recent progress in large language models (LLMs) has led to impressive performance on a range of tasks, yet advanced instruction following (IF)-especially for complex, multi-turn, and system-prompted instructions-remains a significant challenge. Rigorous evaluation and effective training for such capabilities are hindered by the lack of high-quality, human-annotated benchmarks and reliable, interpretable reward signals. In this work, we introduce AdvancedIF (we will release this benchmark soon), a comprehensive benchmark featuring over 1,600 prompts and expert-curated rubrics that assess LLMs ability to follow complex, multi-turn, and system-level instructions. We further propose RIFL (Rubric-based Instruction-Following Learning), a novel post-training pipeline that leverages rubric generation, a finetuned rubric verifier, and reward shaping to enable effective reinforcement learning for instruction following. Extensive experiments demonstrate that RIFL substantially improves the instruction-following abilities of LLMs, achieving a 6.7% absolute gain on AdvancedIF and strong results on public benchmarks. Our ablation studies confirm the effectiveness of each component in RIFL. This work establishes rubrics as a powerful tool for both training and evaluating advanced IF in LLMs, paving the way for more capable and reliable AI systems.

</details>


### [49] [LOCA-R: Near-Perfect Performance on the Chinese Physics Olympiad 2025](https://arxiv.org/abs/2511.10515)
*Dong-Shan Jian,Xiang Li,Chen-Xu Yan,Hui-Wen Zheng,Zhi-Zhang Bian,You-Le Fang,Sheng-Qi Zhang,Bing-Rui Gong,Ren-Xi He,Jing-Tian Zhang,Ce Meng,Yan-Qing Ma*

Main category: cs.CL

TL;DR: LOCA-R，LOCA框架的改进版本，在中国物理奥林匹克（CPhO）2025理论考试中取得了接近满分的成绩，超越了人类参赛者和其他基线方法。


<details>
  <summary>Details</summary>
Motivation: 奥林匹克物理问题解决对人和人工智能（AI）都是一个重大挑战，需要精确计算、抽象推理和对物理原理的深入理解。CPhO以其复杂性和深度著称，是测试这些高级能力的理想平台。

Method: 引入了LOCA-R，这是LOCA框架的改进版本，专为复杂推理设计，并应用于CPhO 2025理论考试。

Result: LOCA-R在CPhO 2025理论考试中取得了313分（满分320分）的接近满分成绩，远超最高分的人类参赛者，并且显著优于所有基线方法。

Conclusion: LOCA-R在奥林匹克物理问题解决中表现出卓越的能力，展示了其在复杂推理任务中的强大潜力。

Abstract: Olympiad-level physics problem-solving presents a significant challenge for both humans and artificial intelligence (AI), as it requires a sophisticated integration of precise calculation, abstract reasoning, and a fundamental grasp of physical principles. The Chinese Physics Olympiad (CPhO), renowned for its complexity and depth, serves as an ideal and rigorous testbed for these advanced capabilities. In this paper, we introduce LOCA-R (LOgical Chain Augmentation for Reasoning), an improved version of the LOCA framework adapted for complex reasoning, and apply it to the CPhO 2025 theory examination. LOCA-R achieves a near-perfect score of 313 out of 320 points, solidly surpassing the highest-scoring human competitor and significantly outperforming all baseline methods.

</details>


### [50] [Say It Differently: Linguistic Styles as Jailbreak Vectors](https://arxiv.org/abs/2511.10519)
*Srikant Panda,Avinash Rai*

Main category: cs.CL

TL;DR: 本文研究了语言风格变化对大型语言模型(LLM)安全性的影响，发现恐惧、好奇等语言风格能显著增加越狱攻击的成功率。


<details>
  <summary>Details</summary>
Motivation: 现有LLM安全性评估多关注语义等价的越狱提示，而忽略了语言风格变化作为攻击面的潜力，这是当前安全流程中未被充分研究的系统性漏洞。

Method: 构建了包含11种不同语言风格(使用手工模板和LLM重写)的风格增强越狱基准，从3个标准数据集转换而来，同时保留语义意图；并引入使用辅助LLM的风格中和预处理步骤。

Result: 对16个开源和闭源指令调优模型评估发现，风格重构可使越狱成功率提升高达57个百分点；恐惧、好奇和富有同情心的风格最有效，情境化重写优于模板变体。

Conclusion: 语言风格变化是LLM中一个系统性的、抗扩展的漏洞，提出的风格中和预处理方法能有效降低越狱成功率，这一发现为改进当前安全流程提供了新方向。

Abstract: Large Language Models (LLMs) are commonly evaluated for robustness against paraphrased or semantically equivalent jailbreak prompts, yet little attention has been paid to linguistic variation as an attack surface. In this work, we systematically study how linguistic styles such as fear or curiosity can reframe harmful intent and elicit unsafe responses from aligned models. We construct style-augmented jailbreak benchmark by transforming prompts from 3 standard datasets into 11 distinct linguistic styles using handcrafted templates and LLM-based rewrites, while preserving semantic intent. Evaluating 16 open- and close-source instruction-tuned models, we find that stylistic reframing increases jailbreak success rates by up to +57 percentage points. Styles such as fearful, curious and compassionate are most effective and contextualized rewrites outperform templated variants.
  To mitigate this, we introduce a style neutralization preprocessing step using a secondary LLM to strip manipulative stylistic cues from user inputs, significantly reducing jailbreak success rates. Our findings reveal a systemic and scaling-resistant vulnerability overlooked in current safety pipelines.

</details>


### [51] [Convomem Benchmark: Why Your First 150 Conversations Don't Need RAG](https://arxiv.org/abs/2511.10523)
*Egor Pakhomov,Erik Nijkamp,Caiming Xiong*

Main category: cs.CL

TL;DR: 本文介绍了一个全面的对话记忆评估基准，包含75,336个问答对，涵盖用户事实、助手回忆、回避、偏好、时间变化和隐含联系等多个类别。


<details>
  <summary>Details</summary>
Motivation: 现有基准在统计功效、数据生成一致性和评估灵活性方面存在局限性，该研究旨在解决这些挑战，并探索对话记忆与检索增强生成（RAG）之间的关系。

Method: 研究通过分析简单全上下文方法和复杂RAG基记忆系统（如Mem0）在不同对话历史长度下的表现，揭示了实用转换点。

Result: 简单全上下文方法在多消息证据案例中达到70-82%的准确率，而RAG基记忆系统在少于150次交互的对话历史中仅达到30-45%的准确率。

Conclusion: 对话记忆的小语料库优势值得专门研究，应针对对话历史开发专门的解决方案，而不是简单地将通用RAG解决方案应用于对话历史。

Abstract: We introduce a comprehensive benchmark for conversational memory evaluation containing 75,336 question-answer pairs across diverse categories including user facts, assistant recall, abstention, preferences, temporal changes, and implicit connections. While existing benchmarks have advanced the field, our work addresses fundamental challenges in statistical power, data generation consistency, and evaluation flexibility that limit current memory evaluation frameworks. We examine the relationship between conversational memory and retrieval-augmented generation (RAG). While these systems share fundamental architectural patterns--temporal reasoning, implicit extraction, knowledge updates, and graph representations--memory systems have a unique characteristic: they start from zero and grow progressively with each conversation. This characteristic enables naive approaches that would be impractical for traditional RAG. Consistent with recent findings on long context effectiveness, we observe that simple full-context approaches achieve 70-82% accuracy even on our most challenging multi-message evidence cases, while sophisticated RAG-based memory systems like Mem0 achieve only 30-45% when operating on conversation histories under 150 interactions. Our analysis reveals practical transition points: long context excels for the first 30 conversations, remains viable with manageable trade-offs up to 150 conversations, and typically requires hybrid or RAG approaches beyond that point as costs and latencies become prohibitive. These patterns indicate that the small-corpus advantage of conversational memory--where exhaustive search and complete reranking are feasible--deserves dedicated research attention rather than simply applying general RAG solutions to conversation histories.

</details>


### [52] [Computing the Formal and Institutional Boundaries of Contemporary Genre and Literary Fiction](https://arxiv.org/abs/2511.10546)
*Natasha Johnson*

Main category: cs.CL

TL;DR: 该研究使用计算方法探讨体裁（genre）是形式上的还是制度上的分类。


<details>
  <summary>Details</summary>
Motivation: 尽管体裁的概念已经被讨论了数千年，但体裁小说的出现为这一讨论增加了新层次。传统观点强调体裁的形式，而当代学术则结合了形式和制度特征对体裁进行分类。

Method: 从Andrew Piper的CONLIT数据集中收集文学和体裁小说，包括浪漫、悬疑和科幻小说。使用Welch's ANOVA分析不同性别作者在各体裁和文学小说中的叙事特征分布，并使用逻辑回归模型分析每个特征对文学分类的影响及作者性别的调节作用。最后，分析体裁类别的风格和语义向量表示。

Result: 研究发现每种文学类别都有显著的形式标记，女性作者的身份缩小并模糊了获得文学地位的界限。

Conclusion: 体裁分类既有形式上的依据，也受到作者性别等制度因素的影响。

Abstract: Though the concept of genre has been a subject of discussion for millennia, the relatively recent emergence of genre fiction has added a new layer to this ongoing conversation. While more traditional perspectives on genre have emphasized form, contemporary scholarship has invoked both formal and institutional characteristics in its taxonomy of genre, genre fiction, and literary fiction. This project uses computational methods to explore the soundness of genre as a formal designation as opposed to an institutional one. Pulling from Andrew Piper's CONLIT dataset of Contemporary Literature, we assemble a corpus of literary and genre fiction, with the latter category containing romance, mystery, and science fiction novels. We use Welch's ANOVA to compare the distribution of narrative features according to author gender within each genre and within genre versus literary fiction. Then, we use logistic regression to model the effect that each feature has on literary classification and to measure how author gender moderates these effects. Finally, we analyze stylistic and semantic vector representations of our genre categories to understand the importance of form and content in literary classification. This project finds statistically significant formal markers of each literary category and illustrates how female authorship narrows and blurs the target for achieving literary status.

</details>


### [53] [URaG: Unified Retrieval and Generation in Multimodal LLMs for Efficient Long Document Understanding](https://arxiv.org/abs/2511.10552)
*Yongxin Shi,Jiapeng Wang,Zeyu Shan,Dezhi Peng,Zening Lin,Lianwen Jin*

Main category: cs.CL

TL;DR: 提出一种新型框架URaG，通过利用多模态大语言模型内在的粗到细推理模式，将检索和生成统一在单一模型中，实现高效长文档理解。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在长文档理解中面临信息干扰和二次计算成本问题，现有方法存在细节丢失或系统复杂等缺陷。

Method: 设计轻量级跨模态检索模块，将早期Transformer层转换为高效证据选择器，保留相关页面并丢弃无关内容，使深层专注于相关信息。

Result: URaG在降低44-56%计算开销的同时达到最优性能，验证了模型内建证据定位能力的有效性。

Conclusion: 通过显式利用MLLMs固有的证据定位能力，URaG成功实现了检索与生成的统一，为长文档理解提供了简单有效的解决方案。

Abstract: Recent multimodal large language models (MLLMs) still struggle with long document understanding due to two fundamental challenges: information interference from abundant irrelevant content, and the quadratic computational cost of Transformer-based architectures. Existing approaches primarily fall into two categories: token compression, which sacrifices fine-grained details; and introducing external retrievers, which increase system complexity and prevent end-to-end optimization. To address these issues, we conduct an in-depth analysis and observe that MLLMs exhibit a human-like coarse-to-fine reasoning pattern: early Transformer layers attend broadly across the document, while deeper layers focus on relevant evidence pages. Motivated by this insight, we posit that the inherent evidence localization capabilities of MLLMs can be explicitly leveraged to perform retrieval during the reasoning process, facilitating efficient long document understanding. To this end, we propose URaG, a simple-yet-effective framework that Unifies Retrieval and Generation within a single MLLM. URaG introduces a lightweight cross-modal retrieval module that converts the early Transformer layers into an efficient evidence selector, identifying and preserving the most relevant pages while discarding irrelevant content. This design enables the deeper layers to concentrate computational resources on pertinent information, improving both accuracy and efficiency. Extensive experiments demonstrate that URaG achieves state-of-the-art performance while reducing computational overhead by 44-56%. The code is available at https://github.com/shi-yx/URaG.

</details>


### [54] [Mined Prompting and Metadata-Guided Generation for Wound Care Visual Question Answering](https://arxiv.org/abs/2511.10591)
*Bavana Durgapraveen,Sornaraj Sivasankaran,Abhinand Balachandran,Sriram Rajkumar*

Main category: cs.CL

TL;DR: 本文提出了两种互补的AI方法，以提高异步远程护理中伤口护理查询的响应效率。


<details>
  <summary>Details</summary>
Motivation: 由于异步远程护理的迅速扩展，医生工作负担加剧，需要AI系统辅助处理病人查询。

Method: 提出两种方法：1) 基于挖掘提示策略，嵌入训练数据并检索最相似的示例作为few-shot演示；2) 基于元数据消融研究，识别并预测四个能提高响应质量的元数据属性，并在生成过程中动态调整输出。

Result: 实验结果表明，挖掘提示策略提高了响应的相关性，而元数据引导生成进一步提升了临床精确性。

Conclusion: 这些方法展示了开发AI驱动工具的潜力，可提供可靠且高效的伤口护理支持。

Abstract: The rapid expansion of asynchronous remote care has intensified provider workload, creating demand for AI systems that can assist clinicians in managing patient queries more efficiently. The MEDIQA-WV 2025 shared task addresses this challenge by focusing on generating free-text responses to wound care queries paired with images. In this work, we present two complementary approaches developed for the English track. The first leverages a mined prompting strategy, where training data is embedded and the top-k most similar examples are retrieved to serve as few-shot demonstrations during generation. The second approach builds on a metadata ablation study, which identified four metadata attributes that consistently enhance response quality. We train classifiers to predict these attributes for test cases and incorporate them into the generation pipeline, dynamically adjusting outputs based on prediction confidence. Experimental results demonstrate that mined prompting improves response relevance, while metadata-guided generation further refines clinical precision. Together, these methods highlight promising directions for developing AI-driven tools that can provide reliable and efficient wound care support.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [55] [An Efficient and Almost Optimal Solver for the Joint Routing-Assignment Problem via Partial JRA and Large-α Optimization](https://arxiv.org/abs/2511.09563)
*Qilong Yuan*

Main category: cs.AI

TL;DR: 本文提出了一种新的高效方法，用于解决大规模联合路由分配（JRA）优化问题。


<details>
  <summary>Details</summary>
Motivation: 由于现有精确方法在大规模实例上计算效率低下，而启发式方法又存在一定偏差，需要一种更高效且能获得高精度解的方法。

Method: 引入了一种部分路径重构（PPR）求解器，首先识别关键项目-占位符对形成简化子问题，并高效求解以优化全局解。还提出了一个全局Large-α约束以增强解的最优性。

Result: 在n = 300, 500, 和 1000的基准数据集上的实验表明，该方法始终能获得几乎最优解，平均偏差为0.00%，同时保持高计算效率。

Conclusion: 该方法在大规模JRA问题上表现出色，并且其框架和方法对其他相关优化问题具有广泛的应用潜力。

Abstract: The Joint Routing-Assignment (JRA) optimization problem simultaneously determines the assignment of items to placeholders and a Hamiltonian cycle that visits each node pair exactly once, with the objective of minimizing total travel cost. Previous studies introduced an exact mixed-integer programming (MIP) solver, along with datasets and a Gurobi implementation, showing that while the exact approach guarantees optimality, it becomes computationally inefficient for large-scale instances. To overcome this limitation, heuristic methods based on merging algorithms and shaking procedures were proposed, achieving solutions within approximately 1% deviation from the optimum. This work presents a novel and more efficient approach that attains high-accuracy, near-optimal solutions for large-scale JRA problems. The proposed method introduces a Partial Path Reconstructon (PPR) solver that first identifies key item-placeholder pairs to form a reduced subproblem, which is solved efficiently to refine the global solution. Using this PJAR framework, the initial heuristic merging solutions can be further improved, reducing the deviation by half. Moreover, the solution can be iteratively polished with PPR based solver along the optimization path to yield highly accurate tours. Additionally, a global Large-α constraint is incorporated into the JRA model to further enhance solution optimality. Experimental evaluations on benchmark datasets with n = 300, 500, and 1000 demonstrate that the proposed method consistently delivers almost optimal solutions, achieving an average deviation of 0.00% from the ground truth while maintaining high computational efficiency. Beyond the JRA problem, the proposed framework and methodologies exhibit strong potential for broader applications. The Framework can be applied to TSP and related optimization problems.

</details>


### [56] [Variable Neighborhood Search for the Electric Vehicle Routing Problem](https://arxiv.org/abs/2511.09570)
*David Woller,Viktor Kozák,Miroslav Kulich,Libor Přeučil*

Main category: cs.AI

TL;DR: 本文介绍了一种基于可变邻域搜索（VNS）的元启发式算法，用于解决容量受限的绿色车辆路径问题（CGVRP），并在2020年IEEE计算智能世界大会的CEC-12竞赛中获得最佳结果。


<details>
  <summary>Details</summary>
Motivation: 由于文献中考虑的约束种类繁多，不同方法在不同问题变体之间进行比较仍具有挑战性。该研究旨在提出一种解决CGVRP的高效算法，以推动电动车路径问题的研究进展。

Method: 本文采用了基于可变邻域搜索（VNS）的元启发式方法，该方法通过动态调整邻域结构来优化路径方案。

Result: 该方法在完整的竞赛数据集上取得了最佳结果，并且性能优于之后发布的更近期的算法。

Conclusion: VNS元启发式算法在解决CGVRP方面表现出色，展示了其在电动车路径问题中的潜力和有效性。

Abstract: The Electric Vehicle Routing Problem (EVRP) extends the classical Vehicle Routing Problem (VRP) to reflect the growing use of electric and hybrid vehicles in logistics. Due to the variety of constraints considered in the literature, comparing approaches across different problem variants remains challenging. A minimalistic variant of the EVRP, known as the Capacitated Green Vehicle Routing Problem (CGVRP), was the focus of the CEC-12 competition held during the 2020 IEEE World Congress on Computational Intelligence. This paper presents the competition-winning approach, based on the Variable Neighborhood Search (VNS) metaheuristic. The method achieves the best results on the full competition dataset and also outperforms a more recent algorithm published afterward.

</details>


### [57] [Proceedings of the Second International Workshop on Next-Generation Language Models for Knowledge Representation and Reasoning (NeLaMKRR 2025)](https://arxiv.org/abs/2511.09575)
*Ha-Thanh Nguyen,Ken Satoh,Francesca Toni,Randy Goebel,Kostas Stathis*

Main category: cs.AI

TL;DR: 该研讨会旨在探索和协调基于变换器的语言模型与基于逻辑的知识表示之间的推理方法。


<details>
  <summary>Details</summary>
Motivation: 传统AI在逻辑知识表示背景下处理推理，但最新的基于变换器的语言模型在自然语言处理方面取得了显著进展，暗示这些模型可能具备推理能力。然而，目前尚不清楚这些模型的推理能力具体能达到什么程度。

Method: 创建一个多学科平台，分析语言模型的推理能力、将基于知识表示的推理能力注入语言模型，并形式化语言模型所进行的推理。

Result: 通过分析、注入和形式化推理，探索语言模型如何有效地整合和利用知识进行推理。

Conclusion: 该探索旨在提高语言模型在需要精确性和可靠性的应用领域的性能和实用性。

Abstract: Reasoning is an essential component of human intelligence in that it plays a fundamental role in our ability to think critically, support responsible decisions, and solve challenging problems. Traditionally, AI has addressed reasoning in the context of logic-based representations of knowledge. However, the recent leap forward in natural language processing, with the emergence of language models based on transformers, is hinting at the possibility that these models exhibit reasoning abilities, particularly as they grow in size and are trained on more and more data. Still, despite ongoing discussions about what reasoning is in language models, it is still not easy to articulate to what extent these models are actually capable of reasoning.
  The goal of this workshop is to create a platform for researchers from different disciplines and/or AI perspectives to explore approaches and techniques with the aim to reconcile reasoning between language models using transformers and logic-based representations. The specific objectives include analysing the reasoning abilities of language models measured alongside KR methods, injecting KR-style reasoning abilities into language models (including by neuro-symbolic means), and formalising the kind of reasoning language models carry out. This exploration aims to uncover how language models can effectively integrate and leverage knowledge and reasoning with it, thus improving their application and utility in areas where precision and reliability are key requirements.

</details>


### [58] [Cogent argument extensions are weakly admissible but not vice versa](https://arxiv.org/abs/2511.09600)
*Gustavo Bodanza*

Main category: cs.AI

TL;DR: 本文研究了两种非可接受论证框架语义（cogent和弱可接受）之间的关系，证明cogent扩展是弱可接受的，但反之不成立。


<details>
  <summary>Details</summary>
Motivation: 探究两种非可接受论证框架语义之间的关系，以填补相关理论空白。

Method: 通过逻辑证明展示cogent扩展与弱可接受扩展之间的关系。

Result: 证明了cogent扩展是弱可接受的，但反之不成立。

Conclusion: cogent和弱可接受语义之间存在单向包含关系，cogent扩展是弱可接受扩展的真子集。

Abstract: In this research note, we show the relationship between two non-admissible argumentation framework semantics: cogent and weakly admissible semantics. We prove that, while cogent extensions are weakly admissible, the converse is not true.

</details>


### [59] [Rebellion: Noise-Robust Reasoning Training for Audio Reasoning Models](https://arxiv.org/abs/2511.09682)
*Tiansheng Huang,Virat Shejwalkar,Oscar Chang,Milad Nasr,Ling Liu*

Main category: cs.AI

TL;DR: 该论文提出了一种名为Rebellion的鲁棒推理训练方法，用于提高音频推理模型（ARMs）在面对越狱攻击时的安全性。


<details>
  <summary>Details</summary>
Motivation: 随着音频推理模型（ARMs）的普及，其面对越狱攻击的安全性问题尚未得到研究。本文旨在探索并解决ARMs在面对高级越狱攻击时的脆弱性。

Method: 论文首先展示了标准推理训练（RT）结合安全推理数据可以防御普通音频越狱攻击，但对提出的简单而有效的越狱攻击无效。原因是普通与高级越狱攻击之间存在显著表示漂移。为此，作者提出了Rebellion，一种鲁棒的推理训练方法，使ARMs能够抵抗最坏情况下的表示漂移。

Result: 在Qwen2-Audio上的实验表明，Rebellion能够有效防御高级音频越狱攻击，同时不影响在良性任务上的性能，并且显著提高了标准RT方法的准确性与安全性之间的权衡。

Conclusion: Rebellion是一种有效的训练方法，可以提升ARMs在面对高级越狱攻击时的鲁棒性，同时保持良好的任务性能。

Abstract: Instilling reasoning capabilities in large models (LMs) using reasoning training (RT) significantly improves LMs' performances. Thus Audio Reasoning Models (ARMs), i.e., audio LMs that can reason, are becoming increasingly popular. However, no work has studied the safety of ARMs against jailbreak attacks that aim to elicit harmful responses from target models. To this end, first, we show that standard RT with appropriate safety reasoning data can protect ARMs from vanilla audio jailbreaks, but cannot protect them against our proposed simple yet effective jailbreaks. We show that this is because of the significant representation drift between vanilla and advanced jailbreaks which forces the target ARMs to emit harmful responses. Based on this observation, we propose Rebellion, a robust RT that trains ARMs to be robust to the worst-case representation drift. All our results are on Qwen2-Audio; they demonstrate that Rebellion: 1) can protect against advanced audio jailbreaks without compromising performance on benign tasks, and 2) significantly improves accuracy-safety trade-off over standard RT method.

</details>


### [60] [AI Annotation Orchestration: Evaluating LLM verifiers to Improve the Quality of LLM Annotations in Learning Analytics](https://arxiv.org/abs/2511.09785)
*Bakhtawar Ahtisham,Kirk Vanacore,Jinsook Lee,Zhuqian Zhou,Doug Pietrzak,Rene F. Kizilcec*

Main category: cs.AI

TL;DR: 本文研究了通过自我验证和交叉验证提高LLMs标注学习互动的可靠性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在标注学习互动中显示出潜力，但其可靠性仍令人担忧，因此需要提高其标注的准确性。

Method: 研究使用30个一对一数学辅导课程的记录，比较三种LLMs（GPT, Claude, Gemini）在三种条件下的表现：无验证标注、自我验证和交叉验证。

Result: 验证导向的协作使Cohen's kappa提高了58%，自我验证几乎使一致性翻倍，交叉验证平均提高了37%。

Conclusion: 验证是提升学习分析中LLMs辅助标注可靠性和可扩展性的有效设计手段，并提出了一种灵活的协作框架和标准化报告符号。

Abstract: Large Language Models (LLMs) are increasingly used to annotate learning interactions, yet concerns about reliability limit their utility. We test whether verification-oriented orchestration-prompting models to check their own labels (self-verification) or audit one another (cross-verification)-improves qualitative coding of tutoring discourse. Using transcripts from 30 one-to-one math sessions, we compare three production LLMs (GPT, Claude, Gemini) under three conditions: unverified annotation, self-verification, and cross-verification across all orchestration configurations. Outputs are benchmarked against a blinded, disagreement-focused human adjudication using Cohen's kappa. Overall, orchestration yields a 58 percent improvement in kappa. Self-verification nearly doubles agreement relative to unverified baselines, with the largest gains for challenging tutor moves. Cross-verification achieves a 37 percent improvement on average, with pair- and construct-dependent effects: some verifier-annotator pairs exceed self-verification, while others reduce alignment, reflecting differences in verifier strictness. We contribute: (1) a flexible orchestration framework instantiating control, self-, and cross-verification; (2) an empirical comparison across frontier LLMs on authentic tutoring data with blinded human "gold" labels; and (3) a concise notation, verifier(annotator) (e.g., Gemini(GPT) or Claude(Claude)), to standardize reporting and make directional effects explicit for replication. Results position verification as a principled design lever for reliable, scalable LLM-assisted annotation in Learning Analytics.

</details>


### [61] [Why Open Small AI Models Matter for Interactive Art](https://arxiv.org/abs/2511.09788)
*Mar Canet Sola,Varvara Guljajeva*

Main category: cs.AI

TL;DR: 本文主张开放的小型AI模型对互动艺术实践中的创作独立性的重要性。


<details>
  <summary>Details</summary>
Motivation: 大型闭源AI模型在互动艺术中存在限制，如内容过滤、保存问题和技术挑战，因此需要开放小型AI模型以赋予艺术家更多控制权和自主性。

Method: 通过对比开放小型AI模型与闭源大型模型，探索其在互动艺术中的实际应用和影响。

Result: 小型AI模型赋予创作者更多自主权、控制权和可持续性，支持长期保存和展览AI作品。

Conclusion: 开放小型AI模型促进艺术家的技术自决权，减少对不适合互动艺术需求的企业AI的依赖。

Abstract: This position paper argues for the importance of open small AI models in creative independence for interactive art practices. Deployable locally, these models offer artists vital control over infrastructure and code, unlike dominant large, closed-source corporate systems. Such centralized platforms function as opaque black boxes, imposing severe limitations on interactive artworks, including restrictive content filters, preservation issues, and technical challenges such as increased latency and limited interfaces. In contrast, small AI models empower creators with more autonomy, control, and sustainability for these artistic processes. They enable the ability to use a model as long as they want, create their own custom model, either by making code changes to integrate new interfaces, or via new datasets by re-training or fine-tuning the model. This fosters technological self-determination, offering greater ownership and reducing reliance on corporate AI ill-suited for interactive art's demands. Critically, this approach empowers the artist and supports long-term preservation and exhibition of artworks with AI components. This paper explores the practical applications and implications of using open small AI models in interactive art, contrasting them with closed-source alternatives.

</details>


### [62] [Thermally Activated Dual-Modal Adversarial Clothing against AI Surveillance Systems](https://arxiv.org/abs/2511.09829)
*Jiahuan Long,Tingsong Jiang,Hanqing Liu,Chao Ma,Wen Yao*

Main category: cs.AI

TL;DR: 提出一种热激活可穿戴对抗系统，通过热致变色染料和柔性加热单元在衣物上实现动态对抗图案，以抵抗AI监控。


<details>
  <summary>Details</summary>
Motivation: 对抗性补丁在抵抗AI驱动的监控系统中是流行的隐私保护方法，但其显眼外观使其在现实世界中难以应用。

Method: 集成热致变色染料与柔性加热单元，使衣物表面在加热时显现隐藏的对抗图案。

Result: 实验显示，对抗性可穿戴设备在50秒内实现快速纹理激活，并在多种现实监控环境中保持超过80%的对抗成功率。

Conclusion: 该工作为物理基础、用户可控的反AI系统提供了新途径，凸显了在普遍AI监控时代主动对抗技术对隐私保护的重要性。

Abstract: Adversarial patches have emerged as a popular privacy-preserving approach for resisting AI-driven surveillance systems. However, their conspicuous appearance makes them difficult to deploy in real-world scenarios. In this paper, we propose a thermally activated adversarial wearable designed to ensure adaptability and effectiveness in complex real-world environments. The system integrates thermochromic dyes with flexible heating units to induce visually dynamic adversarial patterns on clothing surfaces. In its default state, the clothing appears as an ordinary black T-shirt. Upon heating via an embedded thermal unit, hidden adversarial patterns on the fabric are activated, allowing the wearer to effectively evade detection across both visible and infrared modalities. Physical experiments demonstrate that the adversarial wearable achieves rapid texture activation within 50 seconds and maintains an adversarial success rate above 80\% across diverse real-world surveillance environments. This work demonstrates a new pathway toward physically grounded, user-controllable anti-AI systems, highlighting the growing importance of proactive adversarial techniques for privacy protection in the age of ubiquitous AI surveillance.

</details>


### [63] [EgoEMS: A High-Fidelity Multimodal Egocentric Dataset for Cognitive Assistance in Emergency Medical Services](https://arxiv.org/abs/2511.09894)
*Keshara Weerasinghe,Xueren Ge,Tessa Heick,Lahiru Nuwan Wijayasingha,Anthony Cortez,Abhishek Satpathy,John Stankovic,Homa Alemzadeh*

Main category: cs.AI

TL;DR: 介绍EgoEMS：首个端到端、高保真、多模态、多人数据集，用于急救医疗服务（EMS）的AI认知辅助。


<details>
  <summary>Details</summary>
Motivation: 急救医疗服务中，急救人员面临高强度认知需求，AI认知辅助有望通过支持实时数据收集和决策来缓解这一压力。

Method: 与EMS专家合作，开发了一个开源、低成本、可复制的数据收集系统，并创建了一个包含233个模拟紧急场景、62名参与者、20多小时真实过程的多模态数据集。数据集包括关键步骤、带时间戳的音频转录、动作质量指标和带分割掩码的边界框。

Result: 推出了EgoEMS数据集，并提供了用于实时多模态关键步骤识别和动作质量评估的基准测试套件。

Conclusion: EgoEMS旨在推动智能EMS系统的研究，最终提升患者救治效果。希望该数据集能激发研究社区在智能EMS系统领域的进一步探索。

Abstract: Emergency Medical Services (EMS) are critical to patient survival in emergencies, but first responders often face intense cognitive demands in high-stakes situations. AI cognitive assistants, acting as virtual partners, have the potential to ease this burden by supporting real-time data collection and decision making. In pursuit of this vision, we introduce EgoEMS, the first end-to-end, high-fidelity, multimodal, multiperson dataset capturing over 20 hours of realistic, procedural EMS activities from an egocentric view in 233 simulated emergency scenarios performed by 62 participants, including 46 EMS professionals. Developed in collaboration with EMS experts and aligned with national standards, EgoEMS is captured using an open-source, low-cost, and replicable data collection system and is annotated with keysteps, timestamped audio transcripts with speaker diarization, action quality metrics, and bounding boxes with segmentation masks. Emphasizing realism, the dataset includes responder-patient interactions reflecting real-world emergency dynamics. We also present a suite of benchmarks for real-time multimodal keystep recognition and action quality estimation, essential for developing AI support tools for EMS. We hope EgoEMS inspires the research community to push the boundaries of intelligent EMS systems and ultimately contribute to improved patient outcomes.

</details>


### [64] [Boosting In-Silicon Directed Evolution with Fine-Tuned Protein Language Model and Tree Search](https://arxiv.org/abs/2511.09900)
*Yaodong Yang,Yang Wang,Jinpeng Li,Pei Guo,Da Han,Guangyong Chen,Pheng-Ann Heng*

Main category: cs.AI

TL;DR: AlphaDE利用蛋白质语言模型和蒙特卡洛树搜索进行蛋白质序列进化。


<details>
  <summary>Details</summary>
Motivation: 当前的计算机定向进化算法忽视了如何利用蛋白质语言模型来指导搜索，因此作者提出了一个新的框架AlphaDE。

Method: AlphaDE首先通过对预训练的蛋白质语言模型进行掩码语言建模微调，激活目标蛋白类的进化可信性；其次，引入基于蒙特卡洛树搜索的测试时推理，从微调模型中有效进化蛋白质。

Result: 广泛的基准实验表明，AlphaDE即使在小样本微调的情况下，也显著优于之前的最先进方法。

Conclusion: AlphaDE通过计算进化支持压缩蛋白质序列空间，为蛋白质进化提供了新的解决方案。

Abstract: Protein evolution through amino acid sequence mutations is a cornerstone of life sciences. While current in-silicon directed evolution algorithms focus on designing search strategies, they overlook how to utilize the transformative protein language models, which encode rich evolutionary patterns, to guide search. To bridge this gap, we propose AlphaDE, a novel framework to evolve protein sequences by harnessing the innovative paradigms of large language models. First, AlphaDE fine-tunes pretrained protein language models using masked language modeling on homologous protein sequences to activate the evolutionary plausibility for the interested protein class. Second, AlphaDE introduces test-time inference based on Monte Carlo tree search, which effectively evolves proteins with evolutionary guidance from the fine-tuned protein language model. Extensive benchmark experiments show that AlphaDE remarkably outperforms previous state-of-the-art methods even with few-shot fine-tuning. An interesting case study further shows that AlphaDE supports condensing the protein sequence space through computational evolution.

</details>


### [65] [Learning to Pose Problems: Reasoning-Driven and Solver-Adaptive Data Synthesis for Large Reasoning Models](https://arxiv.org/abs/2511.09907)
*Yongxian Wei,Yilin Zhao,Li Shen,Xinrui Chen,Runxi Cheng,Sinan Du,Hao Yu,Gang Liu,Jiahong Yan,Chun Yuan,Dian Li*

Main category: cs.AI

TL;DR: 本文提出了一种能够推理并适应解题者能力的问题生成器，以解决现有数据合成方法中的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在无差别生成问题和缺乏推理的问题，导致低价值问题或复杂的数据管道需求。

Method: 构建相关问题对，并通过推理模型生成中间问题设计链（CoT），利用解题者反馈调整难度并生成合适问题。

Result: 在10个数学和通用推理基准测试中，方法平均提升2.5%，并能够推广到语言和视觉语言模型。

Conclusion: 通过合成数据进行训练的解题者可以为生成器提供改进的奖励信号，实现协同进化，获得额外0.7%的性能提升。

Abstract: Data synthesis for training large reasoning models offers a scalable alternative to limited, human-curated datasets, enabling the creation of high-quality data. However, existing approaches face several challenges: (i) indiscriminate generation that ignores the solver's ability and yields low-value problems, or reliance on complex data pipelines to balance problem difficulty; and (ii) a lack of reasoning in problem generation, leading to shallow problem variants. In this paper, we develop a problem generator that reasons explicitly to plan problem directions before synthesis and adapts difficulty to the solver's ability. Specifically, we construct related problem pairs and augment them with intermediate problem-design CoT produced by a reasoning model. These data bootstrap problem-design strategies from the generator. Then, we treat the solver's feedback on synthetic problems as a reward signal, enabling the generator to calibrate difficulty and produce complementary problems near the edge of the solver's competence. Extensive experiments on 10 mathematical and general reasoning benchmarks show that our method achieves an average improvement of 2.5% and generalizes to both language and vision-language models. Moreover, a solver trained on the synthesized data provides improved rewards for continued generator training, enabling co-evolution and yielding a further 0.7% performance gain. Our code will be made publicly available here.

</details>


### [66] [OIDA-QA: A Multimodal Benchmark for Analyzing the Opioid Industry Documents Archive](https://arxiv.org/abs/2511.09914)
*Xuan Shen,Brian Wingenroth,Zichao Wang,Jason Kuen,Wanrong Zhu,Ruiyi Zhang,Yiwei Wang,Lichun Ma,Anqi Liu,Hongfu Liu,Tong Sun,Kevin S. Hawkins,Kate Tasker,G. Caleb Alexander,Jiuxiang Gu*

Main category: cs.AI

TL;DR: 本文提出了一种创新的分析方法，通过整理和构建大规模数据集，开发特定领域的多模态大语言模型，以提高在UCSF-JHU阿片类药物行业文件档案中的信息提取和问答任务的准确性。


<details>
  <summary>Details</summary>
Motivation: 阿片类药物危机揭示了监管系统、医疗实践、公司治理和公共政策等方面的系统性不足。分析这些相互关联的系统的失败需要创新的分析方法，以探索大量公开的数据和文件。

Method: 通过按文档属性组织原始数据集，并构建包含400k训练文档和10k测试文档的基准。提取文档中的丰富多模态信息，包括文本内容、视觉元素和布局结构，使用多个AI模型生成大规模数据集，开发特定领域的多模态大语言模型，并探索多模态输入对任务性能的影响。

Result: 初步结果表明，在文档信息提取和问答任务中，所提出的AI助手具有显著的性能提升。数据集和模型已在Hugging Face公开。

Conclusion: 通过构建特定领域的多模态大语言模型，并引入历史问答对作为上下文基础，以及重要性基础的页面分类器，可以显著提高信息提取和问答任务的精度和相关性。

Abstract: The opioid crisis represents a significant moment in public health that reveals systemic shortcomings across regulatory systems, healthcare practices, corporate governance, and public policy. Analyzing how these interconnected systems simultaneously failed to protect public health requires innovative analytic approaches for exploring the vast amounts of data and documents disclosed in the UCSF-JHU Opioid Industry Documents Archive (OIDA). The complexity, multimodal nature, and specialized characteristics of these healthcare-related legal and corporate documents necessitate more advanced methods and models tailored to specific data types and detailed annotations, ensuring the precision and professionalism in the analysis. In this paper, we tackle this challenge by organizing the original dataset according to document attributes and constructing a benchmark with 400k training documents and 10k for testing. From each document, we extract rich multimodal information-including textual content, visual elements, and layout structures-to capture a comprehensive range of features. Using multiple AI models, we then generate a large-scale dataset comprising 360k training QA pairs and 10k testing QA pairs. Building on this foundation, we develop domain-specific multimodal Large Language Models (LLMs) and explore the impact of multimodal inputs on task performance. To further enhance response accuracy, we incorporate historical QA pairs as contextual grounding for answering current queries. Additionally, we incorporate page references within the answers and introduce an importance-based page classifier, further improving the precision and relevance of the information provided. Preliminary results indicate the improvements with our AI assistant in document information extraction and question-answering tasks. The dataset and models are publicly available at: https://huggingface.co/opioidarchive

</details>


### [67] [Adaptive Hyperbolic Kernels: Modulated Embedding in de Branges-Rovnyak Spaces](https://arxiv.org/abs/2511.09921)
*Leping Si,Meimei Yang,Hui Xue,Shipeng Zhu,Pengfei Fang*

Main category: cs.AI

TL;DR: 提出了一种新的自适应双曲核方法，通过曲率感知的de Branges-Rovnyak空间，提升了层次数据的建模能力。


<details>
  <summary>Details</summary>
Motivation: 双曲空间因其负曲率特性，在嵌入层次结构方面表现出色，但现有的双曲核存在几何失真或缺乏自适应性的问题。

Method: 引入曲率感知的de Branges-Rovnyak空间，设计了可调节的乘子以适应不同曲率的双曲空间，并构建了自适应双曲核家族，包括新型的自适应双曲径向基核。

Result: 在视觉和语言基准测试中，所提出的核在建模层次依赖方面优于现有双曲核。

Conclusion: 该论文提出的自适应双曲核有效解决了现有双曲核的几何失真和缺乏自适应性的问题，在层次数据建模中具有优越性能。

Abstract: Hierarchical data pervades diverse machine learning applications, including natural language processing, computer vision, and social network analysis. Hyperbolic space, characterized by its negative curvature, has demonstrated strong potential in such tasks due to its capacity to embed hierarchical structures with minimal distortion. Previous evidence indicates that the hyperbolic representation capacity can be further enhanced through kernel methods. However, existing hyperbolic kernels still suffer from mild geometric distortion or lack adaptability. This paper addresses these issues by introducing a curvature-aware de Branges-Rovnyak space, a reproducing kernel Hilbert space (RKHS) that is isometric to a Poincare ball. We design an adjustable multiplier to select the appropriate RKHS corresponding to the hyperbolic space with any curvature adaptively. Building on this foundation, we further construct a family of adaptive hyperbolic kernels, including the novel adaptive hyperbolic radial kernel, whose learnable parameters modulate hyperbolic features in a task-aware manner. Extensive experiments on visual and language benchmarks demonstrate that our proposed kernels outperform existing hyperbolic kernels in modeling hierarchical dependencies.

</details>


### [68] [SPAN: Benchmarking and Improving Cross-Calendar Temporal Reasoning of Large Language Models](https://arxiv.org/abs/2511.09993)
*Zhongjian Miao,Hao Fu,Chen Wei*

Main category: cs.AI

TL;DR: SPAN是一个跨日历时间推理基准，评估LLMs在多种日历间进行时间推理和转换的能力。


<details>
  <summary>Details</summary>
Motivation: 为了评估和提升LLMs在不同日历间进行时间推理和转换的能力，尤其是在时间变化和数据污染方面的挑战。

Method: 引入SPAN基准，包括十个跨日历时间推理方向、两种推理类型和两种问题格式，并提出模板驱动的动态实例生成协议。还开发了一个LLM驱动的Time Agent，利用工具增强代码生成来提升跨日历时间推理能力。

Result: 在1960年至2060年范围内，现有SOTA LLMs的平均准确率仅为34.5%，而Time Agent的平均准确率达95.31%。

Conclusion: 当前LLMs在跨日历时间推理上仍面临挑战，尤其是未来日期退化和日历不对称偏差问题。工具增强代码生成具有显著提升潜力，为更时间和文化自适应的LLMs发展提供了方向。

Abstract: We introduce SPAN, a cross-calendar temporal reasoning benchmark, which requires LLMs to perform intra-calendar temporal reasoning and inter-calendar temporal conversion. SPAN features ten cross-calendar temporal reasoning directions, two reasoning types, and two question formats across six calendars. To enable time-variant and contamination-free evaluation, we propose a template-driven protocol for dynamic instance generation that enables assessment on a user-specified Gregorian date. We conduct extensive experiments on both open- and closed-source state-of-the-art (SOTA) LLMs over a range of dates spanning 100 years from 1960 to 2060. Our evaluations show that these LLMs achieve an average accuracy of only 34.5%, with none exceeding 80%, indicating that this task remains challenging. Through in-depth analysis of reasoning types, question formats, and temporal reasoning directions, we identify two key obstacles for LLMs: Future-Date Degradation and Calendar Asymmetry Bias. To strengthen LLMs' cross-calendar temporal reasoning capability, we further develop an LLM-powered Time Agent that leverages tool-augmented code generation. Empirical results show that Time Agent achieves an average accuracy of 95.31%, outperforming several competitive baselines, highlighting the potential of tool-augmented code generation to advance cross-calendar temporal reasoning. We hope this work will inspire further efforts toward more temporally and culturally adaptive LLMs.

</details>


### [69] [ChEmREF: Evaluating Language Model Readiness for Chemical Emergency Response](https://arxiv.org/abs/2511.10027)
*Risha Surana,Qinyuan Ye,Swabha Swayamdipta*

Main category: cs.AI

TL;DR: 本文研究了语言模型在危险材料（HAZMAT）应急事件中的应用，并提出了一个新的评估框架ChEmREF。


<details>
  <summary>Details</summary>
Motivation: 应急响应人员在处理HAZMAT事件时需快速、可靠地理解关键信息并做出决策。当前，他们需要手动浏览大量化学指南。研究者们探讨了现代语言模型是否能够通过快速、准确地理解信息、识别危险并提供建议来协助应急响应人员。

Method: 引入了化学应急响应评估框架（ChEmREF），该基准涵盖了来自应急响应指南和PubChem数据库的1,035种HAZMAT化学品的问题。ChEmREF分为三项任务：1）化学表示形式的转换，2）应急响应生成，3）化学安全和认证考试领域的知识问答。

Result: 评估的最佳模型在非结构化HAZMAT化学表示转换上的精确匹配率为68.0%，在事件响应建议上的LLM Judge得分为52.7%，在HAZMAT考试选择题上的准确率为63.9%。

Conclusion: 语言模型在协助应急响应人员方面展现出潜力，但由于当前存在局限性，需要仔细的人工监督。

Abstract: Emergency responders managing hazardous material HAZMAT incidents face critical, time-sensitive decisions, manually navigating extensive chemical guidelines. We investigate whether today's language models can assist responders by rapidly and reliably understanding critical information, identifying hazards, and providing recommendations.We introduce the Chemical Emergency Response Evaluation Framework (ChEmREF), a new benchmark comprising questions on 1,035 HAZMAT chemicals from the Emergency Response Guidebook and the PubChem Database. ChEmREF is organized into three tasks: (1) translation of chemical representation between structured and unstructured forms (e.g., converting C2H6O to ethanol), (2) emergency response generation (e.g., recommending appropriate evacuation distances) and (3) domain knowledge question answering from chemical safety and certification exams. Our best evaluated models received an exact match of 68.0% on unstructured HAZMAT chemical representation translation, a LLM Judge score of 52.7% on incident response recommendations, and a multiple-choice accuracy of 63.9% on HAMZAT examinations.These findings suggest that while language models show potential to assist emergency responders in various tasks, they require careful human oversight due to their current limitations.

</details>


### [70] [Beyond ReAct: A Planner-Centric Framework for Complex Tool-Augmented LLM Reasoning](https://arxiv.org/abs/2511.10037)
*Xiaolong Wei,Yuehu Dong,Xingliang Wang,Xingyu Zhang,Zhejun Zhao,Dongdong Shen,Long Xia,Dawei Yin*

Main category: cs.AI

TL;DR: 提出了一种新的以规划器为中心(Planner-centric)的"计划-执行"(Plan-Execute)范式，通过全局DAG规划解决现有工具增强型大语言模型在处理复杂查询时的局部优化问题。


<details>
  <summary>Details</summary>
Motivation: 现有框架如ReAct由于依赖增量决策过程，容易陷入局部优化陷阱，在处理复杂查询时存在明显局限性。

Method: 1. 提出Planner-centric Plan-Execute范式，采用全局DAG规划
2. 创建ComplexTool-Plan基准数据集
3. 开发结合SFT和GRPO的两阶段训练方法

Result: 在StableToolBench基准测试中实现了最先进的性能表现，特别是在复杂用户查询和多工具工作流处理方面。

Conclusion: 该框架通过架构创新有效解决了局部优化瓶颈，展示了更强的全局规划能力和多工具协调执行能力。

Abstract: Existing tool-augmented large language models (LLMs) encounter significant challenges when processing complex queries. Current frameworks such as ReAct are prone to local optimization traps due to their reliance on incremental decision-making processes. To address these limitations, we propose a novel Planner-centric Plan-Execute paradigm that fundamentally resolves local optimization bottlenecks through architectural innovation. Central to our approach is a novel Planner model that performs global Directed Acyclic Graph (DAG) planning for complex queries, enabling optimized execution beyond conventional tool coordination. We also introduce ComplexTool-Plan, a large-scale benchmark dataset featuring complex queries that demand sophisticated multi-tool composition and coordination capabilities. Additionally, we develop a two-stage training methodology that integrates Supervised Fine-Tuning (SFT) with Group Relative Policy Optimization (GRPO), systematically enhancing the Planner's tool selection accuracy and global planning awareness through structured DAG-based planning. When integrated with a capable executor, our framework achieves state-of-the-art performance on the StableToolBench benchmark for complex user queries, demonstrating superior end-to-end execution capabilities and robust handling of intricate multi-tool workflows.

</details>


### [71] [Efficient Thought Space Exploration through Strategic Intervention](https://arxiv.org/abs/2511.10038)
*Ziheng Li,Hengyi Cai,Xiaochi Wei,Yuchen Li,Shuaiqiang Wang,Zhi-Hong Deng,Dawei Yin*

Main category: cs.AI

TL;DR: 提出了一种新的Hint-Practice Reasoning (HPR)框架，通过两个协同组件（提示者和实践者）和分布不一致性减少（DIR）指标，在保持高性能的同时显著减少计算成本。


<details>
  <summary>Details</summary>
Motivation: 当前推理时间扩展方法因全面采样而计算成本过高，研究发现大多数下一个词预测与正确输出一致，但关键词预测偏差导致错误，因此提出HPR框架以解决此问题。

Method: HPR框架包括一个强大的提示者（hinter）和一个高效的小模型实践者（practitioner）。其核心创新是分布不一致性减少（DIR）指标，通过量化和调整在树状概率空间中实践者和提示者之间的差异，动态识别关键干预点。

Result: 在算术和常识推理基准测试中，HPR在解码仅1/5词量的情况下，性能与self-consistency和MCTS基线相当，且在保持相似或更低FLOPs的情况下，最高提升5.1%的绝对准确率。

Conclusion: HPR框架通过提示者和实践者协同工作，利用DIR指标动态识别和修正关键推理步骤，实现了最先进的效率-准确性权衡。

Abstract: While large language models (LLMs) demonstrate emerging reasoning capabilities, current inference-time expansion methods incur prohibitive computational costs by exhaustive sampling. Through analyzing decoding trajectories, we observe that most next-token predictions align well with the golden output, except for a few critical tokens that lead to deviations. Inspired by this phenomenon, we propose a novel Hint-Practice Reasoning (HPR) framework that operationalizes this insight through two synergistic components: 1) a hinter (powerful LLM) that provides probabilistic guidance at critical decision points, and 2) a practitioner (efficient smaller model) that executes major reasoning steps. The framework's core innovation lies in Distributional Inconsistency Reduction (DIR), a theoretically-grounded metric that dynamically identifies intervention points by quantifying the divergence between practitioner's reasoning trajectory and hinter's expected distribution in a tree-structured probabilistic space. Through iterative tree updates guided by DIR, HPR reweights promising reasoning paths while deprioritizing low-probability branches. Experiments across arithmetic and commonsense reasoning benchmarks demonstrate HPR's state-of-the-art efficiency-accuracy tradeoffs: it achieves comparable performance to self-consistency and MCTS baselines while decoding only 1/5 tokens, and outperforms existing methods by at most 5.1% absolute accuracy while maintaining similar or lower FLOPs.

</details>


### [72] [Radiology Workflow-Guided Hierarchical Reinforcement Fine-Tuning for Medical Report Generation](https://arxiv.org/abs/2511.10065)
*Bodong Du,Honglong Yang,Xiaomeng Li*

Main category: cs.AI

TL;DR: 提出RadFlow，一种分层工作流引导的强化优化框架，用于医学报告生成，强调结构化和临床一致性。


<details>
  <summary>Details</summary>
Motivation: 现有医学报告生成系统忽略了放射科医生结构化撰写报告的流程，导致描述性和诊断性内容之间不一致。

Method: RadFlow引入临床基础的奖励分层，全局奖励整合语言流畅性、医学正确性和发现与印象之间的一致性；局部奖励强调印象部分质量，并采用关键感知策略优化机制来调节高风险病例的学习。

Result: 在胸部X光和颈动脉超声数据集上的实验表明，RadFlow在诊断连贯性和整体报告质量上优于现有最佳模型。

Conclusion: RadFlow通过将结构化报告范式转化为强化微调过程，使模型生成的报告在语言一致性和临床契合度上均表现良好。

Abstract: Radiologists compose diagnostic reports through a structured workflow: they describe visual findings, summarize them into impressions, and carefully refine statements in clinically critical cases. However, most existing medical report generation (MRG) systems treat reports as flat sequences, overlooking this hierarchical organization and leading to inconsistencies between descriptive and diagnostic content. To align model behavior with real-world reporting practices, we propose RadFlow, a hierarchical workflow-guided reinforcement optimization framework that explicitly models the structured nature of clinical reporting. RadFlow introduces a clinically grounded reward hierarchy that mirrors the organization of radiological reports. At the global level, the reward integrates linguistic fluency, medical-domain correctness, and cross-sectional consistency between Finding and Impression, promoting coherent and clinically faithful narratives. At the local level, a section-specific reward emphasizes Impression quality, reflecting its central role in diagnostic accuracy. Furthermore, a critical-aware policy optimization mechanism adaptively regularizes learning for high-risk or clinically sensitive cases, emulating the cautious refinement behavior of radiologists when documenting critical findings. Together, these components translate the structured reporting paradigm into the reinforcement fine-tuning process, enabling the model to generate reports that are both linguistically consistent and clinically aligned. Experiments on chest X-ray and carotid ultrasound datasets demonstrate that RadFlow consistently improves diagnostic coherence and overall report quality compared with state-of-the-art baselines.

</details>


### [73] [Enhancing the Medical Context-Awareness Ability of LLMs via Multifaceted Self-Refinement Learning](https://arxiv.org/abs/2511.10067)
*Yuxuan Zhou,Yubin Wang,Bin Wang,Chen Ning,Xien Liu,Ji Wu,Jianye Hao*

Main category: cs.AI

TL;DR: 提出MuSeR方法，通过多层面自我优化提升大语言模型在医疗领域的上下文感知能力。


<details>
  <summary>Details</summary>
Motivation: 在真实医疗场景中，大语言模型需要更强的上下文感知能力，以识别缺失或关键细节，并提供安全、有帮助且上下文适当的响应。

Method: 提出MuSeR方法，通过属性条件查询生成器模拟多样化真实用户场景，让大语言模型进行自我评估与优化，提升决策、沟通和安全三个方面的上下文感知能力。

Result: 在HealthBench数据集上，MuSeR显著提升模型多方面性能，尤其是在上下文感知能力方面。通过知识蒸馏，小模型性能超越教师模型，在HealthBench上达到63.8%，在困难子集上达到43.1%。

Conclusion: MuSeR方法有效提升大语言模型在医疗场景中的上下文感知能力，并能在小模型上实现超越教师模型的性能。

Abstract: Large language models (LLMs) have shown great promise in the medical domain, achieving strong performance on several benchmarks. However, they continue to underperform in real-world medical scenarios, which often demand stronger context-awareness, i.e., the ability to recognize missing or critical details (e.g., user identity, medical history, risk factors) and provide safe, helpful, and contextually appropriate responses. To address this issue, we propose Multifaceted Self-Refinement (MuSeR), a data-driven approach that enhances LLMs' context-awareness along three key facets (decision-making, communication, and safety) through self-evaluation and refinement. Specifically, we first design a attribute-conditioned query generator that simulates diverse real-world user contexts by varying attributes such as role, geographic region, intent, and degree of information ambiguity. An LLM then responds to these queries, self-evaluates its answers along three key facets, and refines its responses to better align with the requirements of each facet. Finally, the queries and refined responses are used for supervised fine-tuning to reinforce the model's context-awareness ability. Evaluation results on the latest HealthBench dataset demonstrate that our method significantly improves LLM performance across multiple aspects, with particularly notable gains in the context-awareness axis. Furthermore, by incorporating knowledge distillation with the proposed method, the performance of a smaller backbone LLM (e.g., Qwen3-32B) surpasses its teacher model, achieving a new SOTA across all open-source LLMs on HealthBench (63.8%) and its hard subset (43.1%). Code and dataset will be released at https://muser-llm.github.io.

</details>


### [74] [RAGFort: Dual-Path Defense Against Proprietary Knowledge Base Extraction in Retrieval-Augmented Generation](https://arxiv.org/abs/2511.10128)
*Qinfeng Li,Miao Pan,Ke Xiong,Ge Su,Zhiqiang Shen,Yan Liu,Bing Sun,Hao Peng,Xuhong Zhang*

Main category: cs.AI

TL;DR: RAG系统在专有知识库上面临重建攻击的威胁，现有防御措施仅针对单一攻击路径，而RAGFort提出了一种双重模块防御策略。


<details>
  <summary>Details</summary>
Motivation: 重建攻击通过聚合模型响应来复制知识库，现有防御措施只针对一种路径，导致另一个路径仍然暴露。

Method: RAGFort采用结构感知的双模块防御，包括用于类间隔离的“对比重新索引”和用于类内保护的“约束级联生成”。

Result: 实验验证了RAGFort在安全、性能和鲁棒性方面显著降低了重建成功率，同时保持了答案质量。

Conclusion: RAGFort通过联合保护两种攻击路径，为知识库提取攻击提供了全面的防御策略。

Abstract: Retrieval-Augmented Generation (RAG) systems deployed over proprietary knowledge bases face growing threats from reconstruction attacks that aggregate model responses to replicate knowledge bases. Such attacks exploit both intra-class and inter-class paths, progressively extracting fine-grained knowledge within topics and diffusing it across semantically related ones, thereby enabling comprehensive extraction of the original knowledge base. However, existing defenses target only one path, leaving the other unprotected. We conduct a systematic exploration to assess the impact of protecting each path independently and find that joint protection is essential for effective defense. Based on this, we propose RAGFort, a structure-aware dual-module defense combining "contrastive reindexing" for inter-class isolation and "constrained cascade generation" for intra-class protection. Experiments across security, performance, and robustness confirm that RAGFort significantly reduces reconstruction success while preserving answer quality, offering comprehensive defense against knowledge base extraction attacks.

</details>


### [75] [DenoGrad: Deep Gradient Denoising Framework for Enhancing the Performance of Interpretable AI Models](https://arxiv.org/abs/2511.10161)
*J. Javier Alonso-Ramos,Ignacio Aguilera-Martos,Andrés Herrera-Poyatos,Francisco Herrera*

Main category: cs.AI

TL;DR: 提出了一种新颖的基于梯度的去噪框架DenoGrad，利用深度学习模型的梯度来检测和修正噪声数据，从而提高机器学习模型的性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 噪声数据显著影响机器学习模型性能，尤其是可解释AI框架中的模型。传统去噪方法常常会改变原始数据分布，导致模型解释性降低。

Method: 提出DenoGrad，一个基于梯度的去噪框架，通过利用训练好的深度学习模型的梯度来动态修正噪声实例，而不改变原始数据分布。

Result: 在表格和时间序列数据集上，DenoGrad在各种噪声环境下都优于现有去噪策略，是唯一保持原始数据分布的高质量方法。

Conclusion: DenoGrad提供了一种更精确和自适应的噪声定义和修正方法，提高了可解释AI模型的性能，同时保持数据分布的真实性。

Abstract: The performance of Machine Learning (ML) models, particularly those operating within the Interpretable Artificial Intelligence (Interpretable AI) framework, is significantly affected by the presence of noise in both training and production data. Denoising has therefore become a critical preprocessing step, typically categorized into instance removal and instance correction techniques. However, existing correction approaches often degrade performance or oversimplify the problem by altering the original data distribution. This leads to unrealistic scenarios and biased models, which is particularly problematic in contexts where interpretable AI models are employed, as their interpretability depends on the fidelity of the underlying data patterns. In this paper, we argue that defining noise independently of the solution may be ineffective, as its nature can vary significantly across tasks and datasets. Using a task-specific high quality solution as a reference can provide a more precise and adaptable noise definition. To this end, we propose DenoGrad, a novel Gradient-based instance Denoiser framework that leverages gradients from an accurate Deep Learning (DL) model trained on the target data -- regardless of the specific task -- to detect and adjust noisy samples. Unlike conventional approaches, DenoGrad dynamically corrects noisy instances, preserving problem's data distribution, and improving AI models robustness. DenoGrad is validated on both tabular and time series datasets under various noise settings against the state-of-the-art. DenoGrad outperforms existing denoising strategies, enhancing the performance of interpretable IA models while standing out as the only high quality approach that preserves the original data distribution.

</details>


### [76] [Two Constraint Compilation Methods for Lifted Planning](https://arxiv.org/abs/2511.10164)
*Periklis Mantenoglou,Luigi Bonassi,Enrico Scala,Pedro Zuidberg Dos Martires*

Main category: cs.AI

TL;DR: 本文研究了PDDL片段中的定性状态-轨迹约束规划问题，提出两种无需实例化的约束消除方法，适用于大规模规划问题。


<details>
  <summary>Details</summary>
Motivation: 解决现有编译器在处理具有大量对象和高阶动作的规划问题时，需要先进行实例化导致的可扩展性问题。

Method: 提出了两种无需实例化即可消除约束的方法，并证明了其正确性和最坏情况下的时间复杂度。

Result: 在最新的国际规划竞赛领域进行的实验表明，所提出的方法高效，产生的规划规范比需要实例化的编译器更简洁，同时在使用最新规划器时仍具竞争力。

Conclusion: 本文提出的方法有效解决了大规模规划问题的可扩展性挑战，同时保持了规划效率。

Abstract: We study planning in a fragment of PDDL with qualitative state-trajectory constraints, capturing safety requirements, task ordering conditions, and intermediate sub-goals commonly found in real-world problems. A prominent approach to tackle such problems is to compile their constraints away, leading to a problem that is supported by state-of-the-art planners. Unfortunately, existing compilers do not scale on problems with a large number of objects and high-arity actions, as they necessitate grounding the problem before compilation. To address this issue, we propose two methods for compiling away constraints without grounding, making them suitable for large-scale planning problems. We prove the correctness of our compilers and outline their worst-case time complexity. Moreover, we present a reproducible empirical evaluation on the domains used in the latest International Planning Competition. Our results demonstrate that our methods are efficient and produce planning specifications that are orders of magnitude more succinct than the ones produced by compilers that ground the domain, while remaining competitive when used for planning with a state-of-the-art planner.

</details>


### [77] [MTP: Exploring Multimodal Urban Traffic Profiling with Modality Augmentation and Spectrum Fusion](https://arxiv.org/abs/2511.10218)
*Haolong Xiang,Peisi Wang,Xiaolong Xu,Kun Yi,Xuyun Zhang,Quanzheng Sheng,Amin Beheshti,Wei Fan*

Main category: cs.AI

TL;DR: 本文提出了一种新型多模态框架MTP，通过数字、视觉和文本视角学习城市交通信号的多模态特征，以实现对复杂交通动态的准确预测。


<details>
  <summary>Details</summary>
Motivation: 现有交通信号建模方法通常依赖于单一模态的原始数据，忽略了多模态异构城市数据中的语义信息，限制了对交通信号的全面理解和复杂交通动态的准确预测。

Method: MTP框架通过三个分支（数字、视觉和文本）在频域内学习城市交通信号的多模态特征。首先，进行视觉增强，将原始数据转换为频域图像和周期性图像；其次，基于特定主题、背景信息和项目描述增强描述性文本；然后，利用频域多层感知器学习原始数据；最后，通过分层对比学习融合三种模态的信息。

Result: 在六个真实世界数据集上的广泛实验表明，MTP相较于现有方法具有更优越的性能。

Conclusion: MTP框架通过多模态学习，有效解决了现有方法忽略多模态信息的问题，提升了交通信号建模和复杂交通动态预测的准确性。

Abstract: With rapid urbanization in the modern era, traffic signals from various sensors have been playing a significant role in monitoring the states of cities, which provides a strong foundation in ensuring safe travel, reducing traffic congestion and optimizing urban mobility. Most existing methods for traffic signal modeling often rely on the original data modality, i.e., numerical direct readings from the sensors in cities. However, this unimodal approach overlooks the semantic information existing in multimodal heterogeneous urban data in different perspectives, which hinders a comprehensive understanding of traffic signals and limits the accurate prediction of complex traffic dynamics. To address this problem, we propose a novel \textit{M}ultimodal framework, \textit{MTP}, for urban \textit{T}raffic \textit{P}rofiling, which learns multimodal features through numeric, visual, and textual perspectives. The three branches drive for a multimodal perspective of urban traffic signal learning in the frequency domain, while the frequency learning strategies delicately refine the information for extraction. Specifically, we first conduct the visual augmentation for the traffic signals, which transforms the original modality into frequency images and periodicity images for visual learning. Also, we augment descriptive texts for the traffic signals based on the specific topic, background information and item description for textual learning. To complement the numeric information, we utilize frequency multilayer perceptrons for learning on the original modality. We design a hierarchical contrastive learning on the three branches to fuse the spectrum of three modalities. Finally, extensive experiments on six real-world datasets demonstrate superior performance compared with the state-of-the-art approaches.

</details>


### [78] [Bridging Synthetic and Real Routing Problems via LLM-Guided Instance Generation and Progressive Adaptation](https://arxiv.org/abs/2511.10233)
*Jianghan Zhu,Yaoxin Wu,Zhuoyi Lin,Zhengyuan Zhang,Haiyan Yin,Zhiguang Cao,Senthilnath Jayavelu,Xiaoli Li*

Main category: cs.AI

TL;DR: EvoReal通过结合大语言模型与进化算法生成更具现实多样性的合成实例，显著提升神经组合优化器在真实世界VRP问题中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有神经组合优化方法在合成数据上表现良好，但难以泛化到真实场景（如TSPLib和CVRPLib），需缩小合成与真实数据间的结构差异。

Method: 提出EvoReal框架，利用LLM引导的进化模块生成统计特征逼近真实场景的合成实例，并通过两阶段微调（先合成后真实）优化预训练NCO模型。

Result: 在TSPLib和CVRPLib多尺度测试中，EvoReal将神经求解器与最优解的差距分别降至1.05%和2.71%。

Conclusion: 通过增强合成数据的现实结构多样性，EvoReal有效提升了NCO模型在真实组合优化问题中的泛化性能。

Abstract: Recent advances in Neural Combinatorial Optimization (NCO) methods have significantly improved the capability of neural solvers to handle synthetic routing instances. Nonetheless, existing neural solvers typically struggle to generalize effectively from synthetic, uniformly-distributed training data to real-world VRP scenarios, including widely recognized benchmark instances from TSPLib and CVRPLib. To bridge this generalization gap, we present Evolutionary Realistic Instance Synthesis (EvoReal), which leverages an evolutionary module guided by large language models (LLMs) to generate synthetic instances characterized by diverse and realistic structural patterns. Specifically, the evolutionary module produces synthetic instances whose structural attributes statistically mimics those observed in authentic real-world instances. Subsequently, pre-trained NCO models are progressively refined, firstly aligning them with these structurally enriched synthetic distributions and then further adapting them through direct fine-tuning on actual benchmark instances. Extensive experimental evaluations demonstrate that EvoReal markedly improves the generalization capabilities of state-of-the-art neural solvers, yielding a notable reduced performance gap compared to the optimal solutions on the TSPLib (1.05%) and CVRPLib (2.71%) benchmarks across a broad spectrum of problem scales.

</details>


### [79] [ProgRAG: Hallucination-Resistant Progressive Retrieval and Reasoning over Knowledge Graphs](https://arxiv.org/abs/2511.10240)
*Minbae Park,Hyemin Yang,Jeonghyun Kim,Kunsoo Park,Hyunjoon Kim*

Main category: cs.AI

TL;DR: ProgRAG是一种多跳知识图谱问答框架，通过分解复杂问题、逐步扩展推理路径和优化推理上下文，提高大语言模型的推理可靠性和质量。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在知识图谱增强的推理任务中面临检索不准确、推理失败以及上下文过长导致的相关信息被掩盖等问题。

Method: ProgRAG框架将复杂问题分解为子问题，逐步扩展部分推理路径，并通过外部检索器和不确定性感知剪枝优化证据，最后通过整理和重排部分推理路径优化推理上下文。

Result: 在三个知名数据集上的实验表明，ProgRAG在多跳知识图谱问答任务中优于现有基线，提供了更高的推理可靠性和质量。

Conclusion: ProgRAG通过分解问题、优化检索和推理过程，有效解决了知识图谱增强的大语言模型中的推理和检索问题，提高了推理的透明度和准确性。

Abstract: Large Language Models (LLMs) demonstrate strong reasoning capabilities but struggle with hallucinations and limited transparency. Recently, KG-enhanced LLMs that integrate knowledge graphs (KGs) have been shown to improve reasoning performance, particularly for complex, knowledge-intensive tasks. However, these methods still face significant challenges, including inaccurate retrieval and reasoning failures, often exacerbated by long input contexts that obscure relevant information or by context constructions that struggle to capture the richer logical directions required by different question types. Furthermore, many of these approaches rely on LLMs to directly retrieve evidence from KGs, and to self-assess the sufficiency of this evidence, which often results in premature or incorrect reasoning. To address the retrieval and reasoning failures, we propose ProgRAG, a multi-hop knowledge graph question answering (KGQA) framework that decomposes complex questions into sub-questions, and progressively extends partial reasoning paths by answering each sub-question. At each step, external retrievers gather candidate evidence, which is then refined through uncertainty-aware pruning by the LLM. Finally, the context for LLM reasoning is optimized by organizing and rearranging the partial reasoning paths obtained from the sub-question answers. Experiments on three well-known datasets demonstrate that ProgRAG outperforms existing baselines in multi-hop KGQA, offering improved reliability and reasoning quality.

</details>


### [80] [Beyond Single-Step Updates: Reinforcement Learning of Heuristics with Limited-Horizon Search](https://arxiv.org/abs/2511.10264)
*Gal Hadar,Forest Agostinelli,Shahaf S. Shperberg*

Main category: cs.AI

TL;DR: 本文提出了一种通过有限视界搜索和基于搜索前沿的最短路径更新启发式值，来增强状态采样和启发式更新的广义方法。


<details>
  <summary>Details</summary>
Motivation: 许多序列决策问题可以建模为最短路径问题，启发式搜索是解决这些问题的方法，但现有方法通常依赖于单步Bellman更新，启发式更新和状态采样有提升空间。

Method: 提出的方法通过执行有限视界搜索，利用到搜索前沿的最短路径，综合考虑边成本和前沿状态的启发式值来更新每个状态的启发式值。

Result: 该方法通过改进状态采样和启发式更新，提高了学习启发式函数的效率和准确性。

Conclusion: 本文的方法通过广义的方式增强了传统启发式搜索，使其在解决最短路径问题时更加高效和准确。

Abstract: Many sequential decision-making problems can be formulated as shortest-path problems, where the objective is to reach a goal state from a given starting state. Heuristic search is a standard approach for solving such problems, relying on a heuristic function to estimate the cost to the goal from any given state. Recent approaches leverage reinforcement learning to learn heuristics by applying deep approximate value iteration. These methods typically rely on single-step Bellman updates, where the heuristic of a state is updated based on its best neighbor and the corresponding edge cost. This work proposes a generalized approach that enhances both state sampling and heuristic updates by performing limited-horizon searches and updating each state's heuristic based on the shortest path to the search frontier, incorporating both edge costs and the heuristic values of frontier states.

</details>


### [81] [Causal-HalBench: Uncovering LVLMs Object Hallucinations Through Causal Intervention](https://arxiv.org/abs/2511.10268)
*Zhe Xu,Zhicai Wang,Junkang Wu,Jinda Lu,Xiang Wang*

Main category: cs.AI

TL;DR: 大型视觉-语言模型（LVLMs）常常出现对象幻觉，本文提出通过因果分析来定义和量化模型中由共现偏见引起的伪相关，并构建了Causal-HalBench基准来评估模型的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: LVLMs在对象识别中常因训练数据中对象高度共现而出现伪相关，从而导致对象幻觉。现有基准主要关注幻觉检测，但缺乏对伪相关的正式定义和量化评估。

Method: 引入因果分析，建立结构因果模型（SCM）来定义伪相关，并开发Causal-HalBench基准，结合反事实样本和因果指标来评估模型鲁棒性。提出可扩展的反事实样本构建流程，利用专有LVLMs和文本到图像（T2I）模型生成样本。

Result: 使用Causal-HalBench评估主流LVLMs，发现这些模型均受伪相关影响，但程度各异。

Conclusion: LVLMs在对象识别中确实存在伪相关，Causal-HalBench为评估和改善模型鲁棒性提供了有效工具和方法。

Abstract: Large Vision-Language Models (LVLMs) often suffer from object hallucination, making erroneous judgments about the presence of objects in images. We propose this primar- ily stems from spurious correlations arising when models strongly associate highly co-occurring objects during train- ing, leading to hallucinated objects influenced by visual con- text. Current benchmarks mainly focus on hallucination de- tection but lack a formal characterization and quantitative evaluation of spurious correlations in LVLMs. To address this, we introduce causal analysis into the object recognition scenario of LVLMs, establishing a Structural Causal Model (SCM). Utilizing the language of causality, we formally de- fine spurious correlations arising from co-occurrence bias. To quantify the influence induced by these spurious correla- tions, we develop Causal-HalBench, a benchmark specifically constructed with counterfactual samples and integrated with comprehensive causal metrics designed to assess model ro- bustness against spurious correlations. Concurrently, we pro- pose an extensible pipeline for the construction of these coun- terfactual samples, leveraging the capabilities of proprietary LVLMs and Text-to-Image (T2I) models for their genera- tion. Our evaluations on mainstream LVLMs using Causal- HalBench demonstrate these models exhibit susceptibility to spurious correlations, albeit to varying extents.

</details>


### [82] [Bidirectional Bounded-Suboptimal Heuristic Search with Consistent Heuristics](https://arxiv.org/abs/2511.10272)
*Shahaf S. Shperberg,Natalie Morad,Lior Siag,Ariel Felner,Dor Atzmon*

Main category: cs.AI

TL;DR: 本文聚焦于有界次优双向搜索，提出了几种基于BAE*的变体算法，并通过实验评估与现有算法的对比。


<details>
  <summary>Details</summary>
Motivation: 以往的研究主要集中在最优搜索方法，而本文关注有界次优双向搜索，旨在限定解代价的次优程度。

Method: 基于最优双向搜索算法BAE*，为有界次优情境设计了几种变体算法。

Result: 通过实验评估，比较了新变体与其他有界次优双向算法及标准加权A*算法的性能，各算法在不同条件下表现各有优劣。

Conclusion: 不同算法在不同条件下各有优势，没有一种算法在所有情况下都是最优的。

Abstract: Recent advancements in bidirectional heuristic search have yielded significant theoretical insights and novel algorithms. While most previous work has concentrated on optimal search methods, this paper focuses on bounded-suboptimal bidirectional search, where a bound on the suboptimality of the solution cost is specified. We build upon the state-of-the-art optimal bidirectional search algorithm, BAE*, designed for consistent heuristics, and introduce several variants of BAE* specifically tailored for the bounded-suboptimal context. Through experimental evaluation, we compare the performance of these new variants against other bounded-suboptimal bidirectional algorithms as well as the standard weighted A* algorithm. Our results demonstrate that each algorithm excels under distinct conditions, highlighting the strengths and weaknesses of each approach.

</details>


### [83] [FactGuard: Event-Centric and Commonsense-Guided Fake News Detection](https://arxiv.org/abs/2511.10281)
*Jing He,Han Zhang,Yuanhui Xiao,Wei Guo,Shaowen Yao,Renyang Liu*

Main category: cs.AI

TL;DR: 提出了一种利用大语言模型（LLM）提取事件核心内容以降低写作风格影响的假新闻检测框架FactGuard，并引入动态可用性机制提升决策可靠性，通过知识蒸馏得到轻量版FactGuard-D以适配资源受限场景，在两个基准数据集上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 基于写作风格的假新闻检测方法因对手模仿真实新闻风格而效果下降，大语言模型虽具潜力却受限于浅层功能探索、模糊可用性和高推理成本，未被充分挖掘。

Method: 提出FactGuard框架，利用LLM提取事件核心内容；设计动态可用性机制识别事实推理中的矛盾与模糊情况，自适应结合LLM建议；采用知识蒸馏得到FactGuard-D以支持高效部署。

Result: 在两个基准数据集上的综合实验表明，该方法在鲁棒性和准确性方面均优于现有方法。

Conclusion: FactGuard有效解决了假新闻检测中的风格敏感性和LLM可用性问题，兼具高性能和实用性。

Abstract: Fake news detection methods based on writing style have achieved remarkable progress. However, as adversaries increasingly imitate the style of authentic news, the effectiveness of such approaches is gradually diminishing. Recent research has explored incorporating large language models (LLMs) to enhance fake news detection. Yet, despite their transformative potential, LLMs remain an untapped goldmine for fake news detection, with their real-world adoption hampered by shallow functionality exploration, ambiguous usability, and prohibitive inference costs. In this paper, we propose a novel fake news detection framework, dubbed FactGuard, that leverages LLMs to extract event-centric content, thereby reducing the impact of writing style on detection performance. Furthermore, our approach introduces a dynamic usability mechanism that identifies contradictions and ambiguous cases in factual reasoning, adaptively incorporating LLM advice to improve decision reliability. To ensure efficiency and practical deployment, we employ knowledge distillation to derive FactGuard-D, enabling the framework to operate effectively in cold-start and resource-constrained scenarios. Comprehensive experiments on two benchmark datasets demonstrate that our approach consistently outperforms existing methods in both robustness and accuracy, effectively addressing the challenges of style sensitivity and LLM usability in fake news detection.

</details>


### [84] [Beyond Verification: Abductive Explanations for Post-AI Assessment of Privacy Leakage](https://arxiv.org/abs/2511.10284)
*Belona Sonna,Alban Grastien,Claire Benn*

Main category: cs.AI

TL;DR: 提出了一个利用溯因解释来审计AI决策中隐私泄露的形式化框架。


<details>
  <summary>Details</summary>
Motivation: AI决策过程中存在通过推理泄露敏感信息的风险，需要一种能够识别和审计此类隐私泄露的框架。

Method: 提出的形式化框架通过溯因解释，识别模型决策的最小充分证据，并确定是否泄露了敏感信息。引入了潜在适用解释（PAE）的概念，以识别可以屏蔽具有敏感特征的个体的个体。

Result: 在德国信用数据集上的实验评估表明，模型决策过程中敏感信息的重要性会影响隐私泄露。尽管存在计算挑战和简化假设，结果表明该方法可以实现可解释的隐私审计。

Conclusion: 该框架通过提供人类可理解的解释，为审计工具提供了严格的隐私保障，为透明性、模型可解释性和隐私保护之间的协调提供了实用途径。

Abstract: Privacy leakage in AI-based decision processes poses significant risks, particularly when sensitive information can be inferred. We propose a formal framework to audit privacy leakage using abductive explanations, which identifies minimal sufficient evidence justifying model decisions and determines whether sensitive information disclosed. Our framework formalizes both individual and system-level leakage, introducing the notion of Potentially Applicable Explanations (PAE) to identify individuals whose outcomes can shield those with sensitive features. This approach provides rigorous privacy guarantees while producing human understandable explanations, a key requirement for auditing tools. Experimental evaluation on the German Credit Dataset illustrates how the importance of sensitive literal in the model decision process affects privacy leakage. Despite computational challenges and simplifying assumptions, our results demonstrate that abductive reasoning enables interpretable privacy auditing, offering a practical pathway to reconcile transparency, model interpretability, and privacy preserving in AI decision-making.

</details>


### [85] [Massively Parallel Proof-Number Search for Impartial Games and Beyond](https://arxiv.org/abs/2511.10339)
*Tomáš Čížek,Martin Balko,Martin Schmid*

Main category: cs.AI

TL;DR: 提出了一种可大规模并行化的Proof-Number Search算法，应用于Sprouts游戏并显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有并行版本的Proof-Number Search在多CPU核心上扩展性差，希望通过并行化加速计算。

Method: 采用两级并行化和共享信息，结合Grundy数减少游戏树，实现高效并行Proof-Number Search算法。

Result: 在1024核心上实现了332.9倍加速，性能优于现有最优Sprouts求解器GLOP，验证了42个新位置的Sprouts猜想。

Conclusion: 所提出的并行Proof-Number Search算法在大规模CPU上具有良好的扩展性，显著提升了Sprouts游戏的求解能力。

Abstract: Proof-Number Search is a best-first search algorithm with many successful applications, especially in game solving. As large-scale computing clusters become increasingly accessible, parallelization is a natural way to accelerate computation. However, existing parallel versions of Proof-Number Search are known to scale poorly on many CPU cores. Using two parallelized levels and shared information among workers, we present the first massively parallel version of Proof-Number Search that scales efficiently even on a large number of CPUs. We apply our solver, enhanced with Grundy numbers for reducing game trees, to the Sprouts game, a case study motivated by the long-standing Sprouts Conjecture. Our solver achieves a significantly improved 332.9$\times$ speedup when run on 1024 cores, enabling it to outperform the state-of-the-art Sprouts solver GLOP by four orders of magnitude in runtime and to generate proofs 1,000$\times$ more complex. Despite exponential growth in game tree size, our solver verified the Sprouts Conjecture for 42 new positions, nearly doubling the number of known outcomes.

</details>


### [86] [SITA: A Framework for Structure-to-Instance Theorem Autoformalization](https://arxiv.org/abs/2511.10356)
*Chenyi Li,Wanli Ma,Zichen Wang,Zaiwen Wen*

Main category: cs.AI

TL;DR: 开发了一个名为SITA的框架，用于在Lean证明助手中自动形式化抽象数学理论及其具体实例。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在数学推理方面已有进展，但在将抽象结构实例化为具体定理方面仍面临挑战。

Method: 将形式化的抽象结构视为包含定义、假设、操作和定理的模块化模板，并使用LLM生成和反馈引导优化来生成Lean定义和实例声明，并通过Lean的类型类机制进行整合。

Result: 在一个优化问题数据集上的实验表明，SITA能有效地将抽象结构基础上的不同实例进行形式化。

Conclusion: SITA框架成功地在抽象数学理论和其具体应用之间建立了桥梁，实现了高度自动化和形式正确性。

Abstract: While large language models (LLMs) have shown progress in mathematical reasoning, they still face challenges in formalizing theorems that arise from instantiating abstract structures in concrete settings. With the goal of auto-formalizing mathematical results at the research level, we develop a framework for structure-to-instance theorem autoformalization (SITA), which systematically bridges the gap between abstract mathematical theories and their concrete applications in Lean proof assistant. Formalized abstract structures are treated as modular templates that contain definitions, assumptions, operations, and theorems. These templates serve as reusable guides for the formalization of concrete instances. Given a specific instantiation, we generate corresponding Lean definitions and instance declarations, integrate them using Lean's typeclass mechanism, and construct verified theorems by checking structural assumptions. We incorporate LLM-based generation with feedback-guided refinement to ensure both automation and formal correctness. Experiments on a dataset of optimization problems demonstrate that SITA effectively formalizes diverse instances grounded in abstract structures.

</details>


### [87] [Explaining Decentralized Multi-Agent Reinforcement Learning Policies](https://arxiv.org/abs/2511.10409)
*Kayla Boggess,Sarit Kraus,Lu Feng*

Main category: cs.AI

TL;DR: 该论文提出了用于去中心化多智能体强化学习（MARL）策略的策略摘要生成方法和基于查询的解释方法，以解决现有方法无法处理去中心化环境中的不确定性和非确定性的问题。


<details>
  <summary>Details</summary>
Motivation: 多智能体强化学习在各种领域得到了广泛应用，但大多数现有解释方法专注于集中式MARL，无法解决去中心化环境中的不确定性和非确定性问题。

Method: 提出的方法包括生成策略摘要，捕捉任务顺序和智能体协作，并针对特定智能体行为的用户查询提供基于查询的解释，包括“何时”、“为什么不是”和“什么”类型的查询。

Result: 在四个MARL领域和两个去中心化MARL算法上评估了所提出的方法，结果表明其具有良好的泛化性和计算效率，用户研究显示策略摘要和解释显著提高了用户回答问题的表现。

Conclusion: 论文提出的方法有效提高了用户对去中心化MARL策略的理解和满意度，具有广泛的应用潜力。

Abstract: Multi-Agent Reinforcement Learning (MARL) has gained significant interest in recent years, enabling sequential decision-making across multiple agents in various domains. However, most existing explanation methods focus on centralized MARL, failing to address the uncertainty and nondeterminism inherent in decentralized settings. We propose methods to generate policy summarizations that capture task ordering and agent cooperation in decentralized MARL policies, along with query-based explanations for When, Why Not, and What types of user queries about specific agent behaviors. We evaluate our approach across four MARL domains and two decentralized MARL algorithms, demonstrating its generalizability and computational efficiency. User studies show that our summarizations and explanations significantly improve user question-answering performance and enhance subjective ratings on metrics such as understanding and satisfaction.

</details>


### [88] [Generalizing Analogical Inference from Boolean to Continuous Domains](https://arxiv.org/abs/2511.10416)
*Francisco Cunha,Yves Lepage,Zied Bouraoui,Miguel Couceiro*

Main category: cs.AI

TL;DR: 本文提出了一种基于广义均值的新型类比推理统一框架，适用于实值域，包括布尔分类和回归，解决了现有框架无法扩展至连续域的问题。


<details>
  <summary>Details</summary>
Motivation: 类比推理在人类认知和人工智能中广泛应用，但现有形式化框架局限于布尔域，无法处理回归或连续域问题。

Method: 引入基于广义均值和参数化类比的统一框架，定义实值域上的类比推理，并分析保持类比的函数类别。

Result: 在平滑假设下，推导了最坏和平均情况误差界，并发现现有泛化界在布尔设置下存在反例。

Conclusion: 该框架提供了一个适用于离散和连续域的类比推理通用理论，扩展了类比推理的应用范围。

Abstract: Analogical reasoning is a powerful inductive mechanism, widely used in human cognition and increasingly applied in artificial intelligence. Formal frameworks for analogical inference have been developed for Boolean domains, where inference is provably sound for affine functions and approximately correct for functions close to affine. These results have informed the design of analogy-based classifiers. However, they do not extend to regression tasks or continuous domains. In this paper, we revisit analogical inference from a foundational perspective. We first present a counterexample showing that existing generalization bounds fail even in the Boolean setting. We then introduce a unified framework for analogical reasoning in real-valued domains based on parameterized analogies defined via generalized means. This model subsumes both Boolean classification and regression, and supports analogical inference over continuous functions. We characterize the class of analogy-preserving functions in this setting and derive both worst-case and average-case error bounds under smoothness assumptions. Our results offer a general theory of analogical inference across discrete and continuous domains.

</details>


### [89] [Using Certifying Constraint Solvers for Generating Step-wise Explanations](https://arxiv.org/abs/2511.10428)
*Ignace Bleukx,Maarten Flippo,Bart Bogaerts,Emir Demirović,Tias Guns*

Main category: cs.AI

TL;DR: 该论文提出了一种利用约束求解器的证明生成逐步解释序列的新方法，以加快生成速度并保持质量。


<details>
  <summary>Details</summary>
Motivation: 当前逐步解释的计算成本很高，限制了其应用的问题范围。论文旨在通过利用约束求解器生成的证明来简化这一过程。

Method: 定义了一个抽象证明框架，其中证明和逐步解释都可以表示。提出多种将证明转换为逐步解释序列的方法，注重简化技术以保持序列及其步骤的简洁性。

Result: 结果显示，该方法显著加快了逐步解释序列的生成速度，同时解释质量与当前最先进水平相当。

Conclusion: 使用约束求解器的证明作为起点，可以高效地生成高质量的逐步解释序列，从而扩展了解释性约束求解的应用范围。

Abstract: In the field of Explainable Constraint Solving, it is common to explain to a user why a problem is unsatisfiable. A recently proposed method for this is to compute a sequence of explanation steps. Such a step-wise explanation shows individual reasoning steps involving constraints from the original specification, that in the end explain a conflict. However, computing a step-wise explanation is computationally expensive, limiting the scope of problems for which it can be used. We investigate how we can use proofs generated by a constraint solver as a starting point for computing step-wise explanations, instead of computing them step-by-step. More specifically, we define a framework of abstract proofs, in which both proofs and step-wise explanations can be represented. We then propose several methods for converting a proof to a step-wise explanation sequence, with special attention to trimming and simplification techniques to keep the sequence and its individual steps small. Our results show our method significantly speeds up the generation of step-wise explanation sequences, while the resulting step-wise explanation has a quality similar to the current state-of-the-art.

</details>


### [90] [Preference Elicitation for Step-Wise Explanations in Logic Puzzles](https://arxiv.org/abs/2511.10436)
*Marco Foschini,Marianne Defresne,Emilio Gamba,Bart Bogaerts,Tias Guns*

Main category: cs.AI

TL;DR: 该论文研究了通过交互偏好引导方法，从逐步解释中学习用户偏好的可行性，并提出了用于提高解释质量的技术。


<details>
  <summary>Details</summary>
Motivation: 逐步解释可以展示逻辑谜题及其他满足性问题的决策过程，但是如何选择最具可理解性的解释步骤是个挑战，需要用户定义目标函数来量化步骤质量。然而，定义好的目标函数是困难的。

Method: 论文引入了来自机器学习的交互式偏好引导方法，提出了两种动态归一化技术以稳定学习过程，并设计了MACHOP（Multi-Armed CHOice Perceptron）策略来生成更高质量的查询，结合非主导约束和基于置信区间的多样化。

Result: 在数独和逻辑网格谜题上的实验表明，MACHOP方法在人工用户和真实用户评估中均优于标准方法，能持续生成更高质量的解释。

Conclusion: 通过引入动态归一化和MACHOP策略，论文有效地解决了逐步解释中的偏好引导问题，提高了生成解释的质量。

Abstract: Step-wise explanations can explain logic puzzles and other satisfaction problems by showing how to derive decisions step by step. Each step consists of a set of constraints that derive an assignment to one or more decision variables. However, many candidate explanation steps exist, with different sets of constraints and different decisions they derive. To identify the most comprehensible one, a user-defined objective function is required to quantify the quality of each step. However, defining a good objective function is challenging. Here, interactive preference elicitation methods from the wider machine learning community can offer a way to learn user preferences from pairwise comparisons. We investigate the feasibility of this approach for step-wise explanations and address several limitations that distinguish it from elicitation for standard combinatorial problems. First, because the explanation quality is measured using multiple sub-objectives that can vary a lot in scale, we propose two dynamic normalization techniques to rescale these features and stabilize the learning process. We also observed that many generated comparisons involve similar explanations. For this reason, we introduce MACHOP (Multi-Armed CHOice Perceptron), a novel query generation strategy that integrates non-domination constraints with upper confidence bound-based diversification. We evaluate the elicitation techniques on Sudokus and Logic-Grid puzzles using artificial users, and validate them with a real-user evaluation. In both settings, MACHOP consistently produces higher-quality explanations than the standard approach.

</details>


### [91] [Non-Monotonic S4F Standpoint Logic](https://arxiv.org/abs/2511.10449)
*Piotr Gorczyca,Hannes Strass*

Main category: cs.AI

TL;DR: 提出了一种新的形式主义S4F Standpoint Logic，能表达多视角和非单调语义承诺。


<details>
  <summary>Details</summary>
Motivation: 现有的逻辑体系难以统一表示多视角和非单调推理。

Method: 定义了S4F Standpoint Logic的语法和语义，并分析了其计算复杂性。

Result: S4F Standpoint Logic的计算复杂性不高于其组成部分逻辑。

Conclusion: S4F Standpoint Logic为多视角和非单调推理提供了一个统一且高效的框架。

Abstract: Standpoint logics offer unified modal logic-based formalisms for representing multiple heterogeneous viewpoints. At the same time, many non-monotonic reasoning frameworks can be naturally captured using modal logics, in particular using the modal logic S4F. In this work, we propose a novel formalism called S4F Standpoint Logic, which generalises both S4F and standpoint propositional logic and is therefore capable of expressing multi-viewpoint, non-monotonic semantic commitments. We define its syntax and semantics and analyze its computational complexity, obtaining the result that S4F Standpoint Logic is not computationally harder than its constituent logics, whether in monotonic or non-monotonic form. We also outline mechanisms for credulous and sceptical acceptance and illustrate the framework with an example.

</details>


### [92] [Proceedings of The third international workshop on eXplainable AI for the Arts (XAIxArts)](https://arxiv.org/abs/2511.10482)
*Corey Ford,Elizabeth Wilson,Shuoyang Zheng,Gabriel Vigliensoni,Jeba Rezwana,Lanxi Xiao,Michael Clemens,Makayla Lewis,Drew Hemment,Alan Chamberlain,Helen Kennedy,Nick Bryan-Kinns*

Main category: cs.AI

TL;DR: 第三次可解释AI艺术国际研讨会(XAIxArts)聚集了人机交互、交互设计、AI、可解释AI(XAI)和数字艺术领域的研究人员，探讨XAI在艺术领域的作用。研讨会于2025年ACM创造力与认知会议(C&C 2025)期间在线举办。


<details>
  <summary>Details</summary>
Motivation: 探索可解释人工智能(XAI)在艺术和创意领域的应用潜力，促进跨学科合作，连接技术与艺术社区。

Method: 通过国际研讨会形式，汇集多学科研究人员进行知识分享和讨论。

Result: 成功举办了第三次XAIxArts国际研讨会，建立了相关研究人员社区。

Conclusion: XAI在艺术领域具有重要应用价值，需要持续推动跨学科合作，以促进技术与艺术的融合创新。

Abstract: This third international workshop on explainable AI for the Arts (XAIxArts) brought together a community of researchers in HCI, Interaction Design, AI, explainable AI (XAI), and digital arts to explore the role of XAI for the Arts. Workshop held at the 17th ACM Conference on Creativity and Cognition (C&C 2025), online.

</details>


### [93] [Rethinking Science in the Age of Artificial Intelligence](https://arxiv.org/abs/2511.10524)
*Maksim E. Eren,Dorianis M. Perez*

Main category: cs.AI

TL;DR: 本文探讨了人工智能（AI）如何改变研究工作的流程，并强调AI应作为科学家的助手而非替代者。


<details>
  <summary>Details</summary>
Motivation: AI正在重塑研究的构思、进行和传播方式，特别是在信息管理和实验设计方面，但其应用需要审慎整合与治理。

Method: 通过分析AI在研究工作中的各种应用，提出AI应增强而非取代人类判断，并呼吁通过政策推动AI的透明、可重复和负责任的使用。

Result: AI系统现在能够协助研究人员过滤文献、生成假设、设计实验等，标志着AI从计算工具转变为科学合作者。

Conclusion: 在学术工作流程中，如同行评审、伦理评估以及结果验证，AI必须增强人类判断，而不是取代人类。

Abstract: Artificial intelligence (AI) is reshaping how research is conceived, conducted, and communicated across fields from chemistry to biomedicine. This commentary examines how AI is transforming the research workflow. AI systems now help researchers manage the information deluge, filtering the literature, surfacing cross-disciplinary links for ideas and collaborations, generating hypotheses, and designing and executing experiments. These developments mark a shift from AI as a mere computational tool to AI as an active collaborator in science. Yet this transformation demands thoughtful integration and governance. We argue that at this time AI must augment but not replace human judgment in academic workflows such as peer review, ethical evaluation, and validation of results. This paper calls for the deliberate adoption of AI within the scientific practice through policies that promote transparency, reproducibility, and accountability.

</details>


### [94] [Regular Games -- an Automata-Based General Game Playing Language](https://arxiv.org/abs/2511.10593)
*Radosław Miernik,Marek Szykuła,Jakub Kowalski,Jakub Cieśluk,Łukasz Galas,Wojciech Pawlik*

Main category: cs.AI

TL;DR: 提出了一种新的通用游戏系统Regular Games (RG)，旨在提高计算效率和游戏设计便利性。


<details>
  <summary>Details</summary>
Motivation: RG的主要目标是设计一个既计算高效又方便游戏设计的系统。

Method: RG系统包含多种语言，核心是一个低层语言，通过有限自动机定义规则，并引入高层语言用于游戏设计，最终转换为低层语言。

Result: RG在效率上超越了现有技术，比其他GGP系统（如Regular Boardgames和Ludii）生成更快的正向模型。

Conclusion: RG不仅计算高效，还具备便利的游戏设计工具生态系统，包括编辑器、自动机可视化、基准测试工具和调试器。

Abstract: We propose a new General Game Playing (GGP) system called Regular Games (RG). The main goal of RG is to be both computationally efficient and convenient for game design. The system consists of several languages. The core component is a low-level language that defines the rules by a finite automaton. It is minimal with only a few mechanisms, which makes it easy for automatic processing (by agents, analysis, optimization, etc.). The language is universal for the class of all finite turn-based games with imperfect information. Higher-level languages are introduced for game design (by humans or Procedural Content Generation), which are eventually translated to a low-level language. RG generates faster forward models than the current state of the art, beating other GGP systems (Regular Boardgames, Ludii) in terms of efficiency. Additionally, RG's ecosystem includes an editor with LSP, automaton visualization, benchmarking tools, and a debugger of game description transformations.

</details>
