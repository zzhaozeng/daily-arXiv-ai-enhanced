<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 62]
- [cs.AI](#cs.AI) [Total: 32]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [BitSkip: An Empirical Analysis of Quantization and Early Exit Composition](https://arxiv.org/abs/2510.23766)
*Ramshankar Bhuvaneswaran,Handan Liu*

Main category: cs.CL

TL;DR: 本文介绍了BitSkip，一个用于探索大型语言模型中复杂技术相互作用的混合架构框架。研究发现，简化的8位量化模型（BitSkip-V1）性能优于更复杂的4位和Hadamard增强模型，并且几乎与全精度模型相当。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型追求高效性，但复杂技术如极端量化和动态路由的组合效应尚不清楚。因此，研究旨在探索这些方法之间的相互作用。

Method: 引入BitSkip，一个混合架构框架，用于系统探索这些技术组合。测试了8位和4位量化模型，以及Hadamard变换的效果。

Result: BitSkip-V1（8位量化模型）性能优于4位和Hadamard增强模型，并且其困惑度为1.13，接近全精度模型的1.19。引入Hadamard变换导致性能大幅下降。BitSkip-V1在早期退出方面表现良好，第18层提供32.5%的速度提升，质量损失仅4%。

Conclusion: 简化的8位量化模型（BitSkip-V1）在性能和效率方面优于更复杂的模型，并且Hadamard变换对训练稳定性有负面影响。

Abstract: The pursuit of efficient Large Language Models (LLMs) has led to increasingly
complex techniques like extreme quantization and dynamic routing. While
individual benefits of these methods are well-documented, their compositional
effects remain poorly understood. This paper introduces BitSkip, a hybrid
architectural framework for systematically explor- ing these interactions.
Counter-intuitively, our findings reveal that a simple 8-bit quantized model
without Hadamard transform (BitSkip-V1) not only outperforms its more complex
4-bit and Hadamard-enhanced counterparts but also competes the full-precision
baseline in quality (perplexity of 1.13 vs 1.19) . The introduction of Hadamard
transforms, even at 8- bit precision, catastrophically degraded performance by
over 37,000%, tracing fundamental training instability. Our BitSkip-V1 recipe
demonstrates superior early-exit characteristics, with layer 18 providing
optimal 32.5% speed gain for minimal 4% quality loss.

</details>


### [2] [How Pragmatics Shape Articulation: A Computational Case Study in STEM ASL Discourse](https://arxiv.org/abs/2510.23842)
*Saki Imai,Lee Kezar,Laurel Aichler,Mert Inan,Erin Walker,Alicia Wooten,Lorna Quandt,Malihe Alikhani*

Main category: cs.CL

TL;DR: 该论文收集了美国手语（ASL）STEM对话的动作捕捉数据集，以分析自然对话中的变异性，并比较了互动对话、单独讲座和口译文章之间的差异。


<details>
  <summary>Details</summary>
Motivation: 现有手语模型多基于孤立词汇数据，忽略了自然对话的变异性。该研究旨在填补这一空白，通过分析真实对话中的时空变化和发音风格，特别是在教育环境中的新词汇使用情况。

Method: 研究团队收集了ASL STEM对话的动作捕捉数据集，并使用连续运动学特征分析对话中的具体参与度，以及STEM词汇重复提及时的时空变化。

Result: 与孤立手语相比，对话中的手语持续时间平均缩短了24.6%-44.6%，并显示出在独白语境中不存在的显著减少。

Conclusion: 该研究通过语言分析和计算建模的结合，探讨了语用学如何塑造手语发音及其在手语技术中的表示，为理解手语的自然变异性提供了新的视角。

Abstract: Most state-of-the-art sign language models are trained on interpreter or
isolated vocabulary data, which overlooks the variability that characterizes
natural dialogue. However, human communication dynamically adapts to contexts
and interlocutors through spatiotemporal changes and articulation style. This
specifically manifests itself in educational settings, where novel vocabularies
are used by teachers, and students. To address this gap, we collect a motion
capture dataset of American Sign Language (ASL) STEM (Science, Technology,
Engineering, and Mathematics) dialogue that enables quantitative comparison
between dyadic interactive signing, solo signed lecture, and interpreted
articles. Using continuous kinematic features, we disentangle dialogue-specific
entrainment from individual effort reduction and show spatiotemporal changes
across repeated mentions of STEM terms. On average, dialogue signs are
24.6%-44.6% shorter in duration than the isolated signs, and show significant
reductions absent in monologue contexts. Finally, we evaluate sign embedding
models on their ability to recognize STEM signs and approximate how entrained
the participants become over time. Our study bridges linguistic analysis and
computational modeling to understand how pragmatics shape sign articulation and
its representation in sign language technologies.

</details>


### [3] [CRADLE Bench: A Clinician-Annotated Benchmark for Multi-Faceted Mental Health Crisis and Safety Risk Detection](https://arxiv.org/abs/2510.23845)
*Grace Byun,Rebecca Lipschutz,Sean T. Minton,Abigail Lott,Jinho D. Choi*

Main category: cs.CL

TL;DR: 本文介绍了CRADLE BENCH，一个用于多层面危机检测的基准，涵盖了七种临床标准定义的危机类型，并首次引入了时间标签。


<details>
  <summary>Details</summary>
Motivation: 检测心理健康危机（如自杀意念、强奸、家庭暴力等）对语言模型来说是一个关键但尚未充分探索的挑战，未能识别这些情况可能导致严重后果。

Method: 引入了CRADLE BENCH，该基准包括600个临床医生标注的评估样本和420个开发样本，以及一个约4K样本的训练语料库，这些样本使用多个语言模型的多数投票集合自动标注。还基于共识和一致集合协议，对六个危机检测模型进行了微调。

Result: 多数投票集合标注显著优于单一模型标注，提供了不同协议标准下训练的互补模型。

Conclusion: CRADLE BENCH为多层面危机检测提供了全面且有效的评估标准，并展示了集成方法在标注和模型训练中的优势。

Abstract: Detecting mental health crisis situations such as suicide ideation, rape,
domestic violence, child abuse, and sexual harassment is a critical yet
underexplored challenge for language models. When such situations arise during
user--model interactions, models must reliably flag them, as failure to do so
can have serious consequences. In this work, we introduce CRADLE BENCH, a
benchmark for multi-faceted crisis detection. Unlike previous efforts that
focus on a limited set of crisis types, our benchmark covers seven types
defined in line with clinical standards and is the first to incorporate
temporal labels. Our benchmark provides 600 clinician-annotated evaluation
examples and 420 development examples, together with a training corpus of
around 4K examples automatically labeled using a majority-vote ensemble of
multiple language models, which significantly outperforms single-model
annotation. We further fine-tune six crisis detection models on subsets defined
by consensus and unanimous ensemble agreement, providing complementary models
trained under different agreement criteria.

</details>


### [4] [Can LLMs Narrate Tabular Data? An Evaluation Framework for Natural Language Representations of Text-to-SQL System Outputs](https://arxiv.org/abs/2510.23854)
*Jyotika Singh,Weiyi Sun,Amit Agarwal,Viji Krishnamurthy,Yassine Benajiba,Sujith Ravi,Dan Roth*

Main category: cs.CL

TL;DR: 本文介绍了一种新颖的评估方法Combo-Eval，用于判断大型语言模型生成的自然语言表示，并引入了首个专门用于NLR基准测试的数据集NLR-BIRD。


<details>
  <summary>Details</summary>
Motivation: 当前，将表格数据库结果转化为自然语言表示（NLR）生成通常由大型语言模型（LLMs）处理，但信息损失或错误在NL展示表格结果方面仍探索不足。

Method: Combo-Eval结合了多种现有方法的优势，通过优化评估保真度，显著减少了LLM调用次数。

Result: Combo-Eval在人类判断方面表现出优越的一致性，并能在有或没有基本真实参考的情况下应用。

Conclusion: Combo-Eval在评估NLR生成方面比现有方法更为有效，并且减少了LLM的调用次数，为自然语言数据库交互提供了更可靠的评估手段。

Abstract: In modern industry systems like multi-turn chat agents, Text-to-SQL
technology bridges natural language (NL) questions and database (DB) querying.
The conversion of tabular DB results into NL representations (NLRs) enables the
chat-based interaction. Currently, NLR generation is typically handled by large
language models (LLMs), but information loss or errors in presenting tabular
results in NL remains largely unexplored. This paper introduces a novel
evaluation method - Combo-Eval - for judgment of LLM-generated NLRs that
combines the benefits of multiple existing methods, optimizing evaluation
fidelity and achieving a significant reduction in LLM calls by 25-61%.
Accompanying our method is NLR-BIRD, the first dedicated dataset for NLR
benchmarking. Through human evaluations, we demonstrate the superior alignment
of Combo-Eval with human judgments, applicable across scenarios with and
without ground truth references.

</details>


### [5] [Language Models for Longitudinal Clinical Prediction](https://arxiv.org/abs/2510.23884)
*Tananun Songdechakraiwut,Michael Lutz*

Main category: cs.CL

TL;DR: 一个轻量级框架，通过整合患者历史和上下文信息，无需微调即可适应大型语言模型分析纵向临床数据。


<details>
  <summary>Details</summary>
Motivation: 解决在纵向临床数据分析中对模型微调的需求，尤其是在训练数据较少的情况下，实现早期阿尔茨海默病监测。

Method: 将患者历史和上下文信息整合进语言模型空间，生成准确预测，无需进行模型微调。

Result: 该方法在神经心理评估中实现了准确和可靠的性能，即使在训练数据极少的情况下。

Conclusion: 该框架在临床数据分析中具有潜力，特别是在早期阿尔茨海默病监测中表现突出。

Abstract: We explore a lightweight framework that adapts frozen large language models
to analyze longitudinal clinical data. The approach integrates patient history
and context within the language model space to generate accurate forecasts
without model fine-tuning. Applied to neuropsychological assessments, it
achieves accurate and reliable performance even with minimal training data,
showing promise for early-stage Alzheimer's monitoring.

</details>


### [6] [AfriMTEB and AfriE5: Benchmarking and Adapting Text Embedding Models for African Languages](https://arxiv.org/abs/2510.23896)
*Kosei Uemura,Miaoran Zhang,David Ifeoluwa Adelani*

Main category: cs.CL

TL;DR: 本文介绍了AfriMTEB，一个覆盖59种非洲语言的MMTEB扩展，并引入了6个新数据集和AfriE5模型，通过跨语言对比蒸馏提升了非洲语言的表现。


<details>
  <summary>Details</summary>
Motivation: 非洲语言在现有文本嵌入基准中代表性不足，限制了NLP任务在这些语言上的表现。

Method: 扩展MMTEB，引入AfriMTEB，覆盖更多非洲语言和任务，并通过跨语言对比蒸馏开发AfriE5模型。

Result: AfriE5在多个任务上实现了最先进的性能，超越了Gemini-Embeddings和mE5等强大基线。

Conclusion: AfriMTEB和AfriE5的引入显著提高了非洲语言在多种NLP任务上的表现，填补了这些语言在文本嵌入领域的空白。

Abstract: Text embeddings are an essential building component of several NLP tasks such
as retrieval-augmented generation which is crucial for preventing
hallucinations in LLMs. Despite the recent release of massively multilingual
MTEB (MMTEB), African languages remain underrepresented, with existing tasks
often repurposed from translation benchmarks such as FLORES clustering or
SIB-200. In this paper, we introduce AfriMTEB -- a regional expansion of MMTEB
covering 59 languages, 14 tasks, and 38 datasets, including six newly added
datasets. Unlike many MMTEB datasets that include fewer than five languages,
the new additions span 14 to 56 African languages and introduce entirely new
tasks, such as hate speech detection, intent detection, and emotion
classification, which were not previously covered. Complementing this, we
present AfriE5, an adaptation of the instruction-tuned mE5 model to African
languages through cross-lingual contrastive distillation. Our evaluation shows
that AfriE5 achieves state-of-the-art performance, outperforming strong
baselines such as Gemini-Embeddings and mE5.

</details>


### [7] [Breaking the Benchmark: Revealing LLM Bias via Minimal Contextual Augmentation](https://arxiv.org/abs/2510.23921)
*Kaveh Eskandari Miandoab,Mahammed Kamruzzaman,Arshia Gharooni,Gene Louis Kim,Vasanth Sarathy,Ninareh Mehrabi*

Main category: cs.CL

TL;DR: 本文提出了一种新颖的通用增强框架，通过三个即插即用的步骤来评估大型语言模型在公平性方面的偏见。


<details>
  <summary>Details</summary>
Motivation: 尽管在开发避免使用刻板信息的模型方面取得了进展，但用于偏见对齐的方法仍显得脆弱，因此需要更全面的评估框架。

Method: 引入了一种包含三个步骤的即插即用增强框架，并将其应用于公平性评估数据集（Bias Benchmark for Question Answering, BBQ）。

Result: 研究发现，包括最先进的开放和封闭权重模型在内的大型语言模型容易受到输入扰动的影响，表现出更高的刻板行为倾向，尤其是在目标人群属于文献中研究较少的社区时。

Conclusion: 当前的大型语言模型在处理不同社区的公平性时仍存在偏见，强调了扩展公平性和安全性研究以涵盖更多多样化社区的必要性。

Abstract: Large Language Models have been shown to demonstrate stereotypical biases in
their representations and behavior due to the discriminative nature of the data
that they have been trained on. Despite significant progress in the development
of methods and models that refrain from using stereotypical information in
their decision-making, recent work has shown that approaches used for bias
alignment are brittle. In this work, we introduce a novel and general
augmentation framework that involves three plug-and-play steps and is
applicable to a number of fairness evaluation benchmarks. Through application
of augmentation to a fairness evaluation dataset (Bias Benchmark for Question
Answering (BBQ)), we find that Large Language Models (LLMs), including
state-of-the-art open and closed weight models, are susceptible to
perturbations to their inputs, showcasing a higher likelihood to behave
stereotypically. Furthermore, we find that such models are more likely to have
biased behavior in cases where the target demographic belongs to a community
less studied by the literature, underlining the need to expand the fairness and
safety research to include more diverse communities.

</details>


### [8] [Auto prompting without training labels: An LLM cascade for product quality assessment in e-commerce catalogs](https://arxiv.org/abs/2510.23941)
*Soham Satyadharma,Fatemeh Sheikholeslami,Swati Kaul,Aziz Umit Batur,Suleiman A. Khan*

Main category: cs.CL

TL;DR: 本文提出了一种无需训练、自动提示大型语言模型（LLMs）以评估电子商务中产品质量的新级联方法。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在通过自动生成和优化提示，提升在复杂工业目录中进行领域特定知识评估的效率和效果，减少对领域专家的依赖。

Method: 该方法从一个人工制作的提示种子开始，通过级联方式自动优化指令，无需训练标签或模型微调，以适应不同产品目录的需求。

Result: 经验评估表明，与传统思维链提示相比，该自动提示级联在精确度和召回率上提高了8-10%，并将领域专家的工作时间从5.1小时减少到3分钟。

Conclusion: 该级联方法在多种语言和多个质量评估任务中有效推广，持续保持性能提升，大幅减少了人工参与。

Abstract: We introduce a novel, training free cascade for auto-prompting Large Language
Models (LLMs) to assess product quality in e-commerce. Our system requires no
training labels or model fine-tuning, instead automatically generating and
refining prompts for evaluating attribute quality across tens of thousands of
product category-attribute pairs. Starting from a seed of human-crafted
prompts, the cascade progressively optimizes instructions to meet
catalog-specific requirements. This approach bridges the gap between general
language understanding and domain-specific knowledge at scale in complex
industrial catalogs. Our extensive empirical evaluations shows the auto-prompt
cascade improves precision and recall by $8-10\%$ over traditional
chain-of-thought prompting. Notably, it achieves these gains while reducing
domain expert effort from 5.1 hours to 3 minutes per attribute - a $99\%$
reduction. Additionally, the cascade generalizes effectively across five
languages and multiple quality assessment tasks, consistently maintaining
performance gains.

</details>


### [9] [Leveraging LLMs for Early Alzheimer's Prediction](https://arxiv.org/abs/2510.23946)
*Tananun Songdechakraiwut*

Main category: cs.CL

TL;DR: 提出了一个连接组信息的大语言模型框架，用于早期阿尔茨海默病的预测。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够利用动态fMRI连接性进行临床预测的模型，以改进早期阿尔茨海默病的检测方法。

Method: 将动态fMRI连接性编码为时间序列，应用鲁棒归一化，并将这些数据映射到适合预训练大语言模型的表示。

Result: 该方法在早期阿尔茨海默病检测中实现了敏感预测，错误率远低于临床公认的范围。

Conclusion: 该框架对及时干预阿尔茨海默病具有重要意义。

Abstract: We present a connectome-informed LLM framework that encodes dynamic fMRI
connectivity as temporal sequences, applies robust normalization, and maps
these data into a representation suitable for a frozen pre-trained LLM for
clinical prediction. Applied to early Alzheimer's detection, our method
achieves sensitive prediction with error rates well below clinically recognized
margins, with implications for timely Alzheimer's intervention.

</details>


### [10] [Uncovering the Potential Risks in Unlearning: Danger of English-only Unlearning in Multilingual LLMs](https://arxiv.org/abs/2510.23949)
*Kyomin Hwang,Hyeonjin Kim,Seungyeon Kim,Sunghyun Wee,Nojun Kwak*

Main category: cs.CL

TL;DR: 该论文探讨了多语言大模型在进行遗忘处理时由于语言混淆现象导致标准基于参考的度量失效，并提出了一种新的基于语义的度量方法。


<details>
  <summary>Details</summary>
Motivation: 现有研究未能充分分析多语言LLMs在进行仅英语数据遗忘时的盲点，尤其是在完全使用平行多语言数据微调后，模型会产生语言混淆，这影响了评估效果。

Method: 通过三步解决语言混淆问题：(1) 引入N-gram-based Language-Mix (N-Mix) 分数来量化语言混淆，(2) 演示基于参考的度量在高N-Mix分数时产生假阴性，(3) 提出需要可以直接评估生成句子内容的新类型度量——基于语义的度量。

Result: N-Mix分数揭示了语言混淆在多语言LLMs中的普遍性和一致性，并表明标准参考度量在语言混淆严重时失效。

Conclusion: 论文强调了引入新的基于语义的度量来评估多语言LLMs遗忘的必要性，以解决语言混淆带来的问题。

Abstract: There have been a couple of studies showing that attempting to erase
multilingual knowledge using only English data is insufficient for multilingual
LLMs. However, their analyses remain highly performance-oriented. In this
paper, we switch the point of view to evaluation, and address an additional
blind spot which reveals itself when the multilingual LLM is fully finetuned
with parallel multilingual dataset before unlearning. Here, language confusion
occurs whereby a model responds in language different from that of the input
prompt. Language confusion is a problematic phenomenon in unlearning, causing
the standard reference-based metrics to fail. We tackle this phenomenon in
three steps: (1) introduce N-gram-based Language-Mix (N-Mix) score to
quantitatively show the language confusion is pervasive and consistent in
multilingual LLMs, (2) demonstrate that reference-based metrics result in false
negatives when N-Mix score is high, and(3) suggest the need of new type of
unlearning evaluation that can directly assess the content of the generated
sentences. We call this type of metrics as semantic-based metric.

</details>


### [11] [M-Eval: A Heterogeneity-Based Framework for Multi-evidence Validation in Medical RAG Systems](https://arxiv.org/abs/2510.23995)
*Mengzhou Sun,Sendong Zhao,Jianyu Chen,Haochun Wang,Bin Qin*

Main category: cs.CL

TL;DR: 提出了一种名为M-Eval的新方法来增强医学问答系统中的检索增强生成（RAG）技术，通过异质性分析检查多来源证据，以减少错误信息生成和提高系统可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前的RAG应用存在生成错误信息和未能正确使用外部知识的问题，需要解决这些问题以提高医学问答系统的准确性和可靠性。

Method: 提出M-Eval方法，受循证医学（EBM）异质性分析启发，从外部知识库提取医学文献，检索RAG系统生成的证据文档，通过异质性分析检查证据对响应中不同观点的支持程度，并评估证据的可靠性。

Result: M-Eval方法在各种大语言模型中表现出高达23.31%的准确性提升。

Conclusion: 该工作有助于检测当前基于RAG的医学系统中的错误，使大语言模型的应用更可靠，并减少诊断错误。

Abstract: Retrieval-augmented Generation (RAG) has demonstrated potential in enhancing
medical question-answering systems through the integration of large language
models (LLMs) with external medical literature. LLMs can retrieve relevant
medical articles to generate more professional responses efficiently. However,
current RAG applications still face problems. They generate incorrect
information, such as hallucinations, and they fail to use external knowledge
correctly. To solve these issues, we propose a new method named M-Eval. This
method is inspired by the heterogeneity analysis approach used in
Evidence-Based Medicine (EBM). Our approach can check for factual errors in RAG
responses using evidence from multiple sources. First, we extract additional
medical literature from external knowledge bases. Then, we retrieve the
evidence documents generated by the RAG system. We use heterogeneity analysis
to check whether the evidence supports different viewpoints in the response. In
addition to verifying the accuracy of the response, we also assess the
reliability of the evidence provided by the RAG system. Our method shows an
improvement of up to 23.31% accuracy across various LLMs. This work can help
detect errors in current RAG-based medical systems. It also makes the
applications of LLMs more reliable and reduces diagnostic errors.

</details>


### [12] [PICOs-RAG: PICO-supported Query Rewriting for Retrieval-Augmented Generation in Evidence-Based Medicine](https://arxiv.org/abs/2510.23998)
*Mengzhou Sun,Sendong Zhao,Jianyu Chen,Bin Qin*

Main category: cs.CL

TL;DR: 提出PICOs-RAG方法，通过扩展和标准化查询，提高医学文献检索的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 当前RAG方法在处理复杂临床查询时表现不佳，缺乏客观性和效率，需要改进查询扩展技术以支持循证医学（EBM）。

Method: 利用PICOs-RAG方法，将用户查询扩展和标准化为专业查询，并使用PICO格式提取关键信息进行检索。

Result: 该方法显著提高了检索效率和相关性，相比基线方法提升了8.8%。

Conclusion: PICOs-RAG提高了大型语言模型在EBM中的性能，使其成为一个更有帮助和可靠的医学助手。

Abstract: Evidence-based medicine (EBM) research has always been of paramount
importance. It is important to find appropriate medical theoretical support for
the needs from physicians or patients to reduce the occurrence of medical
accidents. This process is often carried out by human querying relevant
literature databases, which lacks objectivity and efficiency. Therefore,
researchers utilize retrieval-augmented generation (RAG) to search for evidence
and generate responses automatically. However, current RAG methods struggle to
handle complex queries in real-world clinical scenarios. For example, when
queries lack certain information or use imprecise language, the model may
retrieve irrelevant evidence and generate unhelpful answers. To address this
issue, we present the PICOs-RAG to expand the user queries into a better
format. Our method can expand and normalize the queries into professional ones
and use the PICO format, a search strategy tool present in EBM, to extract the
most important information used for retrieval. This approach significantly
enhances retrieval efficiency and relevance, resulting in up to an 8.8\%
improvement compared to the baseline evaluated by our method. Thereby the
PICOs-RAG improves the performance of the large language models into a helpful
and reliable medical assistant in EBM.

</details>


### [13] [META-RAG: Meta-Analysis-Inspired Evidence-Re-Ranking Method for Retrieval-Augmented Generation in Evidence-Based Medicine](https://arxiv.org/abs/2510.24003)
*Mengzhou Sun,Sendong Zhao,Jianyu Chen,Haochun Wang,Bin Qin*

Main category: cs.CL

TL;DR: 提出一种新方法，通过可靠性、异质性和可外推性分析，对医学证据进行重新排序和筛选，从而提高大型语言模型在循证医学中的表现。


<details>
  <summary>Details</summary>
Motivation: 循证医学对证据质量要求严格，但现有RAG技术在EBM任务中难以有效区分高质量证据。

Method: 受EBM中meta分析的启发，采用多种EBM方法（可靠性分析、异质性分析和可外推性分析）进行证据筛选和重排序。

Result: 实验结果表明，该方法在PubMed数据集上显著提升了证据的质量和可靠性，诊断准确率提高了11.4%。

Conclusion: 该方法有效减少错误知识注入，有助于用户获得更高效的回复，提高RAG在循证医学中的应用效果。

Abstract: Evidence-based medicine (EBM) holds a crucial role in clinical application.
Given suitable medical articles, doctors effectively reduce the incidence of
misdiagnoses. Researchers find it efficient to use large language models (LLMs)
techniques like RAG for EBM tasks. However, the EBM maintains stringent
requirements for evidence, and RAG applications in EBM struggle to efficiently
distinguish high-quality evidence. Therefore, inspired by the meta-analysis
used in EBM, we provide a new method to re-rank and filter the medical
evidence. This method presents multiple principles to filter the best evidence
for LLMs to diagnose. We employ a combination of several EBM methods to emulate
the meta-analysis, which includes reliability analysis, heterogeneity analysis,
and extrapolation analysis. These processes allow the users to retrieve the
best medical evidence for the LLMs. Ultimately, we evaluate these high-quality
articles and show an accuracy improvement of up to 11.4% in our experiments and
results. Our method successfully enables RAG to extract higher-quality and more
reliable evidence from the PubMed dataset. This work can reduce the infusion of
incorrect knowledge into responses and help users receive more effective
replies.

</details>


### [14] [TEXT2DB: Integration-Aware Information Extraction with Large Language Model Agents](https://arxiv.org/abs/2510.24014)
*Yizhu Jiao,Sha Li,Sizhe Zhou,Heng Ji,Jiawei Han*

Main category: cs.CL

TL;DR: 提出了一种新的信息抽取任务TEXT2DB，强调将信息抽取结果与目标数据库整合，并提出了OPAL框架来实现该任务。


<details>
  <summary>Details</summary>
Motivation: 传统信息抽取（IE）面临IE本体与下游应用需求不匹配的问题，因此需要一种新的方法来整合IE输出与目标数据库。

Method: 提出TEXT2DB任务，通过用户指令、文档集和数据库，要求模型从文档集中抽取值更新数据库以满足用户指令。引入OPAL框架，包括Observer、Planner和Analyzer组件，以生成和优化代码计划。

Result: OPAL框架能够成功适应不同的数据库模式，通过生成不同的代码计划并调用所需的IE模型。实验展示了处理数据填充、行填充和列增加等常见需求的能力。

Conclusion: TEXT2DB任务及其OPAL框架有效整合了信息抽取与数据库，并指出在大数据库和复杂依赖及抽取幻觉等情况下仍需进一步研究。

Abstract: The task of information extraction (IE) is to extract structured knowledge
from text. However, it is often not straightforward to utilize IE output due to
the mismatch between the IE ontology and the downstream application needs. We
propose a new formulation of IE TEXT2DB that emphasizes the integration of IE
output and the target database (or knowledge base). Given a user instruction, a
document set, and a database, our task requires the model to update the
database with values from the document set to satisfy the user instruction.
This task requires understanding user instructions for what to extract and
adapting to the given DB/KB schema for how to extract on the fly. To evaluate
this new task, we introduce a new benchmark featuring common demands such as
data infilling, row population, and column addition. In addition, we propose an
LLM agent framework OPAL (Observe-PlanAnalyze LLM) which includes an Observer
component that interacts with the database, the Planner component that
generates a code-based plan with calls to IE models, and the Analyzer component
that provides feedback regarding code quality before execution. Experiments
show that OPAL can successfully adapt to diverse database schemas by generating
different code plans and calling the required IE models. We also highlight
difficult cases such as dealing with large databases with complex dependencies
and extraction hallucination, which we believe deserve further investigation.
Source code: https://github.com/yzjiao/Text2DB

</details>


### [15] [Teaching LLMs to Abstain via Fine-Grained Semantic Confidence Reward](https://arxiv.org/abs/2510.24020)
*Hao An,Yang Xu*

Main category: cs.CL

TL;DR: 提出了一种通过细粒度语义置信度奖励（FineSCoRe）来增强大型语言模型（LLM）在超出知识范围时拒绝回答的精确性的新方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常使用粗粒度信号来指导LLM拒绝回答，这可能导致模型对自身知识边界的认知不精确。为解决这一问题，作者提出了一种新的强化学习框架。

Method: 该方法通过采样多个候选答案并进行语义聚类，然后训练LLM保留高置信度聚类中的答案并丢弃低置信度聚类中的答案，从而实现精确的事后拒绝。

Result: 该方法在领域内和分布外基准测试中显著提高了可靠性。

Conclusion: FineSCoRe通过细粒度语义置信度奖励，有效提升了LLM在拒绝回答任务中的表现和可靠性。

Abstract: Mitigating hallucinations in Large Language Models (LLMs) is critical for
their reliable deployment. Existing methods typically fine-tune LLMs to abstain
from answering questions beyond their knowledge scope. However, these methods
often rely on coarse-grained signals to guide LLMs to abstain, such as overall
confidence or uncertainty scores on multiple sampled answers, which may result
in an imprecise awareness of the model's own knowledge boundaries. To this end,
we propose a novel reinforcement learning framework built on
$\textbf{\underline{Fi}ne-grained \underline{S}emantic \underline{Co}nfidence
\underline{Re}ward (\Ours)}$, which guides LLMs to abstain via sample-specific
confidence. Specifically, our method operates by sampling multiple candidate
answers and conducting semantic clustering, then training the LLM to retain
answers within high-confidence clusters and discard those within low-confidence
ones, thereby promoting accurate post-hoc abstention. Additionally, we propose
a new metric for evaluating the reliability of abstention fine-tuning tasks
more comprehensively. Our method significantly enhances reliability in both
in-domain and out-of-distribution benchmarks.

</details>


### [16] [SpecKD: Speculative Decoding for Effective Knowledge Distillation of LLMs](https://arxiv.org/abs/2510.24021)
*Haiduo Huang,Jiangcheng Song,Yadong Zhang,Pengju Ren*

Main category: cs.CL

TL;DR: 提出了一种新的知识蒸馏方法SpecKD，通过动态token级门控机制提升学生模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统知识蒸馏方法对所有token均匀应用蒸馏损失，忽略了教师模型的置信度，可能导致噪声引入，影响学生模型性能。

Method: SpecKD采用动态、token级门控机制，只对“接受”的token应用蒸馏损失，而对“拒绝”的token进行屏蔽。

Result: 在多个文本生成任务上的实验表明，SpecKD显著优于强基线方法，实现更稳定的训练和更优秀的学生模型。

Conclusion: SpecKD是一种有效的知识蒸馏方法，通过选择性学习教师模型的输出，提高了学生模型的性能和稳定性。

Abstract: Knowledge Distillation (KD) has become a cornerstone technique for
compressing Large Language Models (LLMs) into smaller, more efficient student
models. However, conventional KD approaches typically apply the distillation
loss uniformly across all tokens, regardless of the teacher's confidence. This
indiscriminate mimicry can introduce noise, as the student is forced to learn
from the teacher's uncertain or high-entropy predictions, which may ultimately
harm student performance-especially when the teacher is much larger and more
powerful. To address this, we propose Speculative Knowledge Distillation
(SpecKD), a novel, plug-and-play framework that introduces a dynamic,
token-level gating mechanism inspired by the "propose-and-verify" paradigm of
speculative decoding. At each step, the student's token proposal is verified
against the teacher's distribution; the distillation loss is selectively
applied only to "accepted" tokens, while "rejected" tokens are masked out.
Extensive experiments on diverse text generation tasks show that SpecKD
consistently and significantly outperforms strong KD baselines, leading to more
stable training and more capable student models, and achieving state-of-the-art
results.

</details>


### [17] [Success and Cost Elicit Convention Formation for Efficient Communication](https://arxiv.org/abs/2510.24023)
*Saujas Vaduguru,Yilun Hua,Yoav Artzi,Daniel Fried*

Main category: cs.CL

TL;DR: 该论文提出了一种训练大型多模态模型以形成语言惯例的方法，从而实现高效沟通。


<details>
  <summary>Details</summary>
Motivation: 人类利用共享的会话上下文形成临时语言惯例，以便更高效地交流。该论文旨在使模型也能通过形成惯例来提升沟通效率。

Method: 通过模拟参考游戏来训练模型，无需额外的人类生成数据。模型在重复的参考游戏中学习形成惯例。

Result: 在涉及照片和七巧板图像的重复参考游戏中，该方法使模型与人沟通时信息长度减少了41%，成功率提高了15%。人类在与形成惯例的模型互动时反应更快。

Conclusion: 仅基于成功或成本进行训练不足以引发惯例形成，必须同时考虑两者。

Abstract: Humans leverage shared conversational context to become increasingly
successful and efficient at communicating over time. One manifestation of this
is the formation of ad hoc linguistic conventions, which allow people to
coordinate on short, less costly utterances that are understood using shared
conversational context. We present a method to train large multimodal models to
form conventions, enabling efficient communication. Our approach uses simulated
reference games between models, and requires no additional human-produced data.
In repeated reference games involving photographs and tangram images, our
method enables models to communicate efficiently with people: reducing the
message length by up to 41% while increasing success by 15% over the course of
the interaction. Human listeners respond faster when interacting with our model
that forms conventions. We also show that training based on success or cost
alone is insufficient - both are necessary to elicit convention formation.

</details>


### [18] [Pie: A Programmable Serving System for Emerging LLM Applications](https://arxiv.org/abs/2510.24051)
*In Gim,Zhiyao Ma,Seung-seob Lee,Lin Zhong*

Main category: cs.CL

TL;DR: Pie是一个灵活且高效的LLM服务系统，通过可编程接口和inferlets支持多样化的推理策略和应用优化。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM服务系统基于单一的token生成循环，无法适应多样化的推理策略和agentic工作流，因此需要一种更灵活高效的系统。

Method: Pie将传统的生成循环分解为细粒度的服务处理程序，通过API暴露，并允许用户提供的程序（inferlets）控制生成过程。使用WebAssembly执行inferlets，实现轻量级沙盒化。

Result: Pie在标准任务上的性能与最先进技术相当（延迟开销3-12%），在agentic工作流上显著改善了延迟和吞吐量（提高了1.3x-3.4x）。

Conclusion: Pie通过其灵活性和可编程性，使应用程序能够在不修改服务系统的情况下实现特定优化，从而提升了性能。

Abstract: Emerging large language model (LLM) applications involve diverse reasoning
strategies and agentic workflows, straining the capabilities of existing
serving systems built on a monolithic token generation loop. This paper
introduces Pie, a programmable LLM serving system designed for flexibility and
efficiency. Pie decomposes the traditional generation loop into fine-grained
service handlers exposed via an API and delegates control of the generation
process to user-provided programs, called inferlets. This enables applications
to implement new KV cache strategies, bespoke generation logic, and seamlessly
integrate computation and I/O-entirely within the application, without
requiring modifications to the serving system. Pie executes inferlets using
WebAssembly, benefiting from its lightweight sandboxing. Our evaluation shows
Pie matches state-of-the-art performance on standard tasks (3-12% latency
overhead) while significantly improving latency and throughput (1.3x-3.4x
higher) on agentic workflows by enabling application-specific optimizations.

</details>


### [19] [Challenging Multilingual LLMs: A New Taxonomy and Benchmark for Unraveling Hallucination in Translation](https://arxiv.org/abs/2510.24073)
*Xinwei Wu,Heng Liu,Jiang Zhou,Xiaohu Zhao,Linlong Xu,Longyue Wang,Weihua Luo,Kaifu Zhang*

Main category: cs.CL

TL;DR: 本文介绍了一种用于检测多语言大语言模型中幻觉的诊断框架，并构建了HalloMTBench基准。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在机器翻译中取得了进展，但仍然容易产生幻觉。现有的MT基准无法揭示多语言LLMs的故障。

Method: 引入了诊断框架，将指令脱离和源脱离分类，创建了多语言、人工验证的HalloMTBench基准，并使用前沿LLMs生成候选，再通过LLM评委和专家验证进行筛选。

Result: 构建了5,435个高质量实例的HalloMTBench，评估了17个LLMs，揭示了独特的“幻觉触发器”，包括模型规模、源长度敏感性、语言偏差和强化学习（RL）放大语言混合等失败模式。

Conclusion: HalloMTBench为诊断LLM翻译故障提供了前瞻性的测试平台，可以在https://huggingface.co/collections/AIDC-AI/marco-mt获取。

Abstract: Large Language Models (LLMs) have advanced machine translation but remain
vulnerable to hallucinations. Unfortunately, existing MT benchmarks are not
capable of exposing failures in multilingual LLMs. To disclose hallucination in
multilingual LLMs, we introduce a diagnostic framework with a taxonomy that
separates Instruction Detachment from Source Detachment. Guided by this
taxonomy, we create HalloMTBench, a multilingual, human-verified benchmark
across 11 English-to-X directions. We employed 4 frontier LLMs to generate
candidates and scrutinize these candidates with an ensemble of LLM judges, and
expert validation. In this way, we curate 5,435 high-quality instances. We have
evaluated 17 LLMs on HalloMTBench. Results reveal distinct ``hallucination
triggers'' -- unique failure patterns reflecting model scale, source length
sensitivity, linguistic biases, and Reinforcement-Learning (RL) amplified
language mixing. HalloMTBench offers a forward-looking testbed for diagnosing
LLM translation failures. HalloMTBench is available in
https://huggingface.co/collections/AIDC-AI/marco-mt.

</details>


### [20] [Global PIQA: Evaluating Physical Commonsense Reasoning Across 100+ Languages and Cultures](https://arxiv.org/abs/2510.24081)
*Tyler A. Chang,Catherine Arnett,Abdelrahman Eldesokey,Abdelrahman Sadallah,Abeer Kashar,Abolade Daud,Abosede Grace Olanihun,Adamu Labaran Mohammed,Adeyemi Praise,Adhikarinayum Meerajita Sharma,Aditi Gupta,Afitab Iyigun,Afonso Simplício,Ahmed Essouaied,Aicha Chorana,Akhil Eppa,Akintunde Oladipo,Akshay Ramesh,Aleksei Dorkin,Alfred Malengo Kondoro,Alham Fikri Aji,Ali Eren Çetintaş,Allan Hanbury,Alou Dembele,Alp Niksarli,Álvaro Arroyo,Amin Bajand,Amol Khanna,Ana Chkhaidze,Ana Condez,Andiswa Mkhonto,Andrew Hoblitzell,Andrew Tran,Angelos Poulis,Anirban Majumder,Anna Vacalopoulou,Annette Kuuipolani Kanahele Wong,Annika Simonsen,Anton Kovalev,Ashvanth. S,Ayodeji Joseph Lana,Barkin Kinay,Bashar Alhafni,Benedict Cibalinda Busole,Bernard Ghanem,Bharti Nathani,Biljana Stojanovska Đurić,Bola Agbonile,Bragi Bergsson,Bruce Torres Fischer,Burak Tutar,Burcu Alakuş Çınar,Cade J. Kanoniakapueo Kane,Can Udomcharoenchaikit,Catherine Arnett,Chadi Helwe,Chaithra Reddy Nerella,Chen Cecilia Liu,Chiamaka Glory Nwokolo,Cristina España-Bonet,Cynthia Amol,DaeYeop Lee,Dana Arad,Daniil Dzenhaliou,Daria Pugacheva,Dasol Choi,Daud Abolade,David Liu,David Semedo,Deborah Popoola,Deividas Mataciunas,Delphine Nyaboke,Dhyuthy Krishna Kumar,Diogo Glória-Silva,Diogo Tavares,Divyanshu Goyal,DongGeon Lee,Ebele Nwamaka Anajemba,Egonu Ngozi Grace,Elena Mickel,Elena Tutubalina,Elias Herranen,Emile Anand,Emmanuel Habumuremyi,Emuobonuvie Maria Ajiboye,Eryawan Presma Yulianrifat,Esther Adenuga,Ewa Rudnicka,Faith Olabisi Itiola,Faran Taimoor Butt,Fathima Thekkekara,Fatima Haouari,Filbert Aurelian Tjiaranata,Firas Laakom,Francesca Grasso,Francesco Orabona,Francesco Periti,Gbenga Kayode Solomon,Gia Nghia Ngo,Gloria Udhehdhe-oze,Gonçalo Martins,Gopi Naga Sai Ram Challagolla,Guijin Son,Gulnaz Abdykadyrova,Hafsteinn Einarsson,Hai Hu,Hamidreza Saffari,Hamza Zaidi,Haopeng Zhang,Harethah Abu Shairah,Harry Vuong,Hele-Andra Kuulmets,Houda Bouamor,Hwanjo Yu,Iben Nyholm Debess,İbrahim Ethem Deveci,Ikhlasul Akmal Hanif,Ikhyun Cho,Inês Calvo,Inês Vieira,Isaac Manzi,Ismail Daud,Itay Itzhak,Iuliia,Alekseenko,Ivan Belashkin,Ivan Spada,Ivan Zhelyazkov,Jacob Brinton,Jafar Isbarov,Jaka Čibej,Jan Čuhel,Jan Kocoń,Jauza Akbar Krito,Jebish Purbey,Jennifer Mickel,Jennifer Za,Jenny Kunz,Jihae Jeong,Jimena Tena Dávalos,Jinu Lee,João Magalhães,John Yi,Jongin Kim,Joseph Chataignon,Joseph Marvin Imperial,Jubeerathan Thevakumar,Judith Land,Junchen Jiang,Jungwhan Kim,Kairit Sirts,Kamesh R,Kamesh V,Kanda Patrick Tshinu,Kätriin Kukk,Kaustubh Ponkshe,Kavsar Huseynova,Ke He,Kelly Buchanan,Kengatharaiyer Sarveswaran,Kerem Zaman,Khalil Mrini,Kian Kyars,Krister Kruusmaa,Kusum Chouhan,Lainitha Krishnakumar,Laura Castro Sánchez,Laura Porrino Moscoso,Leshem Choshen,Levent Sencan,Lilja Øvrelid,Lisa Alazraki,Lovina Ehimen-Ugbede,Luheerathan Thevakumar,Luxshan Thavarasa,Mahnoor Malik,Mamadou K. Keita,Mansi Jangid,Marco De Santis,Marcos García,Marek Suppa,Mariam D'Ciofalo,Marii Ojastu,Maryam Sikander,Mausami Narayan,Maximos Skandalis,Mehak Mehak,Mehmet İlteriş Bozkurt,Melaku Bayu Workie,Menan Velayuthan,Michael Leventhal,Michał Marcińczuk,Mirna Potočnjak,Mohammadamin Shafiei,Mridul Sharma,Mrityunjaya Indoria,Muhammad Ravi Shulthan Habibi,Murat Kolić,Nada Galant,Naphat Permpredanun,Narada Maugin,Nicholas Kluge Corrêa,Nikola Ljubešić,Nirmal Thomas,Nisansa de Silva,Nisheeth Joshi,Nitish Ponkshe,Nizar Habash,Nneoma C. Udeze,Noel Thomas,Noémi Ligeti-Nagy,Nouhoum Coulibaly,Nsengiyumva Faustin,Odunayo Kareemat Buliaminu,Odunayo Ogundepo,Oghojafor Godswill Fejiro,Ogundipe Blessing Funmilola,Okechukwu God'spraise,Olanrewaju Samuel,Olaoye Deborah Oluwaseun,Olasoji Akindejoye,Olga Popova,Olga Snissarenko,Onyinye Anulika Chiemezie,Orkun Kinay,Osman Tursun,Owoeye Tobiloba Moses,Oyelade Oluwafemi Joshua,Oyesanmi Fiyinfoluwa,Pablo Gamallo,Pablo Rodríguez Fernández,Palak Arora,Pedro Valente,Peter Rupnik,Philip Oghenesuowho Ekiugbo,Pramit Sahoo,Prokopis Prokopidis,Pua Niau-Puhipau,Quadri Yahya,Rachele Mignone,Raghav Singhal,Ram Mohan Rao Kadiyala,Raphael Merx,Rapheal Afolayan,Ratnavel Rajalakshmi,Rishav Ghosh,Romina Oji,Ron Kekeha Solis,Rui Guerra,Rushikesh Zawar,Sa'ad Nasir Bashir,Saeed Alzaabi,Sahil Sandeep,Sai Pavan Batchu,SaiSandeep Kantareddy,Salsabila Zahirah Pranida,Sam Buchanan,Samuel Rutunda,Sander Land,Sarah Sulollari,Sardar Ali,Saroj Sapkota,Saulius Tautvaisas,Sayambhu Sen,Sayantani Banerjee,Sebastien Diarra,SenthilNathan. M,Sewoong Lee,Shaan Shah,Shankar Venkitachalam,Sharifa Djurabaeva,Sharon Ibejih,Shivanya Shomir Dutta,Siddhant Gupta,Silvia Paniagua Suárez,Sina Ahmadi,Sivasuthan Sukumar,Siyuan Song,Snegha A.,Sokratis Sofianopoulos,Sona Elza Simon,Sonja Benčina,Sophie Gvasalia,Sphurti Kirit More,Spyros Dragazis,Stephan P. Kaufhold,Suba. S,Sultan AlRashed,Surangika Ranathunga,Taiga Someya,Taja Kuzman Pungeršek,Tal Haklay,Tasi'u Jibril,Tatsuya Aoyama,Tea Abashidze,Terenz Jomar Dela Cruz,Terra Blevins,Themistoklis Nikas,Theresa Dora Idoko,Thu Mai Do,Tilek Chubakov,Tommaso Gargiani,Uma Rathore,Uni Johannesen,Uwuma Doris Ugwu,Vallerie Alexandra Putra,Vanya Bannihatti Kumar,Varsha Jeyarajalingam,Varvara Arzt,Vasudevan Nedumpozhimana,Viktoria Ondrejova,Viktoryia Horbik,Vishnu Vardhan Reddy Kummitha,Vuk Dinić,Walelign Tewabe Sewunetie,Winston Wu,Xiaojing Zhao,Yacouba Diarra,Yaniv Nikankin,Yash Mathur,Yixi Chen,Yiyuan Li,Yolanda Xavier,Yonatan Belinkov,Yusuf Ismail Abayomi,Zaid Alyafeai,Zhengyang Shan,Zhi Rui Tam,Zilu Tang,Zuzana Nadova,Baber Abbasi,Stella Biderman,David Stap,Duygu Ataman,Fabian Schmidt,Hila Gonen,Jiayi Wang,David Ifeoluwa Adelani*

Main category: cs.CL

TL;DR: Global PIQA 是一个涵盖100多种语言和文化的大型语言模型（LLMs）文化特定评估基准。


<details>
  <summary>Details</summary>
Motivation: 目前几乎没有覆盖多种语言和文化的特定文化评估基准，Global PIQA旨在填补这一空白。

Method: 由来自65个国家的335名研究人员手动构建，涵盖5大洲、14个语族和23种书写系统。

Result: 最先进的LLMs在Global PIQA上总体表现良好，但在低资源语言上表现较弱，开放模型通常比专有模型表现差。

Conclusion: Global PIQA突出表明，在许多语言和文化中，日常知识仍是需要改进的领域。此外，Global PIQA展示了人类语言所嵌入的文化多样性。

Abstract: To date, there exist almost no culturally-specific evaluation benchmarks for
large language models (LLMs) that cover a large number of languages and
cultures. In this paper, we present Global PIQA, a participatory commonsense
reasoning benchmark for over 100 languages, constructed by hand by 335
researchers from 65 countries around the world. The 116 language varieties in
Global PIQA cover five continents, 14 language families, and 23 writing
systems. In the non-parallel split of Global PIQA, over 50% of examples
reference local foods, customs, traditions, or other culturally-specific
elements. We find that state-of-the-art LLMs perform well on Global PIQA in
aggregate, but they exhibit weaker performance in lower-resource languages (up
to a 37% accuracy gap, despite random chance at 50%). Open models generally
perform worse than proprietary models. Global PIQA highlights that in many
languages and cultures, everyday knowledge remains an area for improvement,
alongside more widely-discussed capabilities such as complex reasoning and
expert knowledge. Beyond its uses for LLM evaluation, we hope that Global PIQA
provides a glimpse into the wide diversity of cultures in which human language
is embedded.

</details>


### [21] [RegSpeech12: A Regional Corpus of Bengali Spontaneous Speech Across Dialects](https://arxiv.org/abs/2510.24096)
*Md. Rezuwan Hassan,Azmol Hossain,Kanij Fatema,Rubayet Sabbir Faruque,Tanmoy Shome,Ruwad Naswan,Trina Chakraborty,Md. Foriduzzaman Zihad,Tawsif Tashwar Dipto,Nazia Tasnim,Nazmuddoha Ansary,Md. Mehedi Hasan Shawon,Ahmed Imtiaz Humayun,Md. Golam Rabiul Alam,Farig Sadeque,Asif Sushmit*

Main category: cs.CL

TL;DR: 该论文研究了孟加拉语不同方言的语音和形态特征，并探讨了为各地方言建立自动语音识别（ASR）系统的可行性。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语在南亚及海外侨民中广泛使用，方言多样性丰富，但系统性的孟加拉语方言计算处理研究仍然有限。

Method: 研究记录了孟加拉语方言的语音和形态特征，并探讨了构建针对这些方言的ASR系统。

Result: 为研究建立的数据库已公开发布，为虚拟助手和更广泛的语言技术应用提供了基础。

Conclusion: 该研究有助于方言多样性的保护，并推动面向孟加拉语社区的包容性数字工具的发展。

Abstract: The Bengali language, spoken extensively across South Asia and among
diasporic communities, exhibits considerable dialectal diversity shaped by
geography, culture, and history. Phonological and pronunciation-based
classifications broadly identify five principal dialect groups: Eastern
Bengali, Manbhumi, Rangpuri, Varendri, and Rarhi. Within Bangladesh, further
distinctions emerge through variation in vocabulary, syntax, and morphology, as
observed in regions such as Chittagong, Sylhet, Rangpur, Rajshahi, Noakhali,
and Barishal. Despite this linguistic richness, systematic research on the
computational processing of Bengali dialects remains limited. This study seeks
to document and analyze the phonetic and morphological properties of these
dialects while exploring the feasibility of building computational models
particularly Automatic Speech Recognition (ASR) systems tailored to regional
varieties. Such efforts hold potential for applications in virtual assistants
and broader language technologies, contributing to both the preservation of
dialectal diversity and the advancement of inclusive digital tools for
Bengali-speaking communities. The dataset created for this study is released
for public use.

</details>


### [22] [Squrve: A Unified and Modular Framework for Complex Real-World Text-to-SQL Tasks](https://arxiv.org/abs/2510.24102)
*Yihan Wang,Peiyu Liu,Runyu Chen,Jiaxing Pu,Wei Xu*

Main category: cs.CL

TL;DR: Squrve 是一个统一、模块化且可扩展的 Text-to-SQL 框架，旨在集成学术研究和实际应用。


<details>
  <summary>Details</summary>
Motivation: 尽管 Text-to-SQL 技术在学术上取得了显著进展，但由于集成工具的局限性，将其应用于实际系统仍然具有挑战性。

Method: Squrve 建立了一个通用执行范式来标准化调用接口，并提出了一种基于七个抽象原子角色组件的多角色协作机制。

Result: 在广泛采用的基准测试上的实验表明，协作工作流始终优于原始的单个方法。

Conclusion: Squrve 为处理复杂的实际查询提供了一种新的有效途径。

Abstract: Text-to-SQL technology has evolved rapidly, with diverse academic methods
achieving impressive results. However, deploying these techniques in real-world
systems remains challenging due to limited integration tools. Despite these
advances, we introduce Squrve, a unified, modular, and extensive Text-to-SQL
framework designed to bring together research advances and real-world
applications. Squrve first establishes a universal execution paradigm that
standardizes invocation interfaces, then proposes a multi-actor collaboration
mechanism based on seven abstracted effective atomic actor components.
Experiments on widely adopted benchmarks demonstrate that the collaborative
workflows consistently outperform the original individual methods, thereby
opening up a new effective avenue for tackling complex real-world queries. The
codes are available at https://github.com/Satissss/Squrve.

</details>


### [23] [Beyond Line-Level Filtering for the Pretraining Corpora of LLMs](https://arxiv.org/abs/2510.24139)
*Chanwoo Park,Suyoung Park,Yelim Ahn,Jongmin Kim,Jongyeon Park,Jaejin Lee*

Main category: cs.CL

TL;DR: 该论文介绍了两种增强传统行级过滤技术的方法，通过考虑行级信号及其文档中的顺序分布，以保留结构上重要的内容。


<details>
  <summary>Details</summary>
Motivation: 传统行级过滤技术（如行级去重和尾随标点符号过滤）可能会丢弃有价值的内容，影响下游性能，因此需要改进。

Method: 引入了两种方法：模式感知的行级去重（PLD）和模式感知的尾随标点符号过滤（PTF），通过增强传统过滤技术，考虑行级信号及其顺序分布。

Result: 在英语和韩语的小型语言模型（1B参数）上评估，结果显示这些方法在多项选择基准上持续提升性能，并显著提高了在SQuAD v1和KorQuAD v1上的生成问答准确率。

Conclusion: 新方法能够有效保留重要内容，从而在各种下游任务中提升模型性能。

Abstract: While traditional line-level filtering techniques, such as line-level
deduplication and trailing-punctuation filters, are commonly used, these basic
methods can sometimes discard valuable content, negatively affecting downstream
performance. In this paper, we introduce two methods-pattern-aware line-level
deduplication (PLD) and pattern-aware trailing punctuation filtering (PTF)-by
enhancing the conventional filtering techniques. Our approach not only
considers line-level signals but also takes into account their sequential
distribution across documents, enabling us to retain structurally important
content that might otherwise be removed. We evaluate these proposed methods by
training small language models (1 B parameters) in both English and Korean. The
results demonstrate that our methods consistently improve performance on
multiple-choice benchmarks and significantly enhance generative
question-answering accuracy on both SQuAD v1 and KorQuAD v1.

</details>


### [24] [Ko-MuSR: A Multistep Soft Reasoning Benchmark for LLMs Capable of Understanding Korean](https://arxiv.org/abs/2510.24150)
*Chanwoo Park,Suyoung Park,JiA Kang,Jongyeon Park,Sangho Kim,Hyunji M. Park,Sumin Bae,Mingyu Kang,Jaejin Lee*

Main category: cs.CL

TL;DR: Ko-MuSR是首个用于全面评估韩语长篇叙述中多步软推理的基准，旨在减少数据污染。


<details>
  <summary>Details</summary>
Motivation: 为了系统性地评估韩语长篇叙述中的推理能力和提示策略，提供一个减少数据污染的基准。

Method: 构建了Ko-MuSR，包括全韩语叙述、推理链和由人类标注者验证的多选题。

Result: 评估显示，多语言模型在韩语推理任务中优于专注于韩语的模型，且特定的提示策略能进一步提升准确率。

Conclusion: Ko-MuSR为推进韩语自然语言处理提供了一个可靠的基础，通过系统评估长文本推理和提示策略。

Abstract: We present Ko-MuSR, the first benchmark to comprehensively evaluate
multistep, soft reasoning in long Korean narratives while minimizing data
contamination. Built following MuSR, Ko-MuSR features fully Korean narratives,
reasoning chains, and multiple-choice questions verified by human annotators
for logical consistency and answerability. Evaluations of four large language
models -- two multilingual and two Korean-specialized -- show that multilingual
models outperform Korean-focused ones even in Korean reasoning tasks,
indicating cross-lingual generalization of reasoning ability. Carefully
designed prompting strategies, which combine few-shot examples, reasoning
traces, and task-specific hints, further boost accuracy, approaching
human-level performance. Ko-MuSR offers a solid foundation for advancing Korean
NLP by enabling systematic evaluation of long-context reasoning and prompting
strategies.

</details>


### [25] [MuSaG: A Multimodal German Sarcasm Dataset with Full-Modal Annotations](https://arxiv.org/abs/2510.24178)
*Aaron Scott,Maike Züfle,Jan Niehues*

Main category: cs.CL

TL;DR: 提出MuSaG，首个德语多模态讽刺检测数据集，包含来自电视节目的33分钟人工标注数据，评估了九种模型，揭示了模型与人在讽刺检测上的差距。


<details>
  <summary>Details</summary>
Motivation: 讽刺在日常交流中常见，对自然语言理解、情感分析和内容审核构成挑战，尤其是在多模态环境中。

Method: 构建并发布了MuSaG数据集，包含文本、音频和视频三种模态，并评估了九种开源和商业模型在单模态和多模态环境下的性能。

Result: 人类在对话场景中主要依赖音频，而模型在文本上表现最佳，显示出当前多模态模型在讽刺检测上的不足。

Conclusion: MuSaG数据集可用于开发更适合现实场景的多模态讽刺检测模型，并促进未来研究和人机对齐。

Abstract: Sarcasm is a complex form of figurative language in which the intended
meaning contradicts the literal one. Its prevalence in social media and popular
culture poses persistent challenges for natural language understanding,
sentiment analysis, and content moderation. With the emergence of multimodal
large language models, sarcasm detection extends beyond text and requires
integrating cues from audio and vision. We present MuSaG, the first German
multimodal sarcasm detection dataset, consisting of 33 minutes of manually
selected and human-annotated statements from German television shows. Each
instance provides aligned text, audio, and video modalities, annotated
separately by humans, enabling evaluation in unimodal and multimodal settings.
We benchmark nine open-source and commercial models, spanning text, audio,
vision, and multimodal architectures, and compare their performance to human
annotations. Our results show that while humans rely heavily on audio in
conversational settings, models perform best on text. This highlights a gap in
current multimodal models and motivates the use of MuSaG for developing models
better suited to realistic scenarios. We release MuSaG publicly to support
future research on multimodal sarcasm detection and human-model alignment.

</details>


### [26] [Exploring the Influence of Relevant Knowledge for Natural Language Generation Interpretability](https://arxiv.org/abs/2510.24179)
*Iván Martínez-Murillo,Paloma Moreda,Elena Lloret*

Main category: cs.CL

TL;DR: 本文探讨了外部知识集成在自然语言生成（NLG）中的影响，特别是在常识生成任务中。


<details>
  <summary>Details</summary>
Motivation: 论文旨在通过创建KITGI基准测试扩展CommonGen数据集，并研究外部知识在NLG中的作用。

Method: 使用T5-Large模型，在完整外部知识和过滤知识两种条件下比较句子生成，并采用三阶段方法进行可解释性基准测试。

Result: 在完整知识条件下生成的句子在两个标准下的正确性为91%，而过滤知识的性能降至6%。

Conclusion: 相关外部知识对于保持NLG中的连贯性和概念覆盖至关重要，强调了可解释知识增强NLG系统的重要性。

Abstract: This paper explores the influence of external knowledge integration in
Natural Language Generation (NLG), focusing on a commonsense generation task.
We extend the CommonGen dataset by creating KITGI, a benchmark that pairs input
concept sets with retrieved semantic relations from ConceptNet and includes
manually annotated outputs. Using the T5-Large model, we compare sentence
generation under two conditions: with full external knowledge and with filtered
knowledge where highly relevant relations were deliberately removed. Our
interpretability benchmark follows a three-stage method: (1) identifying and
removing key knowledge, (2) regenerating sentences, and (3) manually assessing
outputs for commonsense plausibility and concept coverage. Results show that
sentences generated with full knowledge achieved 91\% correctness across both
criteria, while filtering reduced performance drastically to 6\%. These
findings demonstrate that relevant external knowledge is critical for
maintaining both coherence and concept coverage in NLG. This work highlights
the importance of designing interpretable, knowledge-enhanced NLG systems and
calls for evaluation frameworks that capture the underlying reasoning beyond
surface-level metrics.

</details>


### [27] [Beyond Neural Incompatibility: Easing Cross-Scale Knowledge Transfer in Large Language Models through Latent Semantic Alignment](https://arxiv.org/abs/2510.24208)
*Jian Gu,Aldeida Aleti,Chunyang Chen,Hongyu Zhang*

Main category: cs.CL

TL;DR: 本文提出一种新的跨尺度大语言模型参数知识迁移方法，通过潜在空间的语义对齐实现高效知识迁移。


<details>
  <summary>Details</summary>
Motivation: 大语言模型在不同尺度之间进行细粒度参数知识迁移（PKT）存在困难，主要是由于神经不兼容性，导致现有方法受限。

Method: 该方法不使用层参数，而是利用激活作为层间知识迁移的媒介，通过潜在空间的语义对齐来实现知识迁移。

Result: 在四个基准测试中，该方法优于现有方法，更好地对齐了不同尺度模型的行为。

Conclusion: 语义对齐是跨尺度知识迁移的关键因素，该方法简单高效，为知识迁移提供了新思路。

Abstract: Large Language Models (LLMs) encode vast amounts of knowledge in their
massive parameters, which is accessible to locate, trace, and analyze. Despite
advances in neural interpretability, it is still not clear how to transfer
knowledge in a fine-grained manner, namely parametric knowledge transfer (PKT).
A key problem is enabling effective and efficient knowledge transfer across
LLMs of different scales, which is essential for achieving greater flexibility
and broader applicability in transferring knowledge between LLMs. Due to neural
incompatibility, referring to the architectural and parametric differences
between LLMs of varying scales, existing methods that directly reuse layer
parameters are severely limited. In this paper, we identify the semantic
alignment in latent space as the fundamental prerequisite for LLM cross-scale
knowledge transfer. Instead of directly using the layer parameters, our
approach takes activations as the medium of layer-wise knowledge transfer.
Leveraging the semantics in latent space, our approach is simple and
outperforms prior work, better aligning model behaviors across varying scales.
Evaluations on four benchmarks demonstrate the efficacy of our method. Further
analysis reveals the key factors easing cross-scale knowledge transfer and
provides insights into the nature of latent semantic alignment.

</details>


### [28] [HACK: Hallucinations Along Certainty and Knowledge Axes](https://arxiv.org/abs/2510.24222)
*Adi Simhi,Jonathan Herzig,Itay Itzhak,Dana Arad,Zorik Gekhman,Roi Reichart,Fazl Barez,Gabriel Stanovsky,Idan Szpektor,Yonatan Belinkov*

Main category: cs.CL

TL;DR: 提出了一种基于知识和确定性两个维度对LLMs幻觉进行分类的框架，并强调了针对不同幻觉机制采取定制缓解策略的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常根据外部属性对幻觉进行分类，而忽视了幻觉的内在机制可能需要定制缓解策略。因此，本文提出了一种新的分类框架。

Method: 提出了一种基于知识和确定性两个维度对幻觉进行分类的框架，并采用模型特定的数据集构建过程。通过操控模型激活来验证知识轴的分类，并引入新的评估指标来衡量缓解方法的有效性。

Result: 验证了知识轴上的幻觉分类，发现不同模型间存在不同的幻觉模式。同时，识别出一种特别令人担忧的幻觉子集，即模型在拥有正确知识的情况下仍然确定性地产生幻觉。

Conclusion: 强调了考虑知识和确定性在幻觉分析中的重要性，呼吁采用有针对性的缓解方法来处理不同类型的幻觉。

Abstract: Hallucinations in LLMs present a critical barrier to their reliable usage.
Existing research usually categorizes hallucination by their external
properties rather than by the LLMs' underlying internal properties. This
external focus overlooks that hallucinations may require tailored mitigation
strategies based on their underlying mechanism. We propose a framework for
categorizing hallucinations along two axes: knowledge and certainty. Since
parametric knowledge and certainty may vary across models, our categorization
method involves a model-specific dataset construction process that
differentiates between those types of hallucinations. Along the knowledge axis,
we distinguish between hallucinations caused by a lack of knowledge and those
occurring despite the model having the knowledge of the correct response. To
validate our framework along the knowledge axis, we apply steering mitigation,
which relies on the existence of parametric knowledge to manipulate model
activations. This addresses the lack of existing methods to validate knowledge
categorization by showing a significant difference between the two
hallucination types. We further analyze the distinct knowledge and
hallucination patterns between models, showing that different hallucinations do
occur despite shared parametric knowledge. Turning to the certainty axis, we
identify a particularly concerning subset of hallucinations where models
hallucinate with certainty despite having the correct knowledge internally. We
introduce a new evaluation metric to measure the effectiveness of mitigation
methods on this subset, revealing that while some methods perform well on
average, they fail disproportionately on these critical cases. Our findings
highlight the importance of considering both knowledge and certainty in
hallucination analysis and call for targeted mitigation approaches that
consider the hallucination underlying factors.

</details>


### [29] [Towards Transparent Reasoning: What Drives Faithfulness in Large Language Models?](https://arxiv.org/abs/2510.24236)
*Teague McMillan,Gabriele Dominici,Martin Gjoreski,Marc Langheinrich*

Main category: cs.CL

TL;DR: 研究分析了大语言模型在医疗等敏感领域产生不忠实解释的问题，通过实验考察了影响解释忠实度的关键因素，包括少样本示例、提示设计和训练过程。


<details>
  <summary>Details</summary>
Motivation: 大语言模型常生成不忠实于其预测驱动因素的解释，在医疗等高风险场景中，这种不忠实会降低医生信任并导致危险决策，亟需提高模型解释的可靠性。

Method: 在BBQ（社会偏见）和MedQA（医学资格考试）两个数据集上，针对GPT-4.1-mini、LLaMA 70B和LLaMA 8B三个模型，系统操纵了少样本示例的数量与类型、提示策略以及训练流程，评估推断和训练时选择对解释忠实度的影响。

Result: (i) 少样本示例的数量和质量显著影响模型忠实度；(ii) 提示设计对忠实度敏感；(iii) 指令微调阶段显著提升了在MedQA上的忠实度表现。

Conclusion: 通过优化少样本示例、提示设计和训练流程，可以提升大语言模型在敏感领域中的解释忠实度，从而提高其可解释性与可信度，为高风险场景下的应用提供策略参考。

Abstract: Large Language Models (LLMs) often produce explanations that do not
faithfully reflect the factors driving their predictions. In healthcare
settings, such unfaithfulness is especially problematic: explanations that omit
salient clinical cues or mask spurious shortcuts can undermine clinician trust
and lead to unsafe decision support. We study how inference and training-time
choices shape explanation faithfulness, focusing on factors practitioners can
control at deployment. We evaluate three LLMs (GPT-4.1-mini, LLaMA 70B, LLaMA
8B) on two datasets-BBQ (social bias) and MedQA (medical licensing questions),
and manipulate the number and type of few-shot examples, prompting strategies,
and training procedure. Our results show: (i) both the quantity and quality of
few-shot examples significantly impact model faithfulness; (ii) faithfulness is
sensitive to prompting design; (iii) the instruction-tuning phase improves
measured faithfulness on MedQA. These findings offer insights into strategies
for enhancing the interpretability and trustworthiness of LLMs in sensitive
domains.

</details>


### [30] [Abjad AI at NADI 2025: CATT-Whisper: Multimodal Diacritic Restoration Using Text and Speech Representations](https://arxiv.org/abs/2510.24247)
*Ahmad Ghannam,Naif Alharthi,Faris Alasmary,Kholood Al Tabash,Shouq Sadah,Lahouari Ghouti*

Main category: cs.CL

TL;DR: 本文提出了一种结合文本和语音信息的多模态方法，用于解决阿拉伯语方言句子中的变音符号恢复（DR）任务。


<details>
  <summary>Details</summary>
Motivation: 通过结合文本和语音信息，提高阿拉伯语方言句子中变音符号恢复的准确性和鲁棒性。

Method: 提出一种多模态模型，使用CATT预训练模型提取文本模态，OpenAI Whisper模型处理语音模态。采用两种整合策略：早期融合和交叉注意力机制。在训练过程中随机停用语音输入以增强模型鲁棒性。

Result: 在开发集上，该方法的词错误率（WER）为0.25，字符错误率（CER）为0.9；在测试集上，WER和CER分别为0.55和0.13。

Conclusion: 该方法在变音符号恢复任务中表现出色，通过多模态融合和随机停用语音输入，提高了模型的准确性和鲁棒性。

Abstract: In this work, we tackle the Diacritic Restoration (DR) task for Arabic
dialectal sentences using a multimodal approach that combines both textual and
speech information. We propose a model that represents the text modality using
an encoder extracted from our own pre-trained model named CATT. The speech
component is handled by the encoder module of the OpenAI Whisper base model.
Our solution is designed following two integration strategies. The former
consists of fusing the speech tokens with the input at an early stage, where
the 1500 frames of the audio segment are averaged over 10 consecutive frames,
resulting in 150 speech tokens. To ensure embedding compatibility, these
averaged tokens are processed through a linear projection layer prior to
merging them with the text tokens. Contextual encoding is guaranteed by the
CATT encoder module. The latter strategy relies on cross-attention, where text
and speech embeddings are fused. The cross-attention output is then fed to the
CATT classification head for token-level diacritic prediction. To further
improve model robustness, we randomly deactivate the speech input during
training, allowing the model to perform well with or without speech. Our
experiments show that the proposed approach achieves a word error rate (WER) of
0.25 and a character error rate (CER) of 0.9 on the development set. On the
test set, our model achieved WER and CER scores of 0.55 and 0.13, respectively.

</details>


### [31] [Evaluating LLMs on Generating Age-Appropriate Child-Like Conversations](https://arxiv.org/abs/2510.24250)
*Syed Zohaib Hassan,Pål Halvorsen,Miriam S. Johnson,Pierre Lison*

Main category: cs.CL

TL;DR: 本文评估了五种大型语言模型在生成适合5岁和9岁儿童的挪威语对话方面的表现。


<details>
  <summary>Details</summary>
Motivation: 当前的大型语言模型主要在成人对话数据上训练，生成适合儿童的真实对话仍存在挑战。

Method: 通过对五种LLM（GPT-4, RUTER-LLAMA-2-13b, GPTSW, NorMistral-7b, NorBloom-7b）生成的对话样本与真实儿童访谈数据进行盲评，由11位教育专业人士评估其真实性和适龄性。

Result: 评估者间信度较高（ICC=0.75），对5岁儿童年龄预测的准确性高于9岁儿童。GPT-4和NorBloom-7b表现较好，但大多数模型生成的语言被认为比目标年龄组更先进。

Conclusion: 在开发涉及儿童的特殊应用时，尤其是在低资源语言中，存在关键的数据相关挑战，需要更全面适龄的词汇资源。

Abstract: Large Language Models (LLMs), predominantly trained on adult conversational
data, face significant challenges when generating authentic, child-like
dialogue for specialized applications. We present a comparative study
evaluating five different LLMs (GPT-4, RUTER-LLAMA-2-13b, GPTSW, NorMistral-7b,
and NorBloom-7b) to generate age-appropriate Norwegian conversations for
children aged 5 and 9 years. Through a blind evaluation by eleven education
professionals using both real child interview data and LLM-generated text
samples, we assessed authenticity and developmental appropriateness. Our
results show that evaluators achieved strong inter-rater reliability (ICC=0.75)
and demonstrated higher accuracy in age prediction for younger children
(5-year-olds) compared to older children (9-year-olds). While GPT-4 and
NorBloom-7b performed relatively well, most models generated language perceived
as more linguistically advanced than the target age groups. These findings
highlight critical data-related challenges in developing LLM systems for
specialized applications involving children, particularly in low-resource
languages where comprehensive age-appropriate lexical resources are scarce.

</details>


### [32] [MERGE: Minimal Expression-Replacement GEneralization Test for Natural Language Inference](https://arxiv.org/abs/2510.24295)
*Mădălina Zgreabăn,Tejaswini Deoskar,Lasha Abzianidze*

Main category: cs.CL

TL;DR: 提出了一种通过替换开放类词汇自动生成高质量NLI问题变体的方法MERGE，并评估了语言模型在变体上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有NLI语言模型在自然语言推理中缺乏鲁棒性，但手工创建新基准成本高，自动生成高质量基准极其困难。

Method: 通过替换开放类词汇自动生成原始NLI问题的变体，同时保持其基本推理不变，称为MERGE。

Result: NLI模型在变体上的表现比原始问题低4-20%，表明即使在这些微小改动的问题上泛化能力也较差。

Conclusion: 分析了替换词的词类、词概率和合理性对NLI模型性能的影响，为模型改进提供了方向。

Abstract: In recent years, many generalization benchmarks have shown language models'
lack of robustness in natural language inference (NLI). However, manually
creating new benchmarks is costly, while automatically generating high-quality
ones, even by modifying existing benchmarks, is extremely difficult. In this
paper, we propose a methodology for automatically generating high-quality
variants of original NLI problems by replacing open-class words, while
crucially preserving their underlying reasoning. We dub our generalization test
as MERGE (Minimal Expression-Replacements GEneralization), which evaluates the
correctness of models' predictions across reasoning-preserving variants of the
original problem. Our results show that NLI models' perform 4-20% worse on
variants, suggesting low generalizability even on such minimally altered
problems. We also analyse how word class of the replacements, word probability,
and plausibility influence NLI models' performance.

</details>


### [33] [Fine-tuning Large Language Models with Limited Data: A Survey and Practical Guide](https://arxiv.org/abs/2411.09539)
*Marton Szep,Daniel Rueckert,Rüdiger von Eisenhart-Rothe,Florian Hinterwimmer*

Main category: cs.CL

TL;DR: 本文综述了在数据稀缺情况下对大型语言模型（LLMs）进行微调的最新方法。


<details>
  <summary>Details</summary>
Motivation: 在低资源语言、专业领域和受限部署环境中，使用有限数据微调大型语言模型是一个实际挑战。

Method: 系统回顾了参数高效的微调技术、领域和跨语言适应方法、模型专业化策略，以及利用有限反馈的偏好对齐方法。

Result: 突出了经验性权衡、选择标准和最佳实践，帮助根据任务约束选择合适技术。

Conclusion: 旨在为数据资源有限的情况下有效微调LLMs提供可操作的见解。

Abstract: Fine-tuning large language models (LLMs) with limited data poses a practical
challenge in low-resource languages, specialized domains, and constrained
deployment settings. While pre-trained LLMs provide strong foundations,
effective adaptation under data scarcity requires focused and efficient
fine-tuning techniques. This paper presents a structured and practical survey
of recent methods for fine-tuning LLMs in data-scarce scenarios. We
systematically review parameter-efficient fine-tuning techniques that lower
training and deployment costs, domain and cross-lingual adaptation methods for
both encoder and decoder models, and model specialization strategies. We
further examine preference alignment approaches that guide model behavior using
limited human or synthetic feedback, emphasizing sample and compute efficiency.
Throughout, we highlight empirical trade-offs, selection criteria, and best
practices for choosing suitable techniques based on task constraints, including
model scaling, data scaling, and the mitigation of catastrophic forgetting. The
aim is to equip researchers and practitioners with actionable insights for
effectively fine-tuning LLMs when data and resources are limited.

</details>


### [34] [Lookahead Tree-Based Rollouts for Enhanced Trajectory-Level Exploration in Reinforcement Learning with Verifiable Rewards](https://arxiv.org/abs/2510.24302)
*Shangyu Xing,Siyuan Wang,Chenyuan Yang,Xinyu Dai,Xiang Ren*

Main category: cs.CL

TL;DR: 提出了一种新的rollout策略LATR，通过引入树状前瞻模拟和分支修剪来增加轨迹多样性，从而提高强化学习的效果。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习管道中，由于轨迹多样性不足，导致回报信号减少，影响策略学习效果。

Method: 提出Lookahead Tree-Based Rollouts (LATR)策略，在高不确定性生成步骤进行分支，并对每个分支进行前瞻模拟，修剪相似分支，以增强轨迹多样性。

Result: 与随机采样相比，LATR平均加速策略学习131%，在GRPO和DAPO算法上，最终pass@1性能提高4.2%。

Conclusion: LATR策略通过增加轨迹多样性，有效提升了策略学习速度和最终性能。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR), particularly with
algorithms like Group Relative Policy Optimization (GRPO), has proven highly
effective in enhancing the reasoning capabilities of large language models.
However, a critical bottleneck in current pipelines lies in the limited
diversity of sampled trajectories during group rollouts. Homogeneous
trajectories and their associated rewards would diminish the return signals for
policy updates, thereby hindering effective policy learning. This lack of
diversity stems primarily from token-level stochastic sampling, where local
variations are likely to collapse into near-identical reasoning paths. To
address this limitation, we propose Lookahead Tree-Based Rollouts (LATR), a
novel rollout strategy designed to explicitly promotes trajectory-level
diversity by enforcing branching into different candidate tokens likely to
yield distinct continuations. Specifically, LATR iteratively operates in three
stages: (1) branching at high-uncertainty generation steps, (2) performing
lookahead simulation for each new branch, and (3) pruning branches that
exhibits prolonged similarity during simulation. Compared with stochastic
Sampling, LATR accelerates policy learning by 131% on average and improves
final pass@1 performance by 4.2% on both GRPO and Dynamic sAmpling Policy
Optimization (DAPO) algorithms across different reasoning tasks. Our code and
data are publicly available at https://github.com/starreeze/latr.

</details>


### [35] [Critique-RL: Training Language Models for Critiquing through Two-Stage Reinforcement Learning](https://arxiv.org/abs/2510.24320)
*Zhiheng Xi,Jixuan Huang,Xin Guo,Boyang Hong,Dingwen Yang,Xiaoran Fan,Shuo Li,Zehui Chen,Junjie Ye,Siyu Yuan,Zhengyin Du,Xuesong Yao,Yufei Xu,Jiecao Chen,Rui Zheng,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CL

TL;DR: 提出了一种无需更强监督的在线强化学习方法Critique-RL，用于训练批判性语言模型以改进复杂推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前批判性语言模型依赖更强监督者标注的批判数据，为解决此限制，提出Critique-RL以实现无需更强监督的批判性语言模型训练。

Method: Critique-RL采用两阶段优化策略：第一阶段利用基于规则的奖励信号增强评论家的判别性，第二阶段引入基于参与者改进的间接奖励，以提高评论家的建设性反馈能力，同时保持判别性。

Result: 在各种任务和模型上的广泛实验显示，Critique-RL带来了显著的性能提升。例如，在Qwen2.5-7B上，实现了9.02%的领域内任务增益和5.70%的领域外任务增益。

Conclusion: Critique-RL是一种有效的在线强化学习方法，能够在没有更强监督的情况下显著提升批判性语言模型的性能，展示了其潜力。

Abstract: Training critiquing language models to assess and provide feedback on model
outputs is a promising way to improve LLMs for complex reasoning tasks.
However, existing approaches typically rely on stronger supervisors for
annotating critique data. To address this, we propose Critique-RL, an online RL
approach for developing critiquing language models without stronger
supervision. Our approach operates on a two-player paradigm: the actor
generates a response, the critic provides feedback, and the actor refines the
response accordingly. We first reveal that relying solely on indirect reward
signals from the actor's outputs for RL optimization often leads to
unsatisfactory critics: while their helpfulness (i.e., providing constructive
feedback) improves, the discriminability (i.e., determining whether a response
is high-quality or not) remains poor, resulting in marginal performance gains.
To overcome this, Critique-RL adopts a two-stage optimization strategy. In
stage I, it reinforces the discriminability of the critic with direct
rule-based reward signals; in stage II, it introduces indirect rewards based on
actor refinement to improve the critic's helpfulness, while maintaining its
discriminability via appropriate regularization. Extensive experiments across
various tasks and models show that Critique-RL delivers substantial performance
improvements. For example, it achieves a 9.02% gain on in-domain tasks and a
5.70% gain on out-of-domain tasks for Qwen2.5-7B, highlighting its potential.

</details>


### [36] [Beyond MCQ: An Open-Ended Arabic Cultural QA Benchmark with Dialect Variants](https://arxiv.org/abs/2510.24328)
*Hunzalah Hassan Bhatti,Firoj Alam*

Main category: cs.CL

TL;DR: 本文提出了一种综合方法，通过翻译现代标准阿拉伯语（MSA）的多项选择题（MCQs）为英语和多种阿拉伯语方言，并将其转化为开放式问题（OEQs），来评估大型语言模型（LLMs）在文化相关和方言内容上的表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在日常问答中的使用日益增多，但在文化相关和方言内容上的表现仍因语言而异。因此，需要一种方法来评估和提升这些模型在不同语言和文化背景下的表现。

Method: 提出的方法包括：(i) 将MSA的MCQs翻译成英语和多种阿拉伯语方言，(ii) 将MCQs转换为OEQs，(iii) 在MCQ和OEQ设置下对多种零-shot和微调LLMs进行基准测试，(iv) 生成思维链（CoT）推理以微调模型进行逐步推理。

Result: 研究发现：(i) 模型在阿拉伯语方言上的表现较差，揭示了文化相关和方言特定知识方面的持续差距；(ii) 以阿拉伯语为中心的模型在MCQs上表现良好，但在OEQs上表现不佳；(iii) CoT提高了判断的正确性，但在n-gram指标上结果不一。

Conclusion: 该研究扩展了一个现有的数据集，使其成为首个在不同语言变体中并行对齐问答的数据集，并公开了该数据集以支持进一步研究文化和语言包容性评估。

Abstract: Large Language Models (LLMs) are increasingly used to answer everyday
questions, yet their performance on culturally grounded and dialectal content
remains uneven across languages. We propose a comprehensive method that (i)
translates Modern Standard Arabic (MSA) multiple-choice questions (MCQs) into
English and several Arabic dialects, (ii) converts them into open-ended
questions (OEQs), (iii) benchmarks a range of zero-shot and fine-tuned LLMs
under both MCQ and OEQ settings, and (iv) generates chain-of-thought (CoT)
rationales to fine-tune models for step-by-step reasoning. Using this method,
we extend an existing dataset in which QAs are parallelly aligned across
multiple language varieties, making it, to our knowledge, the first of its
kind. We conduct extensive experiments with both open and closed models. Our
findings show that (i) models underperform on Arabic dialects, revealing
persistent gaps in culturally grounded and dialect-specific knowledge; (ii)
Arabic-centric models perform well on MCQs but struggle with OEQs; and (iii)
CoT improves judged correctness while yielding mixed n-gram-based metrics. The
developed dataset will be publicly released to support further research on
culturally and linguistically inclusive evaluation.

</details>


### [37] [LongWeave: A Long-Form Generation Benchmark Bridging Real-World Relevance and Verifiability](https://arxiv.org/abs/2510.24345)
*Zikai Xiao,Fei Huang,Jianhong Tu,Jianhui Wei,Wen Ma,Yuxuan Zhou,Jian Wu,Bowen Yu,Zuozhu Liu,Junyang Lin*

Main category: cs.CL

TL;DR: 本文提出了LongWeave，通过CoV-Eval平衡现实世界和易于验证的评估，以解决LLMs在生成长篇、信息丰富且真实的内容方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 长篇生成对大型语言模型（LLMs）来说仍是一个重大挑战，现有的基准测试要么使用难以验证的指标，要么使用忽略现实复杂性的合成设置。

Method: 引入了LongWeave，通过Constraint-Verifier Evaluation (CoV-Eval) 来定义可验证目标，并生成相应的查询、文本材料和约束，以确保任务既现实又可客观评估。

Result: LongWeave支持可自定义的输入/输出长度（最多64K/8K tokens），在七个不同任务上评估了23个LLMs，结果表明，即使在最先进的模型中，面对现实复杂性和输出长度增加时，长篇生成仍面临显著挑战。

Conclusion: LongWeave通过平衡现实世界和易于验证的评估，为长篇生成任务提供了一个更严格和现实的评估方法，突出了现有模型在复杂现实世界约束下的局限性。

Abstract: Generating long, informative, and factual outputs remains a major challenge
for Large Language Models (LLMs). Existing benchmarks for long-form generation
typically assess real-world queries with hard-to-verify metrics or use
synthetic setups that ease evaluation but overlook real-world intricacies. In
this paper, we introduce \textbf{LongWeave}, which balances real-world and
verifiable assessment with Constraint-Verifier Evaluation (CoV-Eval). CoV-Eval
constructs tasks by first defining verifiable targets within real-world
scenarios, then systematically generating corresponding queries, textual
materials, and constraints based on these targets. This ensures that tasks are
both realistic and objectively assessable, enabling rigorous assessment of
model capabilities in meeting complex real-world constraints. LongWeave
supports customizable input/output lengths (up to 64K/8K tokens) across seven
distinct tasks. Evaluation on 23 LLMs shows that even state-of-the-art models
encounter significant challenges in long-form generation as real-world
complexity and output length increase.

</details>


### [38] [Comprehensive and Efficient Distillation for Lightweight Sentiment Analysis Models](https://arxiv.org/abs/2510.24425)
*Guangyu Xie,Yice Zhang,Jianzhu Bao,Qianlong Wang,Yang Sun,Bingbing Wang,Ruifeng Xu*

Main category: cs.CL

TL;DR: 本文提出了一种名为 COMPEFFDIST 的高效蒸馏框架，旨在解决情感分析模型中人工指令的不足和大型用户文本的高计算成本问题。


<details>
  <summary>Details</summary>
Motivation: 尽管知识蒸馏在情感分析方面已有成果，但人工指令的多样性和数量有限，以及大型用户文本的高计算成本，仍然是主要挑战。

Method: 引入了两个模块：基于属性的自动指令构建和基于难度的数据过滤，以解决上述挑战。

Result: 在多个模型系列中，3B 学生模型能够在大多数任务上匹配 20 倍大的教师模型，并且数据效率远超基线方法。

Conclusion: 该方法不仅提高了模型性能，还显著降低了数据需求，仅需 10% 的数据即可达到相同的性能水平。

Abstract: Recent efforts leverage knowledge distillation techniques to develop
lightweight and practical sentiment analysis models. These methods are grounded
in human-written instructions and large-scale user texts. Despite the promising
results, two key challenges remain: (1) manually written instructions are
limited in diversity and quantity, making them insufficient to ensure
comprehensive coverage of distilled knowledge; (2) large-scale user texts incur
high computational cost, hindering the practicality of these methods. To this
end, we introduce COMPEFFDIST, a comprehensive and efficient distillation
framework for sentiment analysis. Our framework consists of two key modules:
attribute-based automatic instruction construction and difficulty-based data
filtering, which correspondingly tackle the aforementioned challenges. Applying
our method across multiple model series (Llama-3, Qwen-3, and Gemma-3), we
enable 3B student models to match the performance of 20x larger teacher models
on most tasks. In addition, our approach greatly outperforms baseline methods
in data efficiency, attaining the same performance level with only 10% of the
data.

</details>


### [39] [SynthWorlds: Controlled Parallel Worlds for Disentangling Reasoning and Knowledge in Language Models](https://arxiv.org/abs/2510.24427)
*Ken Gu,Advait Bhat,Mike A Merrill,Robert West,Xin Liu,Daniel McDuff,Tim Althoff*

Main category: cs.CL

TL;DR: 提出了一种新的框架SynthWorlds，以分离语言模型的推理能力和知识记忆，通过构建两个平行世界（现实映射和合成映射）来评估模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 由于语言模型广泛的参数化世界知识，评估其推理能力变得复杂，现有方法难以将推理能力与事实记忆分开。

Method: SynthWorlds框架中，构建了两个平行世界，设计了多跳问题回答和页面导航两个任务，以比较模型在现实映射和合成映射下的表现。

Result: 在参数化和知识增强的语言模型设置下，模型在现实映射世界中表现优于合成映射，存在知识优势差距。

Conclusion: 知识获取和整合机制可以减少但不能消除知识优势差距，SynthWorlds为评估语言模型的推理和记忆能力提供了可控环境。

Abstract: Evaluating the reasoning ability of language models (LMs) is complicated by
their extensive parametric world knowledge, where benchmark performance often
reflects factual recall rather than genuine reasoning. Existing datasets and
approaches (e.g., temporal filtering, paraphrasing, adversarial substitution)
cannot cleanly separate the two. We present SynthWorlds, a framework that
disentangles task reasoning complexity from factual knowledge. In SynthWorlds,
we construct parallel corpora representing two worlds with identical
interconnected structure: a real-mapped world, where models may exploit
parametric knowledge, and a synthetic-mapped world, where such knowledge is
meaningless. On top of these corpora, we design two mirrored tasks as case
studies: multi-hop question answering and page navigation, which maintain equal
reasoning difficulty across worlds. Experiments in parametric-only (e.g.,
closed-book QA) and knowledge-augmented (e.g., retrieval-augmented) LM settings
reveal a persistent knowledge advantage gap, defined as the performance boost
models gain from memorized parametric world knowledge. Knowledge acquisition
and integration mechanisms reduce but do not eliminate this gap, highlighting
opportunities for system improvements. Fully automatic and scalable,
SynthWorlds provides a controlled environment for evaluating LMs in ways that
were previously challenging, enabling precise and testable comparisons of
reasoning and memorization.

</details>


### [40] [LuxIT: A Luxembourgish Instruction Tuning Dataset from Monolingual Seed Data](https://arxiv.org/abs/2510.24434)
*Julian Valline,Cedric Lothritz,Jordi Cabot*

Main category: cs.CL

TL;DR: LuxIT是一个为卢森堡语设计的新型单语指令微调数据集，旨在解决低资源语言设置下大型语言模型（LLM）的有效性受限问题。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏高质量训练数据，指令微调的大型语言模型在低资源语言环境中的效果往往受限。为此，研究者开发了LuxIT，以弥补这一不足。

Method: LuxIT通过本地卢森堡语文本合成，利用在卢森堡语上表现优异的DeepSeek-R1-0528模型，并采用LLM-as-a-judge方法进行质量保证。然后，在LuxIT上对多个较小规模的LLM进行微调。

Result: 与基础模型相比，在卢森堡语语言能力测试上的基准测试结果表现不一，不同模型的性能差异显著。

Conclusion: LuxIT是卢森堡语自然语言处理的重要贡献，提供了一种可复制的单语方法。然而，研究结果也强调了进一步优化其应用的必要性。

Abstract: The effectiveness of instruction-tuned Large Language Models (LLMs) is often
limited in low-resource linguistic settings due to a lack of high-quality
training data. We introduce LuxIT, a novel, monolingual instruction tuning
dataset for Luxembourgish developed to mitigate this challenge. We synthesize
the dataset from a corpus of native Luxembourgish texts, utilizing
DeepSeek-R1-0528, chosen for its shown proficiency in Luxembourgish. Following
generation, we apply a quality assurance process, employing an LLM-as-a-judge
approach. To investigate the practical utility of the dataset, we fine-tune
several smaller-scale LLMs on LuxIT. Subsequent benchmarking against their base
models on Luxembourgish language proficiency examinations, however, yields
mixed results, with performance varying significantly across different models.
LuxIT represents a critical contribution to Luxembourgish natural language
processing and offers a replicable monolingual methodology, though our findings
highlight the need for further research to optimize its application.

</details>


### [41] [SPARTA: Evaluating Reasoning Segmentation Robustness through Black-Box Adversarial Paraphrasing in Text Autoencoder Latent Space](https://arxiv.org/abs/2510.24446)
*Viktoriia Zinkovich,Anton Antonov,Andrei Spiridonov,Denis Shepelev,Andrey Moskalenko,Daria Pugacheva,Elena Tutubalina,Andrey Kuznetsov,Vlad Shakhuro*

Main category: cs.CL

TL;DR: 本文介绍了一种新的对抗性文本改写任务，旨在通过在保持原始查询含义的同时生成语法正确的改写，以降低多模态大语言模型在图像分割任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管先前的工作主要集中在图像输入的扰动上，但在现实应用中，用户以不同方式表达相同意图的语义等效文本改写仍被忽视。因此，本文旨在探索文本改写的对抗性潜力。

Method: 提出了一种名为SPARTA的黑盒、句子级优化方法，该方法在文本自编码器的低维语义潜在空间中运行，并通过强化学习进行引导。同时，开发了一种全面的自动评估协议来评估对抗性改写质量。

Result: SPARTA在ReasonSeg和LLMSeg-40k数据集上的成功率显著高于先前方法，提高了2倍。

Conclusion: 高级推理分割模型即使在严格的语义和语法约束下，仍然容易受到对抗性改写的影响，这表明这些模型需要更强的鲁棒性。

Abstract: Multimodal large language models (MLLMs) have shown impressive capabilities
in vision-language tasks such as reasoning segmentation, where models generate
segmentation masks based on textual queries. While prior work has primarily
focused on perturbing image inputs, semantically equivalent textual
paraphrases-crucial in real-world applications where users express the same
intent in varied ways-remain underexplored. To address this gap, we introduce a
novel adversarial paraphrasing task: generating grammatically correct
paraphrases that preserve the original query meaning while degrading
segmentation performance. To evaluate the quality of adversarial paraphrases,
we develop a comprehensive automatic evaluation protocol validated with human
studies. Furthermore, we introduce SPARTA-a black-box, sentence-level
optimization method that operates in the low-dimensional semantic latent space
of a text autoencoder, guided by reinforcement learning. SPARTA achieves
significantly higher success rates, outperforming prior methods by up to 2x on
both the ReasonSeg and LLMSeg-40k datasets. We use SPARTA and competitive
baselines to assess the robustness of advanced reasoning segmentation models.
We reveal that they remain vulnerable to adversarial paraphrasing-even under
strict semantic and grammatical constraints. All code and data will be released
publicly upon acceptance.

</details>


### [42] [Charting the European LLM Benchmarking Landscape: A New Taxonomy and a Set of Best Practices](https://arxiv.org/abs/2510.24450)
*Špela Vintar,Taja Kuzman Pungeršek,Mojca Brglez,Nikola Ljubešić*

Main category: cs.CL

TL;DR: 本文概述了大型语言模型（LLM）基准测试的最新发展，提出了一个针对多语言或非英语使用场景的基准分类法，并倡导对评估方法进行更高程度的语言和文化敏感性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM基准测试的发展未能充分覆盖非英语语言，因此需要专门的多语言基准测试分类法和质量标准的指导。

Method: 提出了一种新的分类法，并建议了一套最佳实践和质量标准，以促进欧洲语言的协调基准开发。

Result: 提出了一个针对多语言或非英语使用场景的分类法，并推荐了一些评估方法的最佳实践。

Conclusion: 通过引入新的分类法和最佳实践，期望能够提升非英语语言基准测试的质量，并推动更协调的发展。

Abstract: While new benchmarks for large language models (LLMs) are being developed
continuously to catch up with the growing capabilities of new models and AI in
general, using and evaluating LLMs in non-English languages remains a
little-charted landscape. We give a concise overview of recent developments in
LLM benchmarking, and then propose a new taxonomy for the categorization of
benchmarks that is tailored to multilingual or non-English use scenarios. We
further propose a set of best practices and quality standards that could lead
to a more coordinated development of benchmarks for European languages. Among
other recommendations, we advocate for a higher language and culture
sensitivity of evaluation methods.

</details>


### [43] [Iterative Critique-Refine Framework for Enhancing LLM Personalization](https://arxiv.org/abs/2510.24469)
*Durga Prasad Maram,Dhruvin Gandhi,Zonghai Yao,Gayathri Akkinapalli,Franck Dernoncourt,Yu Wang,Ryan A. Rossi,Nesreen K. Ahmed*

Main category: cs.CL

TL;DR: PerFine是一个无需训练、通过迭代式、基于档案的反馈来增强个性化文本生成的框架。


<details>
  <summary>Details</summary>
Motivation: 个性化文本生成要求模型生成连贯文本，同时要符合用户的风格、语调和主题焦点，但现有方法在生成过程中容易出现风格、主题漂移。

Method: PerFine采用生成-批评-精炼的迭代流程，其中LLM生成草稿，批评LLM提供结构化反馈，生成器进行修订，并结合新颖的knockout策略保留更强草稿。还研究了Best-of-N和主题提取等推理时策略。

Result: 在Yelp、Goodreads和Amazon数据集上，PerFine在个性化方面持续优于PGraphRAG，GEval指标提升了7-13%，并且在3-5次精炼迭代中表现稳定。

Conclusion: 事后、基于档案的反馈为个性化LLM生成提供了一个强大、无需训练且模型无关的范式。

Abstract: Personalized text generation requires models not only to produce coherent
text but also to align with a target user's style, tone, and topical focus.
Existing retrieval-augmented approaches such as LaMP and PGraphRAG enrich
profiles with user and neighbor histories, but they stop at generation and
often yield outputs that drift in tone, topic, or style. We present PerFine, a
unified, training-free critique-refine framework that enhances personalization
through iterative, profile-grounded feedback. In each iteration, an LLM
generator produces a draft conditioned on the retrieved profile, and a critic
LLM - also conditioned on the same profile - provides structured feedback on
tone, vocabulary, sentence structure, and topicality. The generator then
revises, while a novel knockout strategy retains the stronger draft across
iterations. We further study additional inference-time strategies such as
Best-of-N and Topic Extraction to balance quality and efficiency. Across Yelp,
Goodreads, and Amazon datasets, PerFine consistently improves personalization
over PGraphRAG, with GEval gains of +7-13%, steady improvements over 3-5
refinement iterations, and scalability with increasing critic size. These
results highlight that post-hoc, profile-aware feedback offers a powerful
paradigm for personalized LLM generation that is both training-free and
model-agnostic.

</details>


### [44] [Talk2Ref: A Dataset for Reference Prediction from Scientific Talks](https://arxiv.org/abs/2510.24478)
*Frederik Broy,Maike Züfle,Jan Niehues*

Main category: cs.CL

TL;DR: 本文介绍了从科学演讲中预测相关文献的新任务RPT，并推出了首个大规模数据集Talk2Ref。


<details>
  <summary>Details</summary>
Motivation: 科学演讲是传播研究的重要媒介，自动识别与演讲相关文献对研究人员和学生极具价值。

Method: 引入了RPT任务，并构建了包含6,279个演讲和43,429篇引用论文的数据集Talk2Ref，采用先进的文本嵌入模型和双编码器架构进行训练。

Result: 通过对Talk2Ref的微调显著提高了引用预测性能，验证了数据集在从口语科学内容中学习语义表示的有效性。

Conclusion: 该研究展示了任务挑战性，并开源了数据集和模型以促进未来研究，将口语科学交流整合至引文推荐系统。

Abstract: Scientific talks are a growing medium for disseminating research, and
automatically identifying relevant literature that grounds or enriches a talk
would be highly valuable for researchers and students alike. We introduce
Reference Prediction from Talks (RPT), a new task that maps long, and
unstructured scientific presentations to relevant papers. To support research
on RPT, we present Talk2Ref, the first large-scale dataset of its kind,
containing 6,279 talks and 43,429 cited papers (26 per talk on average), where
relevance is approximated by the papers cited in the talk's corresponding
source publication. We establish strong baselines by evaluating
state-of-the-art text embedding models in zero-shot retrieval scenarios, and
propose a dual-encoder architecture trained on Talk2Ref. We further explore
strategies for handling long transcripts, as well as training for domain
adaptation. Our results show that fine-tuning on Talk2Ref significantly
improves citation prediction performance, demonstrating both the challenges of
the task and the effectiveness of our dataset for learning semantic
representations from spoken scientific content. The dataset and trained models
are released under an open license to foster future research on integrating
spoken scientific communication into citation recommendation systems.

</details>


### [45] [CritiCal: Can Critique Help LLM Uncertainty or Confidence Calibration?](https://arxiv.org/abs/2510.24505)
*Qing Zong,Jiayu Liu,Tianshi Zheng,Chunyang Li,Baixuan Xu,Haochen Shi,Weiqi Wang,Zhaowei Wang,Chunkit Chan,Yangqiu Song*

Main category: cs.CL

TL;DR: 大型语言模型（LLM）的准确置信度校准对于高风险领域的安全使用至关重要。本文提出用自然语言评论来提高置信度校准，并提出了Self-Critique和CritiCal方法。


<details>
  <summary>Details</summary>
Motivation: 在高风险领域，准确的置信度校准对于用户信任至关重要。传统方法在获取精确置信度标签方面存在困难，因此需要新的方法来解决这一问题。

Method: 提出Self-Critique和CritiCal方法，Self-Critique允许LLM自我评论并优化其置信度，CritiCal利用自然语言评论进行置信度校准训练，超越了直接数值优化。

Result: 实验表明，CritiCal显著优于Self-Critique和其他竞争基线，甚至在复杂推理任务中超越了GPT-4o。CritiCal在不分布外情况下也表现出良好的泛化能力。

Conclusion: CritiCal方法在提高LLM的置信度校准和可靠性方面表现出色，具有良好的泛化能力，为LLM在高风险领域的应用提供了新的解决方案。

Abstract: Accurate confidence calibration in Large Language Models (LLMs) is critical
for safe use in high-stakes domains, where clear verbalized confidence enhances
user trust. Traditional methods that mimic reference confidence expressions
often fail to capture the reasoning needed for accurate confidence assessment.
We propose natural language critiques as a solution, ideally suited for
confidence calibration, as precise gold confidence labels are hard to obtain
and often require multiple generations. This paper studies how natural language
critiques can enhance verbalized confidence, addressing: (1) What to critique:
uncertainty (question-focused) or confidence (answer-specific)? Analysis shows
confidence suits multiple-choice tasks, while uncertainty excels in open-ended
scenarios. (2) How to critique: self-critique or critique calibration training?
We propose Self-Critique, enabling LLMs to critique and optimize their
confidence beyond mere accuracy, and CritiCal, a novel Critique Calibration
training method that leverages natural language critiques to improve confidence
calibration, moving beyond direct numerical optimization. Experiments show that
CritiCal significantly outperforms Self-Critique and other competitive
baselines, even surpassing its teacher model, GPT-4o, in complex reasoning
tasks. CritiCal also shows robust generalization in out-of-distribution
settings, advancing LLM's reliability.

</details>


### [46] [Levée d'ambiguïtés par grammaires locales](https://arxiv.org/abs/2510.24530)
*Eric G. C. Laporte*

Main category: cs.CL

TL;DR: 本文介绍了一种用于词类标注的词汇消歧方法，旨在实现零静默率，并展示了在INTEX系统中该方法的实现与形式化描述。


<details>
  <summary>Details</summary>
Motivation: 词类标注是自然语言处理中的一个重要问题，许多应用如拼写纠正、语法检查和文本转语音等都需要准确的词类标注。为了实现零静默率，需要一种能够处理词汇歧义的方法。

Method: 提出的方法通过上下文信息减少词汇的词性歧义，并在Silberztein的INTEX系统中实现。该方法强调在验证局部消歧语法时，需要考虑转换器路径之间的相互作用，而不是孤立地考虑它们。

Result: 结果表明，在实现零静默率的目标下，局部语法需要仔细测试，并且需要详细描述语法应用到文本后的效果。

Conclusion: 为了达到零静默率，局部语法必须经过仔细测试和详细描述，以确保正确标注词汇的词性，尤其是在面对未预见的结构或歧义时。

Abstract: Many words are ambiguous in terms of their part of speech (POS). However,
when a word appears in a text, this ambiguity is generally much reduced.
Disambiguating POS involves using context to reduce the number of POS
associated with words, and is one of the main challenges of lexical tagging.
The problem of labeling words by POS frequently arises in natural language
processing, for example for spelling correction, grammar or style checking,
expression recognition, text-to-speech conversion, text corpus analysis, etc.
Lexical tagging systems are thus useful as an initial component of many natural
language processing systems. A number of recent lexical tagging systems produce
multiple solutions when the text is lexically ambiguous or the uniquely correct
solution cannot be found. These contributions aim to guarantee a zero silence
rate: the correct tag(s) for a word must never be discarded. This objective is
unrealistic for systems that tag each word uniquely. This article concerns a
lexical disambiguation method adapted to the objective of a zero silence rate
and implemented in Silberztein's INTEX system (1993). We present here a formal
description of this method. We show that to verify a local disambiguation
grammar in this framework, it is not sufficient to consider the transducer
paths separately: one needs to verify their interactions. Similarly, if a
combination of multiple transducers is used, the result cannot be predicted by
considering them in isolation. Furthermore, when examining the initial labeling
of a text as produced by INTEX, ideas for disambiguation rules come
spontaneously, but grammatical intuitions may turn out to be inaccurate, often
due to an unforeseen construction or ambiguity. If a zero silence rate is
targeted, local grammars must be carefully tested. This is where a detailed
specification of what a grammar will do once applied to texts would be
necessary.

</details>


### [47] [Dark & Stormy: Modeling Humor in the Worst Sentences Ever Written](https://arxiv.org/abs/2510.24538)
*Venkata S Govindarajan,Laura Biester*

Main category: cs.CL

TL;DR: 该论文介绍并分析了一个新的从Bulwer-Lytton Fiction Contest收集的句子语料库，以更好地理解英语中的“坏”幽默。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于当前幽默检测模型对于“坏”幽默的表现较差，需要更深入地理解这种幽默的复杂性。

Method: 研究人员从Bulwer-Lytton Fiction Contest中收集句子，分析文学手法，并使用标准幽默检测模型进行测试。此外，还使用LLMs生成类似风格的句子进行比较。

Result: 标准幽默检测模型在新收集的语料库上表现不佳，而LLMs生成的句子虽然模仿了形式，但过度使用某些文学手法，包含更多新颖的形容词-名词组合。

Conclusion: 该研究揭示了“坏”幽默的复杂性，并指出当前模型在处理这种幽默时的局限性。

Abstract: Textual humor is enormously diverse and computational studies need to account
for this range, including intentionally bad humor. In this paper, we curate and
analyze a novel corpus of sentences from the Bulwer-Lytton Fiction Contest to
better understand "bad" humor in English. Standard humor detection models
perform poorly on our corpus, and an analysis of literary devices finds that
these sentences combine features common in existing humor datasets (e.g., puns,
irony) with metaphor, metafiction and simile. LLMs prompted to synthesize
contest-style sentences imitate the form but exaggerate the effect by
over-using certain literary devices, and including far more novel
adjective-noun bigrams than human writers. Data, code and analysis are
available at https://github.com/venkatasg/bulwer-lytton

</details>


### [48] [Open Korean Historical Corpus: A Millennia-Scale Diachronic Collection of Public Domain Texts](https://arxiv.org/abs/2510.24541)
*Seyoung Song,Nawon Kim,Songeun Chae,Kiwoong Park,Jiho Jin,Haneul Yoo,Kyunghyun Cho,Alice Oh*

Main category: cs.CL

TL;DR: 本文介绍了Open Korean Historical Corpus，一个涵盖1300年历史、包含6种语言和多种书写系统的大规模、开放授权数据集，并利用该数据集分析了韩语的主要语言变迁。


<details>
  <summary>Details</summary>
Motivation: 韩语历史中口语和书面语的差异以及从汉字到韩文字母的转变，由于缺乏可访问的历史语料库，尚未在自然语言处理（NLP）领域得到充分研究。

Method: 作者引入了Open Korean Historical Corpus，该语料库包括1800万份文档和50亿个标记，时间跨度从7世纪到2025年，并涵盖19个来源。利用这一资源，作者定量分析了主要语言变迁。

Result: 研究发现：(1) Idu的使用在19世纪60年代达到顶峰后急剧下降；(2) 汉字到韩文字母的转变始于1890年左右，是一种迅速的变化；(3) 朝鲜的词汇差异导致现代分词器的未登录词率增加了51倍。

Conclusion: 该工作为定量历时分析提供了基础资源，能够作为大型语言模型的预训练语料库，有助于提高模型对现代韩文字母中的汉字词及古书写系统的理解。

Abstract: The history of the Korean language is characterized by a discrepancy between
its spoken and written forms and a pivotal shift from Chinese characters to the
Hangul alphabet. However, this linguistic evolution has remained largely
unexplored in NLP due to a lack of accessible historical corpora. To address
this gap, we introduce the Open Korean Historical Corpus, a large-scale, openly
licensed dataset spanning 1,300 years and 6 languages, as well as
under-represented writing systems like Korean-style Sinitic (Idu) and
Hanja-Hangul mixed script. This corpus contains 18 million documents and 5
billion tokens from 19 sources, ranging from the 7th century to 2025. We
leverage this resource to quantitatively analyze major linguistic shifts: (1)
Idu usage peaked in the 1860s before declining sharply; (2) the transition from
Hanja to Hangul was a rapid transformation starting around 1890; and (3) North
Korea's lexical divergence causes modern tokenizers to produce up to 51 times
higher out-of-vocabulary rates. This work provides a foundational resource for
quantitative diachronic analysis by capturing the history of the Korean
language. Moreover, it can serve as a pre-training corpus for large language
models, potentially improving their understanding of Sino-Korean vocabulary in
modern Hangul as well as archaic writing systems.

</details>


### [49] [BEST-RQ-Based Self-Supervised Learning for Whisper Domain Adaptation](https://arxiv.org/abs/2510.24570)
*Raphaël Bagat,Irina Illina,Emmanuel Vincent*

Main category: cs.CL

TL;DR: 提出了一种新的BEARD框架，利用无标注数据来适应Whisper的编码器，在低资源和域外场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 自动语音识别（ASR）在多语言训练中，面对标注数据稀缺的域外和低资源场景时表现不佳，需要新的适应方法。

Method: BEARD框架结合了BEST-RQ目标和来自冻结教师编码器的知识蒸馏，利用无标注数据适应Whisper的编码器。

Result: 在ATCO2语料库上，使用约5,000小时的无标注语音和2小时的标注语音，BEARD比之前的基线和微调模型有显著提升，相对于微调模型实现了12%的相对改进。

Conclusion: 该研究首次使用自监督学习目标对Whisper进行领域适应，为低资源和域外场景的ASR系统提供了一种有效的解决方案。

Abstract: Automatic Speech Recognition (ASR) systems, despite large multilingual
training, struggle in out-of-domain and low-resource scenarios where labeled
data is scarce. We propose BEARD (BEST-RQ Encoder Adaptation with Re-training
and Distillation), a novel framework designed to adapt Whisper's encoder using
unlabeled data. Unlike traditional self-supervised learning methods, BEARD
uniquely combines a BEST-RQ objective with knowledge distillation from a frozen
teacher encoder, ensuring the encoder's complementarity with the pre-trained
decoder. Our experiments focus on the ATCO2 corpus from the challenging Air
Traffic Control (ATC) communications domain, characterized by non-native
speech, noise, and specialized phraseology. Using about 5,000 hours of
untranscribed speech for BEARD and 2 hours of transcribed speech for
fine-tuning, the proposed approach significantly outperforms previous baseline
and fine-tuned model, achieving a relative improvement of 12% compared to the
fine-tuned model. To the best of our knowledge, this is the first work to use a
self-supervised learning objective for domain adaptation of Whisper.

</details>


### [50] [Zero-Shot Cross-Lingual Transfer using Prefix-Based Adaptation](https://arxiv.org/abs/2510.24619)
*Snegha A,Sayambhu Sen,Piyush Singh Pasi,Abhishek Singhania,Preethi Jyothi*

Main category: cs.CL

TL;DR: 本文研究了三种基于前缀的方法在零样本跨语言迁移中的表现，发现这些方法在多种语言和资源条件下优于LoRA。


<details>
  <summary>Details</summary>
Motivation: 随着Llama和Mistral等大型语言模型（LLMs）的发布，零样本跨语言迁移变得更加可行。然而，如何有效地将这些模型适应到不同语言的新任务中仍然是一个挑战。当前广泛使用的参数高效微调（PeFT）技术如LoRA，而基于前缀的技术却较少被探索。

Method: 研究比较了三种基于前缀的方法（软提示调整、前缀调整和Llama Adapter）在从英语到35种以上高低资源语言的零样本跨语言迁移中的表现，并分析了不同语言家族、文字体系和模型规模（1B到24B）下的效果。

Result: 在Belebele基准测试中，使用Llama 3.1 8B时，前缀方法比LoRA基线高出6%。Mistral v0.3 7B也表现出类似的改进。前缀调整仅使用1.23M学习参数，却在多个基准测试中实现了持续的改进。

Conclusion: 基于前缀的技术在零样本跨语言迁移中，特别是在低资源多语言环境下，是一种有效且可扩展的LoRA替代方法。

Abstract: With the release of new large language models (LLMs) like Llama and Mistral,
zero-shot cross-lingual transfer has become increasingly feasible due to their
multilingual pretraining and strong generalization capabilities. However,
adapting these decoder-only LLMs to new tasks across languages remains
challenging. While parameter-efficient fine-tuning (PeFT) techniques like
Low-Rank Adaptation (LoRA) are widely used, prefix-based techniques such as
soft prompt tuning, prefix tuning, and Llama Adapter are less explored,
especially for zero-shot transfer in decoder-only models. We present a
comprehensive study of three prefix-based methods for zero-shot cross-lingual
transfer from English to 35+ high- and low-resource languages. Our analysis
further explores transfer across linguistic families and scripts, as well as
the impact of scaling model sizes from 1B to 24B. With Llama 3.1 8B, prefix
methods outperform LoRA-baselines by up to 6% on the Belebele benchmark.
Similar improvements were observed with Mistral v0.3 7B as well. Despite using
only 1.23M learning parameters with prefix tuning, we achieve consistent
improvements across diverse benchmarks. These findings highlight the potential
of prefix-based techniques as an effective and scalable alternative to LoRA,
particularly in low-resource multilingual settings.

</details>


### [51] [ReForm: Reflective Autoformalization with Prospective Bounded Sequence Optimization](https://arxiv.org/abs/2510.24592)
*Guoxin Chen,Jing Wu,Xinjie Chen,Wayne Xin Zhao,Ruihua Song,Chengxi Li,Kai Fan,Dayiheng Liu,Minpeng Liao*

Main category: cs.CL

TL;DR: 本文提出了ReForm，一种新的自省式自动形式化方法，通过集成语义一致性评估，解决了现有大型语言模型在自动形式化过程中无法保持原问题语义的问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在自动形式化过程中，常将任务视为简单翻译，缺乏自我反思和逐步改进机制，导致生成的形式化语句未能保持原始问题语义。

Method: 提出了ReForm方法，将语义一致性评估集成到自动形式化过程中，并结合Prospective Bounded Sequence Optimization (PBSO)训练策略，以增强模型的自我纠正能力。

Result: 在四个自动形式化基准测试中，ReForm比最强基线平均提高了17.2个百分点，并引入了ConsistencyCheck基准，验证了模型的有效性。

Conclusion: ReForm通过自省和逐步优化，显著提高了自动形式化的准确性。同时，ConsistencyCheck基准揭示了自动形式化任务的内在难度，即使是人类专家也有高达38.5%的语义错误率。

Abstract: Autoformalization, which translates natural language mathematics into
machine-verifiable formal statements, is critical for using formal mathematical
reasoning to solve math problems stated in natural language. While Large
Language Models can generate syntactically correct formal statements, they
often fail to preserve the original problem's semantic intent. This limitation
arises from the LLM approaches' treating autoformalization as a simplistic
translation task which lacks mechanisms for self-reflection and iterative
refinement that human experts naturally employ. To address these issues, we
propose ReForm, a Reflective Autoformalization method that tightly integrates
semantic consistency evaluation into the autoformalization process. This
enables the model to iteratively generate formal statements, assess its
semantic fidelity, and self-correct identified errors through progressive
refinement. To effectively train this reflective model, we introduce
Prospective Bounded Sequence Optimization (PBSO), which employs different
rewards at different sequence positions to ensure that the model develops both
accurate autoformalization and correct semantic validations, preventing
superficial critiques that would undermine the purpose of reflection. Extensive
experiments across four autoformalization benchmarks demonstrate that ReForm
achieves an average improvement of 17.2 percentage points over the strongest
baselines. To further ensure evaluation reliability, we introduce
ConsistencyCheck, a benchmark of 859 expert-annotated items that not only
validates LLMs as judges but also reveals that autoformalization is inherently
difficult: even human experts produce semantic errors in up to 38.5% of cases.

</details>


### [52] [Dissecting Role Cognition in Medical LLMs via Neuronal Ablation](https://arxiv.org/abs/2510.24677)
*Xun Liang,Huayi Lai,Hanyu Wang,Wentao Zhang,Linfeng Zhang,Yanfang Chen,Feiyu Xiong,Zhiyu Li*

Main category: cs.CL

TL;DR: 该研究评估了角色提示对大型语言模型（LLMs）推理能力的影响，发现角色提示主要影响语言风格，而非增强推理能力。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于评估Prompt-Based Role Playing (PBRP) 方法在模拟不同临床角色时对模型推理能力的影响，以确定其是否真正模拟了专业认知过程。

Method: 引入RP-Neuron-Activated Evaluation Framework (RPNA)，通过神经元消融和表示分析技术评估角色提示对推理路径的影响。

Result: 结果显示角色提示并未显著增强LLMs的医疗推理能力，主要影响表面语言特征，未发现不同角色间有显著推理路径或认知差异。

Conclusion: 当前PBRP方法无法复制真实医疗实践中的认知复杂性，强调了开发能够模拟真正认知过程模型的需求。

Abstract: Large language models (LLMs) have gained significant traction in medical
decision support systems, particularly in the
  context of medical question answering and role-playing simulations. A common
practice, Prompt-Based Role Playing (PBRP),
  instructs models to adopt different clinical roles (e.g., medical students,
residents, attending physicians) to simulate varied
  professional behaviors. However, the impact of such role prompts on model
reasoning capabilities remains unclear. This
  study introduces the RP-Neuron-Activated Evaluation Framework(RPNA) to
evaluate whether role prompts induce distinct,
  role-specific cognitive processes in LLMs or merely modify linguistic style.
We test this framework on three medical QA
  datasets, employing neuron ablation and representation analysis techniques to
assess changes in reasoning pathways. Our
  results demonstrate that role prompts do not significantly enhance the
medical reasoning abilities of LLMs. Instead, they
  primarily affect surface-level linguistic features, with no evidence of
distinct reasoning pathways or cognitive differentiation
  across clinical roles. Despite superficial stylistic changes, the core
decision-making mechanisms of LLMs remain uniform
  across roles, indicating that current PBRP methods fail to replicate the
cognitive complexity found in real-world medical
  practice. This highlights the limitations of role-playing in medical AI and
emphasizes the need for models that simulate genuine
  cognitive processes rather than linguistic imitation.We have released the
related code in the following repository:https:
  //github.com/IAAR-Shanghai/RolePlay_LLMDoctor

</details>


### [53] [Diffusion LLM with Native Variable Generation Lengths: Let [EOS] Lead the Way](https://arxiv.org/abs/2510.24605)
*Yicun Yang,Cong Wang,Shaobo Wang,Zichen Wen,Biqing Qi,Hanlin Xu,Linfeng Zhang*

Main category: cs.CL

TL;DR: 提出了一种新的扩散式大语言模型（dLLM-Var），支持原生可变长度生成，提高效率和灵活性。


<details>
  <summary>Details</summary>
Motivation: 当前扩散式大语言模型（dLLMs）存在固定生成长度的问题，导致效率与灵活性不足。

Method: 训练一个能准确预测生成文本中[EOS] token的扩散大语言模型，使其能以块扩散方式进行原生推断，同时保持全局双向（完整）注意力和高并行性。

Result: 在标准基准测试中，该方法比传统dLLM推断范式快30.1倍，比Qwen和Llama等自回归模型快2.4倍。

Conclusion: 该方法实现了更高准确性和更快推断速度，使dLLMs超越了单纯的新奇学术价值，支持其在实际应用中的使用。

Abstract: Diffusion-based large language models (dLLMs) have exhibited substantial
potential for parallel text generation, which may enable more efficient
generation compared to autoregressive models. However, current dLLMs suffer
from fixed generation lengths, which indicates the generation lengths of dLLMs
have to be determined before decoding as a hyper-parameter, leading to issues
in efficiency and flexibility. To solve these problems, in this work, we
propose to train a diffusion LLM with native variable generation lengths,
abbreviated as dLLM-Var. Concretely, we aim to train a model to accurately
predict the [EOS] token in the generated text, which makes a dLLM be able to
natively infer in a block diffusion manner, while still maintaining the ability
of global bi-directional (full) attention and high parallelism. Experiments on
standard benchmarks demonstrate that our method achieves a 30.1x speedup over
traditional dLLM inference paradigms and a 2.4x speedup relative to
autoregressive models such as Qwen and Llama. Our method achieves higher
accuracy and faster inference, elevating dLLMs beyond mere academic novelty and
supporting their practical use in real-world applications. Codes and models
have been released.

</details>


### [54] [Long-Context Modeling with Dynamic Hierarchical Sparse Attention for On-Device LLMs](https://arxiv.org/abs/2510.24606)
*Siheng Xiong,Joe Zou,Faramarz Fekri,Yae Jee Cho*

Main category: cs.CL

TL;DR: 为了解决长上下文LLMs中注意力机制的高成本问题，本文提出了动态层次稀疏注意力（DHSA），这是一种数据驱动的动态稀疏注意力框架，无需重训练即可在线预测稀疏性。


<details>
  <summary>Details</summary>
Motivation: 注意力机制的高二次成本阻碍了长上下文LLM的扩展性，现有静态稀疏方法难以适应内容相关变化，而动态方法依赖于预定义模板或启发式机制，限制了通用性和准确性。

Method: DHSA通过自适应地将序列分割为不同长度的块，计算块表示，并通过长度归一化聚合来处理块长度变化，然后上采样块级相似性得分到标记级，以计算重要性得分，决定保留哪些标记级交互。

Result: 在Gemma2上的实验显示，DHSA在精度上媲美密集注意力，同时减少20-60%的预填充延迟和35%的峰值内存使用，相较于其他方法，实现了更高的准确性。

Conclusion: DHSA提供了一种高效且适应性强的解决方案，用于设备上的长上下文LLM，提高了准确性和效率。

Abstract: The quadratic cost of attention hinders the scalability of long-context LLMs,
especially in resource-constrained settings. Existing static sparse methods
such as sliding windows or global tokens utilizes the sparsity of attention to
reduce the cost of attention, but poorly adapts to the content-dependent
variations in attention due to their staticity. While previous work has
proposed several dynamic approaches to improve flexibility, they still depend
on predefined templates or heuristic mechanisms. Such strategies reduce
generality and prune tokens that remain contextually important, limiting their
accuracy across diverse tasks. To tackle these bottlenecks of existing methods
for long-context modeling, we introduce Dynamic Hierarchical Sparse Attention
(DHSA), a data-driven framework that dynamically predicts attention sparsity
online without retraining. Our proposed DHSA adaptively segments sequences into
variable-length chunks, then computes chunk representations by aggregating the
token embeddings within each chunk. To avoid the bias introduced by varying
chunk lengths, we apply length-normalized aggregation that scales the averaged
embeddings by the square root of the chunk size. Finally, DHSA upsamples the
chunk-level similarity scores to token level similarities to calculate
importance scores that determine which token-level interactions should be
preserved. Our experiments on Gemma2 with Needle-in-a-Haystack Test and
LongBench show that DHSA matches dense attention in accuracy, while reducing
prefill latency by 20-60% and peak memory usage by 35%. Compared to other
representative baselines such as block sparse attention, DHSA achieves
consistently higher accuracy (6-18% relative gains) with comparable or lower
cost, offering an efficient and adaptable solution for long-context on-device
LLMs.

</details>


### [55] [Relative Scaling Laws for LLMs](https://arxiv.org/abs/2510.24626)
*William Held,David Hall,Percy Liang,Diyi Yang*

Main category: cs.CL

TL;DR: 本文引入了相对缩放法则，以追踪模型在不同测试分布之间性能差距的变化，揭示了扩展模型时性能提升的不均衡性。


<details>
  <summary>Details</summary>
Motivation: 传统的缩放法则通常关注整体测试集的性能提升，掩盖了不同子群体之间的性能差异。本文旨在揭示这些被平均掉的差异，通过相对缩放法则来关注性能差距。

Method: 作者引入了相对缩放法则，并在标准预训练数据集上训练了255个解码器-only Transformer，使用匹配计算（IsoFLOP）预算，从$10^{18}$到$10^{20}$ FLOPs，以分析不同子群体的性能变化。

Result: 研究发现，不同领域的性能轨迹各异：MMLU学术领域趋向于平等，英语方言随人口规模变化，AI风险行为集群在预训练期间分裂，能力和影响力相关风险增加，而对抗性风险没有。

Conclusion: 扩展模型虽然提升了整体性能，但不是普遍均衡器。作者建议进一步研究时，应结合传统缩放法则与相对缩放法则，以更好地应对模型扩展中的稳健性挑战。

Abstract: Scaling laws describe how language models improve with additional data,
parameters, and compute. While widely used, they are typically measured on
aggregate test sets. Aggregate evaluations yield clean trends but average over
heterogeneous subpopulations, obscuring performance disparities. We introduce
relative scaling laws, which track how performance gaps between test
distributions evolve with scale rather than focusing solely on absolute error.
Using 255 decoder-only Transformers trained under matched-compute (IsoFLOP)
budgets from $10^{18}$--$10^{20}$ FLOPs on standard pretraining datasets, we
find diverse trajectories: academic domains on MMLU converge toward parity;
regional English dialects shift depending on population size; and clusters of
AI risk behaviours split, with capability- and influence-related risks
increasing during pretraining while adversarial risks do not. These results
show that although scaling improves overall performance, it is not a universal
equalizer. To support further study, we release all model checkpoints from this
work to enable practitioners to measure relative alongside traditional scaling
laws, in order to better prioritize robustness challenges in light of the
bitter lesson.

</details>


### [56] [OpenReward: Learning to Reward Long-form Agentic Tasks via Reinforcement Learning](https://arxiv.org/abs/2510.24636)
*Ziyou Hu,Zhengliang Shi,Minghang Zhu,Haitao Li,Teng Sun,Pengjie Ren,Suzan Verberne,Zhaochun Ren*

Main category: cs.CL

TL;DR: 本文提出了一种新的工具增强型长文本奖励模型OpenRM，通过外部工具获取相关证据，以解决现有奖励模型在知识密集型和长文本任务中的评估难题。


<details>
  <summary>Details</summary>
Motivation: 由于现有奖励模型在知识密集和长文本任务中，因模型内部知识不足而难以准确评估答案的正确性，因此需要引入外部工具来辅助评估。

Method: 引入OpenRM，该模型利用工具增强的方法，通过可控数据合成框架生成27K合成的成对样本，并使用Group Relative Policy Optimization (GRPO)进行训练，以联合监督中间工具使用和最终结果的准确性。

Result: 在三个新收集的数据集和两个广泛使用的基准测试中，OpenRM显著优于现有奖励建模方法，并在下游LLM对齐任务中实现了一致的增益。

Conclusion: 工具增强型奖励模型OpenRM在长文本评估中表现出色，展示了其在提高评估可靠性和扩展性方面的潜力。

Abstract: Reward models (RMs) have become essential for aligning large language models
(LLMs), serving as scalable proxies for human evaluation in both training and
inference. However, existing RMs struggle on knowledge-intensive and long-form
tasks, where evaluating correctness requires grounding beyond the model's
internal knowledge. This limitation hinders them from reliably discriminating
subtle quality differences, especially when external evidence is necessary. To
address this, we introduce OpenRM, a tool-augmented long-form reward model that
systematically judges open-ended responses by invoking external tools to gather
relevant evidence. We train OpenRM with Group Relative Policy Optimization
(GRPO) on over 27K synthesized pairwise examples generated through a
controllable data synthesis framework. The training objective jointly
supervises intermediate tool usage and final outcome accuracy, incentivizing
our reward model to learn effective evidence-based judgment strategies.
Extensive experiments on three newly-collected datasets and two widely-used
benchmarks demonstrate that OpenRM substantially outperforms existing reward
modeling approaches. As a further step, we integrate OpenRM into both
inference-time response selection and training-time data selection. This yields
consistent gains in downstream LLM alignment tasks, highlighting the potential
of tool-augmented reward models for scaling reliable long-form evaluation.

</details>


### [57] [ComboBench: Can LLMs Manipulate Physical Devices to Play Virtual Reality Games?](https://arxiv.org/abs/2510.24706)
*Shuqing Li,Jiayi Yan,Chenyu Niu,Jen-tse Huang,Yun Peng,Wenxuan Wang,Yepang Liu,Michael R. Lyu*

Main category: cs.CL

TL;DR: 本文介绍了一个名为ComboBench的基准测试，用于评估大型语言模型在虚拟现实游戏中将语义动作转化为设备操作的能力。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型是否能够像人类一样将高级语义动作转化为VR设备的具体操作仍然是一个未充分探索的领域。

Method: 引入了ComboBench基准，通过262个场景评估七个LLMs在四个流行VR游戏中的表现，并与人工标注和人类表现进行比较。

Result: Gemini-1.5-Pro等模型在任务分解方面表现优异，但在程序推理和空间理解方面仍不如人类。不同游戏间性能差异显著，少量示例能显著提升模型表现。

Conclusion: 尽管LLMs在VR操作方面具备潜力，但其在程序推理和空间理解上仍需提升，且性能受交互复杂性的影响。发布的材料有助于未来研究。

Abstract: Virtual Reality (VR) games require players to translate high-level semantic
actions into precise device manipulations using controllers and head-mounted
displays (HMDs). While humans intuitively perform this translation based on
common sense and embodied understanding, whether Large Language Models (LLMs)
can effectively replicate this ability remains underexplored. This paper
introduces a benchmark, ComboBench, evaluating LLMs' capability to translate
semantic actions into VR device manipulation sequences across 262 scenarios
from four popular VR games: Half-Life: Alyx, Into the Radius, Moss: Book II,
and Vivecraft. We evaluate seven LLMs, including GPT-3.5, GPT-4, GPT-4o,
Gemini-1.5-Pro, LLaMA-3-8B, Mixtral-8x7B, and GLM-4-Flash, compared against
annotated ground truth and human performance. Our results reveal that while
top-performing models like Gemini-1.5-Pro demonstrate strong task decomposition
capabilities, they still struggle with procedural reasoning and spatial
understanding compared to humans. Performance varies significantly across
games, suggesting sensitivity to interaction complexity. Few-shot examples
substantially improve performance, indicating potential for targeted
enhancement of LLMs' VR manipulation capabilities. We release all materials at
https://sites.google.com/view/combobench.

</details>


### [58] [Quantifying the Effects of Word Length, Frequency, and Predictability on Dyslexia](https://arxiv.org/abs/2510.24647)
*Hugo Rydel-Johnston,Alex Kafkas*

Main category: cs.CL

TL;DR: 在大规模自然阅读数据集中，分析阅读障碍者在何种情况下产生阅读成本。


<details>
  <summary>Details</summary>
Motivation: 研究阅读障碍者在自然阅读中的额外成本，并探索其与词长、词频和可预测性等特征的关系。

Method: 使用眼动追踪技术，将眼动数据与词级别特征（词长、频率和可预测性）对齐，建立模型分析每个特征对阅读障碍者阅读时间的影响。

Result: 所有三个特征在典型读者和阅读障碍者中都显著改变阅读时间，阅读障碍者对每个特征更敏感，尤其是可预测性。通过反事实操作这些特征，阅读障碍者与控制组之间的差距缩小了约三分之一，其中可预测性影响最大，其次是词长和频率。

Conclusion: 研究结果支持阅读障碍理论中关于语言工作记忆和语音编码要求增加的假设，并为进一步研究词汇复杂性和副中央凹预览效益提供动力，同时为干预和计算模型提供可操作的指导。

Abstract: We ask where, and under what conditions, dyslexic reading costs arise in a
large-scale naturalistic reading dataset. Using eye-tracking aligned to
word-level features (word length, frequency, and predictability), we model how
each feature influences dyslexic time costs. We find that all three features
robustly change reading times in both typical and dyslexic readers, and that
dyslexic readers show stronger sensitivities to each, especially
predictability. Counterfactual manipulations of these features substantially
narrow the dyslexic-control gap by about one third, with predictability showing
the strongest effect, followed by length and frequency. These patterns align
with dyslexia theories that posit heightened demands on linguistic working
memory and phonological encoding, and they motivate further work on lexical
complexity and parafoveal preview benefits to explain the remaining gap. In
short, we quantify when extra dyslexic costs arise, how large they are, and
offer actionable guidance for interventions and computational models for
dyslexics.

</details>


### [59] [Optimizing Retrieval for RAG via Reinforced Contrastive Learning](https://arxiv.org/abs/2510.24652)
*Jiawei Zhou,Lei Chen*

Main category: cs.CL

TL;DR: R3是一种通过试验和反馈强化对比学习的检索框架，专为检索增强生成（RAG）优化。


<details>
  <summary>Details</summary>
Motivation: 随着RAG的普及，信息检索（IR）的角色正在从为人类用户检索信息转变为为人工智能（AI）系统检索上下文知识，相关性变得难以事先定义或注释。

Method: R3通过试验和反馈强化对比学习，使检索器能在RAG环境中动态探索和优化相关性。在训练过程中，检索结果与环境交互，生成对比信号，自动指导检索器自我改进。

Result: 在多个任务上的广泛实验表明，R3将RAG性能提高了5.2%，超过原始检索器，并超过最先进的检索器4.9%，同时实现了与大模型增强检索和基于训练后或指令调整的大模型的RAG系统相当的结果。

Conclusion: R3高效且实用，仅需4个GPU并在一天内完成训练，为RAG系统提供了一种有效的检索框架。

Abstract: As retrieval-augmented generation (RAG) becomes increasingly widespread, the
role of information retrieval (IR) is shifting from retrieving information for
human users to retrieving contextual knowledge for artificial intelligence (AI)
systems, where relevance becomes difficult to define or annotate beforehand. To
address this challenge, we propose R3, a Retrieval framework optimized for RAG
through trialand-feedback Reinforced contrastive learning. Unlike prior
approaches that rely on annotated or synthetic data for supervised fine-tuning,
R3 enables the retriever to dynamically explore and optimize relevance within
the RAG environment. During training, the retrieved results interact with the
environment to produce contrastive signals that automatically guide the
retriever's self-improvement. Extensive experiments across diverse tasks
demonstrate that R3 improves RAG performance by 5.2% over the original
retriever and surpasses state-of-the-art retrievers by 4.9%, while achieving
comparable results to LLM-augmented retrieval and RAG systems built on
post-trained or instruction-tuned LLMs. It is both efficient and practical,
requiring only 4 GPUs and completing training within a single day.

</details>


### [60] [MQM Re-Annotation: A Technique for Collaborative Evaluation of Machine Translation](https://arxiv.org/abs/2510.24664)
*Parker Riley,Daniel Deutsch,Mara Finkelstein,Colten DiIanni,Juraj Juraska,Markus Freitag*

Main category: cs.CL

TL;DR: 论文提出了一种名为MQM re-annotation的两阶段翻译评估方法，通过重新标注MQM注释来提高标注质量。


<details>
  <summary>Details</summary>
Motivation: 随着机器翻译模型质量的提高，现有评估方法需要改进，以确保质量提升不会因评估噪声而丢失。

Method: 实验采用两阶段MQM评估范式，MQM标注者审查并编辑已有的MQM注释，这些注释可能来自自己、其他标注者或自动MQM标注系统。

Result: 重新标注的行为符合目标，并且重新标注提高了标注质量，主要是通过发现首次标注时遗漏的错误。

Conclusion: 两阶段MQM重标注方法有效提高了翻译评估的精度和可靠性。

Abstract: Human evaluation of machine translation is in an arms race with translation
model quality: as our models get better, our evaluation methods need to be
improved to ensure that quality gains are not lost in evaluation noise. To this
end, we experiment with a two-stage version of the current state-of-the-art
translation evaluation paradigm (MQM), which we call MQM re-annotation. In this
setup, an MQM annotator reviews and edits a set of pre-existing MQM
annotations, that may have come from themselves, another human annotator, or an
automatic MQM annotation system. We demonstrate that rater behavior in
re-annotation aligns with our goals, and that re-annotation results in
higher-quality annotations, mostly due to finding errors that were missed
during the first pass.

</details>


### [61] [SPICE: Self-Play In Corpus Environments Improves Reasoning](https://arxiv.org/abs/2510.24684)
*Bo Liu,Chuanyang Jin,Seungone Kim,Weizhe Yuan,Wenting Zhao,Ilia Kulikov,Xian Li,Sainbayar Sukhbaatar,Jack Lanchantin,Jason Weston*

Main category: cs.CL

TL;DR: SPICE是一个强化学习框架，通过模型在挑战者和推理者两个角色之间进行自我对抗，利用大型文档库自动生成和解决推理任务，从而实现持续自我改进。


<details>
  <summary>Details</summary>
Motivation: 自我改进系统需要与环境的交互以实现持续适应，而现有的自我对抗方法缺乏丰富的外部信号，限制了改进效果。

Method: SPICE框架中，一个模型分为两个角色：挑战者从大型文档库中挖掘文档并生成多样化的推理任务，推理者解决这些任务。通过对抗性动态，挑战者在推理者的能力前沿自动生成课程，而文档库提供了丰富的外部信号。

Result: SPICE在数学（+8.9%）和一般推理（+9.8%）基准测试中实现了持续的改进，优于现有的无根基自我对抗方法。

Conclusion: 文档库是SPICE的关键组成部分，使其能够不断生成更具挑战性的目标并实现这些目标，从而实现持续的自我改进。

Abstract: Self-improving systems require environmental interaction for continuous
adaptation. We introduce SPICE (Self-Play In Corpus Environments), a
reinforcement learning framework where a single model acts in two roles: a
Challenger that mines documents from a large corpus to generate diverse
reasoning tasks, and a Reasoner that solves them. Through adversarial dynamics,
the Challenger creates an automatic curriculum at the frontier of the
Reasoner's capability, while corpus grounding provides the rich,
near-inexhaustible external signal necessary for sustained improvement. Unlike
existing ungrounded self-play methods that offer more limited benefits, SPICE
achieves consistent gains across mathematical (+8.9%) and general reasoning
(+9.8%) benchmarks on multiple model families. Our analysis reveals how
document grounding is a key ingredient in SPICE to continuously generate its
own increasingly challenging goals and achieve them, enabling sustained
self-improvement.

</details>


### [62] [MetricX-25 and GemSpanEval: Google Translate Submissions to the WMT25 Evaluation Shared Task](https://arxiv.org/abs/2510.24707)
*Juraj Juraska,Tobias Domhan,Mara Finkelstein,Tetsuji Nakagawa,Geza Kovacs,Daniel Deutsch,Pidong Wang,Markus Freitag*

Main category: cs.CL

TL;DR: 本文介绍了在WMT25翻译评估共享任务中的两个系统：MetricX-25用于质量分数预测，GemSpanEval用于错误跨度检测。


<details>
  <summary>Details</summary>
Motivation: 旨在提升翻译质量评估的准确性，通过改进输入格式和训练协议，以及开发新模型来预测错误跨度及其严重性和类别。

Method: MetricX-25采用Gemma 3的编码器-回归架构进行质量分数预测；GemSpanEval采用解码器架构，将错误跨度检测作为生成任务，并输出每个预测错误跨度的上下文。

Result: MetricX-25在MQM和ESA质量分数预测上显著优于前代模型；GemSpanEval在错误跨度检测上与xCOMET基准具有竞争力。

Conclusion: 通过采用先进的Gemma 3模型并结合新的训练方法和任务设计，两个系统在各自子任务中均取得了显著效果。

Abstract: In this paper, we present our submissions to the unified WMT25 Translation
Evaluation Shared Task. For the Quality Score Prediction subtask, we create a
new generation of MetricX with improvements in the input format and the
training protocol, while for the Error Span Detection subtask we develop a new
model, GemSpanEval, trained to predict error spans along with their severities
and categories. Both systems are based on the state-of-the-art multilingual
open-weights model Gemma 3, fine-tuned on publicly available WMT data. We
demonstrate that MetricX-25, adapting Gemma 3 to an encoder-only architecture
with a regression head on top, can be trained to effectively predict both MQM
and ESA quality scores, and significantly outperforms its predecessor. Our
decoder-only GemSpanEval model, on the other hand, we show to be competitive in
error span detection with xCOMET, a strong encoder-only sequence-tagging
baseline. With error span detection formulated as a generative task, we
instruct the model to also output the context for each predicted error span,
thus ensuring that error spans are identified unambiguously.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [63] [Game-TARS: Pretrained Foundation Models for Scalable Generalist Multimodal Game Agents](https://arxiv.org/abs/2510.23691)
*Zihao Wang,Xujing Li,Yining Ye,Junjie Fang,Haoming Wang,Longxiang Liu,Shihao Liang,Junting Lu,Zhiyong Wu,Jiazhan Feng,Wanjun Zhong,Zili Li,Yu Wang,Yu Miao,Bo Zhou,Yuanfan Li,Hao Wang,Zhongkai Zhao,Faming Wu,Zhengxuan Jiang,Weihao Tan,Heyuan Yao,Shi Yan,Xiangyang Li,Yitao Liang,Yujia Qin,Guang Shi*

Main category: cs.AI

TL;DR: 提出Game-TARS，一种基于统一可扩展动作空间（键盘-鼠标输入）的通用游戏智能体，通过大规模跨领域预训练和关键技术（衰减持续损失、稀疏思考策略）实现多类游戏任务的性能突破。


<details>
  <summary>Details</summary>
Motivation: 现有API或GUI方法的局限性促使研究者探索更通用、可扩展的游戏智能体训练范式，以实现跨操作系统、网页和模拟游戏的大规模持续学习。

Method: 采用以人类对齐的键盘-鼠标输入为锚点的统一动作空间，结合500B+多领域轨迹数据预训练；关键技术包括减少因果混淆的衰减持续损失和平衡推理深度与成本的稀疏思考策略。

Result: 在Minecraft任务上成功率超现有最优模型2倍；在未见3D网页游戏接近人类水平；在FPS基准测试中性能超过GPT-5、Gemini-2.5-Pro和Claude-4-Sonnet。

Conclusion: 简单可扩展的动作表示与大规模预训练相结合是构建具有广泛计算机操作能力通用智能体的有效路径，且该框架在训练和测试阶段均展现出良好的可扩展性。

Abstract: We present Game-TARS, a generalist game agent trained with a unified,
scalable action space anchored to human-aligned native keyboard-mouse inputs.
Unlike API- or GUI-based approaches, this paradigm enables large-scale
continual pre-training across heterogeneous domains, including OS, web, and
simulation games. Game-TARS is pre-trained on over 500B tokens with diverse
trajectories and multimodal data. Key techniques include a decaying continual
loss to reduce causal confusion and an efficient Sparse-Thinking strategy that
balances reasoning depth and inference cost. Experiments show that Game-TARS
achieves about 2 times the success rate over the previous sota model on
open-world Minecraft tasks, is close to the generality of fresh humans in
unseen web 3d games, and outperforms GPT-5, Gemini-2.5-Pro, and Claude-4-Sonnet
in FPS benchmarks. Scaling results on training-time and test-time confirm that
the unified action space sustains improvements when scaled to cross-game and
multimodal data. Our results demonstrate that simple, scalable action
representations combined with large-scale pre-training provide a promising path
toward generalist agents with broad computer-use abilities.

</details>


### [64] [AI and the Decentering of Disciplinary Creativity](https://arxiv.org/abs/2510.23734)
*Eamon Duede*

Main category: cs.AI

TL;DR: 本文探讨了人工智能在科学问题解决中的作用，特别是其对学科创造力的影响。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于分析人工智能如何在科学领域中影响创造力和学科特定专长的应用。

Method: 通过哲学创造力的最新研究，区分了创造性方法和创造性产品，并引入了学科创造力的概念。通过两个数学案例进行分析。

Result: 计算可以扩展学科创造力，但某些涉及AI的方法可能会取代它。

Conclusion: AI的替代可能会改变或降低科学追求的价值。

Abstract: This paper examines the role of artificial intelligence in scientific
problem-solving, with a focus on its implications for disciplinary creativity.
Drawing on recent work in the philosophy of creativity, I distinguish between
creative approaches and creative products, and introduce the concept of
disciplinary creativity -the creative application of discipline-specific
expertise to a valued problem within that field. Through two cases in
mathematics, I show that while computation can extend disciplinary creativity,
certain approaches involving AI can serve to displace it. This displacement has
the potential to alter (and, perhaps, diminish) the value of scientific
pursuit.

</details>


### [65] [Multi-Environment POMDPs: Discrete Model Uncertainty Under Partial Observability](https://arxiv.org/abs/2510.23744)
*Eline M. Bovy,Caleb Probine,Marnix Suilen,Ufuk Topcu,Nils Jansen*

Main category: cs.AI

TL;DR: 本文扩展了标准POMDPs，引入了多环境POMDPs（ME-POMDPs）和对抗信念POMDPs（AB-POMDPs），并开发了计算鲁棒策略的算法。


<details>
  <summary>Details</summary>
Motivation: ME-POMDPs通过引入离散模型不确定性扩展了标准POMDPs，适用于多个领域专家对问题建模存在分歧的情况，目标是找到一种在所有POMDPs中都能表现良好的鲁棒策略。

Method: 本文首先将ME-POMDPs推广到包含初始信念集的AB-POMDPs，并证明了任意ME-POMDP可以简化为仅在某些函数上变化的ME-POMDP。接着，设计了精确和近似算法来计算AB-POMDPs的鲁棒策略。

Result: 作者展示了算法可以计算标准POMDP基准在多环境设置下的策略，并保持了最优策略。

Conclusion: 通过引入AB-POMDPs和相应的算法，本文提供了一种有效的方式来处理多环境POMDPs，从而增强了模型在不确定性环境中的鲁棒性。

Abstract: Multi-environment POMDPs (ME-POMDPs) extend standard POMDPs with discrete
model uncertainty. ME-POMDPs represent a finite set of POMDPs that share the
same state, action, and observation spaces, but may arbitrarily vary in their
transition, observation, and reward models. Such models arise, for instance,
when multiple domain experts disagree on how to model a problem. The goal is to
find a single policy that is robust against any choice of POMDP within the set,
i.e., a policy that maximizes the worst-case reward across all POMDPs. We
generalize and expand on existing work in the following way. First, we show
that ME-POMDPs can be generalized to POMDPs with sets of initial beliefs, which
we call adversarial-belief POMDPs (AB-POMDPs). Second, we show that any
arbitrary ME-POMDP can be reduced to a ME-POMDP that only varies in its
transition and reward functions or only in its observation and reward
functions, while preserving (optimal) policies. We then devise exact and
approximate (point-based) algorithms to compute robust policies for AB-POMDPs,
and thus ME-POMDPs. We demonstrate that we can compute policies for standard
POMDP benchmarks extended to the multi-environment setting.

</details>


### [66] [Test-Time Tuned Language Models Enable End-to-end De Novo Molecular Structure Generation from MS/MS Spectra](https://arxiv.org/abs/2510.23746)
*Laura Mismetti,Marvin Alberts,Andreas Krause,Mara Graziani*

Main category: cs.AI

TL;DR: 该论文提出了一种利用测试时调整增强预训练transformer模型，直接从串联质谱和分子式生成分子结构的新框架。


<details>
  <summary>Details</summary>
Motivation: 当前方法依赖于数据库匹配或多步骤流程，对未在数据库中的分子识别具有挑战性。本文旨在通过端到端的方式直接从质谱数据生成分子结构，以解决这一难题。

Method: 引入了一个利用测试时调整增强预训练transformer模型的框架，实现从串联质谱和分子式端到端地生成分子结构，无需中间步骤。

Result: 在NPLIB1和MassSpecGym两个基准测试中，该方法超越了现有最佳方法DiffMS，性能分别提升100%和20%。在MassSpecGym上，测试时调整相对于传统微调的性能提升为62%。

Conclusion: 该方法不仅提升了分子结构生成的准确性，还能在预测偏离真实结构时生成结构上准确的候选分子，为人工解释提供了有价值的指导，提升了识别的可靠性。

Abstract: Tandem Mass Spectrometry enables the identification of unknown compounds in
crucial fields such as metabolomics, natural product discovery and
environmental analysis. However, current methods rely on database matching from
previously observed molecules, or on multi-step pipelines that require
intermediate fragment or fingerprint prediction. This makes finding the correct
molecule highly challenging, particularly for compounds absent from reference
databases. We introduce a framework that, by leveraging test-time tuning,
enhances the learning of a pre-trained transformer model to address this gap,
enabling end-to-end de novo molecular structure generation directly from the
tandem mass spectra and molecular formulae, bypassing manual annotations and
intermediate steps. We surpass the de-facto state-of-the-art approach DiffMS on
two popular benchmarks NPLIB1 and MassSpecGym by 100% and 20%, respectively.
Test-time tuning on experimental spectra allows the model to dynamically adapt
to novel spectra, and the relative performance gain over conventional
fine-tuning is of 62% on MassSpecGym. When predictions deviate from the ground
truth, the generated molecular candidates remain structurally accurate,
providing valuable guidance for human interpretation and more reliable
identification.

</details>


### [67] [Evaluating In Silico Creativity: An Expert Review of AI Chess Compositions](https://arxiv.org/abs/2510.23772)
*Vivek Veeriah,Federico Barbero,Marcus Chiam,Xidong Feng,Michael Dennis,Ryan Pachauri,Thomas Tumiel,Johan Obando-Ceron,Jiaxin Shi,Shaobo Hou,Satinder Singh,Nenad Tomašev,Tom Zahavy*

Main category: cs.AI

TL;DR: 本文研究了生成式AI在国际象棋谜题创作中的创造力，并展示了具备美学吸引力、新颖性和独特解法的AI系统。


<details>
  <summary>Details</summary>
Motivation: 生成式AI的快速发展引发了关于其创造力和新颖性输出能力的质疑，本研究旨在探讨AI在国际象棋谜题创作中的实际创造力。

Method: 研究人员设计了一个AI系统来生成具有美学吸引力、新颖性和独特解法的国际象棋谜题，并邀请了三位国际象棋大师对生成的谜题进行评估，包括选择他们最喜欢的谜题并解释其吸引力所在。

Result: 三位国际象棋大师（Amatzia Avni、Jonathan Levitt和Matthew Sadler）参与了评估，他们对AI生成的谜题进行了选择，并基于创造力、挑战性和美学设计等方面进行了评价。

Conclusion: 该研究表明，生成式AI在国际象棋谜题创作中可以表现出一定的创造力，并受到国际象棋专家的认可和欣赏。

Abstract: The rapid advancement of Generative AI has raised significant questions
regarding its ability to produce creative and novel outputs. Our recent work
investigates this question within the domain of chess puzzles and presents an
AI system designed to generate puzzles characterized by aesthetic appeal,
novelty, counter-intuitive and unique solutions. We briefly discuss our method
below and refer the reader to the technical paper for more details. To assess
our system's creativity, we presented a curated booklet of AI-generated puzzles
to three world-renowned experts: International Master for chess compositions
Amatzia Avni, Grandmaster Jonathan Levitt, and Grandmaster Matthew Sadler. All
three are noted authors on chess aesthetics and the evolving role of computers
in the game. They were asked to select their favorites and explain what made
them appealing, considering qualities such as their creativity, level of
challenge, or aesthetic design.

</details>


### [68] [Why Foundation Models in Pathology Are Failing](https://arxiv.org/abs/2510.23807)
*Hamid R. Tizhoosh*

Main category: cs.AI

TL;DR: 该论文探讨了基础模型在计算病理学中的应用，揭示了其在癌症诊断、预测和检索中的基本弱点，并指出了导致这些问题的七个原因。


<details>
  <summary>Details</summary>
Motivation: 基础模型在非医学领域取得了巨大成功，但在计算病理学中的表现却不尽如人意。论文旨在分析这些模型在病理学中表现不佳的根本原因。

Method: 通过系统性评估，论文识别出基础模型在病理学中的七个相互关联的问题原因，包括生物复杂性、无效的自监督、过度泛化、结构复杂性、领域特定创新的缺乏、数据不足和组织块大小的设计缺陷。

Result: 当前的基础模型在病理学中表现出低诊断准确性、鲁棒性差、几何不稳定、计算需求高和安全漏洞等问题。

Conclusion: 基础模型在病理学中的表现不佳是由于与组织形态学本质上的概念不匹配，因此需要对这一范式进行根本性的重新思考。

Abstract: In non-medical domains, foundation models (FMs) have revolutionized computer
vision and language processing through large-scale self-supervised and
multimodal learning. Consequently, their rapid adoption in computational
pathology was expected to deliver comparable breakthroughs in cancer diagnosis,
prognostication, and multimodal retrieval. However, recent systematic
evaluations reveal fundamental weaknesses: low diagnostic accuracy, poor
robustness, geometric instability, heavy computational demands, and concerning
safety vulnerabilities. This short paper examines these shortcomings and argues
that they stem from deeper conceptual mismatches between the assumptions
underlying generic foundation modeling in mainstream AI and the intrinsic
complexity of human tissue. Seven interrelated causes are identified:
biological complexity, ineffective self-supervision, overgeneralization,
excessive architectural complexity, lack of domain-specific innovation,
insufficient data, and a fundamental design flaw related to tissue patch size.
These findings suggest that current pathology foundation models remain
conceptually misaligned with the nature of tissue morphology and call for a
fundamental rethinking of the paradigm itself.

</details>


### [69] [ReCAP: Recursive Context-Aware Reasoning and Planning for Large Language Model Agents](https://arxiv.org/abs/2510.23822)
*Zhenyu Zhang,Tianyi Chen,Weiran Xu,Alex Pentland,Jiaxin Pei*

Main category: cs.AI

TL;DR: ReCAP是一种递归上下文感知推理和规划的层次框架，通过共享上下文提高LLMs在多步推理和动态重规划中的表现。


<details>
  <summary>Details</summary>
Motivation: 长视距任务需要多步推理和动态重规划，但现有的顺序提示方法容易上下文漂移，层次提示方法则可能削弱跨层级连续性或增加运行时间开销。

Method: ReCAP结合了三种关键机制：(i) 提前计划分解，(ii) 父计划结构化重注入，(iii) 记忆高效执行。

Result: 实验表明，ReCAP在各种长视距推理基准测试中显著提高了子目标一致性和成功率，在同步和异步Robotouille任务上分别获得了32%和29%的性能提升。

Conclusion: ReCAP通过其关键机制有效提高了LLMs在长视距任务中的推理和规划能力，减少了冗余提示，并在递归过程中保持上下文一致性。

Abstract: Long-horizon tasks requiring multi-step reasoning and dynamic re-planning
remain challenging for large language models (LLMs). Sequential prompting
methods are prone to context drift, loss of goal information, and recurrent
failure cycles, while hierarchical prompting methods often weaken cross-level
continuity or incur substantial runtime overhead. We introduce ReCAP (Recursive
Context-Aware Reasoning and Planning), a hierarchical framework with shared
context for reasoning and planning in LLMs. ReCAP combines three key
mechanisms: (i) plan-ahead decomposition, in which the model generates a full
subtask list, executes the first item, and refines the remainder; (ii)
structured re-injection of parent plans, maintaining consistent multi-level
context during recursive return; and (iii) memory-efficient execution, bounding
the active prompt so costs scale linearly with task depth. Together these
mechanisms align high-level goals with low-level actions, reduce redundant
prompting, and preserve coherent context updates across recursion. Experiments
demonstrate that ReCAP substantially improves subgoal alignment and success
rates on various long-horizon reasoning benchmarks, achieving a 32% gain on
synchronous Robotouille and a 29% improvement on asynchronous Robotouille under
the strict pass@1 protocol.

</details>


### [70] [Decentralized Multi-Agent Goal Assignment for Path Planning using Large Language Models](https://arxiv.org/abs/2510.23824)
*Murad Ismayilov,Edwin Meriaux,Shuo Wen,Gregory Dudek*

Main category: cs.AI

TL;DR: 本文研究了多智能体路径规划中的分散式目标分配问题，通过结构化环境表示和固定冲突解决规则，比较了贪婪启发式、最优分配和基于大语言模型（LLM）的智能体性能。


<details>
  <summary>Details</summary>
Motivation: 解决在共享环境中多个自主智能体的分散式目标分配问题，尤其是在无需协商或迭代协调的条件下。

Method: 智能体基于结构化环境表示（如网格可视化和场景数据）独立生成目标优先级，通过固定、确定性的冲突解决规则（例如智能体索引排序）进行目标分配，并比较了贪婪启发式、最优分配和LLM-based智能体。

Result: 当提供精心设计的提示和相关量化信息时，基于LLM的智能体能够实现接近最优的makespan，并且始终优于传统启发式方法。

Conclusion: 语言模型在多智能体路径规划的分散式目标分配中具有潜力，同时强调了信息结构在此类系统中的重要性。

Abstract: Coordinating multiple autonomous agents in shared environments under
decentralized conditions is a long-standing challenge in robotics and
artificial intelligence. This work addresses the problem of decentralized goal
assignment for multi-agent path planning, where agents independently generate
ranked preferences over goals based on structured representations of the
environment, including grid visualizations and scenario data. After this
reasoning phase, agents exchange their goal rankings, and assignments are
determined by a fixed, deterministic conflict-resolution rule (e.g., agent
index ordering), without negotiation or iterative coordination. We
systematically compare greedy heuristics, optimal assignment, and large
language model (LLM)-based agents in fully observable grid-world settings. Our
results show that LLM-based agents, when provided with well-designed prompts
and relevant quantitative information, can achieve near-optimal makespans and
consistently outperform traditional heuristics. These findings underscore the
potential of language models for decentralized goal assignment in multi-agent
path planning and highlight the importance of information structure in such
systems.

</details>


### [71] [Generating Creative Chess Puzzles](https://arxiv.org/abs/2510.23881)
*Xidong Feng,Vivek Veeriah,Marcus Chiam,Michael Dennis,Ryan Pachauri,Thomas Tumiel,Federico Barbero,Johan Obando-Ceron,Jiaxin Shi,Satinder Singh,Shaobo Hou,Nenad Tomašev,Tom Zahavy*

Main category: cs.AI

TL;DR: 本文提出了一种通过强化学习框架和基于国际象棋引擎搜索统计的新奖励机制，以生成更具创意和反直觉的国际象棋谜题。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在创意、美学和反直觉输出方面仍面临挑战，尤其是在国际象棋谜题的生成上。

Method: 引入强化学习框架，并设计新颖的奖励机制，通过国际象棋引擎搜索统计数据来增强谜题的独特性、反直觉性、多样性和真实性。

Result: 强化学习方法将反直觉谜题的生成率从0.22%提高到2.5%，显著超过现有数据集和最佳Lichess训练模型。生成的谜题在创意和享受度方面被人类专家评价为优于传统书集谜题。

Conclusion: 该研究成功生成了被三位世界级专家认可为富有创意的国际象棋谜题，并汇编成册。

Abstract: While Generative AI rapidly advances in various domains, generating truly
creative, aesthetic, and counter-intuitive outputs remains a challenge. This
paper presents an approach to tackle these difficulties in the domain of chess
puzzles. We start by benchmarking Generative AI architectures, and then
introduce an RL framework with novel rewards based on chess engine search
statistics to overcome some of those shortcomings. The rewards are designed to
enhance a puzzle's uniqueness, counter-intuitiveness, diversity, and realism.
Our RL approach dramatically increases counter-intuitive puzzle generation by
10x, from 0.22\% (supervised) to 2.5\%, surpassing existing dataset rates
(2.1\%) and the best Lichess-trained model (0.4\%). Our puzzles meet novelty
and diversity benchmarks, retain aesthetic themes, and are rated by human
experts as more creative, enjoyable, and counter-intuitive than composed book
puzzles, even approaching classic compositions. Our final outcome is a curated
booklet of these AI-generated puzzles, which is acknowledged for creativity by
three world-renowned experts.

</details>


### [72] [Hybrid Modeling, Sim-to-Real Reinforcement Learning, and Large Language Model Driven Control for Digital Twins](https://arxiv.org/abs/2510.23882)
*Adil Rasheed,Oscar Ravik,Omer San*

Main category: cs.AI

TL;DR: 本文研究了数字孪生技术在动态系统建模与控制中的应用，通过在微型温室平台上测试多种模型和控制策略，发现混合分析建模（HAM）和模型预测控制（MPC）在性能上表现出色。


<details>
  <summary>Details</summary>
Motivation: 该研究旨在探索数字孪生技术结合物理、数据驱动和混合方法在动态系统建模与控制中的有效性，以及不同模型和控制策略的权衡。

Method: 研究使用了一个微型温室作为测试平台，开发了四种预测模型（线性、基于物理的建模（PBM）、长短期记忆（LSTM）、混合分析建模（HAM）），并实施了三种控制策略（模型预测控制（MPC）、强化学习（RL）、基于大型语言模型（LLM）的控制）进行比较。

Result: 建模方面，HAM在准确性、泛化性和计算效率方面表现最平衡，而LSTM在更高资源成本下实现高精度。控制方面，MPC提供稳健和预测性性能，RL表现出强大的适应性，LLM控制器在与预测工具结合时提供灵活的人机交互。

Conclusion: HAM和MPC在建模和控制中分别展示了最优性能，而LSTM和RL在特定场景下也有其优势，LLM控制器则展示了人机交互的潜力。

Abstract: This work investigates the use of digital twins for dynamical system modeling
and control, integrating physics-based, data-driven, and hybrid approaches with
both traditional and AI-driven controllers. Using a miniature greenhouse as a
test platform, four predictive models Linear, Physics-Based Modeling (PBM),
Long Short Term Memory (LSTM), and Hybrid Analysis and Modeling (HAM) are
developed and compared under interpolation and extrapolation scenarios. Three
control strategies Model Predictive Control (MPC), Reinforcement Learning (RL),
and Large Language Model (LLM) based control are also implemented to assess
trade-offs in precision, adaptability, and implementation effort. Results show
that in modeling HAM provides the most balanced performance across accuracy,
generalization, and computational efficiency, while LSTM achieves high
precision at greater resource cost. Among controllers, MPC delivers robust and
predictable performance, RL demonstrates strong adaptability, and LLM-based
controllers offer flexible human-AI interaction when coupled with predictive
tools.

</details>


### [73] [Latent Chain-of-Thought for Visual Reasoning](https://arxiv.org/abs/2510.23925)
*Guohao Sun,Hang Hua,Jian Wang,Jiebo Luo,Sohail Dianat,Majid Rabbani,Raghuveer Rao,Zhiqiang Tao*

Main category: cs.AI

TL;DR: 本文提出了一种基于变分推断和多样性寻求强化学习的可扩展训练算法，用于提升大型视觉-语言模型（LVLMs）的思维链（CoT）推理能力，并引入稀疏奖励函数和贝叶斯推理扩展策略，以增强模型的泛化性、有效性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前的LVLMs在推理任务上的训练算法（如SFT, PPO, GRPO）存在泛化能力差和依赖有偏奖励模型的问题，作者希望通过新的训练方法改善这些不足。

Method: 将LVLMs的推理过程重构为后验推断，提出基于amortized variational inference的可扩展训练算法，引入多样性寻求的强化学习算法和稀疏奖励函数，并采用贝叶斯推理扩展策略。

Result: 在七个推理基准测试中，该方法显著提升了LVLMs的性能，改善了模型的有效性、泛化能力和可解释性。

Conclusion: 通过引入新的训练算法和稀疏奖励函数，该方法有效解决了现有LVLMs推理训练中的泛化和奖励偏差问题，为未来推理任务的研究提供了新的方向。

Abstract: Chain-of-thought (CoT) reasoning is critical for improving the
interpretability and reliability of Large Vision-Language Models (LVLMs).
However, existing training algorithms such as SFT, PPO, and GRPO may not
generalize well across unseen reasoning tasks and heavily rely on a biased
reward model. To address this challenge, we reformulate reasoning in LVLMs as
posterior inference and propose a scalable training algorithm based on
amortized variational inference. By leveraging diversity-seeking reinforcement
learning algorithms, we introduce a novel sparse reward function for
token-level learning signals that encourage diverse, high-likelihood latent
CoT, overcoming deterministic sampling limitations and avoiding reward hacking.
Additionally, we implement a Bayesian inference-scaling strategy that replaces
costly Best-of-N and Beam Search with a marginal likelihood to efficiently rank
optimal rationales and answers. We empirically demonstrate that the proposed
method enhances the state-of-the-art LVLMs on seven reasoning benchmarks, in
terms of effectiveness, generalization, and interpretability.

</details>


### [74] [Decentralized Causal Discovery using Judo Calculus](https://arxiv.org/abs/2510.23942)
*Sridhar Mahadevan*

Main category: cs.AI

TL;DR: 提出了一种基于judo calculus的因果发现框架，该框架通过局部真理性来处理不同背景下的因果关系，并在多个领域进行了实验验证。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的因果效应依赖于不同背景（如年龄、国家、剂量等），需要一个能形式化这种上下文依赖的理论框架。

Method: 提出judo calculus，形式化为j-stable因果推断，使用Lawvere-Tierney模态算子j选择相关背景，并结合多种因果发现方法（基于评分、约束和梯度的方法）。

Result: 实验结果表明，该方法在合成和真实数据集上均具有计算效率优势，并优于传统因果发现方法。

Conclusion: 所提出的judo calculus框架能够有效处理因果效应的背景依赖性，并在因果发现中表现出良好的性能和效率。

Abstract: We describe a theory and implementation of an intuitionistic decentralized
framework for causal discovery using judo calculus, which is formally defined
as j-stable causal inference using j-do-calculus in a topos of sheaves. In
real-world applications -- from biology to medicine and social science --
causal effects depend on regime (age, country, dose, genotype, or lab
protocol). Our proposed judo calculus formalizes this context dependence
formally as local truth: a causal claim is proven true on a cover of regimes,
not everywhere at once. The Lawvere-Tierney modal operator j chooses which
regimes are relevant; j-stability means the claim holds constructively and
consistently across that family. We describe an algorithmic and implementation
framework for judo calculus, combining it with standard score-based,
constraint-based, and gradient-based causal discovery methods. We describe
experimental results on a range of domains, from synthetic to real-world
datasets from biology and economics. Our experimental results show the
computational efficiency gained by the decentralized nature of sheaf-theoretic
causal discovery, as well as improved performance over classical causal
discovery methods.

</details>


### [75] [The Sign Estimator: LLM Alignment in the Face of Choice Heterogeneity](https://arxiv.org/abs/2510.23965)
*Aymane El Gadarri,Ali Aouad,Vivek F. Farias*

Main category: cs.AI

TL;DR: 提出了一种新的方法，称为符号估计器，通过将交叉熵替换为二分类损失来解决传统LLM对齐方法在人类偏好异质性下的不一致问题。


<details>
  <summary>Details</summary>
Motivation: 传统LLM对齐方法在处理人类偏好的异质性时存在问题，导致对总体平均效用的估计不一致。

Method: 提出了一种新的一致且高效的符号估计器，通过修改聚合步骤中的损失函数，从交叉熵变为二分类损失。

Result: 在模拟实验中，符号估计器显著减少了偏好失真，与标准RLHF相比，估计误差减少了近35%，并且与真实总体偏好的不一致率从12%降低到8%。

Conclusion: 符号估计器在保持实现简单性的同时，优于现有LLM对齐方法，并首次在此类设定下实现了多项式有限样本误差边界。

Abstract: Traditional LLM alignment methods are vulnerable to heterogeneity in human
preferences. Fitting a na\"ive probabilistic model to pairwise comparison data
(say over prompt-completion pairs) yields an inconsistent estimate of the
population-average utility -a canonical measure of social welfare. We propose a
new method, dubbed the sign estimator, that provides a simple, provably
consistent, and efficient estimator by replacing cross-entropy with binary
classification loss in the aggregation step. This simple modification recovers
consistent ordinal alignment under mild assumptions and achieves the first
polynomial finite-sample error bounds in this setting. In realistic simulations
of LLM alignment using digital twins, the sign estimator substantially reduces
preference distortion over a panel of simulated personas, cutting (angular)
estimation error by nearly 35% and decreasing disagreement with true population
preferences from 12% to 8% compared to standard RLHF. Our method also compares
favorably to panel data heuristics that explicitly model user heterogeneity and
require tracking individual-level preference data-all while maintaining the
implementation simplicity of existing LLM alignment pipelines.

</details>


### [76] [Learning Individual Movement Shifts After Urban Disruptions with Social Infrastructure Reliance](https://arxiv.org/abs/2510.23989)
*Shangde Gao,Zelin Xu,Zhe Jiang*

Main category: cs.AI

TL;DR: 本文提出一种新方法，通过结合个体的社会基础设施韧性（SIR）和空间背景，使用条件深度学习模型来预测破坏性事件后个体的移动模式变化。


<details>
  <summary>Details</summary>
Motivation: 预测破坏性事件后个体移动模式的变化具有挑战性，因为缺乏对个体SIR的衡量，且现有特征在规模上受限。此外，个体移动模式与空间背景之间的复杂互动尚未被充分捕捉。

Method: 该研究将个体的SIR纳入条件深度学习模型，利用大规模稀疏个体级数据，捕捉个体移动模式与局部空间背景之间的复杂关系。

Result: 实验表明，结合个体的SIR和空间背景，可以增强模型预测事件后个体移动模式的能力。模型能够捕捉到在SIR上不同但事件前模式相似的个体之间的移动模式差异。

Conclusion: 通过结合SIR和空间背景，条件深度学习模型在预测个体移动模式方面表现更优，能够更好地理解和预测个体在破坏性事件后的行为变化。

Abstract: Shifts in individual movement patterns following disruptive events can reveal
changing demands for community resources. However, predicting such shifts
before disruptive events remains challenging for several reasons. First,
measures are lacking for individuals' heterogeneous social infrastructure
resilience (SIR), which directly influences their movement patterns, and
commonly used features are often limited or unavailable at scale, e.g.,
sociodemographic characteristics. Second, the complex interactions between
individual movement patterns and spatial contexts have not been sufficiently
captured. Third, individual-level movement may be spatially sparse and not
well-suited to traditional decision-making methods for movement predictions.
This study incorporates individuals' SIR into a conditioned deep learning model
to capture the complex relationships between individual movement patterns and
local spatial context using large-scale, sparse individual-level data. Our
experiments demonstrate that incorporating individuals' SIR and spatial context
can enhance the model's ability to predict post-event individual movement
patterns. The conditioned model can capture the divergent shifts in movement
patterns among individuals who exhibit similar pre-event patterns but differ in
SIR.

</details>


### [77] [OneCast: Structured Decomposition and Modular Generation for Cross-Domain Time Series Forecasting](https://arxiv.org/abs/2510.24028)
*Tingyue Pan,Mingyue Cheng,Shilong Zhang,Zhiding Liu,Xiaoyu Tao,Yucong Luo,Jintao Zhang,Qi Liu*

Main category: cs.AI

TL;DR: OneCast是一种新型结构化、模块化时间序列预测框架，通过将时间序列分解为季节性和趋势成分，并利用定制的生成路径进行建模，从而有效解决跨域时间序列预测中的泛化问题。


<details>
  <summary>Details</summary>
Motivation: 当前的时间序列预测方法将时间序列视为未区分的序列，未能显式解耦其固有结构成分，导致在应对特定领域趋势转变和不一致的周期性模式时表现不佳。

Method: OneCast框架通过将时间序列分解为季节性和趋势成分，分别利用轻量级投影模块和语义感知标记器建模。季节性成分通过可解释基函数重建周期性模式，趋势成分通过掩码离散扩散机制进行推断。

Result: 在八个领域的广泛实验表明，OneCast在大多数情况下优于最先进的方法。

Conclusion: 通过显式解耦时间序列的结构成分，OneCast能够更有效地捕捉季节性模式并跟踪特定领域的趋势，为跨域时间序列预测提供了一种有前景的解决方案。

Abstract: Cross-domain time series forecasting is a valuable task in various web
applications. Despite its rapid advancement, achieving effective generalization
across heterogeneous time series data remains a significant challenge. Existing
methods have made progress by extending single-domain models, yet often fall
short when facing domain-specific trend shifts and inconsistent periodic
patterns. We argue that a key limitation lies in treating temporal series as
undifferentiated sequence, without explicitly decoupling their inherent
structural components. To address this, we propose OneCast, a structured and
modular forecasting framework that decomposes time series into seasonal and
trend components, each modeled through tailored generative pathways.
Specifically, the seasonal component is captured by a lightweight projection
module that reconstructs periodic patterns via interpretable basis functions.
In parallel, the trend component is encoded into discrete tokens at segment
level via a semantic-aware tokenizer, and subsequently inferred through a
masked discrete diffusion mechanism. The outputs from both branches are
combined to produce a final forecast that captures seasonal patterns while
tracking domain-specific trends. Extensive experiments across eight domains
demonstrate that OneCast mostly outperforms state-of-the-art baselines.

</details>


### [78] [Modeling Electric Vehicle Car-Following Behavior: Classical vs Machine Learning Approach](https://arxiv.org/abs/2510.24085)
*Md. Shihab Uddin,Md Nazmus Shakib,Rahul Bhadani*

Main category: cs.AI

TL;DR: 该研究比较了经典和机器学习模型在电动车（EV）跟车行为预测方面的表现，发现随机森林模型在所有场景中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 随着电动车（EV）的普及，了解其驾驶行为对提高交通安全和开发智能驾驶系统至关重要。

Method: 研究采用了经典模型（IDM、OVM、OVRV和简化的CACC模型）和机器学习方法（随机森林回归器）。使用真实世界的电动车跟车数据集进行模型参数校准，并比较其性能。

Result: 随机森林模型表现最优，不同跟车间距下的RMSE分别为0.0046（中等间距）、0.0016（长间距）和0.0025（超长间距）。物理模型中，CACC模型表现最好，其RMSE为2.67（长间距）。

Conclusion: 机器学习模型在模拟电动车行为和混合自动驾驶交通动力学分析中具有显著优势，为智能交通系统的发展提供了有力支持。

Abstract: The increasing adoption of electric vehicles (EVs) necessitates an
understanding of their driving behavior to enhance traffic safety and develop
smart driving systems. This study compares classical and machine learning
models for EV car following behavior. Classical models include the Intelligent
Driver Model (IDM), Optimum Velocity Model (OVM), Optimal Velocity Relative
Velocity (OVRV), and a simplified CACC model, while the machine learning
approach employs a Random Forest Regressor. Using a real world dataset of an EV
following an internal combustion engine (ICE) vehicle under varied driving
conditions, we calibrated classical model parameters by minimizing the RMSE
between predictions and real data. The Random Forest model predicts
acceleration using spacing, speed, and gap type as inputs. Results demonstrate
the Random Forest's superior accuracy, achieving RMSEs of 0.0046 (medium gap),
0.0016 (long gap), and 0.0025 (extra long gap). Among physics based models,
CACC performed best, with an RMSE of 2.67 for long gaps. These findings
highlight the machine learning model's performance across all scenarios. Such
models are valuable for simulating EV behavior and analyzing mixed autonomy
traffic dynamics in EV integrated environments.

</details>


### [79] [HistoLens: An Interactive XAI Toolkit for Verifying and Mitigating Flaws in Vision-Language Models for Histopathology](https://arxiv.org/abs/2510.24115)
*Sandeep Vissapragada,Vikrant Sahu,Gagan Raj Gupta,Vandita Singh*

Main category: cs.AI

TL;DR: HistoLens1是一个旨在提高AI在医疗领域透明度的系统，允许病理学家通过自然语言提问并获得AI的详细、可视化报告。


<details>
  <summary>Details</summary>
Motivation: 为了让医生真正信任AI，AI系统需要具备透明性和可解释性，以便医生理解其推理过程。

Method: 创建了HistoLens1系统，将病理学家的自然语言问题转化为AI的精确查询，并提供结构化报告。系统还能通过热力图提供‘视觉证据’，并专注于患者组织，忽略背景噪音。

Result: 病理学家可以在AI的辅助下验证自己的诊断，提高诊断速度和信心，同时保持主导地位。

Conclusion: HistoLens1通过提供透明、协作的AI助手，使病理学家能够更好地理解和信任AI的推理过程，从而提升医疗诊断的质量和效率。

Abstract: For doctors to truly trust artificial intelligence, it can't be a black box.
They need to understand its reasoning, almost as if they were consulting a
colleague. We created HistoLens1 to be that transparent, collaborative partner.
It allows a pathologist to simply ask a question in plain English about a
tissue slide--just as they would ask a trainee. Our system intelligently
translates this question into a precise query for its AI engine, which then
provides a clear, structured report. But it doesn't stop there. If a doctor
ever asks, "Why?", HistoLens can instantly provide a 'visual proof' for any
finding--a heatmap that points to the exact cells and regions the AI used for
its analysis. We've also ensured the AI focuses only on the patient's tissue,
just like a trained pathologist would, by teaching it to ignore distracting
background noise. The result is a workflow where the pathologist remains the
expert in charge, using a trustworthy AI assistant to verify their insights and
make faster, more confident diagnoses.

</details>


### [80] [From Observability Data to Diagnosis: An Evolving Multi-agent System for Incident Management in Cloud Systems](https://arxiv.org/abs/2510.24145)
*Yu Luo,Jiamin Jiang,Jingfei Feng,Lei Tao,Qingliang Zhang,Xidao Wen,Yongqian Sun,Shenglin Zhang,Jielong Huang,Nan Qi,Dan Pei*

Main category: cs.AI

TL;DR: 提出了一种轻量级、自进化的多智能体系统OpsAgent，用于大规模云系统中的事件管理。


<details>
  <summary>Details</summary>
Motivation: 手动事件管理在庞大的异构可观察性数据面前劳动密集且容易出错，而现有的自动化方法在通用性、可解释性和部署成本方面存在挑战。

Method: OpsAgent使用无训练数据处理器将异构可观察性数据转化为结构化文本描述，并采用多智能体协作框架，实现透明和可审计的诊断推理，还引入了双自我进化机制。

Result: 在OPENRCA基准测试中，OpsAgent表现出最先进的性能，具有通用性、可解释性、成本效益和自我进化能力。

Conclusion: OpsAgent是一个可实际部署和可持续的解决方案，适合在真实世界云系统中长期运行。

Abstract: Incident management (IM) is central to the reliability of large-scale cloud
systems. Yet manual IM, where on-call engineers examine metrics, logs, and
traces is labor-intensive and error-prone in the face of massive and
heterogeneous observability data. Existing automated IM approaches often
struggle to generalize across systems, provide limited interpretability, and
incur high deployment costs, which hinders adoption in practice. In this paper,
we present OpsAgent, a lightweight, self-evolving multi-agent system for IM
that employs a training-free data processor to convert heterogeneous
observability data into structured textual descriptions, along with a
multi-agent collaboration framework that makes diagnostic inference transparent
and auditable. To support continual capability growth, OpsAgent also introduces
a dual self-evolution mechanism that integrates internal model updates with
external experience accumulation, thereby closing the deployment loop.
Comprehensive experiments on the OPENRCA benchmark demonstrate state-of-the-art
performance and show that OpsAgent is generalizable, interpretable,
cost-efficient, and self-evolving, making it a practically deployable and
sustainable solution for long-term operation in real-world cloud systems.

</details>


### [81] [BMGQ: A Bottom-up Method for Generating Complex Multi-hop Reasoning Questions from Semi-structured Data](https://arxiv.org/abs/2510.24151)
*Bingsen Qiu,Zijian Liu,Xiao Liu,Haoshen Yang,Zeren Gao,Bingjie Wang,Feier Zhang,Yixuan Qin,Chunyan Li*

Main category: cs.AI

TL;DR: 本文提出了一种自动化框架，用于从半结构化知识源生成高难度、可用于训练的多跳问题，以减少人工标注成本并提升模型检索和推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前多跳QA数据集稀缺且不适合监督微调（SFT）或强化学习（RL），而人工标注成本高昂且难以扩展，因此需要一种自动化、可扩展的方法来生成高质量的多跳问题。

Method: 该框架通过三个步骤实现：(i) 使用自然语言推理（NLI）和多样性扩展构建逻辑标记的证据簇；(ii) 逆向问题构建，组合间接线索使单一信息不足但联合信息唯一确定目标实体；(iii) 两阶段评估管道（多模型共识过滤+结构化约束分解与证据匹配）确保质量。

Result: 生成的数据集具有复杂、抗检索但可验证的问题，适用于SFT/RL训练和评估，显著降低人工成本，同时保持与基准评估集相当的问题难度。

Conclusion: 该框架解决了多跳QA训练数据稀缺和人工成本高的瓶颈，提供了一种可扩展的自动化方法，生成的数据能有效提升模型的多跳推理能力。

Abstract: Building training-ready multi-hop question answering (QA) datasets that truly
stress a model's retrieval and reasoning abilities remains highly challenging
recently. While there have been a few recent evaluation datasets that capture
the characteristics of hard-to-search but easy-to-verify problems -- requiring
the integration of ambiguous, indirect, and cross-domain cues -- these data
resources remain scarce and are mostly designed for evaluation, making them
unsuitable for supervised fine-tuning (SFT) or reinforcement learning (RL).
Meanwhile, manually curating non-trivially retrievable questions -- where
answers cannot be found through a single direct query but instead require
multi-hop reasoning over oblique and loosely connected evidence -- incurs
prohibitive human costs and fails to scale, creating a critical data bottleneck
for training high-capability retrieval-and-reasoning agents.
  To address this, we present an automated framework for generating
high-difficulty, training-ready multi-hop questions from semi-structured
knowledge sources. The system (i) grows diverse, logically labeled evidence
clusters through Natural Language Inference (NLI)-based relation typing and
diversity-aware expansion; (ii) applies reverse question construction to
compose oblique cues so that isolated signals are underinformative but their
combination uniquely identifies the target entity; and (iii) enforces quality
with a two-step evaluation pipeline that combines multi-model consensus
filtering with structured constraint decomposition and evidence-based matching.
The result is a scalable process that yields complex, retrieval-resistant yet
verifiable questions suitable for SFT/RL training as well as challenging
evaluation, substantially reducing human curation effort while preserving the
difficulty profile of strong evaluation benchmarks.

</details>


### [82] [BLM$_1$: A Boundless Large Model for Cross-Space, Cross-Task, and Cross-Embodiment Learning](https://arxiv.org/abs/2510.24161)
*Wentao Tan,Bowen Wang,Heng Zhi,Chenyu Liu,Zhe Li,Jian Liu,Zengrong Lin,Yukun Dai,Yipeng Chen,Wenjie Yang,Enci Xie,Hao Xue,Baixu Ji,Chen Xu,Zhibin Wang,Tianshi Wang,Lei Zhu,Heng Tao Shen*

Main category: cs.AI

TL;DR: 本文介绍了一种名为BLM₁的多模态空间基础模型，该模型能在数字和物理空间中无缝操作，实现跨空间、跨任务和跨形态的泛化。


<details>
  <summary>Details</summary>
Motivation: 当前的多模态大语言模型在数字与物理空间、不同形态间的泛化能力差，视觉-语言-动作模型缺乏高级推理能力，因此需要一种统一的模型解决这些问题。

Method: BLM₁通过两阶段训练范式实现三种关键能力：1）注入具身知识到MLLM中；2）通过意图桥接接口训练策略模块。该过程得到了涵盖四种机器人形态和六个任务的数据集支持。

Result: 在数字和物理基准测试中，BLM₁的表现优于MLLMs、ELLMs、VLAs和GMLMs四种模型系列，在数字任务中提升约6%，在物理任务中提升约3%。

Conclusion: BLM₁是一个能在数字和物理空间无缝操作的多模态空间基础模型，实现了跨空间、跨任务和跨形态的泛化，为具身智能体提供了新的可能性。

Abstract: Multimodal large language models (MLLMs) have advanced vision-language
reasoning and are increasingly deployed in embodied agents. However,
significant limitations remain: MLLMs generalize poorly across digital-physical
spaces and embodiments; vision-language-action models (VLAs) produce low-level
actions yet lack robust high-level embodied reasoning; and most embodied large
language models (ELLMs) are constrained to digital-space with poor
generalization to the physical world. Thus, unified models that operate
seamlessly across digital and physical spaces while generalizing across
embodiments and tasks remain absent. We introduce the \textbf{Boundless Large
Model (BLM$_1$)}, a multimodal spatial foundation model that preserves
instruction following and reasoning, incorporates embodied knowledge, and
supports robust cross-embodiment control. BLM$_1$ integrates three key
capabilities -- \textit{cross-space transfer, cross-task learning, and
cross-embodiment generalization} -- via a two-stage training paradigm. Stage I
injects embodied knowledge into the MLLM through curated digital corpora while
maintaining language competence. Stage II trains a policy module through an
intent-bridging interface that extracts high-level semantics from the MLLM to
guide control, without fine-tuning the MLLM backbone. This process is supported
by a self-collected cross-embodiment demonstration suite spanning four robot
embodiments and six progressively challenging tasks. Evaluations across digital
and physical benchmarks show that a single BLM$_1$ instance outperforms four
model families -- MLLMs, ELLMs, VLAs, and GMLMs -- achieving
$\sim\!\textbf{6%}$ gains in digital tasks and $\sim\!\textbf{3%}$ in physical
tasks.

</details>


### [83] [Investigating Intra-Abstraction Policies For Non-exact Abstraction Algorithms](https://arxiv.org/abs/2510.24297)
*Robin Schmöcker,Alexander Dockhorn,Bodo Rosenhahn*

Main category: cs.AI

TL;DR: 论文提出并评估了几种替代的抽象内策略，以改进蒙特卡洛树搜索（MCTS）中的样本效率，通过实验证明这些策略在多数环境和参数设置下优于随机策略。


<details>
  <summary>Details</summary>
Motivation: MCTS的一个弱点是其样本效率，可以通过在树搜索中并行使用状态和/或动作抽象来改进，以便在同一层的节点之间共享信息。然而，当前抽象方法未考虑多个具有相同父节点的动作可能属于同一抽象节点的情况，导致这些动作的UCB值相同，需要打破平局规则。

Method: 论文提出并实证评估了几种替代的抽象内策略，以改进UCB值在树策略中的使用，避免依赖随机打破平局规则。

Result: 在多数环境和参数设置下，提出的几种替代策略优于随机策略。

Conclusion: 选择合适的抽象内策略可以显著提升MCTS的性能，尤其是在处理同一抽象节点中具有相同父节点的多个动作的情况下。

Abstract: One weakness of Monte Carlo Tree Search (MCTS) is its sample efficiency which
can be addressed by building and using state and/or action abstractions in
parallel to the tree search such that information can be shared among nodes of
the same layer. The primary usage of abstractions for MCTS is to enhance the
Upper Confidence Bound (UCB) value during the tree policy by aggregating visits
and returns of an abstract node. However, this direct usage of abstractions
does not take the case into account where multiple actions with the same parent
might be in the same abstract node, as these would then all have the same UCB
value, thus requiring a tiebreak rule. In state-of-the-art abstraction
algorithms such as pruned On the Go Abstractions (pruned OGA), this case has
not been noticed, and a random tiebreak rule was implicitly chosen. In this
paper, we propose and empirically evaluate several alternative
intra-abstraction policies, several of which outperform the random policy
across a majority of environments and parameter settings.

</details>


### [84] [Verifying Large Language Models' Reasoning Paths via Correlation Matrix Rank](https://arxiv.org/abs/2510.24299)
*Jiayu Liu,Wei Dai,Zhenya Huang,Ning Miao,Enhong Chen*

Main category: cs.AI

TL;DR: 大型语言模型尽管具有强大的推理能力，但容易出现错误和幻觉。本文提出了一种基于内部行为检查推理路径可信度的方法，利用输入问题与输出推理路径之间相关矩阵的秩作为推理正确性的稳健指标。该方法无需外部资源，实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的输出检查是一个关键问题，现有方法依赖外部资源，造成高计算开销并仅适用于特定领域。因此，研究如何利用模型内部行为来评估推理路径的可信度。

Method: 提出了一种称为Self-Indicator的方法，通过计算输入问题与输出推理路径之间的相关矩阵的秩，来评估推理路径的正确性，并重新加权候选推理路径。

Result: Self-Indicator在多个不同规模和模型家族的大型语言模型上表现出色，能够在区分正确和错误推理路径方面实现超过75%的准确率，并在三个推理基准上提高准确率超过8%。

Conclusion: Self-Indicator是一种简单且高效的方法，利用模型内部行为来检查推理路径的可信度，避免了外部资源的需求，显著提升了性能。

Abstract: Despite the strong reasoning ability of large language models~(LLMs), they
are prone to errors and hallucinations. As a result, how to check their outputs
effectively and efficiently has become a critical problem in their
applications. Existing checking methods heavily rely on external resources,
such as trained verifiers (e.g., process/outcome reward models) or elaborate
prompts, which lead to high computational overhead and are only applicable to
specific domains. In this paper, we investigate whether the internal behaviors
of LLMs have already implied the credibility of their reasoning paths.
Specifically, we find that the rank of the correlation matrix between the input
problem and the output reasoning path is a robust indicator of reasoning
correctness. Different from other correctness indicators for LLMs, the
calculation of the correlation matrix only relies on the LLM itself, which
avoids the hassle of training a separate model or designing complicated
prompts. Based on it, we design a simple, plug-and-play Self-Indicator method
to reweight candidate reasoning paths, which achieves significant performance
improvements than other voting and verification methods with very few
computational overhead. Our experiments across multiple LLMs of varying scales
and model families have further shown the effectiveness of Self-Indicator. It
achieves over 75% accuracy in distinguishing correct reasoning paths from
incorrect ones, and, in turn, improves the accuracies on three reasoning
benchmarks by more than 8%.

</details>


### [85] [Retrieval and Argumentation Enhanced Multi-Agent LLMs for Judgmental Forecasting](https://arxiv.org/abs/2510.24303)
*Deniz Gorur,Antoni Rago,Francesca Toni*

Main category: cs.AI

TL;DR: 提出了一种新型多智能体框架用于基于人类判断的未来事件预测（claim verification），通过不同智能体之间的证据支持或反驳来提高预测准确性。


<details>
  <summary>Details</summary>
Motivation: 判断性预测是基于人类判断对未来事件进行预测，可以视为一种声明验证任务。现有方法在证据生成和评估方面存在局限，需要结合多源证据提高准确性。

Method: 提出了一个多智能体框架，包括ArgLLM智能体、RbAM智能体和RAG-ArgLLM智能体，利用大型语言模型（LLMs）生成和评估定量双极论证框架（QBAFs）。

Result: 在两个标准判断性预测数据集上的实验表明，结合来自多个智能体的证据可以提高预测准确性，尤其是三个智能体的情况，并提供了可解释的证据组合。

Conclusion: 多智能体框架通过结合不同智能体的证据，不仅提高了判断性预测的准确性，还增强了声明验证的解释性。

Abstract: Judgmental forecasting is the task of making predictions about future events
based on human judgment. This task can be seen as a form of claim verification,
where the claim corresponds to a future event and the task is to assess the
plausibility of that event. In this paper, we propose a novel multi-agent
framework for claim verification, whereby different agents may disagree on
claim veracity and bring specific evidence for and against the claims,
represented as quantitative bipolar argumentation frameworks (QBAFs). We then
instantiate the framework for supporting claim verification, with a variety of
agents realised with Large Language Models (LLMs): (1) ArgLLM agents, an
existing approach for claim verification that generates and evaluates QBAFs;
(2) RbAM agents, whereby LLM-empowered Relation-based Argument Mining (RbAM)
from external sources is used to generate QBAFs; (3) RAG-ArgLLM agents,
extending ArgLLM agents with a form of Retrieval-Augmented Generation (RAG) of
arguments from external sources. Finally, we conduct experiments with two
standard judgmental forecasting datasets, with instances of our framework with
two or three agents, empowered by six different base LLMs. We observe that
combining evidence from agents can improve forecasting accuracy, especially in
the case of three agents, while providing an explainable combination of
evidence for claim verification.

</details>


### [86] [Generative Large Language Models (gLLMs) in Content Analysis: A Practical Guide for Communication Research](https://arxiv.org/abs/2510.24337)
*Daria Kravets-Meinke,Hannah Schmid-Petri,Sonja Niemann,Ute Schmid*

Main category: cs.AI

TL;DR: 本文探讨了生成式大语言模型（gLLMs）在通信研究内容分析中的应用，并提出了一个最佳实践指南，以解决使用gLLMs时面临的七个关键挑战。


<details>
  <summary>Details</summary>
Motivation: gLLMs在内容分析中表现出巨大潜力，但其在通信研究中的应用尚不充分，需要解决一系列影响结果质量的关键挑战。

Method: 本文综述了关于gLLMs辅助定量内容分析的最新研究，并提出了全面最佳实践指南，以应对相关挑战。

Result: 提出了一个综合指南，帮助研究人员应对gLLMs在内容分析中的挑战，并使其更易于被通信研究人员使用。

Conclusion: 通过遵循最佳实践指南，gLLMs可以在通信研究中更广泛地应用，同时确保符合学科的质量标准和伦理要求。

Abstract: Generative Large Language Models (gLLMs), such as ChatGPT, are increasingly
being used in communication research for content analysis. Studies show that
gLLMs can outperform both crowd workers and trained coders, such as research
assistants, on various coding tasks relevant to communication science, often at
a fraction of the time and cost. Additionally, gLLMs can decode implicit
meanings and contextual information, be instructed using natural language,
deployed with only basic programming skills, and require little to no annotated
data beyond a validation dataset - constituting a paradigm shift in automated
content analysis. Despite their potential, the integration of gLLMs into the
methodological toolkit of communication research remains underdeveloped. In
gLLM-assisted quantitative content analysis, researchers must address at least
seven critical challenges that impact result quality: (1) codebook development,
(2) prompt engineering, (3) model selection, (4) parameter tuning, (5)
iterative refinement, (6) validation of the model's reliability, and
optionally, (7) performance enhancement. This paper synthesizes emerging
research on gLLM-assisted quantitative content analysis and proposes a
comprehensive best-practice guide to navigate these challenges. Our goal is to
make gLLM-based content analysis more accessible to a broader range of
communication researchers and ensure adherence to established disciplinary
quality standards of validity, reliability, reproducibility, and research
ethics.

</details>


### [87] [VDSAgents: A PCS-Guided Multi-Agent System for Veridical Data Science Automation](https://arxiv.org/abs/2510.24339)
*Yunxuan Jiang,Silan Hu,Xiaoning Wang,Yuanyuan Zhang,Xiangyu Chang*

Main category: cs.AI

TL;DR: 本文提出了一种基于可预测性-可计算性-稳定性（PCS）原则的多智能体系统VDSAgents，用于增强大型语言模型（LLM）驱动的数据科学工作流的科学性和可信度。


<details>
  <summary>Details</summary>
Motivation: LLM驱动的数据科学系统仅依赖模型内部推理，缺乏科学和理论指导，导致在处理复杂真实数据时可信度和鲁棒性受限。

Method: VDSAgents系统基于PCS原则，采用模块化工作流，包括数据清洗、特征工程、建模和评估，各阶段由专门智能体处理，结合扰动分析、单元测试和模型验证。

Result: 在九种不同特性数据集上，VDSAgents相比AutoKaggle和DataInterpreter等先进系统表现更优，验证了PCS原则在LLM驱动数据科学自动化中的可行性。

Conclusion: 将PCS原则嵌入LLM驱动的数据科学自动化中，可以提升系统的功能性和科学可审计性，增强其在实际应用中的表现。

Abstract: Large language models (LLMs) become increasingly integrated into data science
workflows for automated system design. However, these LLM-driven data science
systems rely solely on the internal reasoning of LLMs, lacking guidance from
scientific and theoretical principles. This limits their trustworthiness and
robustness, especially when dealing with noisy and complex real-world datasets.
This paper provides VDSAgents, a multi-agent system grounded in the
Predictability-Computability-Stability (PCS) principles proposed in the
Veridical Data Science (VDS) framework. Guided by PCS principles, the system
implements a modular workflow for data cleaning, feature engineering, modeling,
and evaluation. Each phase is handled by an elegant agent, incorporating
perturbation analysis, unit testing, and model validation to ensure both
functionality and scientific auditability. We evaluate VDSAgents on nine
datasets with diverse characteristics, comparing it with state-of-the-art
end-to-end data science systems, such as AutoKaggle and DataInterpreter, using
DeepSeek-V3 and GPT-4o as backends. VDSAgents consistently outperforms the
results of AutoKaggle and DataInterpreter, which validates the feasibility of
embedding PCS principles into LLM-driven data science automation.

</details>


### [88] [An N-of-1 Artificial Intelligence Ecosystem for Precision Medicine](https://arxiv.org/abs/2510.24359)
*Pedram Fard,Alaleh Azhir,Neguine Rezaii,Jiazi Tian,Hossein Estiri*

Main category: cs.AI

TL;DR: 提出一个多智能体生态系统以支持个体化医疗决策，解决传统AI在边缘患者群体中表现不佳的问题。


<details>
  <summary>Details</summary>
Motivation: 传统医学AI服务于平均患者，导致在罕见变异、多病共存和少数群体等边缘患者中表现不佳，影响公平性和信任。

Method: 设计一个多智能体生态系统，智能体按器官系统、患者群体和分析模式聚类，利用共享模型库和证据综合工具，在协调层中整合结果，提供风险估计和置信范围等决策支持包。

Result: 验证从总体平均值转向个体可靠性，重点在低密度区域误差、个体校准和风险-覆盖权衡上。

Conclusion: 通过从单一模型转向协调智能，该方案旨在使医学AI与医学首要原则保持一致：提供透明、公平和以个体为中心的医疗。

Abstract: Artificial intelligence in medicine is built to serve the average patient. By
minimizing error across large datasets, most systems deliver strong aggregate
accuracy yet falter at the margins: patients with rare variants,
multimorbidity, or underrepresented demographics. This average patient fallacy
erodes both equity and trust. We propose a different design: a multi-agent
ecosystem for N-of-1 decision support. In this environment, agents clustered by
organ systems, patient populations, and analytic modalities draw on a shared
library of models and evidence synthesis tools. Their results converge in a
coordination layer that weighs reliability, uncertainty, and data density
before presenting the clinician with a decision-support packet: risk estimates
bounded by confidence ranges, outlier flags, and linked evidence. Validation
shifts from population averages to individual reliability, measured by error in
low-density regions, calibration in the small, and risk--coverage trade-offs.
Anticipated challenges include computational demands, automation bias, and
regulatory fit, addressed through caching strategies, consensus checks, and
adaptive trial frameworks. By moving from monolithic models to orchestrated
intelligence, this approach seeks to align medical AI with the first principle
of medicine: care that is transparent, equitable, and centered on the
individual.

</details>


### [89] [Improving LLM Reasoning via Dependency-Aware Query Decomposition and Logic-Parallel Content Expansion](https://arxiv.org/abs/2510.24390)
*Xianjun Gao,Jianchun Liu,Hongli Xu,Liusheng Huang*

Main category: cs.AI

TL;DR: 本文提出了一种名为Orion的新型高效推理框架，通过依赖感知查询分解和逻辑并行内容扩展，解决了大型语言模型在实时Web应用中的高延迟和低效率问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在实时Web应用中面临高复杂推理需求与低延迟、高吞吐要求的矛盾，现有方法难以同时满足效率和质量要求。

Method: Orion通过两个协同阶段实现：(1) 关键点生成，采用检索增强的少样本提示提取结构化关键点；(2) 内容并行扩展，基于依赖图并行扩展内容以确保逻辑一致性。同时引入跨查询的流水线调度机制，利用两阶段的互补计算特性。

Result: 在多种基准测试中，Orion相比基线实现了高达4.33倍的标记生成速度和3.42倍的回答延迟降低，并通过显式建模点间依赖关系将推理质量提升18.75%。

Conclusion: Orion框架通过创新的分解-并行扩展方法和流水线调度机制，成功实现了大型语言模型在Web服务中效率和质量的双重突破。

Abstract: The integration of Large Language Models (LLMs) into real-time Web
applications, such as AI-powered search and conversational agents, presents a
fundamental Web infrastructure challenge: reconciling the demand for
high-quality, complex reasoning with the stringent low-latency and
high-throughput requirements of interactive services. Current LLM reasoning,
hindered by computationally inefficient sequential generation and rigid
reasoning strategies, creates a critical bottleneck for the Web services.
Existing approaches typically optimize the LLM reasoning for either efficiency
or quality but struggle to achieve both, and thus fail to meet the dual
requirements of modern Web platforms. To overcome these limitations, we propose
Orion, a novel and efficient reasoning framework that enables dependency-aware
query decomposition and logic-parallel content expansion. Concretely, Orion
decomposes a single query reasoning process into two synergistic phases: (1)
\textit{key point generation}, which distills logically structured key points
through retrieval-augmented few-shot prompting, and (2) \textit{content
parallel expansion}, which concurrently elaborates on these points based on a
dependency graph to ensure logical consistency. Furthermore, Orion introduces a
pipeline scheduling mechanism that exploits the complementary computational
characteristics of the two phases (generation imposes pressure on GPU computing
and expansion stresses on GPU memory) across multiple queries, enabling
cross-query parallelism and dramatically improving reasoning performance (\ie,
efficiency and quality). Experiments on diverse benchmarks show that Orion not
only delivers up to 4.33x higher token generation speed and 3.42x lower answer
latency over the baselines but also improves reasoning quality by up to 18.75%
through explicitly modeling inter-point dependencies.

</details>


### [90] [Human-Level Reasoning: A Comparative Study of Large Language Models on Logical and Abstract Reasoning](https://arxiv.org/abs/2510.24435)
*Benjamin Grando Moreira*

Main category: cs.AI

TL;DR: 该研究评估了多个大语言模型在逻辑和抽象推理任务上的表现，并与人类表现进行对比。


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型的推理能力对于推进人工智能至关重要，因为它超越了单纯的语言任务表现，涉及模型是否真正理解信息、进行推理并以逻辑有效的方式得出结论。

Method: 使用8个自定义设计的推理问题，评估了包括GPT、Claude、DeepSeek、Gemini、Grok、Llama、Mistral、Perplexity和Sabi'a在内的多个大语言模型的逻辑和抽象推理能力，并将结果与人类在同一任务上的表现进行对比。

Result: 研究发现，大语言模型在推理任务上的表现与人类存在显著差异，揭示了模型在演绎推理方面的不足。

Conclusion: 该研究指出了大语言模型在逻辑推理方面的局限性，并强调了未来需要改进的方向。

Abstract: Evaluating reasoning ability in Large Language Models (LLMs) is important for
advancing artificial intelligence, as it transcends mere linguistic task
performance. It involves understanding whether these models truly understand
information, perform inferences, and are able to draw conclusions in a logical
and valid way. This study compare logical and abstract reasoning skills of
several LLMs - including GPT, Claude, DeepSeek, Gemini, Grok, Llama, Mistral,
Perplexity, and Sabi\'a - using a set of eight custom-designed reasoning
questions. The LLM results are benchmarked against human performance on the
same tasks, revealing significant differences and indicating areas where LLMs
struggle with deduction.

</details>


### [91] [From Cross-Task Examples to In-Task Prompts: A Graph-Based Pseudo-Labeling Framework for In-context Learning](https://arxiv.org/abs/2510.24528)
*Zihan Chen,Song Wang,Xingbo Fu,Chengshuai Shi,Zhenyu Lei,Cong Shen,Jundong Li*

Main category: cs.AI

TL;DR: 提出一种成本效益高的两阶段流程，利用跨任务示例和基于图的标签传播方法，减少对大型语言模型数据标注的依赖。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在上下文学习能力方面表现出色，但为新任务或挑战性任务收集高质量示例可能成本高且劳动强度大。

Method: 第一阶段利用跨任务示例引导大型语言模型对目标任务实例进行伪标签。第二阶段引入基于图的标签传播方法，将标签信息传播到其余目标示例，无需额外的大型语言模型查询。

Result: 实验在五个任务上表明，该方法在降低标注成本的同时实现了强大性能。

Conclusion: 该方法结合了跨任务监督的灵活性和无大型语言模型标签传播的可扩展性，为数据标注提供了一种经济高效的解决方案。

Abstract: The capability of in-context learning (ICL) enables large language models
(LLMs) to perform novel tasks without parameter updates by conditioning on a
few input-output examples. However, collecting high-quality examples for new or
challenging tasks can be costly and labor-intensive. In this work, we propose a
cost-efficient two-stage pipeline that reduces reliance on LLMs for data
labeling. Our approach first leverages readily available cross-task examples to
prompt an LLM and pseudo-label a small set of target task instances. We then
introduce a graph-based label propagation method that spreads label information
to the remaining target examples without additional LLM queries. The resulting
fully pseudo-labeled dataset is used to construct in-task demonstrations for
ICL. This pipeline combines the flexibility of cross-task supervision with the
scalability of LLM-free propagation. Experiments across five tasks demonstrate
that our method achieves strong performance while lowering labeling costs.

</details>


### [92] [Advancing site-specific disease and pest management in precision agriculture: From reasoning-driven foundation models to adaptive, feedback-based learning](https://arxiv.org/abs/2510.24650)
*Nitin Rai,Daeun,Choi,Nathan S. Boyd,Arnold W. Schumann*

Main category: cs.AI

TL;DR: 本文综述了基础模型在作物特定地点疾病管理(SSDM)中的应用，强调了视觉-语言模型(VLMs)和大型语言模型(LLMs)在自适应学习、强化学习和数字孪生框架中的作用。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习和深度学习的发展，SSDM已经实现了从手工特征提取到自动化特征学习的转变。基础模型(FMs)的引入，使得作物病害数据以全新的方式进行处理，为精准农业提供了新思路。

Method: 文章筛选了约40篇关于基础模型在SSDM中应用的研究，重点讨论了LLMs和VLMs，以及它们在自适应学习(AL)、强化学习(RL)和数字孪生框架中的作用。

Result: (a) 2023-24年，基础模型的应用文献激增；(b) VLMs的发表量远超LLMs，增长了5-10倍；(c) RL和AL在智能喷雾方面仍处于初级阶段；(d) 数字孪生结合RL能虚拟模拟靶向喷雾；(e) 解决模拟到现实的差距对实际应用至关重要；(f) 人机协作，尤其是在回路中的人类验证，仍然有限；(g) 多模态基础模型与实时反馈将推动下一代SSDM的发展。

Conclusion: 基础模型，特别是视觉-语言模型，将在作物疾病管理中发挥越来越重要的作用。未来的研究应关注缩小模拟与现实的差距以及提升人机协作效率，以推动智能农业的进步。

Abstract: Site-specific disease management (SSDM) in crops has advanced rapidly through
machine and deep learning (ML and DL) for real-time computer vision. Research
evolved from handcrafted feature extraction to large-scale automated feature
learning. With foundation models (FMs), crop disease datasets are now processed
in fundamentally new ways. Unlike traditional neural networks, FMs integrate
visual and textual data, interpret symptoms in text, reason about
symptom-management relationships, and support interactive QA for growers and
educators. Adaptive and imitation learning in robotics further enables
field-based disease management. This review screened approx. 40 articles on FM
applications for SSDM, focusing on large-language models (LLMs) and
vision-language models (VLMs), and discussing their role in adaptive learning
(AL), reinforcement learning (RL), and digital twin frameworks for targeted
spraying. Key findings: (a) FMs are gaining traction with surging literature in
2023-24; (b) VLMs outpace LLMs, with a 5-10x increase in publications; (c) RL
and AL are still nascent for smart spraying; (d) digital twins with RL can
simulate targeted spraying virtually; (e) addressing the sim-to-real gap is
critical for real-world deployment; (f) human-robot collaboration remains
limited, especially in human-in-the-loop approaches where robots detect early
symptoms and humans validate uncertain cases; (g) multi-modal FMs with
real-time feedback will drive next-gen SSDM. For updates, resources, and
contributions, visit, https://github.com/nitin-dominic/AgriPathogenDatabase, to
submit papers, code, or datasets.

</details>


### [93] [OrchDAG: Complex Tool Orchestration in Multi-Turn Interactions with Plan DAGs](https://arxiv.org/abs/2510.24663)
*Yifu Lu,Shengjie Liu,Li Dong*

Main category: cs.AI

TL;DR: OrchDAG引入有向无环图建模多轮工具调用，提出基于图的奖励机制提升RLVR训练效果。


<details>
  <summary>Details</summary>
Motivation: 现有研究忽视多轮工具交互的复杂性，需要更精细的建模方法和训练机制。

Method: 构建可控复杂度的DAG数据生成管道，设计基于拓扑结构的图奖励函数并与GRPO算法结合。

Result: OrchDAG数据集具有挑战性但可解，图奖励机制在GRPO框架下表现有效。

Conclusion: 利用拓扑结构和数据复杂度建模对多轮工具使用至关重要。

Abstract: Agentic tool use has gained traction with the rise of agentic tool calling,
yet most existing work overlooks the complexity of multi-turn tool
interactions. We introduce OrchDAG, a synthetic data generation pipeline that
models tool execution as directed acyclic graphs (DAGs) with controllable
complexity. Using this dataset, we benchmark model performance and propose a
graph-based reward to enhance RLVR training. Experiments show that the dataset
presents a challenging but solvable benchmark, and the proposed reward is
effective when combined with GRPO-style algorithms, highlighting the importance
of leveraging topological structure and data complexity in multi-turn tool use.

</details>


### [94] [Bridging Tool Dependencies and Domain Knowledge: A Graph-Based Framework for In-Context Planning](https://arxiv.org/abs/2510.24690)
*Shengjie Liu,Li Dong,Zhenyu Zhang*

Main category: cs.AI

TL;DR: 提出了一个通过构建和融合工具知识图谱与文档知识图谱，利用工具与文档之间的依赖关系来增强范例工件生成的框架。


<details>
  <summary>Details</summary>
Motivation: 旨在通过发现和利用工具与文档之间的依赖关系，提升工具增强推理和计划生成的效率。

Method: 首先，从工具模式中构建工具知识图谱，并通过DeepResearch-inspired分析。并行地，从内部文档和SOPs中导出互补的知识图谱，然后与工具图谱融合。采用深度稀疏集成策略生成范例计划。

Result: 实验表明，该统一框架有效地建模了工具交互，并改进了计划生成，突出了将工具图谱与领域知识图谱连接的好处。

Conclusion: 将工具图谱与领域知识图谱结合，可以显著提升工具增强推理和计划生成的效果。

Abstract: We present a framework for uncovering and exploiting dependencies among tools
and documents to enhance exemplar artifact generation. Our method begins by
constructing a tool knowledge graph from tool schemas,including descriptions,
arguments, and output payloads, using a DeepResearch-inspired analysis. In
parallel, we derive a complementary knowledge graph from internal documents and
SOPs, which is then fused with the tool graph. To generate exemplar plans, we
adopt a deep-sparse integration strategy that aligns structural tool
dependencies with procedural knowledge. Experiments demonstrate that this
unified framework effectively models tool interactions and improves plan
generation, underscoring the benefits of linking tool graphs with domain
knowledge graphs for tool-augmented reasoning and planning.

</details>
