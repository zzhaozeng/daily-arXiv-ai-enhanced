<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 40]
- [cs.AI](#cs.AI) [Total: 40]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Last Layer Logits to Logic: Empowering LLMs with Logic-Consistent Structured Knowledge Reasoning](https://arxiv.org/abs/2511.07910)
*Songze Li,Zhiqiang Liu,Zhaoyan Gong,Xiaoke Guo,Zhengke Gui,Huajun Chen,Wen Zhang*

Main category: cs.CL

TL;DR: 本文提出Logits-to-Logic框架，通过强化和过滤逻辑，提高大型语言模型在结构化知识推理中的逻辑一致性。


<details>
  <summary>Details</summary>
Motivation: 由于非结构化与结构化知识的表示差异，LLMs在知识图谱问答等结构化知识推理任务中面临逻辑漂移挑战。现有方法仅提供输入级指导，无法根本解决LLMs输出中的逻辑漂移问题。

Method: 提出Logits-to-Logic框架，针对自回归生成过程中的logits输出，包含logits强化和logits过滤两个核心模块，以纠正LLMs输出中的逻辑缺陷。

Result: 在多个知识图谱问答基准测试中，该方法显著提高了LLMs的逻辑一致性，并实现了最先进的性能。

Conclusion: Logits-to-Logic框架通过纠正LLMs输出中的逻辑缺陷，有效增强了其在结构化知识推理中的逻辑一致性。

Abstract: Large Language Models (LLMs) achieve excellent performance in natural language reasoning tasks through pre-training on vast unstructured text, enabling them to understand the logic in natural language and generate logic-consistent responses. However, the representational differences between unstructured and structured knowledge make LLMs inherently struggle to maintain logic consistency, leading to \textit{Logic Drift} challenges in structured knowledge reasoning tasks such as Knowledge Graph Question Answering (KGQA). Existing methods address this limitation by designing complex workflows embedded in prompts to guide LLM reasoning. Nevertheless, these approaches only provide input-level guidance and fail to fundamentally address the \textit{Logic Drift} in LLM outputs. Additionally, their inflexible reasoning workflows cannot adapt to different tasks and knowledge graphs. To enhance LLMs' logic consistency in structured knowledge reasoning, we specifically target the logits output from the autoregressive generation process. We propose the \textit{Logits-to-Logic} framework, which incorporates logits strengthening and logits filtering as core modules to correct logical defects in LLM outputs. Extensive experiments show that our approach significantly improves LLMs' logic consistency in structured knowledge reasoning and achieves state-of-the-art performance on multiple KGQA benchmarks.

</details>


### [2] [Self-Correction Distillation for Structured Data Question Answering](https://arxiv.org/abs/2511.07998)
*Yushan Zhu,Wen Zhang,Long Jin,Mengshu Sun,Ling Zhong,Zhiqiang Liu,Juan Li,Lei Liang,Chong Long,Chao Deng,Junlan Feng*

Main category: cs.CL

TL;DR: 提出了一种自我纠正蒸馏（SCD）方法，以增强小规模LLMs的结构化数据问答能力。


<details>
  <summary>Details</summary>
Motivation: 小规模LLMs在生成结构化查询时容易出错，而现有的统一结构化QA框架在此方面表现不佳。

Method: SCD方法包括错误提示机制（EPM）和两阶段蒸馏策略，以提高小规模LLMs的查询生成和错误纠正能力。

Result: 在5个基准测试中，SCD方法在小规模LLMs（8B）上实现了最佳性能和优越的泛化能力，并在某些数据集上接近GPT4的性能。

Conclusion: 配备EPM的大规模LLMs在大多数数据集上超越了现有最佳结果。

Abstract: Structured data question answering (QA), including table QA, Knowledge Graph (KG) QA, and temporal KG QA, is a pivotal research area. Advances in large language models (LLMs) have driven significant progress in unified structural QA frameworks like TrustUQA. However, these frameworks face challenges when applied to small-scale LLMs since small-scale LLMs are prone to errors in generating structured queries. To improve the structured data QA ability of small-scale LLMs, we propose a self-correction distillation (SCD) method. In SCD, an error prompt mechanism (EPM) is designed to detect errors and provide customized error messages during inference, and a two-stage distillation strategy is designed to transfer large-scale LLMs' query-generation and error-correction capabilities to small-scale LLM. Experiments across 5 benchmarks with 3 structured data types demonstrate that our SCD achieves the best performance and superior generalization on small-scale LLM (8B) compared to other distillation methods, and closely approaches the performance of GPT4 on some datasets. Furthermore, large-scale LLMs equipped with EPM surpass the state-of-the-art results on most datasets.

</details>


### [3] [HyCoRA: Hyper-Contrastive Role-Adaptive Learning for Role-Playing](https://arxiv.org/abs/2511.08017)
*Shihao Yang,Zhicong Lu,Yong Yang,Bo Lv,Yang Shen,Nayu Liu*

Main category: cs.CL

TL;DR: 提出一种新颖的HyCoRA框架，通过平衡不同和共享特征的学习，有效提高多角色扮演能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么使用角色共享模块，要么为每个角色分配单独模块，但各有缺陷。前者忽略角色独特性，后者忽略角色间共享特征。

Method: 提出HyCoRA框架，采用Hyper-Half Low-Rank Adaptation结构，结合角色特定模块和角色共享模块，并设计超对比学习机制。

Result: 在英语和中文基准测试中表现出优越性，GPT-4评估和可视化分析验证了框架捕捉角色特征的能力。

Conclusion: HyCoRA框架通过结合角色特定和角色共享模块以及超对比学习机制，在多角色扮演中取得了优异效果。

Abstract: Multi-character role-playing aims to equip models with the capability to simulate diverse roles. Existing methods either use one shared parameterized module across all roles or assign a separate parameterized module to each role. However, the role-shared module may ignore distinct traits of each role, weakening personality learning, while the role-specific module may overlook shared traits across multiple roles, hindering commonality modeling. In this paper, we propose a novel HyCoRA: Hyper-Contrastive Role-Adaptive learning framework, which efficiently improves multi-character role-playing ability by balancing the learning of distinct and shared traits. Specifically, we propose a Hyper-Half Low-Rank Adaptation structure, where one half is a role-specific module generated by a lightweight hyper-network, and the other half is a trainable role-shared module. The role-specific module is devised to represent distinct persona signatures, while the role-shared module serves to capture common traits. Moreover, to better reflect distinct personalities across different roles, we design a hyper-contrastive learning mechanism to help the hyper-network distinguish their unique characteristics. Extensive experimental results on both English and Chinese available benchmarks demonstrate the superiority of our framework. Further GPT-4 evaluations and visual analyses also verify the capability of HyCoRA to capture role characteristics.

</details>


### [4] [BARD10: A New Benchmark Reveals Significance of Bangla Stop-Words in Authorship Attribution](https://arxiv.org/abs/2511.08085)
*Abdullah Muhammad Moosa,Nusrat Sultana,Mahdi Muhammad Moosa,Md. Miraiz Hossain*

Main category: cs.CL

TL;DR: 该研究介绍了新的平衡基准语料库BARD10，并系统分析了停用词去除对古典和深度学习模型的影响，揭示了孟加拉语停用词的文体重要性。


<details>
  <summary>Details</summary>
Motivation: 探究孟加拉语作者归属问题，分析停用词在文体中的重要性，并建立一个基准语料库来评估不同模型的性能。

Method: 引入BARD10语料库，并评估四种代表分类器（SVM，Bangla BERT，XGBoost和MLP）在停用词去除条件下的表现。

Result: 在所有数据集中，TF-IDF + SVM基线表现最佳，在BAAD16和BARD10上的macro-F1分数分别为0.997和0.921。停用词修剪对BARD10作者影响较大，而BAAD16作者相对稳健。

Conclusion: 孟加拉语停用词是关键的文体指标，经过精细校准的机器学习模型在短文本限制下非常有效，BARD10为未来长文本或领域适应性变换模型提供了可复现的基准。

Abstract: This research presents a comprehensive investigation into Bangla authorship attribution, introducing a new balanced benchmark corpus BARD10 (Bangla Authorship Recognition Dataset of 10 authors) and systematically analyzing the impact of stop-word removal across classical and deep learning models to uncover the stylistic significance of Bangla stop-words. BARD10 is a curated corpus of Bangla blog and opinion prose from ten contemporary authors, alongside the methodical assessment of four representative classifiers: SVM (Support Vector Machine), Bangla BERT (Bidirectional Encoder Representations from Transformers), XGBoost, and a MLP (Multilayer Perception), utilizing uniform preprocessing on both BARD10 and the benchmark corpora BAAD16 (Bangla Authorship Attribution Dataset of 16 authors). In all datasets, the classical TF-IDF + SVM baseline outperformed, attaining a macro-F1 score of 0.997 on BAAD16 and 0.921 on BARD10, while Bangla BERT lagged by as much as five points. This study reveals that BARD10 authors are highly sensitive to stop-word pruning, while BAAD16 authors remain comparatively robust highlighting genre-dependent reliance on stop-word signatures. Error analysis revealed that high frequency components transmit authorial signatures that are diminished or reduced by transformer models. Three insights are identified: Bangla stop-words serve as essential stylistic indicators; finely calibrated ML models prove effective within short-text limitations; and BARD10 connects formal literature with contemporary web dialogue, offering a reproducible benchmark for future long-context or domain-adapted transformers.

</details>


### [5] [Estranged Predictions: Measuring Semantic Category Disruption with Masked Language Modelling](https://arxiv.org/abs/2511.08109)
*Yuxuan Liu,Haim Dubossarsky,Ruth Ahnert*

Main category: cs.CL

TL;DR: 本文利用掩码语言建模（MLM）技术，通过RoBERTa和Gemini模型，分析科幻文学如何打破人类、动物和机器的本体论分类。


<details>
  <summary>Details</summary>
Motivation: 探索科幻文学如何通过语言打破传统本体论分类，并量化这种分类的渗透性，以验证Darko Suvin的异化理论。

Method: 采用RoBERTa生成词汇替代，Gemini进行分类，通过保留率、替换率和熵三个指标量化概念渗透性。

Result: 科幻文学在机器指称上表现出更高的概念渗透性，而人类术语则保持语义一致性。

Conclusion: 科幻文学通过受控的语义扰动实现异化，MLMs可以作为揭示类型条件本体论假设的解释工具。

Abstract: This paper examines how science fiction destabilises ontological categories by measuring conceptual permeability across the terms human, animal, and machine using masked language modelling (MLM). Drawing on corpora of science fiction (Gollancz SF Masterworks) and general fiction (NovelTM), we operationalise Darko Suvin's theory of estrangement as computationally measurable deviation in token prediction, using RoBERTa to generate lexical substitutes for masked referents and classifying them via Gemini. We quantify conceptual slippage through three metrics: retention rate, replacement rate, and entropy, mapping the stability or disruption of category boundaries across genres. Our findings reveal that science fiction exhibits heightened conceptual permeability, particularly around machine referents, which show significant cross-category substitution and dispersion. Human terms, by contrast, maintain semantic coherence and often anchor substitutional hierarchies. These patterns suggest a genre-specific restructuring within anthropocentric logics. We argue that estrangement in science fiction operates as a controlled perturbation of semantic norms, detectable through probabilistic modelling, and that MLMs, when used critically, serve as interpretive instruments capable of surfacing genre-conditioned ontological assumptions. This study contributes to the methodological repertoire of computational literary studies and offers new insights into the linguistic infrastructure of science fiction.

</details>


### [6] [Sentence-Anchored Gist Compression for Long-Context LLMs](https://arxiv.org/abs/2511.08128)
*Dmitrii Tarasov,Elizaveta Goncharova,Kuznetsov Andrey*

Main category: cs.CL

TL;DR: 本文研究了使用学习到的压缩标记对大型语言模型（LLM）进行上下文压缩，以减少处理长序列的内存和计算需求。


<details>
  <summary>Details</summary>
Motivation: 处理长序列时，LLM面临高内存和计算需求的问题，需要有效的方法来压缩上下文。

Method: 通过对预训练的LLM进行微调，使用学习到的压缩标记来压缩上下文。

Result: 在不显著降低性能的前提下，上下文可被压缩2倍到8倍，并在30亿参数的LLaMA模型上实现了高压缩比率。

Conclusion: 该方法在压缩比率和性能之间实现了良好的平衡，优于其他压缩技术。

Abstract: This work investigates context compression for Large Language Models (LLMs) using learned compression tokens to reduce the memory and computational demands of processing long sequences. We demonstrate that pre-trained LLMs can be fine-tuned to compress their context by factors of 2x to 8x without significant performance degradation, as evaluated on both short-context and long-context benchmarks. Furthermore, in experiments on a 3-billion-parameter LLaMA model, our method achieves results on par with alternative compression techniques while attaining higher compression ratios.

</details>


### [7] [On the Interplay between Positional Encodings, Morphological Complexity, and Word Order Flexibility](https://arxiv.org/abs/2511.08139)
*Kushal Tatariya,Wessel Poelman,Miryam de Lhoneux*

Main category: cs.CL

TL;DR: 本文研究了不同语言结构下位置编码对语言模型性能的影响，发现任务、语言和度量标准的选择对结论至关重要。


<details>
  <summary>Details</summary>
Motivation: 探究英语主导的语言模型架构（特别是位置编码）是否会对结构不同于英语的语言造成性能下降。

Method: 通过对七种不同语言分别预训练带有绝对位置编码、相对位置编码和无位置编码的单语模型，并在四个下游任务上进行评估。

Result: 没有观察到位置编码与形态复杂性或词序灵活性之间明显的相互作用。

Conclusion: 任务、语言和度量标准的选择对于得出稳定结论至关重要。

Abstract: Language model architectures are predominantly first created for English and subsequently applied to other languages. It is an open question whether this architectural bias leads to degraded performance for languages that are structurally different from English. We examine one specific architectural choice: positional encodings, through the lens of the trade-off hypothesis: the supposed interplay between morphological complexity and word order flexibility. This hypothesis posits a trade-off between the two: a more morphologically complex language can have a more flexible word order, and vice-versa. Positional encodings are a direct target to investigate the implications of this hypothesis in relation to language modelling. We pretrain monolingual model variants with absolute, relative, and no positional encodings for seven typologically diverse languages and evaluate them on four downstream tasks. Contrary to previous findings, we do not observe a clear interaction between position encodings and morphological complexity or word order flexibility, as measured by various proxies. Our results show that the choice of tasks, languages, and metrics are essential for drawing stable conclusions

</details>


### [8] [Relation as a Prior: A Novel Paradigm for LLM-based Document-level Relation Extraction](https://arxiv.org/abs/2511.08143)
*Qiankun Pi,Yepeng Sun,Jicang Lu,Qinlong Fan,Ningbo Huang,Shiyu Wang*

Main category: cs.CL

TL;DR: 提出了一种新的基于LLM的DocRE方法RelPrior，通过关系作为先验，提高文档级关系抽取性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在文档理解中表现出色，但在文档级关系抽取（DocRE）中仍存在性能差距，主要由于无关实体对引入噪声和预定义关系标签限制。

Method: 提出了Relation as a Prior (RelPrior)范式，利用二元关系作为先验来提取和确定两个实体是否相关，从而过滤无关实体对，减少预测噪声，并使用预定义关系匹配实体进行三元组提取。

Result: 在两个基准测试中，RelPrior实现了最先进的性能，超越了现有的基于LLM的方法。

Conclusion: RelPrior通过将关系作为先验，有效解决了DocRE中的噪声和关系标签限制问题，显著提升了关系抽取的效果。

Abstract: Large Language Models (LLMs) have demonstrated their remarkable capabilities in document understanding. However, recent research reveals that LLMs still exhibit performance gaps in Document-level Relation Extraction (DocRE) as requiring fine-grained comprehension. The commonly adopted "extract entities then predict relations" paradigm in LLM-based methods leads to these gaps due to two main reasons: (1) Numerous unrelated entity pairs introduce noise and interfere with the relation prediction for truly related entity pairs. (2) Although LLMs have identified semantic associations between entities, relation labels beyond the predefined set are still treated as prediction errors. To address these challenges, we propose a novel Relation as a Prior (RelPrior) paradigm for LLM-based DocRE. For challenge (1), RelPrior utilizes binary relation as a prior to extract and determine whether two entities are correlated, thereby filtering out irrelevant entity pairs and reducing prediction noise. For challenge (2), RelPrior utilizes predefined relation as a prior to match entities for triples extraction instead of directly predicting relation. Thus, it avoids misjudgment caused by strict predefined relation labeling. Extensive experiments on two benchmarks demonstrate that RelPrior achieves state-of-the-art performance, surpassing existing LLM-based methods.

</details>


### [9] [Still Not There: Can LLMs Outperform Smaller Task-Specific Seq2Seq Models on the Poetry-to-Prose Conversion Task?](https://arxiv.org/abs/2511.08145)
*Kunal Kingkar Das,Manoj Balaji Jagadeeshan,Nallani Chakravartula Sahith,Jivnesh Sandhan,Pawan Goyal*

Main category: cs.CL

TL;DR: 本文比较了指令微调和上下文提示的大语言模型（LLMs）与特定任务编码器-解码器模型在梵文诗歌转散文任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 探讨大语言模型是否在低资源和形态丰富的语言（如梵文）上能够超越专门模型，特别是在诗歌到散文的转换任务中。

Method: 对通用模型进行指令微调，并基于帕尼尼语法和经典注释启发式设计上下文学习模板。同时，完全微调一个ByT5-Sanskrit Seq2Seq模型用于特定任务建模。

Result: 领域特定的ByT5-Sanskrit微调在所有指令驱动的LLM方法中表现显著更好，人类评估结果也高度一致。

Conclusion: 在梵文诗歌到散文转换任务中，领域特定的Seq2Seq模型优于通用LLMs。同时，上下文提示策略在缺乏领域特定诗歌语料库时提供了微调之外的替代方案。

Abstract: Large Language Models (LLMs) are increasingly treated as universal, general-purpose solutions across NLP tasks, particularly in English. But does this assumption hold for low-resource, morphologically rich languages such as Sanskrit? We address this question by comparing instruction-tuned and in-context-prompted LLMs with smaller task-specific encoder-decoder models on the Sanskrit poetry-to-prose conversion task. This task is intrinsically challenging: Sanskrit verse exhibits free word order combined with rigid metrical constraints, and its conversion to canonical prose (anvaya) requires multi-step reasoning involving compound segmentation, dependency resolution, and syntactic linearisation. This makes it an ideal testbed to evaluate whether LLMs can surpass specialised models. For LLMs, we apply instruction fine-tuning on general-purpose models and design in-context learning templates grounded in Paninian grammar and classical commentary heuristics. For task-specific modelling, we fully fine-tune a ByT5-Sanskrit Seq2Seq model. Our experiments show that domain-specific fine-tuning of ByT5-Sanskrit significantly outperforms all instruction-driven LLM approaches. Human evaluation strongly corroborates this result, with scores exhibiting high correlation with Kendall's Tau scores. Additionally, our prompting strategies provide an alternative to fine-tuning when domain-specific verse corpora are unavailable, and the task-specific Seq2Seq model demonstrates robust generalisation on out-of-domain evaluations.

</details>


### [10] [Do Syntactic Categories Help in Developmentally Motivated Curriculum Learning for Language Models?](https://arxiv.org/abs/2511.08199)
*Arzu Burcu Güven,Anna Rogers,Rob van der Goot*

Main category: cs.CL

TL;DR: 研究BabyLM和CHILDES数据集的句法特性，并探讨课程学习对模型性能的影响。


<details>
  <summary>Details</summary>
Motivation: 探讨不同年龄段和句法知识对训练模型在语言任务中表现的影响，以及课程学习的效果。

Method: 分析BabyLM和CHILDES数据集的句法特性，并测试多种课程学习方法。

Result: CHILDES数据集未显示按年龄的强句法差异，某些课程有助于阅读任务，但主要性能提升来自使用句法可分类数据的子集。

Conclusion: 句法可分类数据的子集比全量嘈杂数据更有助于提升模型性能，而课程学习的效果有限。

Abstract: We examine the syntactic properties of BabyLM corpus, and age-groups within CHILDES. While we find that CHILDES does not exhibit strong syntactic differentiation by age, we show that the syntactic knowledge about the training data can be helpful in interpreting model performance on linguistic tasks. For curriculum learning, we explore developmental and several alternative cognitively inspired curriculum approaches. We find that some curricula help with reading tasks, but the main performance improvement come from using the subset of syntactically categorizable data, rather than the full noisy corpus.

</details>


### [11] [Encoder Fine-tuning with Stochastic Sampling Outperforms Open-weight GPT in Astronomy Knowledge Extraction](https://arxiv.org/abs/2511.08204)
*Shivam Rawat,Lucie Flek,Akbar Karimi*

Main category: cs.CL

TL;DR: 本文提出了一种基于编码器系统，从天文学文章中自动提取关键实体和上下文信息。


<details>
  <summary>Details</summary>
Motivation: 天文学科学文献迅速增长，使得自动提取关键实体和上下文信息变得日益重要。

Method: 实现了一种基于多任务变换器的系统，该系统建立在SciBERT模型之上，并针对天文学语料库进行微调。通过随机抽样训练数据片段，并在推理时对测试片段进行多数投票。

Result: 尽管系统实现简单且成本低，但显著优于开放权重的GPT基线。

Conclusion: 该多任务系统能够有效地分类望远镜引用、检测辅助语义属性，并识别文本内容中的仪器提及。

Abstract: Scientific literature in astronomy is rapidly expanding, making it increasingly important to automate the extraction of key entities and contextual information from research papers. In this paper, we present an encoder-based system for extracting knowledge from astronomy articles. Our objective is to develop models capable of classifying telescope references, detecting auxiliary semantic attributes, and recognizing instrument mentions from textual content. To this end, we implement a multi-task transformer-based system built upon the SciBERT model and fine-tuned for astronomy corpora classification. To carry out the fine-tuning, we stochastically sample segments from the training data and use majority voting over the test segments at inference time. Our system, despite its simplicity and low-cost implementation, significantly outperforms the open-weight GPT baseline.

</details>


### [12] [Benchmarking Educational LLMs with Analytics: A Case Study on Gender Bias in Feedback](https://arxiv.org/abs/2511.08225)
*Yishan Du,Conrad Borchers,Mutlu Cukurova*

Main category: cs.CL

TL;DR: 本文提出了一种基于嵌入的基准测试框架，用于检测形成性反馈中大型语言模型（LLMs）的性别偏见。


<details>
  <summary>Details</summary>
Motivation: 教师越来越多地在教学实践中使用生成式人工智能，需要可靠的方法来为教学目的对大型语言模型进行基准测试。

Method: 使用来自AES 2.0语料库的600篇真实学生论文，构建了在两个维度上的受控反事实：(i)通过词汇替换引入的隐性性别提示，(ii)通过提示中的性别作者背景引入的显性提示。研究了六个代表性的LLMs，首先用余弦和欧几里得距离量化响应差异，然后通过排列测试评估显著性，最后用降维可视化结构。

Result: 所有模型中，隐性操作对男性-女性反事实引发的语义变化大于女性-男性。只有GPT和Llama模型对显性性别提示敏感。定性分析揭示了语言差异（例如，男性提示下更多自主支持反馈，女性提示下更多控制性反馈）。

Conclusion: 即使是先进的LLMs在反馈中仍表现出性别偏见。本文讨论了这对教学用生成式人工智能公平性审计的影响，提出了学习分析中反事实评估的报告标准，并概述了提示设计和部署的实践指南，以保障公平反馈。

Abstract: As teachers increasingly turn to GenAI in their educational practice, we need robust methods to benchmark large language models (LLMs) for pedagogical purposes. This article presents an embedding-based benchmarking framework to detect bias in LLMs in the context of formative feedback. Using 600 authentic student essays from the AES 2.0 corpus, we constructed controlled counterfactuals along two dimensions: (i) implicit cues via lexicon-based swaps of gendered terms within essays, and (ii) explicit cues via gendered author background in the prompt. We investigated six representative LLMs (i.e. GPT-5 mini, GPT-4o mini, DeepSeek-R1, DeepSeek-R1-Qwen, Gemini 2.5 Pro, Llama-3-8B). We first quantified the response divergence with cosine and Euclidean distances over sentence embeddings, then assessed significance via permutation tests, and finally, visualised structure using dimensionality reduction. In all models, implicit manipulations reliably induced larger semantic shifts for male-female counterfactuals than for female-male. Only the GPT and Llama models showed sensitivity to explicit gender cues. These findings show that even state-of-the-art LLMs exhibit asymmetric semantic responses to gender substitutions, suggesting persistent gender biases in feedback they provide learners. Qualitative analyses further revealed consistent linguistic differences (e.g., more autonomy-supportive feedback under male cues vs. more controlling feedback under female cues). We discuss implications for fairness auditing of pedagogical GenAI, propose reporting standards for counterfactual evaluation in learning analytics, and outline practical guidance for prompt design and deployment to safeguard equitable feedback.

</details>


### [13] [VocalBench-zh: Decomposing and Benchmarking the Speech Conversational Abilities in Mandarin Context](https://arxiv.org/abs/2511.08230)
*Heyang Liu,Ziyang Cheng,Yuhao Wang,Hongcheng Liu,Yiqi Li,Ronghua Wu,Qunshan Gu,Yanfeng Wang,Yu Wang*

Main category: cs.CL

TL;DR: 提出了一个针对普通话的语音到语音评测套件VocalBench-zh，涵盖12个用户导向特征，包含10个精心设计的子集和10K+高质量实例。


<details>
  <summary>Details</summary>
Motivation: 多模态大型语言模型（LLMs）的快速发展需要更全面的普通话语音交互能力评估工具，但现有基准测试稀缺，不利于开发者和用户的系统评估和比较。

Method: 设计并实现了VocalBench-zh，包含10个不同能力维度的子集和超过10,000个高质量实例，覆盖12个用户导向特征。

Result: 在14个主流模型上的评测实验揭示了当前语音交互系统的共同挑战，强调了下一代语音交互系统需要新的突破。

Conclusion: VocalBench-zh为普通话语音交互能力提供了系统化的评测工具，并突出了当前技术的局限性和未来发展方向。

Abstract: The development of multi-modal large language models (LLMs) leads to intelligent approaches capable of speech interactions. As one of the most widely spoken languages globally, Mandarin is supported by most models to enhance their applicability and reach. However, the scarcity of comprehensive speech-to-speech (S2S) benchmarks in Mandarin contexts impedes systematic evaluation for developers and hinders fair model comparison for users. In this work, we propose VocalBench-zh, an ability-level divided evaluation suite adapted to Mandarin context consisting of 10 well-crafted subsets and over 10K high-quality instances, covering 12 user-oriented characters. The evaluation experiment on 14 mainstream models reveals the common challenges for current routes, and highlights the need for new insights into next-generation speech interactive systems. The evaluation codes and datasets will be available at https://github.com/SJTU-OmniAgent/VocalBench-zh.

</details>


### [14] [ParliaBench: An Evaluation and Benchmarking Framework for LLM-Generated Parliamentary Speech](https://arxiv.org/abs/2511.08247)
*Marios Koniaris,Argyro Tsipi,Panayiotis Tsanakas*

Main category: cs.CL

TL;DR: 提出ParliaBench议会演讲生成基准测试框架，包含新数据集和结合计算指标与LLM-as-a-judge的评估体系，通过微调5个LLM验证有效性


<details>
  <summary>Details</summary>
Motivation: 议会演讲需要政治真实性和意识形态一致性，但现有语言模型缺乏议会场景专业训练，评估方法也忽视政治真实性维度

Method: 1) 构建英国议会演讲数据集 2) 提出包含语言质量、语义连贯性、政治真实性三维度的评估框架 3) 设计政治光谱对齐和政党对齐两个新嵌入指标 4) 微调5个LLM并生成2.8万篇演讲进行对比实验

Result: 微调模型在多数指标上均有统计显著提升，新提出的政治维度指标展现出强判别能力

Conclusion: ParliaBench能有效评估和提升议会演讲生成的政治真实性，为专业领域文本生成提供了新范式

Abstract: Parliamentary speech generation presents specific challenges for large language models beyond standard text generation tasks. Unlike general text generation, parliamentary speeches require not only linguistic quality but also political authenticity and ideological consistency. Current language models lack specialized training for parliamentary contexts, and existing evaluation methods focus on standard NLP metrics rather than political authenticity. To address this, we present ParliaBench, a benchmark for parliamentary speech generation. We constructed a dataset of speeches from UK Parliament to enable systematic model training. We introduce an evaluation framework combining computational metrics with LLM-as-a-judge assessments for measuring generation quality across three dimensions: linguistic quality, semantic coherence, and political authenticity. We propose two novel embedding-based metrics, Political Spectrum Alignment and Party Alignment, to quantify ideological positioning. We fine-tuned five large language models (LLMs), generated 28k speeches, and evaluated them using our framework, comparing baseline and fine-tuned models. Results show that fine-tuning produces statistically significant improvements across the majority of metrics and our novel metrics demonstrate strong discriminative power for political dimensions.

</details>


### [15] [Hierarchical structure understanding in complex tables with VLLMs: a benchmark and experiments](https://arxiv.org/abs/2511.08298)
*Luca Bindini,Simone Giovannini,Simone Marinai,Valeria Nardoni,Kimiya Noor Ali*

Main category: cs.CL

TL;DR: 本文研究了视觉大语言模型（VLLMs）理解和解释科学文章表格结构的能力，并探讨了VLLMs是否能无需额外处理即可推断表格的层次结构。


<details>
  <summary>Details</summary>
Motivation: 探索VLLMs在无需额外处理的情况下，推断科学文章表格层次结构的能力，为未来整合结构化数据理解到通用VLLMs中提供指导。

Method: 采用PubTables-1M数据集，提取复杂层次表格（CHiTab）作为基准，使用一系列提示工程策略，对多个先进的开源VLLMs进行评估，并对其进行微调。还测量了人类在少量表格上的表现以进行比较。

Result: 实验支持了通用VLLMs即使没有专门设计用于理解表格结构，也能执行此任务的直觉。

Conclusion: 该研究提供了VLLMs处理复杂表格的潜力和局限性见解，并为未来将结构化数据理解整合到通用VLLMs中的工作提供指导。

Abstract: This work investigates the ability of Vision Large Language Models (VLLMs) to understand and interpret the structure of tables in scientific articles. Specifically, we explore whether VLLMs can infer the hierarchical structure of tables without additional processing. As a basis for our experiments we use the PubTables-1M dataset, a large-scale corpus of scientific tables. From this dataset, we extract a subset of tables that we introduce as Complex Hierarchical Tables (CHiTab): a benchmark collection of complex tables containing hierarchical headings. We adopt a series of prompt engineering strategies to probe the models' comprehension capabilities, experimenting with various prompt formats and writing styles. Multiple state-of-the-art open-weights VLLMs are evaluated on the benchmark first using their off-the-shelf versions and then fine-tuning some models on our task. We also measure the performance of humans to solve the task on a small set of tables comparing with performance of the evaluated VLLMs. The experiments support our intuition that generic VLLMs, not explicitly designed for understanding the structure of tables, can perform this task. This study provides insights into the potential and limitations of VLLMs to process complex tables and offers guidance for future work on integrating structured data understanding into general-purpose VLLMs.

</details>


### [16] [Adaptive Multi-Agent Response Refinement in Conversational Systems](https://arxiv.org/abs/2511.08319)
*Soyeong Jeong,Aparna Elangovan,Emine Yilmaz,Oleg Rokhlenko*

Main category: cs.CL

TL;DR: 本文提出了一种通过多智能体框架细化大型语言模型对话响应的方法，其中每个智能体负责一个特定的对话质量方面，并引入了动态通信策略以提高协作效率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在对话系统中表现出色，但在个性化和特定知识方面存在不足，且用户难以发现错误，因此需要在返回响应之前进行自动细化。

Method: 采用多智能体框架，每个智能体负责细化对话的一个关键方面（真实性、个性化、连贯性），并引入动态通信策略以自适应选择和协调最相关的智能体。

Result: 在具有挑战性的对话数据集上验证了该框架，结果表明该方法在涉及知识或用户角色的对话任务中显著优于相关基线。

Conclusion: 多智能体框架结合动态通信策略能够有效提升对话响应质量，尤其在个性化和知识相关的任务中表现突出。

Abstract: Large Language Models (LLMs) have demonstrated remarkable success in conversational systems by generating human-like responses. However, they can fall short, especially when required to account for personalization or specific knowledge. In real-life settings, it is impractical to rely on users to detect these errors and request a new response. One way to address this problem is to refine the response before returning it to the user. While existing approaches focus on refining responses within a single LLM, this method struggles to consider diverse aspects needed for effective conversations. In this work, we propose refining responses through a multi-agent framework, where each agent is assigned a specific role for each aspect. We focus on three key aspects crucial to conversational quality: factuality, personalization, and coherence. Each agent is responsible for reviewing and refining one of these aspects, and their feedback is then merged to improve the overall response. To enhance collaboration among them, we introduce a dynamic communication strategy. Instead of following a fixed sequence of agents, our approach adaptively selects and coordinates the most relevant agents based on the specific requirements of each query. We validate our framework on challenging conversational datasets, demonstrating that ours significantly outperforms relevant baselines, particularly in tasks involving knowledge or user's persona, or both.

</details>


### [17] [DPRM: A Dual Implicit Process Reward Model in Multi-Hop Question Answering](https://arxiv.org/abs/2511.08364)
*Xinyi Wang,Yiping Song,Zhiliang Tian,Bo Liu,Tingjin Luo,Minlie Huang*

Main category: cs.CL

TL;DR: 提出了一种双隐式过程奖励模型DPRM，以增强多跳问答中的推理过程。


<details>
  <summary>Details</summary>
Motivation: 多跳问答任务中，隐式过程奖励模型无法处理知识图谱结构约束和思维链与图谱路径之间的不一致性。

Method: DPRM训练两个隐式过程奖励模型（KG-PRM和CoT-PRM），并通过一致性约束优化推理路径。

Result: 在多个数据集上超越了13个基线方法，Hit@1指标提升高达16.6%。

Conclusion: DPRM通过双模型协作和一致性约束有效提升了多跳问答任务的推理质量。

Abstract: In multi-hop question answering (MHQA) tasks, Chain of Thought (CoT) improves the quality of generation by guiding large language models (LLMs) through multi-step reasoning, and Knowledge Graphs (KGs) reduce hallucinations via semantic matching. Outcome Reward Models (ORMs) provide feedback after generating the final answers but fail to evaluate the process for multi-step reasoning. Traditional Process Reward Models (PRMs) evaluate the reasoning process but require costly human annotations or rollout generation. While implicit PRM is trained only with outcome signals and derives step rewards through reward parameterization without explicit annotations, it is more suitable for multi-step reasoning in MHQA tasks. However, existing implicit PRM has only been explored for plain text scenarios. When adapting to MHQA tasks, it cannot handle the graph structure constraints in KGs and capture the potential inconsistency between CoT and KG paths. To address these limitations, we propose the DPRM (Dual Implicit Process Reward Model). It trains two implicit PRMs for CoT and KG reasoning in MHQA tasks. Both PRMs, namely KG-PRM and CoT-PRM, derive step-level rewards from outcome signals via reward parameterization without additional explicit annotations. Among them, KG-PRM uses preference pairs to learn structural constraints from KGs. DPRM further introduces a consistency constraint between CoT and KG reasoning steps, making the two PRMs mutually verify and collaboratively optimize the reasoning paths. We also provide a theoretical demonstration of the derivation of process rewards. Experimental results show that our method outperforms 13 baselines on multiple datasets with up to 16.6% improvement on Hit@1.

</details>


### [18] [The Dynamic Articulatory Model DYNARTmo: Dynamic Movement Generation and Speech Gestures](https://arxiv.org/abs/2511.08372)
*Bernd J. Kröger*

Main category: cs.CL

TL;DR: 本文描述了动态发音模型DYNARTmo的当前实现，该模型基于言语动作及其动作乐谱生成连续的发音器运动。


<details>
  <summary>Details</summary>
Motivation: 提供一个神经生物学启发的计算框架，用于模拟从语言表征到发音-声学实现的层次控制。

Method: 介绍了动作库存的结构、动作乐谱中的动作协调，以及这些动作如何转化为控制DYNARTmo发音通道模型的连续发音器轨迹。

Result: 展示了DYNARTmo模型的结构和实现方法，强调了其在发音动作和发音器轨迹生成中的作用。

Conclusion: 该模型为理解言语产生的层次控制提供了一个计算上可行的框架，并为未来的语音研究提供了工具。

Abstract: This paper describes the current implementation of the dynamic articulatory model DYNARTmo, which generates continuous articulator movements based on the concept of speech gestures and a corresponding gesture score. The model provides a neurobiologically inspired computational framework for simulating the hierarchical control of speech production from linguistic representation to articulatory-acoustic realization. We present the structure of the gesture inventory, the coordination of gestures in the gesture score, and their translation into continuous articulator trajectories controlling the DYNARTmo vocal tract model.

</details>


### [19] [TurkEmbed: Turkish Embedding Model on NLI & STS Tasks](https://arxiv.org/abs/2511.08376)
*Özay Ezerceli,Gizem Gümüşçekiçci,Tuğba Erkoç,Berke Özenç*

Main category: cs.CL

TL;DR: TurkEmbed是一种新颖的土耳其语嵌入模型，旨在在自然语言推理(NLI)和语义文本相似性(STS)任务中优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 当前土耳其语嵌入模型通常依赖于机器翻译的数据集，这可能会限制其准确性和语义理解。

Method: TurkEmbed利用了多种数据集和先进的训练技术，包括套娃表示学习(matryoshka representation learning)，以实现更强大和准确的嵌入。

Result: TurkEmbed在土耳其STS-b-TR数据集上的评估中，使用Pearson和Spearman相关度量，显著提升了语义相似性任务的性能，并在All-NLI-TR和STS-b-TR基准测试中超越了当前最先进的模型Emrecan，取得了1-4%的提升。

Conclusion: TurkEmbed通过提供对语言的更细致的理解，并促进下游应用的进展，有望增强土耳其语NLP生态系统。

Abstract: This paper introduces TurkEmbed, a novel Turkish language embedding model designed to outperform existing models, particularly in Natural Language Inference (NLI) and Semantic Textual Similarity (STS) tasks. Current Turkish embedding models often rely on machine-translated datasets, potentially limiting their accuracy and semantic understanding. TurkEmbed utilizes a combination of diverse datasets and advanced training techniques, including matryoshka representation learning, to achieve more robust and accurate embeddings. This approach enables the model to adapt to various resource-constrained environments, offering faster encoding capabilities. Our evaluation on the Turkish STS-b-TR dataset, using Pearson and Spearman correlation metrics, demonstrates significant improvements in semantic similarity tasks. Furthermore, TurkEmbed surpasses the current state-of-the-art model, Emrecan, on All-NLI-TR and STS-b-TR benchmarks, achieving a 1-4\% improvement. TurkEmbed promises to enhance the Turkish NLP ecosystem by providing a more nuanced understanding of language and facilitating advancements in downstream applications.

</details>


### [20] [PCRLLM: Proof-Carrying Reasoning with Large Language Models under Stepwise Logical Constraints](https://arxiv.org/abs/2511.08392)
*Tangrui Li,Pei Wang,Hongzheng Wang Christian Hahm,Matteo Spatola,Justin Shi*

Main category: cs.CL

TL;DR: 提出PCRLLM框架，通过单步推理和显式规则约束提升大模型推理可信度。


<details>
  <summary>Details</summary>
Motivation: 大模型存在逻辑不连贯、推理过程不透明的问题，需要可验证的推理框架。

Method: PCRLLM框架要求每步输出明确标注前提、规则和结论，支持逻辑验证与多模型协作。

Result: 实现链级推理验证、多模型协同，并构建兼顾自然语言与形式逻辑的基准数据集。

Conclusion: 该方法在保持自然语言表达的同时增强推理可追溯性，为黑箱模型提供可信度保障。

Abstract: Large Language Models (LLMs) often exhibit limited logical coherence, mapping premises to conclusions without adherence to explicit inference rules. We propose Proof-Carrying Reasoning with LLMs (PCRLLM), a framework that constrains reasoning to single-step inferences while preserving natural language formulations. Each output explicitly specifies premises, rules, and conclusions, thereby enabling verification against a target logic. This mechanism mitigates trustworthiness concerns by supporting chain-level validation even in black-box settings. Moreover, PCRLLM facilitates systematic multi-LLM collaboration, allowing intermediate steps to be compared and integrated under formal rules. Finally, we introduce a benchmark schema for generating large-scale step-level reasoning data, combining natural language expressiveness with formal rigor.

</details>


### [21] [Interaction Dynamics as a Reward Signal for LLMs](https://arxiv.org/abs/2511.08394)
*Sian Gooding,Edward Grefenstette*

Main category: cs.CL

TL;DR: 本文提出了TRACE，一种基于对话嵌入轨迹几何特性的新奖励信号，用于多轮对话中大型语言模型的对齐。


<details>
  <summary>Details</summary>
Motivation: 当前LLMs在多轮对话中的对齐通常仅依赖文本内容的奖励信号，忽略了互动本身的动态信号，因此希望利用对话的‘几何’特性来补充这一缺失。

Method: 引入TRACE，通过对话嵌入轨迹的几何属性生成奖励信号，并展示了结构信号与文本分析的结合如何提升性能。

Result: 仅基于结构信号的奖励模型实现了68.20%的成对准确率，接近分析完整文本的强大LLM基线（70.04%），而结合互动动态与文本分析的混合模型达到80.17%的性能。

Conclusion: 互动方式与内容一样，是预测成功的重要指标，该方法为交互式设置提供了新的隐私保护框架，并有助于诊断成功协作的互动模式。

Abstract: The alignment of Large Language Models (LLMs) for multi-turn conversations typically relies on reward signals derived from the content of the text. This approach, however, overlooks a rich, complementary source of signal: the dynamics of the interaction itself. This paper introduces TRACE (Trajectory-based Reward for Agent Collaboration Estimation), a novel reward signal derived from the geometric properties of a dialogue's embedding trajectory--a concept we term 'conversational geometry'. Our central finding is that a reward model trained only on these structural signals achieves a pairwise accuracy (68.20%) comparable to a powerful LLM baseline that analyzes the full transcript (70.04%). Furthermore, a hybrid model combining interaction dynamics with textual analysis achieves the highest performance (80.17%), demonstrating their complementary nature. This work provides strong evidence that for interactive settings, how an agent communicates is as powerful a predictor of success as what it says, offering a new, privacy-preserving framework that not only aligns agents but also serves as a diagnostic tool for understanding the distinct interaction patterns that drive successful collaboration.

</details>


### [22] [Bot Meets Shortcut: How Can LLMs Aid in Handling Unknown Invariance OOD Scenarios?](https://arxiv.org/abs/2511.08455)
*Shiyan Zheng,Herun Wan,Minnan Luo,Junhang Huang*

Main category: cs.CL

TL;DR: 现有的社交机器人检测器在基准测试中表现良好，但在多样化的现实场景中鲁棒性有限。本文研究了基于文本特征的快捷学习对检测器的影响，并提出利用大型语言模型进行反事实数据增强的缓解策略。


<details>
  <summary>Details</summary>
Motivation: 社交机器人检测器在真实场景中由于不明确的地面真相和多样的误导性线索，鲁棒性受限。尤其是快捷学习的影响研究较少，这促使本文深入研究文本特征对检测器的影响。

Method: 通过构建用户标签与表面文本线索之间的虚假关联，设计一系列快捷学习场景来评估模型鲁棒性。提出利用大型语言模型进行反事实数据增强，从数据和模型两个层面缓解问题。

Result: 在基线模型中，无关特征分布的偏移导致社交机器人检测器性能显著下降，平均相对准确率下降了32%。提出的策略在快捷学习场景下实现了平均56%的相对性能提升。

Conclusion: 本文提出的方法有效缓解了快捷学习对社交机器人检测器的影响，提高了模型在多样化现实场景中的鲁棒性。

Abstract: While existing social bot detectors perform well on benchmarks, their robustness across diverse real-world scenarios remains limited due to unclear ground truth and varied misleading cues. In particular, the impact of shortcut learning, where models rely on spurious correlations instead of capturing causal task-relevant features, has received limited attention. To address this gap, we conduct an in-depth study to assess how detectors are influenced by potential shortcuts based on textual features, which are most susceptible to manipulation by social bots. We design a series of shortcut scenarios by constructing spurious associations between user labels and superficial textual cues to evaluate model robustness. Results show that shifts in irrelevant feature distributions significantly degrade social bot detector performance, with an average relative accuracy drop of 32\% in the baseline models. To tackle this challenge, we propose mitigation strategies based on large language models, leveraging counterfactual data augmentation. These methods mitigate the problem from data and model perspectives across three levels, including data distribution at both the individual user text and overall dataset levels, as well as the model's ability to extract causal information. Our strategies achieve an average relative performance improvement of 56\% under shortcut scenarios.

</details>


### [23] [SPEAR-MM: Selective Parameter Evaluation and Restoration via Model Merging for Efficient Financial LLM Adaptation](https://arxiv.org/abs/2511.08500)
*Berkcan Kapusuzoglu,Supriyo Chakraborty,Renkun Ni,Stephen Rawls,Sambit Sahu*

Main category: cs.CL

TL;DR: SPEAR-MM框架通过选择性参数评估和模型合并，在金融领域适应中保持通用推理能力，有效缓解灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 金融领域的大型语言模型常常会遗忘关键的通用推理能力，这对于客户交互和复杂金融分析至关重要。

Method: 提出SPEAR-MM框架，通过事后分析评估各层对外部基准的影响，并通过球插值合并选择性地冻结或恢复transformer层。

Result: 在LLaMA-3.1-8B上应用，SPEAR-MM在保持94%领域适应提升的同时，通用能力保留率从69.7%提升到91.2%，计算成本降低90%。

Conclusion: SPEAR-MM提供了可解释的权衡控制，显著降低了计算成本，适用于资源受限的金融机构。

Abstract: Large language models (LLMs) adapted to financial domains often suffer from catastrophic forgetting of general reasoning capabilities essential for customer interactions and complex financial analysis. We introduce Selective Parameter Evaluation and Restoration via Model Merging (SPEAR-MM), a practical framework that preserves critical capabilities while enabling domain adaptation. Our method approximates layer-wise impact on external benchmarks through post-hoc analysis, then selectively freezes or restores transformer layers via spherical interpolation merging. Applied to LLaMA-3.1-8B for financial tasks, SPEAR-MM achieves 91.2% retention of general capabilities versus 69.7% for standard continual pretraining, while maintaining 94% of domain adaptation gains. The approach provides interpretable trade-off control and reduces computational costs by 90% crucial for resource-constrained financial institutions.

</details>


### [24] [Structured RAG for Answering Aggregative Questions](https://arxiv.org/abs/2511.08505)
*Omri Koshorek,Niv Granot,Aviv Alloni,Shahar Admati,Roee Hendel,Ido Weiss,Alan Arazi,Shay-Nitzan Cohen,Yonatan Belinkov*

Main category: cs.CL

TL;DR: 提出了一种针对聚合性查询的检索增强生成方法S-RAG，并引入了两个新数据集HOTELS和WORLD CUP。


<details>
  <summary>Details</summary>
Motivation: 当前的数据集和方法主要集中在只有少量相关文档的查询，无法处理需要从大量文档中聚合信息的复杂查询。

Method: S-RAG在数据摄取时构建语料库的结构化表示，在推理时将自然语言查询翻译成形式化查询。

Result: 实验证明，S-RAG在新数据集和公共基准上显著优于传统RAG系统和长上下文LLMs。

Conclusion: S-RAG能有效处理聚合性查询，为未来的研究提供了新的方向和基准。

Abstract: Retrieval-Augmented Generation (RAG) has become the dominant approach for answering questions over large corpora. However, current datasets and methods are highly focused on cases where only a small part of the corpus (usually a few paragraphs) is relevant per query, and fail to capture the rich world of aggregative queries. These require gathering information from a large set of documents and reasoning over them. To address this gap, we propose S-RAG, an approach specifically designed for such queries. At ingestion time, S-RAG constructs a structured representation of the corpus; at inference time, it translates natural-language queries into formal queries over said representation. To validate our approach and promote further research in this area, we introduce two new datasets of aggregative queries: HOTELS and WORLD CUP. Experiments with S-RAG on the newly introduced datasets, as well as on a public benchmark, demonstrate that it substantially outperforms both common RAG systems and long-context LLMs.

</details>


### [25] [Introducing A Bangla Sentence - Gloss Pair Dataset for Bangla Sign Language Translation and Research](https://arxiv.org/abs/2511.08507)
*Neelavro Saha,Rafi Shahriyar,Nafis Ashraf Roudra,Saadman Sakib,Annajiat Alim Rasel*

Main category: cs.CL

TL;DR: 本文介绍了一种新的孟加拉手语翻译数据集Bangla-SGP，并采用基于规则的RAG方法进行数据增强，然后微调多个基于Transformer的模型进行句子到手语词汇的翻译。


<details>
  <summary>Details</summary>
Motivation: 孟加拉手语翻译由于缺乏大规模的数据集而受到限制，现有研究仅限于单词和字母级别的检测，因此需要解决句子级翻译的问题。

Method: 引入了一个包含1000个手动注释的句子-手语词汇对的新数据集，并通过基于规则的检索增强生成（RAG）方法，使用句法和形态规则合成约3000个额外数据对。此外，微调了几个基于Transformer的模型，并使用BLEU分数评估其性能。

Result: 通过BLEU评分评估了多个模型在句子到手语词汇翻译中的性能，并与RWTH-PHOENIX-2014T基准数据集进行了比较。

Conclusion: Bangla-SGP数据集的引入和基于规则的增强方法有效提升了孟加拉手语句子级翻译的研究，为低资源NLP任务提供了新的解决方案。

Abstract: Bangla Sign Language (BdSL) translation represents a low-resource NLP task due to the lack of large-scale datasets that address sentence-level translation. Correspondingly, existing research in this field has been limited to word and alphabet level detection. In this work, we introduce Bangla-SGP, a novel parallel dataset consisting of 1,000 human-annotated sentence-gloss pairs which was augmented with around 3,000 synthetically generated pairs using syntactic and morphological rules through a rule-based Retrieval-Augmented Generation (RAG) pipeline. The gloss sequences of the spoken Bangla sentences are made up of individual glosses which are Bangla sign supported words and serve as an intermediate representation for a continuous sign. Our dataset consists of 1000 high quality Bangla sentences that are manually annotated into a gloss sequence by a professional signer. The augmentation process incorporates rule-based linguistic strategies and prompt engineering techniques that we have adopted by critically analyzing our human annotated sentence-gloss pairs and by working closely with our professional signer. Furthermore, we fine-tune several transformer-based models such as mBart50, Google mT5, GPT4.1-nano and evaluate their sentence-to-gloss translation performance using BLEU scores, based on these evaluation metrics we compare the model's gloss-translation consistency across our dataset and the RWTH-PHOENIX-2014T benchmark.

</details>


### [26] [Investigating CoT Monitorability in Large Reasoning Models](https://arxiv.org/abs/2511.08525)
*Shu Yang,Junchao Wu,Xilin Gou,Xuansheng Wu,Derek Wong,Ninhao Liu,Di Wang*

Main category: cs.CL

TL;DR: 本文系统研究了通过思维链（CoT）分析进行大型推理模型（LRMs）监控的挑战与潜力，提出了两个核心视角：LRMs在CoT中真实表达决策因素的程度，以及基于CoT的监控器的可靠性。


<details>
  <summary>Details</summary>
Motivation: 由于LRMs在复杂任务中的表现，其详细的推理过程为AI安全性提供了新的监控机会，但存在模型在CoT中不忠实表达决策过程和监控器敏感度问题两大挑战。

Method: 研究围绕两个中心视角展开：(i) 表达性：LRMs在CoT中真实表达决策因素的程度；(ii) 监控可靠性：基于CoT的监控器在检测不当行为方面的可靠性。通过数学、科学和伦理领域的实证证据和相关性分析，并进一步研究不同的CoT干预方法对监控效果的影响。

Result: 提出了MoME新范式，LRMs通过CoT监控其他模型的不当行为，并提供结构化判断和支持证据。

Conclusion: 该研究为通过CoT分析提高LRMs安全性提供了系统性见解和新方法，强调了表达性和监控可靠性在AI安全性中的重要性。

Abstract: Large Reasoning Models (LRMs) have demonstrated remarkable performance on complex tasks by engaging in extended reasoning before producing final answers. Beyond improving abilities, these detailed reasoning traces also create a new opportunity for AI safety, CoT Monitorability: monitoring potential model misbehavior, such as the use of shortcuts or sycophancy, through their chain-of-thought (CoT) during decision-making. However, two key fundamental challenges arise when attempting to build more effective monitors through CoT analysis. First, as prior research on CoT faithfulness has pointed out, models do not always truthfully represent their internal decision-making in the generated reasoning. Second, monitors themselves may be either overly sensitive or insufficiently sensitive, and can potentially be deceived by models' long, elaborate reasoning traces. In this paper, we present the first systematic investigation of the challenges and potential of CoT monitorability. Motivated by two fundamental challenges we mentioned before, we structure our study around two central perspectives: (i) verbalization: to what extent do LRMs faithfully verbalize the true factors guiding their decisions in the CoT, and (ii) monitor reliability: to what extent can misbehavior be reliably detected by a CoT-based monitor? Specifically, we provide empirical evidence and correlation analyses between verbalization quality, monitor reliability, and LLM performance across mathematical, scientific, and ethical domains. Then we further investigate how different CoT intervention methods, designed to improve reasoning efficiency or performance, will affect monitoring effectiveness. Finally, we propose MoME, a new paradigm in which LLMs monitor other models' misbehavior through their CoT and provide structured judgments along with supporting evidence.

</details>


### [27] [From Semantic Roles to Opinion Roles: SRL Data Extraction for Multi-Task and Transfer Learning in Low-Resource ORL](https://arxiv.org/abs/2511.08537)
*Amirmohammad Omidi Galdiani,Sepehr Rezaei Melal,Mohammad Norasteh,Arash Yousefi Jordehi,Seyed Abolghasem Mirroshandel*

Main category: cs.CL

TL;DR: 本文提出了一种从Ontonotes 5.0语料库的华尔街日报(WSJ)部分构建高质量语义角色标注(SRL)数据集，并使其适用于观点角色标注(ORL)任务的方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决在低资源观点挖掘场景下，如何有效利用SRL来增强ORL的问题，作者提出了一种可复现的提取流程。

Method: 利用PropBank标注框架，实现了将谓词-论元结构与表面文本对齐的可复现提取流程，将句法树指针转换为连贯的跨度，并应用严格的清洗步骤以确保语义保真度。

Result: 构建了一个包含97,169个谓词-论元实例的数据集，这些实例具有明确定义的Agent (ARG0)、Predicate (REL)和Patient (ARG1)角色，并映射到ORL的Holder, Expression, 和Target模式。

Conclusion: 本文的工作为研究人员提供了一个可重用的资源，旨在利用SRL来增强ORL，尤其是在低资源观点挖掘场景下。

Abstract: This report presents a detailed methodology for constructing a high-quality Semantic Role Labeling (SRL) dataset from the Wall Street Journal (WSJ) portion of the OntoNotes 5.0 corpus and adapting it for Opinion Role Labeling (ORL) tasks. Leveraging the PropBank annotation framework, we implement a reproducible extraction pipeline that aligns predicate-argument structures with surface text, converts syntactic tree pointers to coherent spans, and applies rigorous cleaning to ensure semantic fidelity. The resulting dataset comprises 97,169 predicate-argument instances with clearly defined Agent (ARG0), Predicate (REL), and Patient (ARG1) roles, mapped to ORL's Holder, Expression, and Target schema. We provide a detailed account of our extraction algorithms, discontinuous argument handling, annotation corrections, and statistical analysis of the resulting dataset. This work offers a reusable resource for researchers aiming to leverage SRL for enhancing ORL, especially in low-resource opinion mining scenarios.

</details>


### [28] [Moral Susceptibility and Robustness under Persona Role-Play in Large Language Models](https://arxiv.org/abs/2511.08565)
*Davi Bastos Costa,Felippe Alves,Renato Vicente*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLMs）在社交情境中表达和转变道德判断的方式，通过引入道德基础问卷（MFQ）来量化模型在角色扮演时的道德易感性和道德鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在社交情境中的应用增多，理解它们如何表达和转变道德判断变得重要。

Method: 使用道德基础问卷（MFQ）来测量不同角色下模型的道德易感性和道德鲁棒性，并进行基准测试。

Result: 发现模型家族对道德鲁棒性影响最大，Claude家族最为鲁棒；道德易感性则有明显的家族内大小效应，规模更大的模型更易受影响。鲁棒性和易感性呈正相关，且在家族层面更明显。

Conclusion: 角色扮演对大型语言模型的道德行为有系统性影响，不同模型家族和规模在道德响应上表现出不同的特性。

Abstract: Large language models (LLMs) increasingly operate in social contexts, motivating analysis of how they express and shift moral judgments. In this work, we investigate the moral response of LLMs to persona role-play, prompting a LLM to assume a specific character. Using the Moral Foundations Questionnaire (MFQ), we introduce a benchmark that quantifies two properties: moral susceptibility and moral robustness, defined from the variability of MFQ scores across and within personas, respectively. We find that, for moral robustness, model family accounts for most of the variance, while model size shows no systematic effect. The Claude family is, by a significant margin, the most robust, followed by Gemini and GPT-4 models, with other families exhibiting lower robustness. In contrast, moral susceptibility exhibits a mild family effect but a clear within-family size effect, with larger variants being more susceptible. Moreover, robustness and susceptibility are positively correlated, an association that is more pronounced at the family level. Additionally, we present moral foundation profiles for models without persona role-play and for personas averaged across models. Together, these analyses provide a systematic view of how persona conditioning shapes moral behavior in large language models.

</details>


### [29] [Think-at-Hard: Selective Latent Iterations to Improve Reasoning Language Models](https://arxiv.org/abs/2511.08577)
*Tianyu Fu,Yichen You,Zekai Chen,Guohao Dai,Huazhong Yang,Yu Wang*

Main category: cs.CL

TL;DR: 提出了一种动态潜在思维方法 TaH，通过只在困难标记上迭代来提升大型语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 在参数约束下提升大型语言模型的推理能力，并解决过度思考现象。

Method: TaH 方法通过轻量级神经决策器在困难标记上触发潜在迭代，并使用 LoRA 模块和 duo-causal 注意力机制。

Result: TaH 在五个挑战性基准上提高了 LLM 的推理性能，与迭代两次的基线相比，准确率提高了 8.1-11.3%。

Conclusion: TaH 方法在保持参数数量不变的情况下，显著提升了模型的推理性能。

Abstract: Improving reasoning capabilities of Large Language Models (LLMs), especially under parameter constraints, is crucial for real-world applications. Prior work proposes recurrent transformers, which allocate a fixed number of extra iterations per token to improve generation quality. After the first, standard forward pass, instead of verbalization, last-layer hidden states are fed back as inputs for additional iterations to refine token predictions. Yet we identify a latent overthinking phenomenon: easy token predictions that are already correct after the first pass are sometimes revised into errors in additional iterations. To address this, we propose Think-at-Hard (TaH), a dynamic latent thinking method that iterates deeper only at hard tokens. It employs a lightweight neural decider to trigger latent iterations only at tokens that are likely incorrect after the standard forward pass. During latent iterations, Low-Rank Adaptation (LoRA) modules shift the LLM objective from general next-token prediction to focused hard-token refinement. We further introduce a duo-causal attention mechanism that extends attention from the token sequence dimension to an additional iteration depth dimension. This enables cross-iteration information flow while maintaining full sequential parallelism. Experiments show that TaH boosts LLM reasoning performance across five challenging benchmarks while maintaining the same parameter count. Compared with baselines that iterate twice for all output tokens, TaH delivers 8.1-11.3% accuracy gains while exempting 94% of tokens from the second iteration. Against strong single-iteration Qwen3 models finetuned with the same data, it also delivers 4.0-5.0% accuracy gains. When allowing less than 3% additional parameters from LoRA and the iteration decider, the gains increase to 8.5-12.6% and 5.3-5.4%, respectively. Our code is available at https://github.com/thu-nics/TaH.

</details>


### [30] [Training Language Models to Explain Their Own Computations](https://arxiv.org/abs/2511.08579)
*Belinda Z. Li,Zifan Carl Guo,Vincent Huang,Jacob Steinhardt,Jacob Andreas*

Main category: cs.CL

TL;DR: 语言模型可以通过微调学习解释自己的内部计算过程，且自身解释效果优于其他模型。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型是否能够利用其对自身内部机制的优先访问，生成解释其行为的新技术。

Method: 使用现有的可解释性技术作为真实依据，微调语言模型以生成三类自然语言描述：1) 模型特征编码的信息，2) 模型内部激活的因果结构，3) 特定输入标记对模型输出的影响。

Result: 经过数万条示例解释的训练后，解释模型在新查询上表现出非平凡的泛化能力，且使用模型解释自身计算的效果优于使用其他模型。

Conclusion: 语言模型能够学习可靠地解释其内部计算，这种解释为现有的可解释性方法提供了可扩展的补充。

Abstract: Can language models (LMs) learn to faithfully describe their internal computations? Are they better able to describe themselves than other models? We study the extent to which LMs' privileged access to their own internals can be leveraged to produce new techniques for explaining their behavior. Using existing interpretability techniques as a source of ground truth, we fine-tune LMs to generate natural language descriptions of (1) the information encoded by LM features, (2) the causal structure of LMs' internal activations, and (3) the influence of specific input tokens on LM outputs. When trained with only tens of thousands of example explanations, explainer models exhibit non-trivial generalization to new queries. This generalization appears partly attributable to explainer models' privileged access to their own internals: using a model to explain its own computations generally works better than using a *different* model to explain its computations (even if the other model is significantly more capable). Our results suggest not only that LMs can learn to reliably explain their internal computations, but that such explanations offer a scalable complement to existing interpretability methods.

</details>


### [31] [A Preliminary Study of RAG for Taiwanese Historical Archives](https://arxiv.org/abs/2511.07445)
*Claire Lin,Bo-Han Feng,Xuanjun Chen,Te-Lun Yang,Hung-yi Lee,Jyh-Shing Roger Jang*

Main category: cs.CL

TL;DR: 该论文研究了检索增强生成（RAG）在台湾历史档案中的应用，探讨了查询特征和元数据整合策略对系统性能的影响。


<details>
  <summary>Details</summary>
Motivation: 探索RAG在特定领域（台湾历史档案）的应用效果，填补相关研究的空白。

Method: 在两个历史繁体中文数据集（Fort Zeelandia和Taiwan Provincial Council Gazette）上应用RAG流程，并系统研究查询特征和元数据整合策略。

Result: 早期元数据整合提高了检索和答案准确性，同时揭示RAG系统存在幻觉问题和处理时间或多跳历史查询的困难。

Conclusion: 早期元数据整合有益于RAG系统性能，但在生成和处理复杂历史查询方面仍面临挑战。

Abstract: Retrieval-Augmented Generation (RAG) has emerged as a promising approach for knowledge-intensive tasks. However, few studies have examined RAG for Taiwanese Historical Archives. In this paper, we present an initial study of a RAG pipeline applied to two historical Traditional Chinese datasets, Fort Zeelandia and the Taiwan Provincial Council Gazette, along with their corresponding open-ended query sets. We systematically investigate the effects of query characteristics and metadata integration strategies on retrieval quality, answer generation, and the performance of the overall system. The results show that early-stage metadata integration enhances both retrieval and answer accuracy while also revealing persistent challenges for RAG systems, including hallucinations during generation and difficulties in handling temporal or multi-hop historical queries.

</details>


### [32] [GRIP: In-Parameter Graph Reasoning through Fine-Tuning Large Language Models](https://arxiv.org/abs/2511.07457)
*Jiarui Feng,Donghong Cai,Yixin Chen,Muhan Zhang*

Main category: cs.CL

TL;DR: GRIP是一种新颖的框架，通过精心设计的微调任务，使大型语言模型（LLMs）能够从图中内化复杂的关系信息，并将这些知识存储在轻量级LoRA参数中，从而在推理时无需访问原始图即可执行多种图相关任务。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在建模序列文本数据方面表现出色，但在处理知识图谱或网页数据等结构化数据时仍面临挑战。现有方法要么将图转换为文本序列导致显著的计算开销，要么引入额外模块进行图编码但效果不佳。

Method: GRIP通过精心设计的微调任务，利用in-parameter知识注入技术，将图中的复杂关系信息内化到LLMs中，并将这些信息存储在轻量级LoRA参数中。

Result: 大量实验验证了GRIP在多个基准上的有效性和高效性，表明其能够在无需访问原始图的情况下，执行多种图相关任务。

Conclusion: GRIP框架成功地将LLMs适配到结构化数据上，提供了一种高效且有效的解决方案，能够在推理时避免访问原始图，从而提升模型的实际应用价值。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in modeling sequential textual data and generalizing across diverse tasks. However, adapting LLMs to effectively handle structural data, such as knowledge graphs or web data, remains a challenging problem. Some approaches adopt complex strategies to convert graphs into text sequences, resulting in significant token overhead and rendering them impractical for large-scale graphs. Others introduce additional modules to encode graphs into fixed-size token representations for LLMs. However, these methods typically require large-scale post-training on graph-text corpus and complex alignment procedures, yet often yield sub-optimal results due to poor modality alignment. Inspired by in-parameter knowledge injection for test-time adaptation of LLMs, we propose GRIP, a novel framework that equips LLMs with the ability to internalize complex relational information from graphs through carefully designed fine-tuning tasks. This knowledge is efficiently stored within lightweight LoRA parameters, enabling the fine-tuned LLM to perform a wide range of graph-related tasks without requiring access to the original graph at inference time. Extensive experiments across multiple benchmarks validate the effectiveness and efficiency of our approach.

</details>


### [33] [REFLEX: Reference-Free Evaluation of Log Summarization via Large Language Model Judgment](https://arxiv.org/abs/2511.07458)
*Priyanka Mudgal*

Main category: cs.CL

TL;DR: 引入REFLEX，一种基于大语言模型（LLM）的无参考日志摘要评价指标，通过多维度评估摘要质量。


<details>
  <summary>Details</summary>
Motivation: 日志摘要系统评估缺乏高质量参考摘要，且现有指标（如ROUGE和BLEU）存在局限性，依赖表面词汇重叠。

Method: 利用大语言模型作为零样本评估器，评估摘要的相关性、信息量和一致性，无需参考摘要或人工标注。

Result: REFLEX在多个日志摘要数据集上生成稳定、可解释且细粒度的评估，比传统指标更有效区分模型输出。

Conclusion: REFLEX为参考数据稀缺或不可用的现实场景提供了可扩展的日志摘要评估替代方案。

Abstract: Evaluating log summarization systems is challenging due to the lack of high-quality reference summaries and the limitations of existing metrics like ROUGE and BLEU, which depend on surface-level lexical overlap. We introduce REFLEX, a reference-free evaluation metric for log summarization based on large language model (LLM) judgment. REFLEX uses LLMs as zero-shot evaluators to assess summary quality along dimensions such as relevance, informativeness, and coherence, without requiring gold-standard references or human annotations. We show that REFLEX produces stable, interpretable, and fine-grained evaluations across multiple log summarization dataset, and more effectively distinguishes model outputs than traditional metrics. REFLEX provides a scalable alternative for evaluating log summaries in real-world settings where reference data is scarce or unavailable.

</details>


### [34] [It Takes Two: A Dual Stage Approach for Terminology-Aware Translation](https://arxiv.org/abs/2511.07461)
*Akshat Singh Jaswal*

Main category: cs.CL

TL;DR: DuTerm是一种新的两阶段术语约束机器翻译架构，结合术语感知的神经机器翻译模型和基于提示的大语言模型进行后编辑。


<details>
  <summary>Details</summary>
Motivation: 解决现有机器翻译在术语一致性和翻译质量之间的平衡问题，尤其是在需要灵活术语处理的情况下。

Method: 采用两阶段方法：首先使用术语感知的NMT模型进行初步翻译，然后通过基于提示的LLM进行后编辑和术语校正。

Result: 在WMT 2025术语共享任务数据集上，DuTerm在英到德、英到西、英到俄翻译任务中表现优于严格约束的翻译方法。

Conclusion: LLM在高质量翻译中最适合作为上下文驱动的修改者，而非生成者，强调了灵活术语处理的重要性。

Abstract: This paper introduces DuTerm, a novel two-stage architecture for terminology-constrained machine translation. Our system combines a terminology-aware NMT model, adapted via fine-tuning on large-scale synthetic data, with a prompt-based LLM for post-editing. The LLM stage refines NMT output and enforces terminology adherence. We evaluate DuTerm on English-to German, English-to-Spanish, and English-to-Russian with the WMT 2025 Terminology Shared Task corpus. We demonstrate that flexible, context-driven terminology handling by the LLM consistently yields higher quality translations than strict constraint enforcement. Our results highlight a critical trade-off, revealing that an LLM's work best for high-quality translation as context-driven mutators rather than generators.

</details>


### [35] [Motif 2 12.7B technical report](https://arxiv.org/abs/2511.07464)
*Junghwan Lim,Sungmin Lee,Dongseok Kim,Taehyun Kim,Eunhwan Park,Jeesoo Lee,Jeongdoo Lee,Junhyeok Lee,Wai Ting Cheung,Dahye Choi,Jaeheui Her,Jaeyeon Huh,Hanbin Jung,Changjin Kang,Beomgyu Kim,Minjae Kim,Taewhan Kim,Youngrok Kim,Hyukjin Kweon,Haesol Lee,Kungyu Lee,Dongpin Oh,Yeongjae Park,Bokki Ryu,Dongjoo Weon*

Main category: cs.CL

TL;DR: Motif-2-12.7B是一个结合架构创新和系统级优化的新型开放权重基础模型，旨在通过分组差分注意力(GDA)等方法，在受限计算预算下实现高效的大规模语言模型性能。


<details>
  <summary>Details</summary>
Motivation: 设计目标是在计算资源受限的条件下，实现可扩展的语言理解和稳健的指令泛化能力，通过改进注意力机制提高模型表示效率。

Method: 模型基于Motif-2.6B，集成分组差分注意力(GDA)，在5.5万亿词元上进行预训练，采用课程驱动的数据调度器。训练系统使用MuonClip优化器和自定义高性能内核，包括融合PolyNorm激活和并行Muon算法。后训练采用三阶段监督微调流程。

Result: 在多样化基准测试中表现出色，证明其架构扩展和优化训练设计能够与更大模型相媲美。

Conclusion: Motif-2-12.7B通过架构创新和训练优化，在计算效率方面取得突破，为大规模语言模型的发展提供了新方向。

Abstract: We introduce Motif-2-12.7B, a new open-weight foundation model that pushes the efficiency frontier of large language models by combining architectural innovation with system-level optimization. Designed for scalable language understanding and robust instruction generalization under constrained compute budgets, Motif-2-12.7B builds upon Motif-2.6B with the integration of Grouped Differential Attention (GDA), which improves representational efficiency by disentangling signal and noise-control attention pathways. The model is pre-trained on 5.5 trillion tokens spanning diverse linguistic, mathematical, scientific, and programming domains using a curriculum-driven data scheduler that gradually changes the data composition ratio. The training system leverages the MuonClip optimizer alongside custom high-performance kernels, including fused PolyNorm activations and the Parallel Muon algorithm, yielding significant throughput and memory efficiency gains in large-scale distributed environments. Post-training employs a three-stage supervised fine-tuning pipeline that successively enhances general instruction adherence, compositional understanding, and linguistic precision. Motif-2-12.7B demonstrates competitive performance across diverse benchmarks, showing that thoughtful architectural scaling and optimized training design can rival the capabilities of much larger models.

</details>


### [36] [Focusing on Language: Revealing and Exploiting Language Attention Heads in Multilingual Large Language Models](https://arxiv.org/abs/2511.07498)
*Xin Liu,Qiyang Song,Qihang Zhou,Haichao Du,Shaowen Xu,Wenbo Jiang,Weijuan Zhang,Xiaoqi Jia*

Main category: cs.CL

TL;DR: 该论文研究了多语言处理中多头部自注意力（MHA）的作用，提出了一种新方法LAHIS来评估注意力头的重要性，并揭示了语言特定和语言通用注意力头的存在。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）支持多语言理解与生成，但MHA在多语言能力中的角色尚未充分探索。该研究旨在揭示MHA在多语言处理中的贡献，以提升LLM的多语言性能。

Method: 提出LAHIS方法，通过单次前向和后向传递识别多语言能力中的注意力头重要性，并引入轻量级适配方法，通过软头掩码调节注意力输出。

Result: 应用LAHIS于Aya-23-8B、Llama-3.2-3B和Mistral-7B-v0.1，发现语言特定和语言通用注意力头的存在。语言特定头有助于跨语言注意力转移，减轻非目标语言生成问题。

Conclusion: 该研究通过MHA的视角，提高了LLM的可解释性和多语言能力，为改进多语言LLM提供了新思路。

Abstract: Large language models (LLMs) increasingly support multilingual understanding and generation. Meanwhile, efforts to interpret their internal mechanisms have emerged, offering insights to enhance multilingual performance. While multi-head self-attention (MHA) has proven critical in many areas, its role in multilingual capabilities remains underexplored. In this work, we study the contribution of MHA in supporting multilingual processing in LLMs. We propose Language Attention Head Importance Scores (LAHIS), an effective and efficient method that identifies attention head importance for multilingual capabilities via a single forward and backward pass through the LLM. Applying LAHIS to Aya-23-8B, Llama-3.2-3B, and Mistral-7B-v0.1, we reveal the existence of both language-specific and language-general heads. Language-specific heads enable cross-lingual attention transfer to guide the model toward target language contexts and mitigate off-target language generation issue, contributing to addressing challenges in multilingual LLMs. We also introduce a lightweight adaptation that learns a soft head mask to modulate attention outputs over language heads, requiring only 20 tunable parameters to improve XQuAD accuracy. Overall, our work enhances both the interpretability and multilingual capabilities of LLMs from the perspective of MHA.

</details>


### [37] [Revisiting NLI: Towards Cost-Effective and Human-Aligned Metrics for Evaluating LLMs in Question Answering](https://arxiv.org/abs/2511.07659)
*Sai Shridhar Balamurali,Lu Cheng*

Main category: cs.CL

TL;DR: 该论文提出使用简单的NLI评分和词汇匹配标记作为轻量级替代方案来评估大型语言模型的答案，其准确率与GPT-4o相当，但参数少得多。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型的答案具有挑战性，词汇指标无法捕捉语义细微差别，而“LLM-as-Judge”评分计算开销大。

Method: 重新评估一种简单的替代方案——现成的自然语言推理（NLI）评分，并结合简单的词汇匹配标记。并引入了一个新的3000样本的人类标注基准DIVER-QA，以严格测试这些指标的人类对齐程度。

Result: 该技术在长问答（QA）中与GPT-4o的准确率（89.9%）相匹配，但所需的参数少几个数量级。

Conclusion: 廉价的基于NLI的评估仍然具有竞争力，并且DIVER-QA可以作为未来指标研究的开放资源。

Abstract: Evaluating answers from state-of-the-art large language models (LLMs) is challenging: lexical metrics miss semantic nuances, whereas "LLM-as-Judge" scoring is computationally expensive. We re-evaluate a lightweight alternative -- off-the-shelf Natural Language Inference (NLI) scoring augmented by a simple lexical-match flag and find that this decades-old technique matches GPT-4o's accuracy (89.9%) on long-form QA, while requiring orders-of-magnitude fewer parameters. To test human alignment of these metrics rigorously, we introduce DIVER-QA, a new 3000-sample human-annotated benchmark spanning five QA datasets and five candidate LLMs. Our results highlight that inexpensive NLI-based evaluation remains competitive and offer DIVER-QA as an open resource for future metric research.

</details>


### [38] [Stress Testing Factual Consistency Metrics for Long-Document Summarization](https://arxiv.org/abs/2511.07689)
*Zain Muhammad Mujahid,Dustin Wright,Isabelle Augenstein*

Main category: cs.CL

TL;DR: 这篇论文评估了六种常用的无参考事实性指标在长文档摘要中的可靠性，发现这些指标在语义等价的摘要上评分不一致，且在信息内容密集的声明上可靠性下降。


<details>
  <summary>Details</summary>
Motivation: 长文档摘要的事实一致性评估是一个重要挑战，传统指标在处理长文档时存在局限性，因此需要系统评估现有指标在长文档环境下的可靠性。

Method: 通过应用七种保持事实性的扰动（如释义、简化、同义词替换等）来评估六种无参考事实性指标的鲁棒性，并在三个长文档基准数据集上进行分析。

Result: 现有短文档指标在长文档摘要上表现不一致，信息内容密集的声明上可靠性下降，扩展检索上下文在某些领域提高稳定性，但无指标在长上下文条件下始终保持事实一致性。

Conclusion: 现有事实性指标在长文档摘要中表现不佳，提出了改进事实性评估的具体方向，包括多跨度推理、上下文感知校准和基于意义保持变体的训练。

Abstract: Evaluating the factual consistency of abstractive text summarization remains a significant challenge, particularly for long documents, where conventional metrics struggle with input length limitations and long-range dependencies. In this work, we systematically evaluate the reliability of six widely used reference-free factuality metrics, originally proposed for short-form summarization, in the long-document setting. We probe metric robustness through seven factuality-preserving perturbations applied to summaries, namely paraphrasing, simplification, synonym replacement, logically equivalent negations, vocabulary reduction, compression, and source text insertion, and further analyze their sensitivity to retrieval context and claim information density. Across three long-form benchmark datasets spanning science fiction, legal, and scientific domains, our results reveal that existing short-form metrics produce inconsistent scores for semantically equivalent summaries and exhibit declining reliability for information-dense claims whose content is semantically similar to many parts of the source document. While expanding the retrieval context improves stability in some domains, no metric consistently maintains factual alignment under long-context conditions. Finally, our results highlight concrete directions for improving factuality evaluation, including multi-span reasoning, context-aware calibration, and training on meaning-preserving variations to enhance robustness in long-form summarization. We release all code, perturbed data, and scripts required to reproduce our results at https://github.com/zainmujahid/metricEval-longSum.

</details>


### [39] [CAPO: Confidence Aware Preference Optimization Learning for Multilingual Preferences](https://arxiv.org/abs/2511.07691)
*Rhitabrat Pokharel,Yufei Tao,Ameeta Agrawal*

Main category: cs.CL

TL;DR: 提出了一种新的偏好优化方法CAPO，通过动态损失缩放机制提高多语言环境下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: DPO等偏好优化方法在多语言环境下泛化能力较差，存在噪声或低边际比较问题。

Method: 提出CAPO，基于相对奖励的动态损失缩放机制替代DPO的固定处理方式。

Result: CAPO在奖励准确率上至少优于现有基线16%，并显著提升跨语言对齐效果。

Conclusion: 动态调整学习信号置信度能增强多语言偏好优化的鲁棒性，CAPO是一种简单而有效的替代方案。

Abstract: Preference optimization is a critical post-training technique used to align large language models (LLMs) with human preferences, typically by fine-tuning on ranked response pairs. While methods like Direct Preference Optimization (DPO) have proven effective in English, they often fail to generalize robustly to multilingual settings. We propose a simple yet effective alternative, Confidence-Aware Preference Optimization (CAPO), which replaces DPO's fixed treatment of preference pairs with a dynamic loss scaling mechanism based on a relative reward. By modulating the learning signal according to the confidence in each preference pair, CAPO enhances robustness to noisy or low-margin comparisons, typically encountered in multilingual text. Empirically, CAPO outperforms existing preference optimization baselines by at least 16% in reward accuracy, and improves alignment by widening the gap between preferred and dispreferred responses across languages.

</details>


### [40] [NOTAM-Evolve: A Knowledge-Guided Self-Evolving Optimization Framework with LLMs for NOTAM Interpretation](https://arxiv.org/abs/2511.07982)
*Maoqi Liu,Quan Fang,Yuhao Wu,Can Zhao,Yang Yang,Kaiquan Cai*

Main category: cs.CL

TL;DR: NOTAM-Evolve是一个自我进化的框架，通过知识图谱增强检索模块和闭环学习过程，提升大型语言模型对航空通告的解析能力。


<details>
  <summary>Details</summary>
Motivation: 准确解读航空通告对航空安全至关重要，但现有自动化系统仅限于浅层解析，难以提取可操作信息。

Method: 提出了一种名为NOTAM-Evolve的框架，利用知识图谱增强的数据检索和闭环学习过程，实现动态知识基础和基于模式的推理。

Result: 实验表明，NOTAM-Evolve在结构化航空通告解析任务上，比基础大型语言模型提升了30.4%的绝对准确率。

Conclusion: NOTAM-Evolve在航空通告的深度解析任务中设立了新的技术标准，大幅提升了自动化系统的表现。

Abstract: Accurate interpretation of Notices to Airmen (NOTAMs) is critical for aviation safety, yet their condensed and cryptic language poses significant challenges to both manual and automated processing. Existing automated systems are typically limited to shallow parsing, failing to extract the actionable intelligence needed for operational decisions. We formalize the complete interpretation task as deep parsing, a dual-reasoning challenge requiring both dynamic knowledge grounding (linking the NOTAM to evolving real-world aeronautical data) and schema-based inference (applying static domain rules to deduce operational status). To tackle this challenge, we propose NOTAM-Evolve, a self-evolving framework that enables a large language model (LLM) to autonomously master complex NOTAM interpretation. Leveraging a knowledge graph-enhanced retrieval module for data grounding, the framework introduces a closed-loop learning process where the LLM progressively improves from its own outputs, minimizing the need for extensive human-annotated reasoning traces. In conjunction with this framework, we introduce a new benchmark dataset of 10,000 expert-annotated NOTAMs. Our experiments demonstrate that NOTAM-Evolve achieves a 30.4% absolute accuracy improvement over the base LLM, establishing a new state of the art on the task of structured NOTAM interpretation.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [41] [Beyond Correctness: Confidence-Aware Reward Modeling for Enhancing Large Language Model Reasoning](https://arxiv.org/abs/2511.07483)
*Qianxi He,Qingyu Ren,Shanzhe Lei,Xuhong Wang,Yingchun Wang*

Main category: cs.AI

TL;DR: 本文提出了一种新的基于置信度的奖励模型，用于增强STEM推理能力，通过惩罚错误答案和低置信度的正确回答，促进更稳健和逻辑一致的推理。


<details>
  <summary>Details</summary>
Motivation: 传统规则奖励的强化学习在基础模型较小时，常常导致低质量的推理链或推理过程与最终答案不一致，限制了资源有限组织在小规模模型上进行直接强化学习训练的能力。

Method: 提出了一种基于置信度的奖励模型，该模型不仅惩罚错误答案，还惩罚低置信度的正确回答，通过静态评估、Best-of-N推理测试和PPO-based RL训练验证方法的有效性。

Result: 该方法在多个STEM基准测试中优于几种最先进的开源奖励模型。

Conclusion: 置信度奖励模型能有效提升STEM推理能力，代码和模型已在https://github.com/qianxiHe147/C2RM上发布。

Abstract: Recent advancements in large language models (LLMs) have shifted the post-training paradigm from traditional instruction tuning and human preference alignment toward reinforcement learning (RL) focused on reasoning capabilities. However, numerous technical reports indicate that purely rule-based reward RL frequently results in poor-quality reasoning chains or inconsistencies between reasoning processes and final answers, particularly when the base model is of smaller scale. During the RL exploration process, models might employ low-quality reasoning chains due to the lack of knowledge, occasionally producing correct answers randomly and receiving rewards based on established rule-based judges. This constrains the potential for resource-limited organizations to conduct direct reinforcement learning training on smaller-scale models. We propose a novel confidence-based reward model tailored for enhancing STEM reasoning capabilities. Unlike conventional approaches, our model penalizes not only incorrect answers but also low-confidence correct responses, thereby promoting more robust and logically consistent reasoning. We validate the effectiveness of our approach through static evaluations, Best-of-N inference tests, and PPO-based RL training. Our method outperforms several state-of-the-art open-source reward models across diverse STEM benchmarks. We release our codes and model in https://github.com/qianxiHe147/C2RM.

</details>


### [42] [Beyond Fact Retrieval: Episodic Memory for RAG with Generative Semantic Workspaces](https://arxiv.org/abs/2511.07587)
*Shreyas Rajesh,Pavan Holur,Chenda Duan,David Chong,Vwani Roychowdhury*

Main category: cs.AI

TL;DR: 提出了一种新的神经启发式生成记忆框架GSW，以解决大型语言模型在长上下文推理中的挑战。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在处理超过其上下文窗口的文档时面临挑战，且在较短文本上的性能也随着序列长度的增加而下降，因此需要外部记忆框架的增强。现有解决方案主要适用于事实检索，但缺乏构建时空锚定叙事表示的能力。

Method: 提出了一种名为Generative Semantic Workspace (GSW)的框架，包含一个Operator和一个Reconciler。Operator将输入观察映射到中间语义结构，Reconciler将其整合到持久工作空间中，以保持时间、空间和逻辑的一致性。

Result: 在Episodic Memory Benchmark (EpBench)上，GSW的性能比现有的RAG基线高出20%，并且查询时上下文标记减少了51%，显著降低了推理时间成本。

Conclusion: GSW为大型语言模型提供了一种人类式的情景记忆方案，使其能够在长时间跨度内进行推理，为更强大的智能体铺平了道路。

Abstract: Large Language Models (LLMs) face fundamental challenges in long-context reasoning: many documents exceed their finite context windows, while performance on texts that do fit degrades with sequence length, necessitating their augmentation with external memory frameworks. Current solutions, which have evolved from retrieval using semantic embeddings to more sophisticated structured knowledge graphs representations for improved sense-making and associativity, are tailored for fact-based retrieval and fail to build the space-time-anchored narrative representations required for tracking entities through episodic events. To bridge this gap, we propose the \textbf{Generative Semantic Workspace} (GSW), a neuro-inspired generative memory framework that builds structured, interpretable representations of evolving situations, enabling LLMs to reason over evolving roles, actions, and spatiotemporal contexts. Our framework comprises an \textit{Operator}, which maps incoming observations to intermediate semantic structures, and a \textit{Reconciler}, which integrates these into a persistent workspace that enforces temporal, spatial, and logical coherence. On the Episodic Memory Benchmark (EpBench) \cite{huet_episodic_2025} comprising corpora ranging from 100k to 1M tokens in length, GSW outperforms existing RAG based baselines by up to \textbf{20\%}. Furthermore, GSW is highly efficient, reducing query-time context tokens by \textbf{51\%} compared to the next most token-efficient baseline, reducing inference time costs considerably. More broadly, GSW offers a concrete blueprint for endowing LLMs with human-like episodic memory, paving the way for more capable agents that can reason over long horizons.

</details>


### [43] [Alignment-Aware Quantization for LLM Safety](https://arxiv.org/abs/2511.07842)
*Sunghyun Wee,Suyoung Kim,Hyeonjin Kim,Kyomin Hwang,Nojun Kwak*

Main category: cs.AI

TL;DR: 提出了一种新的量化方法AAQ，通过引入APC损失函数，在保持模型效率的同时不牺牲安全性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在部署时需要兼顾安全和效率，但传统的量化方法往往只关注效率，忽视了安全性，导致安全策略的失准。

Method: 提出Alignment-Aware Quantization (AAQ)，将Alignment-Preserving Contrastive (APC) 损失集成到PTQ流程中，使量化后的模型在保持安全对齐的同时不依赖特定的安全校准数据集。

Result: AAQ能够在不牺牲安全性的前提下实现高效的4-bit量化，适用于LLaMA、Qwen和Mistral等多种模型家族，解决了安全与效率之间的关键权衡问题。

Conclusion: AAQ方法为大型语言模型提供了一种在保持高效的同时确保安全性的新途径，为构建高效且可信赖的LLMs奠定了基础。

Abstract: Safety and efficiency are both important factors when deploying large language models(LLMs). LLMs are trained to follow human alignment for safety, and post training quantization(PTQ) is applied afterward for efficiency. However, these two objectives are often in conflict, revealing a fundamental flaw in the conventional PTQ paradigm: quantization can turn into a safety vulnerability if it only aims to achieve low perplexity. Models can demonstrate low perplexity yet exhibit significant degradation in alignment with the safety policy, highlighting that perplexity alone is an insufficient and often misleading proxy for model safety. To address this, we propose Alignment-Aware Quantization(AAQ), a novel approach that integrates Alignment-Preserving Contrastive(APC) loss into the PTQ pipeline. Compared to simple reconstruction loss, ours explicitly preserves alignment by encouraging the quantized model to mimic its safe, instruction-tuned model while diverging from the unaligned, pre-trained counterpart. Our method achieves this robust safety alignment without resorting to specialized safety-focused calibration datasets, highlighting its practical utility and broad applicability. AAQ is compatible with standard PTQ techniques and enables robust 4-bit (W4A4) quantization across diverse model families such as LLaMA, Qwen, and Mistral while maintaining safety where previous methods fail. Our work resolves the critical trade-off between efficiency and safety, paving the way toward LLMs that are both efficient and trustworthy. Anonymized code is available in the supplementary material.

</details>


### [44] [Toward Robust EEG-based Intention Decoding during Misarticulated Speech in Aphasia](https://arxiv.org/abs/2511.07895)
*Ha-Na Jo,Jung-Sun Lee,Eunyeong Ko*

Main category: cs.AI

TL;DR: 开发了一种基于EEG的软性多任务学习框架，用于解码失语症患者的语言意图，即使在发音错误的情况下也能有效工作。


<details>
  <summary>Details</summary>
Motivation: 由于脑机接口技术在针对失语症患者的支持系统方面关注度较低，因此需要开发专门的EEG通信支持系统以帮助这些患者。

Method: 通过对一位表达性失语症参与者进行韩语自动言语任务，记录EEG信号，并根据言语是否成功标记为正确或错误。利用软多任务学习框架与最大均值差异正则化，专注于delta波特征，优化类别判别并调整正确和错误发音试验的EEG特征分布。

Result: 所提出的模型在正确试验中准确率达到58.6%，在错误发音试验中达到45.5%，在后者的表现上超过基线45%以上。

Conclusion: 该研究证明了即使在真实世界的不完美语音条件下，基于EEG的辅助系统也能有效支持失语症患者的交流。

Abstract: Aphasia severely limits verbal communication due to impaired language production, often leading to frequent misarticulations during speech attempts. Despite growing interest in brain-computer interface technologies, relatively little attention has been paid to developing EEG-based communication support systems tailored for aphasic patients. To address this gap, we recruited a single participant with expressive aphasia and conducted an Korean-based automatic speech task. EEG signals were recorded during task performance, and each trial was labeled as either correct or incorrect depending on whether the intended word was successfully spoken. Spectral analysis revealed distinct neural activation patterns between the two trial types: misarticulated trials exhibited excessive delta power across widespread channels and increased theta-alpha activity in frontal regions. Building upon these findings, we developed a soft multitask learning framework with maximum mean discrepancy regularization that focus on delta features to jointly optimize class discrimination while aligning the EEG feature distributions of correct and misarticulated trials. The proposed model achieved 58.6 % accuracy for correct and 45.5 % for misarticulated trials-outperforming the baseline by over 45 % on the latter-demonstrating robust intention decoding even under articulation errors. These results highlight the feasibility of EEG-based assistive systems capable of supporting real-world, imperfect speech conditions in aphasia patients.

</details>


### [45] [SparseRM: A Lightweight Preference Modeling with Sparse Autoencoder](https://arxiv.org/abs/2511.07896)
*Dengcan Liu,Jiahao Li,Zheren Fu,Yi Tu,Jiajun Li,Zhendong Mao,Yongdong Zhang*

Main category: cs.AI

TL;DR: 提出SparseRM，利用稀疏自编码器（SAE）从大型语言模型（LLM）表征中提取偏好相关信息，构建轻量级且可解释的奖励模型。


<details>
  <summary>Details</summary>
Motivation: 在资源有限的情况下训练可靠的奖励模型（RMs）仍具挑战性，因为需要大规模偏好标注和昂贵的LLM微调。

Method: SparseRM采用SAE将LLM表征分解为可解释的方向，捕捉与偏好相关的特征，并将表征投影到这些方向以计算对齐分数，使用简单的奖励头预测偏好分数。

Result: 在三个偏好建模任务上的实验表明，SparseRM在使用不到1%可训练参数的情况下，性能优于大多数主流RMs。

Conclusion: SparseRM能够无缝集成到下游对齐流程中，具有高效对齐的潜力。

Abstract: Reward models (RMs) are a core component in the post-training of large language models (LLMs), serving as proxies for human preference evaluation and guiding model alignment. However, training reliable RMs under limited resources remains challenging due to the reliance on large-scale preference annotations and the high cost of fine-tuning LLMs. To address this, we propose SparseRM, which leverages Sparse Autoencoder (SAE) to extract preference-relevant information encoded in model representations, enabling the construction of a lightweight and interpretable reward model. SparseRM first employs SAE to decompose LLM representations into interpretable directions that capture preference-relevant features. The representations are then projected onto these directions to compute alignment scores, which quantify the strength of each preference feature in the representations. A simple reward head aggregates these scores to predict preference scores. Experiments on three preference modeling tasks show that SparseRM achieves superior performance over most mainstream RMs while using less than 1% of trainable parameters. Moreover, it integrates seamlessly into downstream alignment pipelines, highlighting its potential for efficient alignment.

</details>


### [46] [Computational Blueprints: Generating Isomorphic Mathematics Problems with Large Language Models](https://arxiv.org/abs/2511.07932)
*Jeong-Hoon Kim,Jinwoo Nam,Geunsik Jo*

Main category: cs.AI

TL;DR: 本文定义了同构数学问题生成（IMPG）任务，并提出了一种基于大语言模型（LLM）的框架CBIT，用于生成结构一致的数学问题变体。


<details>
  <summary>Details</summary>
Motivation: 个性化数学教育迅速发展，对大量相似练习题的需求增加，但现有数学问题生成研究主要集中在数据增强而非直接教育部署。

Method: 通过连续优化，探索了基于大语言模型的自动IMPG框架，并建立了计算蓝图用于同构双胞胎（CBIT），采用元级生成和基于模板的选择性变化。

Result: 经验结果表明，CBIT在生成准确性和成本效益上优于其他方法，CBIT生成的问题错误率比专家编写的问题低17.8%。

Conclusion: CBIT在商业教育平台上成功部署，产生了大量用户交互，展示了其在教育应用中的潜力和优势。

Abstract: Personalized mathematics education is growing rapidly, creating a strong demand for large sets of similar practice problems. Yet existing studies on mathematics problem generation have focused on data augmentation for training neural language models rather than on direct educational deployment. To bridge this gap, we define a new task, Isomorphic Math Problem Generation (IMPG), designed to produce structurally consistent variants of source problems. Subsequently, we explored LLM-based frameworks for automatic IMPG through successive refinements, and established Computational Blueprints for Isomorphic Twins (CBIT). With meta-level generation and template-based selective variation, CBIT achieves high mathematical correctness and structural consistency while reducing the cost of generation. Empirical results across refinements demonstrate that CBIT is superior on generation accuracy and cost-effectiveness at scale. Most importantly, CBIT-generated problems exhibited an error rate 17.8% lower than expert-authored items, with deployment to 6,732 learners on a commercial education platform yielding 186,870 interactions.

</details>


### [47] [Toward Practical BCI: A Real-time Wireless Imagined Speech EEG Decoding System](https://arxiv.org/abs/2511.07936)
*Ji-Ha Park,Heon-Gyu Kwak,Gi-Hwan Shin,Yoo-In Jeon,Sun-Min Park,Ji-Yeon Hwang,Seong-Whan Lee*

Main category: cs.AI

TL;DR: 提出了一种实时无线想象语音EEG解码系统，提升了BCI在现实世界中的实用性。


<details>
  <summary>Details</summary>
Motivation: 当前BCI研究主要局限于静态和固定环境，限制了其在现实世界中的应用。为了实现更实用的BCI，研究人员引入了一个灵活且适用于日常使用的实时无线想象语音EEG解码系统。

Method: 设计了一个实时无线EEG解码框架，包括用户识别模块和个性化服务，利用lab streaming layer管理连续EEG信号流，实现端到端的实时应用。

Result: 该系统在有线设备上实现了62.00%的四类准确率，在便携式无线耳机上实现了46.67%的准确率。

Conclusion: 该论文展示了向真正实用和可访问的BCI技术迈出的重要一步，为未来研究提供了稳健、实用和个性化神经接口的明确方向。

Abstract: Brain-computer interface (BCI) research, while promising, has largely been confined to static and fixed environments, limiting real-world applicability. To move towards practical BCI, we introduce a real-time wireless imagined speech electroencephalogram (EEG) decoding system designed for flexibility and everyday use. Our framework focuses on practicality, demonstrating extensibility beyond wired EEG devices to portable, wireless hardware. A user identification module recognizes the operator and provides a personalized, user-specific service. To achieve seamless, real-time operation, we utilize the lab streaming layer to manage the continuous streaming of live EEG signals to the personalized decoder. This end-to-end pipeline enables a functional real-time application capable of classifying user commands from imagined speech EEG signals, achieving an overall 4-class accuracy of 62.00 % on a wired device and 46.67 % on a portable wireless headset. This paper demonstrates a significant step towards truly practical and accessible BCI technology, establishing a clear direction for future research in robust, practical, and personalized neural interfaces.

</details>


### [48] [Thinker: Training LLMs in Hierarchical Thinking for Deep Search via Multi-Turn Interaction](https://arxiv.org/abs/2511.07943)
*Jun Xu,Xinkai Du,Yu Ao,Peilong Zhao,Yang Li,Ling Zhong,Lin Yuan,Zhongpu Bo,Xiaorui Wang,Mengshu Sun,Zhengke Gui,Dalong Zhang,Zhaoyang Wang,Qiwei Wang,Yangyang Hou,Zhiying Yin,Haofen Wang,Huajun Chen,Lei Liang,Jun Zhou*

Main category: cs.AI

TL;DR: 提出了一种名为Thinker的分层思维模型，通过多轮交互实现深度搜索，使推理过程可监督和验证。


<details>
  <summary>Details</summary>
Motivation: 现有方法在训练LLMs利用外部检索器解决复杂问题时，忽视了对推理过程的监督，导致逻辑一致性和严谨性难以保证。

Method: Thinker将复杂问题分解为可独立解决的子问题，每个子问题用自然语言和等效逻辑函数双重表示，支持知识库和网页搜索。同时，通过逻辑函数传递子问题间的依赖关系，并进行知识边界判定以减少不必要的外部搜索。

Result: 实验表明，仅需几百个训练样本，Thinker的性能就与已有基线方法相当；使用完整训练集时，Thinker在各类数据集和模型尺寸上显著优于这些方法。

Conclusion: Thinker通过分层思维和多轮交互，有效提升了LLMs在外部知识检索和复杂问题解决中的推理能力。

Abstract: Efficient retrieval of external knowledge bases and web pages is crucial for enhancing the reasoning abilities of LLMs. Previous works on training LLMs to leverage external retrievers for solving complex problems have predominantly employed end-to-end reinforcement learning. However, these approaches neglect supervision over the reasoning process, making it difficult to guarantee logical coherence and rigor. To address these limitations, we propose Thinker, a hierarchical thinking model for deep search through multi-turn interaction, making the reasoning process supervisable and verifiable. It decomposes complex problems into independently solvable sub-problems, each dually represented in both natural language and an equivalent logical function to support knowledge base and web searches. Concurrently, dependencies between sub-problems are passed as parameters via these logical functions, enhancing the logical coherence of the problem-solving process. To avoid unnecessary external searches, we perform knowledge boundary determination to check if a sub-problem is within the LLM's intrinsic knowledge, allowing it to answer directly. Experimental results indicate that with as few as several hundred training samples, the performance of Thinker is competitive with established baselines. Furthermore, when scaled to the full training set, Thinker significantly outperforms these methods across various datasets and model sizes. The source code is available at https://github.com/OpenSPG/KAG-Thinker.

</details>


### [49] [TimeFlow: Towards Stochastic-Aware and Efficient Time Series Generation via Flow Matching Modeling](https://arxiv.org/abs/2511.07968)
*He Panjing,Cheng Mingyue,Li Li,Zhang XiaoHan*

Main category: cs.AI

TL;DR: 提出TimeFlow，一种新颖的基于SDE的流匹配框架，用于高效生成高质量时间序列数据。


<details>
  <summary>Details</summary>
Motivation: 时间序列数据生成的关键在于建模时间动态的内在随机性，传统ODE-based流匹配方法无法有效捕捉随机性，而SDE天然适合建模随机性和不确定性。

Method: 设计了一种组件分解速度场来捕捉时间序列的多面结构，并在流匹配优化中增加随机项以增强表达性，采用encoder-only架构。

Result: 在多个数据集上的广泛实验表明，TimeFlow在生成质量、多样性和效率方面均优于强基线模型。

Conclusion: TimeFlow是一个灵活且通用的框架，支持无条件和条件生成任务，在时间序列生成中表现出色。

Abstract: Generating high-quality time series data has emerged as a critical research topic due to its broad utility in supporting downstream time series mining tasks. A major challenge lies in modeling the intrinsic stochasticity of temporal dynamics, as real-world sequences often exhibit random fluctuations and localized variations. While diffusion models have achieved remarkable success, their generation process is computationally inefficient, often requiring hundreds to thousands of expensive function evaluations per sample. Flow matching has emerged as a more efficient paradigm, yet its conventional ordinary differential equation (ODE)-based formulation fails to explicitly capture stochasticity, thereby limiting the fidelity of generated sequences. By contrast, stochastic differential equation (SDE) are naturally suited for modeling randomness and uncertainty. Motivated by these insights, we propose TimeFlow, a novel SDE-based flow matching framework that integrates a encoder-only architecture. Specifically, we design a component-wise decomposed velocity field to capture the multi-faceted structure of time series and augment the vanilla flow-matching optimization with an additional stochastic term to enhance representational expressiveness. TimeFlow is flexible and general, supporting both unconditional and conditional generation tasks within a unified framework. Extensive experiments across diverse datasets demonstrate that our model consistently outperforms strong baselines in generation quality, diversity, and efficiency.

</details>


### [50] [Versatile and Risk-Sensitive Cardiac Diagnosis via Graph-Based ECG Signal Representation](https://arxiv.org/abs/2511.07973)
*Yue Wang,Yuyang Xu,Renjun Hu,Fanqi Shen,Hanyun Jiang,Jun Wang,Jintai Chen,Danny Z. Chen,Jian Wu,Haochao Ying*

Main category: cs.AI

TL;DR: 本文提出了一种名为VARS的创新心电图（ECG）诊断方法，通过图形化表示处理不同配置的ECG信号，并解决样本不平衡的问题，从而提高临床诊断的通用性和风险信号的检测能力。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在ECG信号处理方面取得快速进展，但现有方法在临床应用中存在两个主要障碍：处理多样化ECG信号配置的能力不足，以及由于样本不平衡导致风险信号检测不佳。

Method: VARS采用基于图的表示方法，将ECG信号转化为能够捕捉关键诊断特征的图结构，不受导联数、采样频率和持续时间的影响。结合去噪重建和对比学习，该方法在保留原始ECG信息的同时突出病理性特征。

Result: 在三个不同结构变异的ECG数据集上，VARS始终优于现有最先进的模型，并显著提高了风险信号的识别能力。模型还具备可解释性，能够准确定位导致特定输出的波形。

Conclusion: VARS作为一种具有高度通用性和风险敏感性的诊断工具，有望成为全面心脏健康评估的重要工具，帮助临床医生做出更明智的决策。

Abstract: Despite the rapid advancements of electrocardiogram (ECG) signal diagnosis and analysis methods through deep learning, two major hurdles still limit their clinical adoption: the lack of versatility in processing ECG signals with diverse configurations, and the inadequate detection of risk signals due to sample imbalances. Addressing these challenges, we introduce VersAtile and Risk-Sensitive cardiac diagnosis (VARS), an innovative approach that employs a graph-based representation to uniformly model heterogeneous ECG signals. VARS stands out by transforming ECG signals into versatile graph structures that capture critical diagnostic features, irrespective of signal diversity in the lead count, sampling frequency, and duration. This graph-centric formulation also enhances diagnostic sensitivity, enabling precise localization and identification of abnormal ECG patterns that often elude standard analysis methods. To facilitate representation transformation, our approach integrates denoising reconstruction with contrastive learning to preserve raw ECG information while highlighting pathognomonic patterns. We rigorously evaluate the efficacy of VARS on three distinct ECG datasets, encompassing a range of structural variations. The results demonstrate that VARS not only consistently surpasses existing state-of-the-art models across all these datasets but also exhibits substantial improvement in identifying risk signals. Additionally, VARS offers interpretability by pinpointing the exact waveforms that lead to specific model outputs, thereby assisting clinicians in making informed decisions. These findings suggest that our VARS will likely emerge as an invaluable tool for comprehensive cardiac health assessment.

</details>


### [51] [Towards Fine-Grained Interpretability: Counterfactual Explanations for Misclassification with Saliency Partition](https://arxiv.org/abs/2511.07974)
*Lintong Zhang,Kang Yin,Seong-Whan Lee*

Main category: cs.AI

TL;DR: 提出了一种细粒度反事实解释框架，通过对象级和部件级解释提高模型可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有基于归因的解释技术缺乏细粒度，尤其在模型误分类情况下解释不够详细。

Method: 提出的方法通过量化正确分类和误分类样本之间感兴趣区域的相似性并加权和隔离部件贡献，以非生成方式生成可解释的反事实。

Result: 在细粒度任务中，该方法能够捕捉更细致、直观上有意义的区域，优于现有细粒度方法。

Conclusion: 细粒度反事实解释框架通过引入显著性分割模块和Shapley值贡献，提高了模型的可解释性和解释的细粒度。

Abstract: Attribution-based explanation techniques capture key patterns to enhance visual interpretability; however, these patterns often lack the granularity needed for insight in fine-grained tasks, particularly in cases of model misclassification, where explanations may be insufficiently detailed. To address this limitation, we propose a fine-grained counterfactual explanation framework that generates both object-level and part-level interpretability, addressing two fundamental questions: (1) which fine-grained features contribute to model misclassification, and (2) where dominant local features influence counterfactual adjustments. Our approach yields explainable counterfactuals in a non-generative manner by quantifying similarity and weighting component contributions within regions of interest between correctly classified and misclassified samples. Furthermore, we introduce a saliency partition module grounded in Shapley value contributions, isolating features with region-specific relevance. Extensive experiments demonstrate the superiority of our approach in capturing more granular, intuitively meaningful regions, surpassing fine-grained methods.

</details>


### [52] [Benchmarking Multi-Step Legal Reasoning and Analyzing Chain-of-Thought Effects in Large Language Models](https://arxiv.org/abs/2511.07979)
*Wenhan Yu,Xinbo Lin,Lanxin Ni,Jinhua Cheng,Lei Sha*

Main category: cs.AI

TL;DR: 介绍MSLR，首个基于真实世界司法决策的中国多步法律推理数据集，并提出自生成思维链提示方法。


<details>
  <summary>Details</summary>
Motivation: 现有法律基准在评估法律推理时混淆了事实回忆与真正推理，且忽略了推理质量，因此需要新的数据集和方法。

Method: 采用IRAC框架构建MSLR数据集，并设计可扩展的人机协作标注流程，引入Self-Initiated Chain-of-Thought提示方法。

Result: 在MSLR上评估多个LLM，表现一般，但Self-Initiated Chain-of-Thought提示方法优于人工设计提示。

Conclusion: MSLR推动了LLM推理和思维链策略的发展，为未来研究提供了开放资源。

Abstract: Large language models (LLMs) have demonstrated strong reasoning abilities across specialized domains, motivating research into their application to legal reasoning. However, existing legal benchmarks often conflate factual recall with genuine inference, fragment the reasoning process, and overlook the quality of reasoning. To address these limitations, we introduce MSLR, the first Chinese multi-step legal reasoning dataset grounded in real-world judicial decision making. MSLR adopts the IRAC framework (Issue, Rule, Application, Conclusion) to model structured expert reasoning from official legal documents. In addition, we design a scalable Human-LLM collaborative annotation pipeline that efficiently produces fine-grained step-level reasoning annotations and provides a reusable methodological framework for multi-step reasoning datasets. Evaluation of multiple LLMs on MSLR shows only moderate performance, highlighting the challenges of adapting to complex legal reasoning. Further experiments demonstrate that Self-Initiated Chain-of-Thought prompts generated by models autonomously improve reasoning coherence and quality, outperforming human-designed prompts. MSLR contributes to advancing LLM reasoning and Chain-of-Thought strategies and offers open resources for future research. The dataset and code are available at https://github.com/yuwenhan07/MSLR-Bench and https://law.sjtu.edu.cn/flszyjzx/index.html.

</details>


### [53] [Capturing Complex Spatial-Temporal Dependencies in Traffic Forecasting: A Self-Attention Approach](https://arxiv.org/abs/2511.07980)
*Zheng Chenghong,Zongyin Deng,Liu Cheng,Xiong Simin,Di Deshi,Li Guanyao*

Main category: cs.AI

TL;DR: 本文提出了一种新的高效时空自注意力模型ST-SAM用于交通流量预测。


<details>
  <summary>Details</summary>
Motivation: 交通流量预测由于区域间复杂的时空相互依赖性而变得复杂。之前的研究以解耦方式分析空间和时间依赖关系，未能捕捉其联合效应。

Method: ST-SAM采用区域嵌入层从交通数据中学习时间特定的区域嵌入，并利用基于自注意力机制的时空依赖学习模块来捕捉邻近和远处区域的联合时空依赖关系。

Result: 在两个真实世界数据集上的大量实验表明，ST-SAM在准确性（RMSE提升15%，MAPE提升17%）和效率（训练时间减少32倍）上显著优于现有方法。

Conclusion: ST-SAM完全依赖自注意力机制捕捉局部和全局时空相关性，使其在交通预测中高效且有效。

Abstract: We study the problem of traffic forecasting, aiming to predict the inflow and outflow of a region in the subsequent time slot. The problem is complex due to the intricate spatial and temporal interdependence among regions. Prior works study the spatial and temporal dependency in a decouple manner, failing to capture their joint effect. In this work, we propose ST-SAM, a novel and efficient Spatial-Temporal Self-Attention Model for traffic forecasting. ST-SAM uses a region embedding layer to learn time-specific embedding from traffic data for regions. Then, it employs a spatial-temporal dependency learning module based on self-attention mechanism to capture the joint spatial-temporal dependency for both nearby and faraway regions. ST-SAM entirely relies on self-attention to capture both local and global spatial-temporal correlations, which make it effective and efficient. Extensive experiments on two real world datasets show that ST-SAM is substantially more accurate and efficient than the state-of-the-art approaches (with an average improvement of up to 15% on RMSE, 17% on MAPE, and 32 times on training time in our experiments).

</details>


### [54] [The One Where They Brain-Tune for Social Cognition: Multi-Modal Brain-Tuning on Friends](https://arxiv.org/abs/2511.07988)
*Nico Policzer,Cameron Braunstein,Mariya Toneva*

Main category: cs.AI

TL;DR: 该研究通过多模态音视频模型，扩展了脑调优方法，提高了大脑与社会认知相关的功能区域的对齐，并在下游任务（情景喜剧中的讽刺检测）中表现更优。


<details>
  <summary>Details</summary>
Motivation: 研究动机是增强多模态音频-视频模型的社会认知能力，通过脑调优方法来更好地预测大脑活动，尤其是与社会处理相关的关键区域。

Method: 采用多模态音视频模型，并在观看情景喜剧《Friends》时进行脑调优，目标是与社会认知相关的STS区域。

Result: 显著提高了模型与STS及其邻近ROI的大脑对齐，并改善了一个与训练数据相关的社会认知任务，即情景喜剧中的讽刺检测。

Conclusion: 该研究成功将脑调优方法扩展到多模态领域，通过调整与特定功能相关的脑区，提升了下游任务的表现。

Abstract: Recent studies on audio models show brain-tuning - fine-tuning models to better predict corresponding fMRI activity - improves brain alignment and increases performance on downstream semantic and audio tasks. We extend this approach to a multimodal audio-video model to enhance social cognition, targeting the Superior Temporal Sulcus (STS), a key region for social processing, while subjects watch Friends. We find significant increases in brain alignment to the STS and an adjacent ROI, as well as improvements to a social cognition task related to the training data - sarcasm detection in sitcoms. In summary, our study extends brain-tuning to the multi-modal domain, demonstrating improvements to a downstream task after tuning to a relevant functional region.

</details>


### [55] [VSPO: Validating Semantic Pitfalls in Ontology via LLM-Based CQ Generation](https://arxiv.org/abs/2511.07991)
*Hyojun Choi,Seokju Hwang,Kyong-Ho Lee*

Main category: cs.AI

TL;DR: 本文提出VSPO数据集和模型，利用LLMs自动生成能验证本体语义陷阱的能力问题（CQs），以检测如错误使用allValuesFrom等建模错误。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过CQ相似度评估，难以检测语义陷阱；规则方法无法可靠识别这些错误，需要自动化且精准的CQ生成方案。

Method: 构建VSPO数据集，模拟缺失和错误公理，使用LLMs生成类与属性的自然语言定义并引入定义与本体间的不一致，微调LLaMA-3.1-8B-Instruct模型生成验证CQs。

Result: 模型在CQ生成上优于基线方法，相比GPT-4.1，精确率提高26%，召回率提高28.2%，能检测更广泛的建模错误。

Conclusion: 本研究首次实现利用LLMs自动生成用于TBox验证的CQs，显著减少人工成本，并提升本体与专家知识间的语义一致性。

Abstract: Competency Questions (CQs) play a crucial role in validating ontology design. While manually crafting CQs can be highly time-consuming and costly for ontology engineers, recent studies have explored the use of large language models (LLMs) to automate this process. However, prior approaches have largely evaluated generated CQs based on their similarity to existing datasets, which often fail to verify semantic pitfalls such as "Misusing allValuesFrom". Since such pitfalls cannot be reliably detected through rule-based methods, we propose a novel dataset and model of Validating Semantic Pitfalls in Ontology (VSPO) for CQ generation specifically designed to verify the semantic pitfalls. To simulate missing and misused axioms, we use LLMs to generate natural language definitions of classes and properties and introduce misalignments between the definitions and the ontology by removing axioms or altering logical operators (e.g., substituting union with intersection). We then fine-tune LLaMA-3.1-8B-Instruct to generate CQs that validate these semantic discrepancies between the provided definitions and the corresponding axioms. The resulting CQs can detect a broader range of modeling errors compared to existing public datasets. Our fine-tuned model demonstrates superior performance over baselines, showing 26% higher precision and 28.2% higher recall than GPT-4.1 in generating CQs for pitfall validation. This research enables automatic generation of TBox-validating CQs using LLMs, significantly reducing manual effort while improving semantic alignment between ontologies and expert knowledge. To the best of our knowledge, this is the first study to target semantic pitfall validation in CQ generation using LLMs.

</details>


### [56] [Enhancing Logical Expressiveness in Graph Neural Networks via Path-Neighbor Aggregation](https://arxiv.org/abs/2511.07994)
*Han Yu,Xiaojuan Zhao,Aiping Li,Kai Chen,Ziniu Liu,Zhichao Peng*

Main category: cs.AI

TL;DR: 提出PN-GNN，通过聚合推理路径上的节点-邻居嵌入，增强GNN的逻辑表达能力。


<details>
  <summary>Details</summary>
Motivation: 现有GNN表达能力的研究主要集中在简单的单关系图，缺乏对GNN在知识图中表达逻辑规则的深入探讨，增强GNN的逻辑表达能力仍是一个关键问题。

Method: PN-GNN通过聚合推理路径上的节点-邻居嵌入来增强GNN的逻辑表达能力。首先分析现有GNN方法的逻辑表达能力并指出其不足，然后从理论上探讨PN-GNN的逻辑表达能力，证明其表达能力优于C-GNN，并且其$(k+1)$-hop逻辑表达能力严格优于$k$-hop。

Result: 在六个合成数据集和两个真实世界数据集上评估PN-GNN的逻辑表达能力，理论和实验结果均表明PN-GNN在不损害泛化能力的前提下，增强了逻辑规则的表达能力，并在KG推理任务中表现出竞争力。

Conclusion: PN-GNN通过聚合推理路径上的节点-邻居嵌入，有效增强了GNN的逻辑表达能力，并在知识图推理任务中取得了良好性能。

Abstract: Graph neural networks (GNNs) can effectively model structural information of graphs, making them widely used in knowledge graph (KG) reasoning. However, existing studies on the expressive power of GNNs mainly focuses on simple single-relation graphs, and there is still insufficient discussion on the power of GNN to express logical rules in KGs. How to enhance the logical expressive power of GNNs is still a key issue. Motivated by this, we propose Path-Neighbor enhanced GNN (PN-GNN), a method to enhance the logical expressive power of GNN by aggregating node-neighbor embeddings on the reasoning path. First, we analyze the logical expressive power of existing GNN-based methods and point out the shortcomings of the expressive power of these methods. Then, we theoretically investigate the logical expressive power of PN-GNN, showing that it not only has strictly stronger expressive power than C-GNN but also that its $(k+1)$-hop logical expressiveness is strictly superior to that of $k$-hop. Finally, we evaluate the logical expressive power of PN-GNN on six synthetic datasets and two real-world datasets. Both theoretical analysis and extensive experiments confirm that PN-GNN enhances the expressive power of logical rules without compromising generalization, as evidenced by its competitive performance in KG reasoning tasks.

</details>


### [57] [Multivariate Time series Anomaly Detection:A Framework of Hidden Markov Models](https://arxiv.org/abs/2511.07995)
*Jinbo Li,Witold Pedrycz,Iqbal Jamal*

Main category: cs.AI

TL;DR: 本文开发了一种将多元时间序列转换为单变量时间序列以进行异常检测的方法，研究了FCM聚类和模糊积分等变换技术，并应用HMM进行异常检测。


<details>
  <summary>Details</summary>
Motivation: 多元时间序列异常检测的复杂性促使研究者开发将多元时间序列转化为单变量时间序列的方法，以简化检测过程。

Method: 研究了几种涉及FCM聚类和模糊积分的多元时间序列到单变量时间序列的变换技术，并应用HMM进行异常检测。

Result: 构建了基于HMM的异常检测器，并比较了几种变换方法，报告了一系列实验研究及对比分析。

Conclusion: 该研究展示了通过变换技术将多元时间序列转化为单变量时间序列后，使用HMM进行异常检测的有效性，并提供了不同变换方法的比较。

Abstract: In this study, we develop an approach to multivariate time series anomaly detection focused on the transformation of multivariate time series to univariate time series. Several transformation techniques involving Fuzzy C-Means (FCM) clustering and fuzzy integral are studied. In the sequel, a Hidden Markov Model (HMM), one of the commonly encountered statistical methods, is engaged here to detect anomalies in multivariate time series. We construct HMM-based anomaly detectors and in this context compare several transformation methods. A suite of experimental studies along with some comparative analysis is reported.

</details>


### [58] [Numerical Sensitivity and Robustness: Exploring the Flaws of Mathematical Reasoning in Large Language Models](https://arxiv.org/abs/2511.08022)
*Zhishen Sun,Guang Dai,Ivor Tsang,Haishan Ye*

Main category: cs.AI

TL;DR: 提出了一种新的扰动框架来评估大型语言模型在复杂环境中的数学推理能力，发现模型对数值扰动敏感，且可能依赖记忆模板。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型是否具备真正的数学理解能力，尤其是在面对复杂和扰动环境时的表现。

Method: 通过注入语义无关的扰动句子和核心提问指令缺失的额外扰动方法，逐步增加扰动强度，评估模型的推理能力。

Result: 模型在数值扰动下性能下降显著，开源小参数模型最多下降51.55%，商业模型下降3%-10%。核心提问指令缺失时，模型仍能维持20%-40%的准确率。

Conclusion: 当前大型语言模型在推理能力上存在不足和局限，对数值信息敏感，可能依赖记忆模板或模式匹配，而非逻辑推理。

Abstract: LLMs have made significant progress in the field of mathematical reasoning, but whether they have true the mathematical understanding ability is still controversial. To explore this issue, we propose a new perturbation framework to evaluate LLMs' reasoning ability in complex environments by injecting additional semantically irrelevant perturbation sentences and gradually increasing the perturbation intensity. At the same time, we use an additional perturbation method: core questioning instruction missing, to further analyze the LLMs' problem-solving mechanism. The experimental results show that LLMs perform stably when facing perturbation sentences without numbers, but there is also a robustness boundary. As the perturbation intensity increases, the performance exhibits varying degrees of decline; when facing perturbation sentences with numbers, the performance decreases more significantly, most open source models with smaller parameters decrease by nearly or even more than 10%, and further increasing with the enhancement of perturbation intensity, with the maximum decrease reaching 51.55%. Even the most advanced commercial LLMs have seen a 3%-10% performance drop. By analyzing the reasoning process of LLMs in detail, We find that models are more sensitive to perturbations with numerical information and are more likely to give incorrect answers when disturbed by irrelevant numerical information. The higher the perturbation intensity, the more obvious these defects are. At the same time, in the absence of core questioning instruction, models can still maintain an accuracy of 20%-40%, indicating that LLMs may rely on memory templates or pattern matching to complete the task, rather than logical reasoning. In general, our work reveals the shortcomings and limitations of current LLMs in their reasoning capabilities, which is of great significance for the further development of LLMs.

</details>


### [59] [Knowledge-Augmented Long-CoT Generation for Complex Biomolecular Reasoning](https://arxiv.org/abs/2511.08024)
*Tianwen Lyu,Xiang Zhuang,Keyan Ding,Xinzhe Cao,Lei Liang,Wei Zhao,Qiang Zhang,Huajun Chen*

Main category: cs.AI

TL;DR: 提出了一个知识增强的长链推理框架，通过知识图谱多跳推理链增强大模型在复杂生物分子机制理解中的逻辑一致性和领域知识基础，并引入新基准PrimeKGQA。


<details>
  <summary>Details</summary>
Motivation: 复杂生物分子机制理解需要多步推理，但现有大模型存在逻辑不一致和领域知识缺失问题，且现有基准数据集在规模和深度上有限。

Method: 构建知识图谱引导的多跳推理链，结合监督微调和强化学习优化模型推理；引入包含深度推理链标注的新基准PrimeKGQA。

Result: 在PrimeKGQA和现有数据集上，所提方法在需要结构生物学知识遍历的多跳任务中达到SOTA，尤其随推理深度增加优势更明显。

Conclusion: 结构化知识与先进推理策略的结合能实现更可靠、可解释的生物分子机制推理，为领域应用提供了新方向。

Abstract: Understanding complex biomolecular mechanisms requires multi-step reasoning across molecular interactions, signaling cascades, and metabolic pathways. While large language models(LLMs) show promise in such tasks, their application to biomolecular problems is hindered by logical inconsistencies and the lack of grounding in domain knowledge. Existing approaches often exacerbate these issues: reasoning steps may deviate from biological facts or fail to capture long mechanistic dependencies. To address these challenges, we propose a Knowledge-Augmented Long-CoT Reasoning framework that integrates LLMs with knowledge graph-based multi-hop reasoning chains. The framework constructs mechanistic chains via guided multi-hop traversal and pruning on the knowledge graph; these chains are then incorporated into supervised fine-tuning to improve factual grounding and further refined with reinforcement learning to enhance reasoning reliability and consistency. Furthermore, to overcome the shortcomings of existing benchmarks, which are often restricted in scale and scope and lack annotations for deep reasoning chains, we introduce PrimeKGQA, a comprehensive benchmark for biomolecular question answering. Experimental results on both PrimeKGQA and existing datasets demonstrate that although larger closed-source models still perform well on relatively simple tasks, our method demonstrates clear advantages as reasoning depth increases, achieving state-of-the-art performance on multi-hop tasks that demand traversal of structured biological knowledge. These findings highlight the effectiveness of combining structured knowledge with advanced reasoning strategies for reliable and interpretable biomolecular reasoning.

</details>


### [60] [Dual-Process Scaffold Reasoning for Enhancing LLM Code Debugging](https://arxiv.org/abs/2511.08052)
*Po-Chung Hsieh,Chin-Po Chen,Jeng-Lin Li,Ming-Ching Chang*

Main category: cs.AI

TL;DR: 提出了一种新颖的、基于心理学理论支撑的脚手架推理框架用于代码调试，该框架包含脚手架流、分析流和集成流，并在DebugBench上实现了88.91%的通过率和平均每个问题5.36秒的推理时间，优于其他推理方法。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLM）在各种基准测试中表现出复杂的问题解决能力，但如何平衡推理步骤的复杂性和计算效率的关键研究问题仍未解决。此外，对System 2推理的深入探索也较为缺乏。

Method: 提出了一种新颖的心理学支持的Scaffold Reasoning框架，该框架包括Scaffold Stream、Analytic Stream和Integration Stream，通过将Scaffold Stream中的参考代码构建与Analytic Stream产生的有bug代码分析结果集成，实现代码调试。

Result: 该框架在DebugBench上实现了88.91%的通过率和平均每个问题5.36秒的推理时间，优于其他推理方法，并在不同的LLM中均表现出更高的推理准确性和效率。

Conclusion: Scaffold Reasoning框架不仅在性能上优于其他推理方法，而且其优势和各种认知路径的局限性在不同的问题难度和错误类型中得到了详细分析，同时该框架与人类认知过程具有高度一致性。

Abstract: Recent LLMs have demonstrated sophisticated problem-solving capabilities on various benchmarks through advanced reasoning algorithms. However, the key research question of identifying reasoning steps that balance complexity and computational efficiency remains unsolved. Recent research has increasingly drawn upon psychological theories to explore strategies for optimizing cognitive pathways. The LLM's final outputs and intermediate steps are regarded as System 1 and System 2, respectively. However, an in-depth exploration of the System 2 reasoning is still lacking. Therefore, we propose a novel psychologically backed Scaffold Reasoning framework for code debugging, which encompasses the Scaffold Stream, Analytic Stream, and Integration Stream. The construction of reference code within the Scaffold Stream is integrated with the buggy code analysis results produced by the Analytic Stream through the Integration Stream. Our framework achieves an 88.91% pass rate and an average inference time of 5.36 seconds per-problem on DebugBench, outperforming other reasoning approaches across various LLMs in both reasoning accuracy and efficiency. Further analyses elucidate the advantages and limitations of various cognitive pathways across varying problem difficulties and bug types. Our findings also corroborate the alignment of the proposed Scaffold Reasoning framework with human cognitive processes.

</details>


### [61] [Information Capacity: Evaluating the Efficiency of Large Language Models via Text Compression](https://arxiv.org/abs/2511.08066)
*Cheng Yuan,Jiawei Shao,Chi Zhang,Xuelong Li*

Main category: cs.AI

TL;DR: 本文提出了一种新的度量标准“信息容量”，用于评估不同规模和架构的大语言模型的效率。


<details>
  <summary>Details</summary>
Motivation: 由于大语言模型对计算资源的需求不断增长，现有度量标准无法准确反映模型效率，因此需要一种新的统一度量方法。

Method: 引入信息容量，该度量基于文本压缩性能和计算复杂度之间的关系，并考虑了分词器效率。

Result: 在主流开源模型上的实验表明，信息容量可以在不同模型之间进行公平的效率比较，并准确预测模型性能。

Conclusion: 信息容量是一种有效的模型效率度量，可以一致地反映不同模型的影响因素，如分词器效率、预训练数据和专家混合架构。

Abstract: Recent years have witnessed the rapid advancements of large language models (LLMs) and their expanding applications, leading to soaring demands for computational resources. The widespread adoption of test-time scaling further aggravates the tension between model capability and resource consumption, highlighting the importance of inference efficiency. However, a unified metric that accurately reflects an LLM's efficiency across different model sizes and architectures remains absent. Motivated by the correlation between compression and intelligence, we introduce information capacity, a measure of model efficiency based on text compression performance relative to computational complexity. Larger models can predict the next token more accurately, achieving greater compression gains but at higher computational costs. Empirical evaluations on mainstream open-source models show that models of varying sizes within a series exhibit consistent information capacity. This metric enables a fair efficiency comparison across model series and accurate performance prediction within a model series. A distinctive feature of information capacity is that it incorporates tokenizer efficiency, which affects both input and output token counts but is often neglected in LLM evaluations. We assess the information capacity of 49 models on 5 heterogeneous datasets and observe consistent results on the influences of tokenizer efficiency, pretraining data, and the mixture-of-experts architecture.

</details>


### [62] [Clustering-based Anomaly Detection in Multivariate Time Series Data](https://arxiv.org/abs/2511.08072)
*Jinbo Li,Hesam Izakian,Witold Pedrycz,Iqbal Jamal*

Main category: cs.AI

TL;DR: 提出了一种基于聚类的方法，用于检测多变量时间序列数据的异常，包括幅值和形状。


<details>
  <summary>Details</summary>
Motivation: 多变量时间序列数据的异常检测是一个具有挑战性的问题，涉及同时考虑时间和变量关系，应用于科学和工程领域。

Method: 利用滑动窗口生成多变量子序列，采用扩展模糊聚类揭示子序列结构，并使用重建准则和粒子群优化进行异常检测。

Result: 在多个合成和真实世界数据集上的实验表明，该方法能有效检测多变量时间序列的异常。

Conclusion: 提出的框架通过扩展模糊聚类，能够识别多变量时间序列中的异常幅值和形状模式，适用于多个应用领域。

Abstract: Multivariate time series data come as a collection of time series describing different aspects of a certain temporal phenomenon. Anomaly detection in this type of data constitutes a challenging problem yet with numerous applications in science and engineering because anomaly scores come from the simultaneous consideration of the temporal and variable relationships. In this paper, we propose a clustering-based approach to detect anomalies concerning the amplitude and the shape of multivariate time series. First, we use a sliding window to generate a set of multivariate subsequences and thereafter apply an extended fuzzy clustering to reveal a structure present within the generated multivariate subsequences. Finally, a reconstruction criterion is employed to reconstruct the multivariate subsequences with the optimal cluster centers and the partition matrix. We construct a confidence index to quantify a level of anomaly detected in the series and apply Particle Swarm Optimization as an optimization vehicle for the problem of anomaly detection. Experimental studies completed on several synthetic and six real-world datasets suggest that the proposed methods can detect the anomalies in multivariate time series. With the help of available clusters revealed by the extended fuzzy clustering, the proposed framework can detect anomalies in the multivariate time series and is suitable for identifying anomalous amplitude and shape patterns in various application domains such as health care, weather data analysis, finance, and disease outbreak detection.

</details>


### [63] [Prudential Reliability of Large Language Models in Reinsurance: Governance, Assurance, and Capital Efficiency](https://arxiv.org/abs/2511.08082)
*Stella C. Dong*

Main category: cs.AI

TL;DR: 本文提出了一个用于评估大型语言模型（LLMs）在再保险领域可靠性的审慎框架，并介绍了其实施基准RAIRAB，结果表明该框架在治理嵌入、数据可追溯性和可验证保障下能显著提升模型的基础准确性、透明度和稳定性。


<details>
  <summary>Details</summary>
Motivation: 在再保险领域，需要确保大型语言模型的可靠性，以降低风险转移和资本分配中的信息摩擦。现有审慎原则需要具体化为可操作的框架，以应对AI在金融领域的应用挑战。

Method: 开发了一个五支柱架构（治理、数据血统、保障、弹性和监管对齐），将Solvency II、SR 11-7等监管要求转化为可衡量的生命周期控制，并通过RAIRAB基准实施，评估治理嵌入的LLMs。

Result: 检索基础的配置在六个任务家族中实现了更高基础准确性（0.90），减少约40%的幻觉和解释性漂移，并几乎使透明度翻倍。

Conclusion: 当治理明确、数据可追溯、保障可验证时，现有审慎原则已经能够支持可靠的AI应用，从而降低再保险领域的信息摩擦。

Abstract: This paper develops a prudential framework for assessing the reliability of large language models (LLMs) in reinsurance. A five-pillar architecture--governance, data lineage, assurance, resilience, and regulatory alignment--translates supervisory expectations from Solvency II, SR 11-7, and guidance from EIOPA (2025), NAIC (2023), and IAIS (2024) into measurable lifecycle controls. The framework is implemented through the Reinsurance AI Reliability and Assurance Benchmark (RAIRAB), which evaluates whether governance-embedded LLMs meet prudential standards for grounding, transparency, and accountability. Across six task families, retrieval-grounded configurations achieved higher grounding accuracy (0.90), reduced hallucination and interpretive drift by roughly 40%, and nearly doubled transparency. These mechanisms lower informational frictions in risk transfer and capital allocation, showing that existing prudential doctrines already accommodate reliable AI when governance is explicit, data are traceable, and assurance is verifiable.

</details>


### [64] [Gateways to Tractability for Satisfiability in Pearl's Causal Hierarchy](https://arxiv.org/abs/2511.08091)
*Robert Ganian,Marlene Gründel,Simon Wietheger*

Main category: cs.AI

TL;DR: 通过参数化复杂性重新审视PCH公式的可满足性问题，识别出可处理性的首个入口，提出了固定参数和XP算法，并探讨了可处理性的极限。


<details>
  <summary>Details</summary>
Motivation: Pearl的因果层次（PCH）是处理概率性、干预性和反事实陈述的核心框架，但在几乎所有经典设置中，PCH公式的可满足性问题是计算上难以处理的。本文旨在通过参数化复杂性寻找可处理性的可能路径。

Method: 采用参数化复杂性理论，引入了如 primal treewidth 和变量数量等参数，提出了固定参数和XP算法。利用因果模型的良好形成结构特征，而不是通常的动态规划范式。

Result: 在关键概率和反事实片段中实现了可满足性的固定参数和XP算法，并提供了匹配的难度结果，界定了可处理性的极限。

Conclusion: 通过引入新的参数和算法工具包，为因果推理提供了新的算法策略，并明确了PCH公式可满足性问题的可处理性边界。

Abstract: Pearl's Causal Hierarchy (PCH) is a central framework for reasoning about probabilistic, interventional, and counterfactual statements, yet the satisfiability problem for PCH formulas is computationally intractable in almost all classical settings. We revisit this challenge through the lens of parameterized complexity and identify the first gateways to tractability. Our results include fixed-parameter and XP-algorithms for satisfiability in key probabilistic and counterfactual fragments, using parameters such as primal treewidth and the number of variables, together with matching hardness results that map the limits of tractability. Technically, we depart from the dynamic programming paradigm typically employed for treewidth-based algorithms and instead exploit structural characterizations of well-formed causal models, providing a new algorithmic toolkit for causal reasoning.

</details>


### [65] [Improving Industrial Injection Molding Processes with Explainable AI for Quality Classification](https://arxiv.org/abs/2511.08108)
*Georg Rottenwalter,Marcel Tilly,Victor Owolabi*

Main category: cs.AI

TL;DR: 利用可解释人工智能（XAI）技术减少特征数量，提升注塑件质量分类的模型泛化和解释性。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型的复杂性限制了在工业质量控制中的实用性，且工业设备传感器技术不足导致数据不完整。

Method: 应用SHAP、Grad-CAM和LIME分析LSTM模型特征重要性，将19个输入特征减少到9个和6个，评估模型精度、推理速度和可解释性的权衡。

Result: 减少特征可以提高模型的泛化能力，同时保持高分类性能，并略微提升推理速度。

Conclusion: 该方法提高了AI驱动的质量控制的可行性，尤其是在传感器能力有限的工业环境中，为制造业中更高效和可解释的机器学习应用铺平了道路。

Abstract: Machine learning is an essential tool for optimizing industrial quality control processes. However, the complexity of machine learning models often limits their practical applicability due to a lack of interpretability. Additionally, many industrial machines lack comprehensive sensor technology, making data acquisition incomplete and challenging. Explainable Artificial Intelligence offers a solution by providing insights into model decision-making and identifying the most relevant features for classification. In this paper, we investigate the impact of feature reduction using XAI techniques on the quality classification of injection-molded parts. We apply SHAP, Grad-CAM, and LIME to analyze feature importance in a Long Short-Term Memory model trained on real production data. By reducing the original 19 input features to 9 and 6, we evaluate the trade-off between model accuracy, inference speed, and interpretability. Our results show that reducing features can improve generalization while maintaining high classification performance, with an small increase in inference speed. This approach enhances the feasibility of AI-driven quality control, particularly for industrial settings with limited sensor capabilities, and paves the way for more efficient and interpretable machine learning applications in manufacturing.

</details>


### [66] [Advancements in synthetic data extraction for industrial injection molding](https://arxiv.org/abs/2511.08117)
*Georg Rottenwalter,Marcel Tilly,Christian Bielenberg,Katharina Obermeier*

Main category: cs.AI

TL;DR: 本文探讨了将合成数据集成到注塑成型过程训练中的可行性，结果表明合成数据可以提升机器学习模型的鲁棒性，为工业应用提供了一种减少人工、机器使用和材料浪费的替代方案。


<details>
  <summary>Details</summary>
Motivation: 数据采集耗时且成本高，合成数据有望增强不足的数据集并提高机器学习模型的鲁棒性。

Method: 通过模拟生产周期生成合成数据，并将其加入训练数据集中，试验不同比例以找到最优平衡。

Result: 合成数据的加入提升了模型处理不同场景的能力，具有减少人工、机器使用和材料浪费的潜在工业应用。

Conclusion: 在数据收集和维护不切实际或成本高昂的情况下，合成数据提供了一种有价值的替代方案，有助于未来更高效的制造过程。

Abstract: Machine learning has significant potential for optimizing various industrial processes. However, data acquisition remains a major challenge as it is both time-consuming and costly. Synthetic data offers a promising solution to augment insufficient data sets and improve the robustness of machine learning models. In this paper, we investigate the feasibility of incorporating synthetic data into the training process of the injection molding process using an existing Long Short-Term Memory architecture. Our approach is to generate synthetic data by simulating production cycles and incorporating them into the training data set. Through iterative experimentation with different proportions of synthetic data, we attempt to find an optimal balance that maximizes the benefits of synthetic data while preserving the authenticity and relevance of real data. Our results suggest that the inclusion of synthetic data improves the model's ability to handle different scenarios, with potential practical industrial applications to reduce manual labor, machine use, and material waste. This approach provides a valuable alternative for situations where extensive data collection and maintenance has been impractical or costly and thus could contribute to more efficient manufacturing processes in the future.

</details>


### [67] [National Institute on Aging PREPARE Challenge: Early Detection of Cognitive Impairment Using Speech - The SpeechCARE Solution](https://arxiv.org/abs/2511.08132)
*Maryam Zolnoori,Hossein Azadmaleki,Yasaman Haghbin,Ali Zolnour,Mohammad Javad Momeni Nezhad,Sina Rashidi,Mehdi Naserian,Elyas Esmaeili,Sepehr Karimi Arpanahi*

Main category: cs.AI

TL;DR: SpeechCARE是一种新颖的多模态语音处理流程，利用预训练的多语言声学和语言变换模型，通过动态融合架构，为阿尔茨海默病及相关痴呆（ADRD）的早期检测提供了一种高效、可解释的方法。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病和相关痴呆影响了大量的老年人，但许多认知衰退的个体仍未被诊断。传统的语音处理流程性能有限，因此需要一种更强大、更通用的方法来检测与认知障碍相关的语音特征。

Method: SpeechCARE使用多模态语音处理流程，采用预训练的多语言声学和语言变换模型，并结合Mixture of Experts（MoE）的动态融合架构。流程包括自动转录、基于LLM的异常检测、任务识别、以及SHAP-based可解释性模块。

Result: SpeechCARE在分类认知健康、MCI和AD个体方面实现了AUC = 0.88和F1 = 0.72，对MCI检测的AUC = 0.90和F1 = 0.62。偏差分析显示除了80岁以上成年人外，其他群体差异很小。

Conclusion: SpeechCARE是一种强大且可解释的多模态语音处理流程，为ADRD的早期检测提供了有效工具。未来的工作包括在真实世界护理环境中的部署，以及针对少数群体进行EHR集成的可解释性增强。

Abstract: Alzheimer's disease and related dementias (ADRD) affect one in five adults over 60, yet more than half of individuals with cognitive decline remain undiagnosed. Speech-based assessments show promise for early detection, as phonetic motor planning deficits alter acoustic features (e.g., pitch, tone), while memory and language impairments lead to syntactic and semantic errors. However, conventional speech-processing pipelines with hand-crafted features or general-purpose audio classifiers often exhibit limited performance and generalizability. To address these limitations, we introduce SpeechCARE, a multimodal speech processing pipeline that leverages pretrained, multilingual acoustic and linguistic transformer models to capture subtle speech-related cues associated with cognitive impairment. Inspired by the Mixture of Experts (MoE) paradigm, SpeechCARE employs a dynamic fusion architecture that weights transformer-based acoustic, linguistic, and demographic inputs, allowing integration of additional modalities (e.g., social factors, imaging) and enhancing robustness across diverse tasks. Its robust preprocessing includes automatic transcription, large language model (LLM)-based anomaly detection, and task identification. A SHAP-based explainability module and LLM reasoning highlight each modality's contribution to decision-making. SpeechCARE achieved AUC = 0.88 and F1 = 0.72 for classifying cognitively healthy, MCI, and AD individuals, with AUC = 0.90 and F1 = 0.62 for MCI detection. Bias analysis showed minimal disparities, except for adults over 80. Mitigation techniques included oversampling and weighted loss. Future work includes deployment in real-world care settings (e.g., VNS Health, Columbia ADRC) and EHR-integrated explainability for underrepresented populations in New York City.

</details>


### [68] [oboro: Text-to-Image Synthesis on Limited Data using Flow-based Diffusion Transformer with MMH Attention](https://arxiv.org/abs/2511.08168)
*Ryusuke Mizutani,Kazuaki Matano,Tsugumi Kadowaki,Haruki Tenya,Layris,nuigurumi,Koki Hashimoto,Yu Tanaka*

Main category: cs.AI

TL;DR: 开发一个从零开始训练的图像生成模型 "oboro:"，以应对日本动画产业劳动力短缺问题。


<details>
  <summary>Details</summary>
Motivation: 解决日本动画产业面临的劳动力短缺问题，并推动国内AI开发生态系统。

Method: 仅使用版权清理后的图像训练，从零开始构建新的图像生成模型，并公开模型权重和推理代码。

Result: 成功开发了名为 "oboro:" 的图像生成模型，并首次在日本发布了开源的、商业导向的图像生成AI。

Conclusion: 通过开发过程透明化，为日本AI研究人员和工程师社区做出贡献，并促进国内AI发展生态系统。

Abstract: This project was conducted as a 2nd-term adopted project of the "Post-5G Information and Communication System Infrastructure Enhancement R&D Project Development of Competitive Generative AI Foundation Models (GENIAC)," a business of the Ministry of Economy, Trade and Industry (METI) and the New Energy and Industrial Technology Development Organization (NEDO). To address challenges such as labor shortages in Japan's anime production industry, this project aims to develop an image generation model from scratch. This report details the technical specifications of the developed image generation model, "oboro:." We have developed "oboro:," a new image generation model built from scratch, using only copyright-cleared images for training. A key characteristic is its architecture, designed to generate high-quality images even from limited datasets. The foundation model weights and inference code are publicly available alongside this report. This project marks the first release of an open-source, commercially-oriented image generation AI fully developed in Japan. AiHUB originated from the OSS community; by maintaining transparency in our development process, we aim to contribute to Japan's AI researcher and engineer community and promote the domestic AI development ecosystem.

</details>


### [69] [Towards Provably Unlearnable Examples via Bayes Error Optimisation](https://arxiv.org/abs/2511.08191)
*Ruihan Zhang,Jun Sun,Ee-Peng Lim,Peixin Zhang*

Main category: cs.AI

TL;DR: 本文提出了一种通过最大化贝叶斯误差来构建不可学习样本的新方法，以确保用户数据的隐私保护。


<details>
  <summary>Details</summary>
Motivation: 大规模机器学习模型依赖于海量在线数据进行训练，这引发了关于用户数据隐私的担忧。为此，研究人员引入了不可学习样本的概念，但现有方法缺乏形式保证且在混合数据情况下效果不佳。

Method: 提出一种通过系统最大化贝叶斯误差来构建不可学习样本的优化方法，并使用投影梯度上升提供高效解决方案。

Result: 该方法在理论上增加了贝叶斯误差，并在实验中证明在混合数据情况下依然有效，能限制数据的可学习性。

Conclusion: 该方法为不可学习样本提供了形式化保证，并能在实际应用中有效保护用户数据。

Abstract: The recent success of machine learning models, especially large-scale classifiers and language models, relies heavily on training with massive data. These data are often collected from online sources. This raises serious concerns about the protection of user data, as individuals may not have given consent for their data to be used in training. To address this concern, recent studies introduce the concept of unlearnable examples, i.e., data instances that appear natural but are intentionally altered to prevent models from effectively learning from them. While existing methods demonstrate empirical effectiveness, they typically rely on heuristic trials and lack formal guarantees. Besides, when unlearnable examples are mixed with clean data, as is often the case in practice, their unlearnability disappears. In this work, we propose a novel approach to constructing unlearnable examples by systematically maximising the Bayes error, a measurement of irreducible classification error. We develop an optimisation-based approach and provide an efficient solution using projected gradient ascent. Our method provably increases the Bayes error and remains effective when the unlearning examples are mixed with clean samples. Experimental results across multiple datasets and model architectures are consistent with our theoretical analysis and show that our approach can restrict data learnability, effectively in practice.

</details>


### [70] [EHRStruct: A Comprehensive Benchmark Framework for Evaluating Large Language Models on Structured Electronic Health Record Tasks](https://arxiv.org/abs/2511.08206)
*Xiao Yang,Xuejiao Zhao,Zhiqi Shen*

Main category: cs.AI

TL;DR: 该论文介绍了EHRStruct，一个用于评估大型语言模型在结构化电子健康记录（EHR）数据上性能的基准。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏标准化的评估框架和明确的任务定义，使得系统评估和比较LLM在结构化EHR数据上的性能变得困难。

Method: 提出了EHRStruct基准，定义了11个具有代表性的任务，涵盖了不同的临床需求，并使用两个广泛使用的EHR数据集生成2,200个任务特定评估样本。评估了20个先进的和代表性的LLM，分析了输入格式、少样本泛化和微调策略对性能的影响，并与11种最先进的基于LLM的增强方法进行了比较。

Result: 结果表明，许多结构化EHR任务对LLM的理解和推理能力提出了高要求。提出的EHRMaster方法实现了最先进的性能。

Conclusion: 该研究通过引入EHRStruct基准和EHRMaster方法，为结构化EHR数据的LLM评估和提升提供了系统化的框架和解决方案。

Abstract: Structured Electronic Health Record (EHR) data stores patient information in relational tables and plays a central role in clinical decision-making. Recent advances have explored the use of large language models (LLMs) to process such data, showing promise across various clinical tasks.However, the absence of standardized evaluation frameworks and clearly defined tasks makes it difficult to systematically assess and compare LLM performance on structured EHR data.To address these evaluation challenges, we introduce EHRStruct, a benchmark specifically designed to evaluate LLMs on structured EHR tasks.EHRStruct defines 11 representative tasks spanning diverse clinical needs and includes 2,200 task-specific evaluation samples derived from two widely used EHR datasets.We use EHRStruct to evaluate 20 advanced and representative LLMs, covering both general and medical models.We further analyze key factors influencing model performance, including input formats, few-shot generalisation, and finetuning strategies, and compare results with 11 state-of-the-art LLM-based enhancement methods for structured data reasoning. Our results indicate that many structured EHR tasks place high demands on the understanding and reasoning capabilities of LLMs.In response, we propose EHRMaster, a code-augmented method that achieves state-of-the-art performance and offers practical

</details>


### [71] [MADD: Multi-Agent Drug Discovery Orchestra](https://arxiv.org/abs/2511.08217)
*Gleb V. Solovev,Alina B. Zhidkovskaya,Anastasia Orlova,Nina Gubina,Anastasia Vepreva,Rodion Golovinskii,Ilya Tonkii,Ivan Dubrovsky,Ivan Gurev,Dmitry Gilemkhanov,Denis Chistiakov,Timur A. Aliev,Ivan Poddiakov,Galina Zubkova,Ekaterina V. Skorb,Vladimir Vinogradov,Alexander Boukhanovsky,Nikolay Nikitin,Andrei Dmitrenko,Anna Kalyuzhnaya,Andrey Savchenko*

Main category: cs.AI

TL;DR: 本文提出了一种多智能体系统MADD，通过自然语言查询构建和执行定制化的药物筛选流程，提高效率和可访问性。


<details>
  <summary>Details</summary>
Motivation: 在早期药物发现中，命中识别是一个核心挑战，传统方法需要大量实验资源，而现有的虚拟筛选方法复杂且难以访问。多智能体系统结合了LLMs的可解释性和专业模型的精确性，提供了一种有前途的解决方案。

Method: MADD系统采用四个协调智能体，分别处理新化合物生成和筛选中的关键子任务，从自然语言查询中构建和执行定制化的命中识别流程。

Result: 在七个药物发现案例中，MADD表现出优于现有基于LLM的解决方案的性能，成功应用于五个生物靶标的AI优先药物设计，并发布了已识别的命中分子。

Conclusion: MADD系统通过多智能体协作，显著提高了药物发现的效率和可访问性，并引入了一个新的查询-分子对和对接分数基准，为药物设计的智能体化未来做出贡献。

Abstract: Hit identification is a central challenge in early drug discovery, traditionally requiring substantial experimental resources. Recent advances in artificial intelligence, particularly large language models (LLMs), have enabled virtual screening methods that reduce costs and improve efficiency. However, the growing complexity of these tools has limited their accessibility to wet-lab researchers. Multi-agent systems offer a promising solution by combining the interpretability of LLMs with the precision of specialized models and tools. In this work, we present MADD, a multi-agent system that builds and executes customized hit identification pipelines from natural language queries. MADD employs four coordinated agents to handle key subtasks in de novo compound generation and screening. We evaluate MADD across seven drug discovery cases and demonstrate its superior performance compared to existing LLM-based solutions. Using MADD, we pioneer the application of AI-first drug design to five biological targets and release the identified hit molecules. Finally, we introduce a new benchmark of query-molecule pairs and docking scores for over three million compounds to contribute to the agentic future of drug design.

</details>


### [72] [Beyond Distributions: Geometric Action Control for Continuous Reinforcement Learning](https://arxiv.org/abs/2511.08234)
*Zhihao Lin*

Main category: cs.AI

TL;DR: 提出一种新颖的几何动作控制（GAC）方法，通过简化的计算和几何保持，改进了连续控制中的动作生成。


<details>
  <summary>Details</summary>
Motivation: 高斯策略在深度强化学习中占主导地位，但在有界动作空间中，其无限支持需要人为的压缩函数，造成几何失真。虽然vMF分布在球面上提供了理论上的替代方案，但其在实际应用中受限。

Method: 提出GAC，将动作生成分解为方向向量和可学习浓度参数，实现高效插值和简化计算，避免了vMF的复杂性。

Result: 在六个MuJoCo基准测试中，GAC始终匹配或超过最先进的方法，在Ant-v4任务上比SAC提高37.6%，并在6个任务中的4个中取得最佳结果。

Conclusion: 稳健且高效的连续控制不需要复杂分布，而是需要对动作空间几何的合理尊重。

Abstract: Gaussian policies have dominated continuous control in deep reinforcement learning (RL), yet they suffer from a fundamental mismatch: their unbounded support requires ad-hoc squashing functions that distort the geometry of bounded action spaces. While von Mises-Fisher (vMF) distributions offer a theoretically grounded alternative on the sphere, their reliance on Bessel functions and rejection sampling hinders practical adoption. We propose \textbf{Geometric Action Control (GAC)}, a novel action generation paradigm that preserves the geometric benefits of spherical distributions while \textit{simplifying computation}. GAC decomposes action generation into a direction vector and a learnable concentration parameter, enabling efficient interpolation between deterministic actions and uniform spherical noise. This design reduces parameter count from \(2d\) to \(d+1\), and avoids the \(O(dk)\) complexity of vMF rejection sampling, achieving simple \(O(d)\) operations. Empirically, GAC consistently matches or exceeds state-of-the-art methods across six MuJoCo benchmarks, achieving 37.6\% improvement over SAC on Ant-v4 and the best results on 4 out of 6 tasks. Our ablation studies reveal that both \textbf{spherical normalization} and \textbf{adaptive concentration control} are essential to GAC's success. These findings suggest that robust and efficient continuous control does not require complex distributions, but a principled respect for the geometry of action spaces. Code and pretrained models are available in supplementary materials.

</details>


### [73] [Where and What Matters: Sensitivity-Aware Task Vectors for Many-Shot Multimodal In-Context Learning](https://arxiv.org/abs/2511.08246)
*Ziyu Ma,Chenhui Gou,Yiming Hu,Yong Wang,Xiangxiang Chu,Bohan Zhuang,Jianfei Cai*

Main category: cs.AI

TL;DR: 提出了一种新颖的敏感性感知任务向量插入框架（STV），解决了多模态大模型在多示例学习中插入位置与值选择的问题。


<details>
  <summary>Details</summary>
Motivation: 现有任务向量方法在插入位置选择或插入值确定方面存在不足，且难以扩展到多示例设置。

Method: 提出STV框架，利用查询-上下文对的激活增量结构模式确定插入位置，通过预聚类激活库和强化学习选择最合适的插入值。

Result: 在多个多模态模型和任务上验证了STV的有效性，表现出优于以往任务向量方法的性能，并展示了强大的泛化能力。

Conclusion: STV框架提供了一种有效且通用的解决方案，用于确定任务向量的插入位置和值，从而提升了多模态大模型的多示例学习能力。

Abstract: Large Multimodal Models (LMMs) have shown promising in-context learning (ICL) capabilities, but scaling to many-shot settings remains difficult due to limited context length and high inference cost. To address these challenges, task-vector-based methods have been explored by inserting compact representations of many-shot in-context demonstrations into model activations. However, existing task-vector-based methods either overlook the importance of where to insert task vectors or struggle to determine suitable values for each location. To this end, we propose a novel Sensitivity-aware Task Vector insertion framework (STV) to figure out where and what to insert. Our key insight is that activation deltas across query-context pairs exhibit consistent structural patterns, providing a reliable cue for insertion. Based on the identified sensitive-aware locations, we construct a pre-clustered activation bank for each location by clustering the activation values, and then apply reinforcement learning to choose the most suitable one to insert. We evaluate STV across a range of multimodal models (e.g., Qwen-VL, Idefics-2) and tasks (e.g., VizWiz, OK-VQA), demonstrating its effectiveness and showing consistent improvements over previous task-vector-based methods with strong generalization.

</details>


### [74] [DiagramIR: An Automatic Pipeline for Educational Math Diagram Evaluation](https://arxiv.org/abs/2511.08283)
*Vishal Kumar,Shubhra Mishra,Rebecca Hao,Rizwaan Malik,David Broman,Dorottya Demszky*

Main category: cs.AI

TL;DR: 提出DiagramIR，一种基于LaTeX TikZ中间表示的自动可扩展几何图形评估流程。


<details>
  <summary>Details</summary>
Motivation: 现有LLM生成教育用图缺乏可扩展评估方法，尤其在数学等需可视化领域。

Method: 利用TikZ代码的中间表示（IR）构建自动评估流程，与LLM-as-a-Judge等基线对比。

Result: DiagramIR与人工评分一致性更高，GPT-4.1-Mini性能接近GPT-5且成本低10倍。

Conclusion: 该方法提升了评估效率，支持轻量模型实现高性价比教育技术应用。

Abstract: Large Language Models (LLMs) are increasingly being adopted as tools for learning; however, most tools remain text-only, limiting their usefulness for domains where visualizations are essential, such as mathematics. Recent work shows that LLMs are capable of generating code that compiles to educational figures, but a major bottleneck remains: scalable evaluation of these diagrams. We address this by proposing DiagramIR: an automatic and scalable evaluation pipeline for geometric figures. Our method relies on intermediate representations (IRs) of LaTeX TikZ code. We compare our pipeline to other evaluation baselines such as LLM-as-a-Judge, showing that our approach has higher agreement with human raters. This evaluation approach also enables smaller models like GPT-4.1-Mini to perform comparably to larger models such as GPT-5 at a 10x lower inference cost, which is important for deploying accessible and scalable education technologies.

</details>


### [75] [AI-Powered Data Visualization Platform: An Intelligent Web Application for Automated Dataset Analysis](https://arxiv.org/abs/2511.08363)
*Srihari R,Pallavi M,Tejaswini S,Vaishnavi R C*

Main category: cs.AI

TL;DR: 一个自动化数据分析过程的人工智能驱动的数据可视化平台，从上传数据集到生成互动可视化。


<details>
  <summary>Details</summary>
Motivation: 解决手动数据分析耗时的问题，通过自动化AI分析和可视化流程，提高数据分析效率。

Method: 使用Python Flask后端与React前端结合，通过高级机器学习算法进行数据清洗、预处理、特征选择、智能标题生成和可视化。平台与Firebase Cloud Storage集成，支持实时数据处理。

Result: 平台能处理多达100,000行的数据集，支持多用户同时请求，并显著减少了手动输入，同时保持了高质量的可视化输出和用户体验。

Conclusion: 该云数据可视化应用显著减少了数据分析过程中的人工输入，同时维持高质量、有影响力的可视化输出和用户体验。

Abstract: An AI-powered data visualization platform that automates the entire data analysis process, from uploading a dataset to generating an interactive visualization. Advanced machine learning algorithms are employed to clean and preprocess the data, analyse its features, and automatically select appropriate visualizations. The system establishes the process of automating AI-based analysis and visualization from the context of data-driven environments, and eliminates the challenge of time-consuming manual data analysis. The combination of a Python Flask backend to access the dataset, paired with a React frontend, provides a robust platform that automatically interacts with Firebase Cloud Storage for numerous data processing and data analysis solutions and real-time sources. Key contributions include automatic and intelligent data cleaning, with imputation for missing values, and detection of outliers, via analysis of the data set. AI solutions to intelligently select features, using four different algorithms, and intelligent title generation and visualization are determined by the attributes of the dataset. These contributions were evaluated using two separate datasets to assess the platform's performance. In the process evaluation, the initial analysis was performed in real-time on datasets as large as 100000 rows, while the cloud-based demand platform scales to meet requests from multiple users and processes them simultaneously. In conclusion, the cloud-based data visualization application allowed for a significant reduction of manual inputs to the data analysis process while maintaining a high quality, impactful visual outputs, and user experiences

</details>


### [76] [SOM Directions are Better than One: Multi-Directional Refusal Suppression in Language Models](https://arxiv.org/abs/2511.08379)
*Giorgio Piras,Raffaele Mura,Fabio Brau,Luca Oneto,Fabio Roli,Battista Biggio*

Main category: cs.AI

TL;DR: 本文提出了一种利用自组织映射（SOM）提取多拒绝方向的新方法，以提高安全对齐语言模型对有害提示的拒绝能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究将拒绝行为编码为模型潜在空间中的单一方向，但新兴证据表明，LLMs中的概念通常表现为嵌入在高维潜在空间中的低维流形，因此需要探索更复杂的拒绝方向表示。

Method: 提出了一种利用自组织映射（SOM）提取多个拒绝方向的方法，通过训练SOM识别有害提示表示中的多个神经元，并计算这些神经元与无害提示表示质心的差值，得到多个拒绝方向。

Result: 在广泛的实验设置中，该方法通过消融多个方向，不仅在单方向基线表现上优于专门设计的越狱算法，还实现了对拒绝行为的有效抑制。

Conclusion: 通过分析该方法的机制含义，强调了多方向表示在理解LLMs拒绝行为中的重要性。

Abstract: Refusal refers to the functional behavior enabling safety-aligned language models to reject harmful or unethical prompts. Following the growing scientific interest in mechanistic interpretability, recent work encoded refusal behavior as a single direction in the model's latent space; e.g., computed as the difference between the centroids of harmful and harmless prompt representations. However, emerging evidence suggests that concepts in LLMs often appear to be encoded as a low-dimensional manifold embedded in the high-dimensional latent space. Motivated by these findings, we propose a novel method leveraging Self-Organizing Maps (SOMs) to extract multiple refusal directions. To this end, we first prove that SOMs generalize the prior work's difference-in-means technique. We then train SOMs on harmful prompt representations to identify multiple neurons. By subtracting the centroid of harmless representations from each neuron, we derive a set of multiple directions expressing the refusal concept. We validate our method on an extensive experimental setup, demonstrating that ablating multiple directions from models' internals outperforms not only the single-direction baseline but also specialized jailbreak algorithms, leading to an effective suppression of refusal. Finally, we conclude by analyzing the mechanistic implications of our approach.

</details>


### [77] [FaithAct: Faithfulness Planning and Acting in MLLMs](https://arxiv.org/abs/2511.08409)
*Junxian Li,Xinyue Xu,Sai Ma,Sichao Li*

Main category: cs.AI

TL;DR: 本文提出了一种解决大型语言模型在推理过程中产生的不忠实问题的新方法，通过引入FaithEval评估工具及FaithAct框架，提高模型在行为忠实性和感知忠实性方面的表现。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型常生成看似合理却与感知证据或最终结论脱节的推理链，这种不忠实性是一个持续存在的挑战。

Method: 提出FaithEval用于量化步骤级和链级的忠实性，并基于此设计FaithAct，一个以忠实性为先的规划与行动框架，强制每个推理步骤都有证据支持。

Result: 在多个推理基准测试中，FaithAct使感知忠实性提高了最多26%，且未降低任务准确率。

Conclusion: 将忠实性作为指导原则不仅减轻了模型的幻觉现象，还导致更稳定的推理轨迹，为多模态推理建立了一个统一的评估和强化框架。

Abstract: Unfaithfulness remains a persistent challenge for large language models (LLMs), which often produce plausible yet ungrounded reasoning chains that diverge from perceptual evidence or final conclusions. We distinguish between behavioral faithfulness (alignment between reasoning and output) and perceptual faithfulness (alignment between reasoning and input), and introduce FaithEval for quantifying step-level and chain-level faithfulness by evaluating whether each claimed object is visually supported by the image. Building on these insights, we propose FaithAct, a faithfulness-first planning and acting framework that enforces evidential grounding at every reasoning step. Experiments across multiple reasoning benchmarks demonstrate that FaithAct improves perceptual faithfulness by up to 26% without degrading task accuracy compared to prompt-based and tool-augmented baselines. Our analysis shows that treating faithfulness as a guiding principle not only mitigates hallucination but also leads to more stable reasoning trajectories. This work thereby establishes a unified framework for both evaluating and enforcing faithfulness in multimodal reasoning.

</details>


### [78] [Dataset Safety in Autonomous Driving: Requirements, Risks, and Assurance](https://arxiv.org/abs/2511.08439)
*Alireza Abbaspour,Tejaskumar Balgonda Patil,B Ravi Kiran,Russel Mohr,Senthil Yogamani*

Main category: cs.AI

TL;DR: 本文提出了一个符合ISO/PAS 8800指南的结构化框架，用于开发自动驾驶AI系统的安全数据集，介绍了AI Data Flywheel和数据集生命周期，涵盖数据收集、标注、整理和维护，并提出了严格的安全分析、安全需求建立及验证策略，以确保数据集符合安全标准。


<details>
  <summary>Details</summary>
Motivation: 数据集完整性对自动驾驶AI系统的安全性和可靠性至关重要，当前缺乏一个结构化框架来开发符合安全标准的数据集。

Method: 引入AI Data Flywheel和数据集生命周期，覆盖数据收集、标注、整理和维护，并结合严格的安全分析、安全需求建立及验证策略。

Result: 提出了一个结构化框架，定义了数据集的安全需求流程，并提出了验证和确认策略，以确保符合安全标准。

Conclusion: 通过整合这些方法，本文旨在为自动驾驶应用推进稳健且安全可靠的AI系统，并回顾了当前挑战和未来方向。

Abstract: Dataset integrity is fundamental to the safety and reliability of AI systems, especially in autonomous driving. This paper presents a structured framework for developing safe datasets aligned with ISO/PAS 8800 guidelines. Using AI-based perception systems as the primary use case, it introduces the AI Data Flywheel and the dataset lifecycle, covering data collection, annotation, curation, and maintenance. The framework incorporates rigorous safety analyses to identify hazards and mitigate risks caused by dataset insufficiencies. It also defines processes for establishing dataset safety requirements and proposes verification and validation strategies to ensure compliance with safety standards. In addition to outlining best practices, the paper reviews recent research and emerging trends in dataset safety and autonomous vehicle development, providing insights into current challenges and future directions. By integrating these perspectives, the paper aims to advance robust, safety-assured AI systems for autonomous driving applications.

</details>


### [79] [Patching LLM Like Software: A Lightweight Method for Improving Safety Policy in Large Language Models](https://arxiv.org/abs/2511.08484)
*Huzaifa Arif,Keerthiram Murugesan,Ching-Yun Ko,Pin-Yu Chen,Payel Das,Alex Gittens*

Main category: cs.AI

TL;DR: 提出一种类似软件版本修补的轻量级、模块化方法，用于解决大型语言模型（LLM）的安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 主要LLM版本更新成本高且难以满足客户需求，导致已发布模型存在已知的安全缺陷。

Method: 通过添加一个可学习的前缀，以“补丁”方式快速修复现有模型，仅引入0.003%的额外参数。

Result: 在毒性缓解、偏见减少和有害拒绝三个关键领域，策略补丁实现了与下一代安全对齐模型相媲美的安全改进，同时保持模型的流畅性。

Conclusion: LLM可以像软件一样进行“修补”，为供应商和从业者提供了一种在实际应用中进行可扩展、高效和组合的安全更新的实用机制。

Abstract: We propose patching for large language models (LLMs) like software versions, a lightweight and modular approach for addressing safety vulnerabilities. While vendors release improved LLM versions, major releases are costly, infrequent, and difficult to tailor to customer needs, leaving released models with known safety gaps. Unlike full-model fine-tuning or major version updates, our method enables rapid remediation by prepending a compact, learnable prefix to an existing model. This "patch" introduces only 0.003% additional parameters, yet reliably steers model behavior toward that of a safer reference model. Across three critical domains (toxicity mitigation, bias reduction, and harmfulness refusal) policy patches achieve safety improvements comparable to next-generation safety-aligned models while preserving fluency. Our results demonstrate that LLMs can be "patched" much like software, offering vendors and practitioners a practical mechanism for distributing scalable, efficient, and composable safety updates between major model releases.

</details>


### [80] [A Matter of Interest: Understanding Interestingness of Math Problems in Humans and Language Models](https://arxiv.org/abs/2511.08548)
*Shubhra Mishra,Yuka Machino,Gabriel Poesia,Albert Jiang,Joy Hsu,Adrian Weller,Challenger Mishra,David Broman,Joshua B. Tenenbaum,Mateja Jamnik,Cedegao E. Zhang,Katherine M. Collins*

Main category: cs.AI

TL;DR: 本文通过两项实证研究探讨了大型语言模型（LLMs）与人类对数学趣味性和难度判断的契合度。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统（如LLMs）在数学研究和教育中的参与日益增多，了解它们的判断是否与人类一致变得至关重要。

Method: 研究涵盖了两个群体：来自众包平台的参与者和国际数学奥林匹克竞赛的选手。

Result: 许多LLMs在数学趣味性上与人类有广泛的一致性，但在捕捉人类判断分布和选择理由方面表现不佳。

Conclusion: 当前LLMs在捕捉人类对数学趣味性判断方面既有希望也存在限制。

Abstract: The evolution of mathematics has been guided in part by interestingness. From researchers choosing which problems to tackle next, to students deciding which ones to engage with, people's choices are often guided by judgments about how interesting or challenging problems are likely to be. As AI systems, such as LLMs, increasingly participate in mathematics with people -- whether for advanced research or education -- it becomes important to understand how well their judgments align with human ones. Our work examines this alignment through two empirical studies of human and LLM assessment of mathematical interestingness and difficulty, spanning a range of mathematical experience. We study two groups: participants from a crowdsourcing platform and International Math Olympiad competitors. We show that while many LLMs appear to broadly agree with human notions of interestingness, they mostly do not capture the distribution observed in human judgments. Moreover, most LLMs only somewhat align with why humans find certain math problems interesting, showing weak correlation with human-selected interestingness rationales. Together, our findings highlight both the promises and limitations of current LLMs in capturing human interestingness judgments for mathematical AI thought partnerships.

</details>
