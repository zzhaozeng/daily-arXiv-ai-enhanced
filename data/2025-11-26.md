<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 25]
- [cs.AI](#cs.AI) [Total: 16]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Efficient Multi-Hop Question Answering over Knowledge Graphs via LLM Planning and Embedding-Guided Search](https://arxiv.org/abs/2511.19648)
*Manil Shrestha,Edward Kim*

Main category: cs.CL

TL;DR: 提出两种混合算法LLM-Guided Planning和Embedding-Guided Neural Search，解决知识图谱多跳问答的计算效率和可验证性问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖昂贵LLM推理且缺乏结构化知识可验证性，难以实际部署。

Method: 1) 单次LLM调用预测关系序列+广度优先搜索；2) 融合文本/图嵌入的轻量级边评分器；3) 知识蒸馏压缩到4B参数模型。

Result: LLM-Guided Planning微F1>0.90；Embedding-Guided Search提速100倍；4B模型达到大模型零API成本性能。

Conclusion: 可验证推理不需要大规模模型，而需结合符号结构与学习表征的合适架构归纳偏置。

Abstract: Multi-hop question answering over knowledge graphs remains computationally challenging due to the combinatorial explosion of possible reasoning paths. Recent approaches rely on expensive Large Language Model (LLM) inference for both entity linking and path ranking, limiting their practical deployment. Additionally, LLM-generated answers often lack verifiable grounding in structured knowledge. We present two complementary hybrid algorithms that address both efficiency and verifiability: (1) LLM-Guided Planning that uses a single LLM call to predict relation sequences executed via breadth-first search, achieving near-perfect accuracy (micro-F1 > 0.90) while ensuring all answers are grounded in the knowledge graph, and (2) Embedding-Guided Neural Search that eliminates LLM calls entirely by fusing text and graph embeddings through a lightweight 6.7M-parameter edge scorer, achieving over 100 times speedup with competitive accuracy. Through knowledge distillation, we compress planning capability into a 4B-parameter model that matches large-model performance at zero API cost. Evaluation on MetaQA demonstrates that grounded reasoning consistently outperforms ungrounded generation, with structured planning proving more transferable than direct answer generation. Our results show that verifiable multi-hop reasoning does not require massive models at inference time, but rather the right architectural inductive biases combining symbolic structure with learned representations.

</details>


### [2] [Can LLMs Faithfully Explain Themselves in Low-Resource Languages? A Case Study on Emotion Detection in Persian](https://arxiv.org/abs/2511.19719)
*Mobina Mehrazar,Mohammad Amin Yousefi,Parisa Abolfath Beygi,Behnam Bahrak*

Main category: cs.CL

TL;DR: 该研究评估了大型语言模型在低资源语言波斯语情感分类中生成解释的可信度，发现模型解释与人类判断存在较大差异。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在生成预测的同时生成自我解释，但在低资源语言中，这些解释的可信度令人担忧。

Method: 通过在波斯语情感分类的背景下，比较模型识别的影响词与人类标注者识别的影响词，并使用基于标记级对数概率的置信度评分评估可信度。测试了两种提示策略（Predict-then-Explain 和 Explain-then-Predict）对解释可信度的影响。

Result: 尽管LLMs在分类任务中表现出色，但生成的解释往往与可信推理不一致，彼此之间的共识高于与人类判断的共识。

Conclusion: 当前解释方法和指标存在局限，需要更稳健的方法来确保LLM在多语言和少资源环境中的可靠性。

Abstract: Large language models (LLMs) are increasingly used to generate self-explanations alongside their predictions, a practice that raises concerns about the faithfulness of these explanations, especially in low-resource languages. This study evaluates the faithfulness of LLM-generated explanations in the context of emotion classification in Persian, a low-resource language, by comparing the influential words identified by the model against those identified by human annotators. We assess faithfulness using confidence scores derived from token-level log-probabilities. Two prompting strategies, differing in the order of explanation and prediction (Predict-then-Explain and Explain-then-Predict), are tested for their impact on explanation faithfulness. Our results reveal that while LLMs achieve strong classification performance, their generated explanations often diverge from faithful reasoning, showing greater agreement with each other than with human judgments. These results highlight the limitations of current explanation methods and metrics, emphasizing the need for more robust approaches to ensure LLM reliability in multilingual and low-resource contexts.

</details>


### [3] [Comparative Analysis of LoRA-Adapted Embedding Models for Clinical Cardiology Text Representation](https://arxiv.org/abs/2511.19739)
*Richard J. Young,Alice M. Matthews*

Main category: cs.CL

TL;DR: 该研究评估了十种基于Transformer的嵌入模型在心脏病学领域的性能，发现编码器架构（尤其是BioLinkBERT）优于更大的解码器模型，且计算资源需求更低。


<details>
  <summary>Details</summary>
Motivation: 临床自然语言处理需要特定领域的文本嵌入，但不同模型架构间的系统性比较仍然有限。

Method: 通过LoRA对106,535对心脏病学文本进行微调，评估了十种基于Transformer的嵌入模型。

Result: 编码器架构（特别是BioLinkBERT）在领域特定性能上表现最佳（分离度得分0.510），且比更大的解码器模型需要更少计算资源。

Conclusion: 研究结果挑战了大模型必然产生更好领域特定嵌入的假设，为临床NLP系统开发提供了实践指导。所有模型、训练代码和评估数据集均已公开。

Abstract: Domain-specific text embeddings are critical for clinical natural language processing, yet systematic comparisons across model architectures remain limited. This study evaluates ten transformer-based embedding models adapted for cardiology through Low-Rank Adaptation (LoRA) fine-tuning on 106,535 cardiology text pairs derived from authoritative medical textbooks. Results demonstrate that encoder-only architectures, particularly BioLinkBERT, achieve superior domain-specific performance (separation score: 0.510) compared to larger decoder-based models, while requiring significantly fewer computational resources. The findings challenge the assumption that larger language models necessarily produce better domain-specific embeddings and provide practical guidance for clinical NLP system development. All models, training code, and evaluation datasets are publicly available to support reproducible research in medical informatics.

</details>


### [4] [What does it mean to understand language?](https://arxiv.org/abs/2511.19757)
*Colton Casto,Anna Ivanova,Evelina Fedorenko,Nancy Kanwisher*

Main category: cs.CL

TL;DR: 语言理解需要将信息从语言系统导出到负责感知和运动表征、构建心理模型以及存储世界知识和自传体记忆的其他脑区。


<details>
  <summary>Details</summary>
Motivation: 大脑核心语言系统处理能力的局限性促使我们探讨语言理解的深层机制，即如何构建丰富的心理模型。

Method: 回顾支持该假说的现有证据，并讨论认知神经科学的最新进展，为直接测试该假说提供了概念基础和方法。

Result: 提供了证据和理论基础，支持语言理解涉及多个脑区协作，并展示了验证这一假说的可行方法。

Conclusion: 语言理解的深入研究需要跨脑区的信息整合，认知神经科学的进展为此提供了新的策略。

Abstract: Language understanding entails not just extracting the surface-level meaning of the linguistic input, but constructing rich mental models of the situation it describes. Here we propose that because processing within the brain's core language system is fundamentally limited, deeply understanding language requires exporting information from the language system to other brain regions that compute perceptual and motor representations, construct mental models, and store our world knowledge and autobiographical memories. We review the existing evidence for this hypothesis, and argue that recent progress in cognitive neuroscience provides both the conceptual foundation and the methods to directly test it, thus opening up a new strategy to reveal what it means, cognitively and neurally, to understand language.

</details>


### [5] [Gender Bias in Emotion Recognition by Large Language Models](https://arxiv.org/abs/2511.19785)
*Maureen Herbert,Katie Sun,Angelica Lim,Yasaman Etesam*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型在情感理论心智任务中的性别偏见，并探讨了多种去偏策略，发现基于训练的去偏方法比推理时的提示工程方法更有效。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在日常生活的广泛应用，确保其公平性变得至关重要。本文聚焦于情感理论心智任务中的性别偏见问题。

Method: 提出了几种去偏策略，包括基于训练和推理时的方法，并通过实验评估其效果。

Result: 实验表明，仅依靠推理时的提示工程方法无法显著减少偏见，而基于训练的去偏方法能更有效地降低偏见。

Conclusion: 为了在大型语言模型中实现有意义的偏见减少，必须采用基于训练的去偏方法，而不是仅仅依赖推理时的提示工程。

Abstract: The rapid advancement of large language models (LLMs) and their growing integration into daily life underscore the importance of evaluating and ensuring their fairness. In this work, we examine fairness within the domain of emotional theory of mind, investigating whether LLMs exhibit gender biases when presented with a description of a person and their environment and asked, "How does this person feel?". Furthermore, we propose and evaluate several debiasing strategies, demonstrating that achieving meaningful reductions in bias requires training based interventions rather than relying solely on inference-time prompt-based approaches such as prompt engineering.

</details>


### [6] [Breaking Bad: Norms for Valence, Arousal, and Dominance for over 10k English Multiword Expressions](https://arxiv.org/abs/2511.19816)
*Saif M. Mohammad*

Main category: cs.CL

TL;DR: 本文介绍了一种扩展的情感词典NRC VAD Lexicon v2，增加了对10k多词表达（MWEs）及其组成词的情感评分，并提高了对2018年以来常用词的覆盖。


<details>
  <summary>Details</summary>
Motivation: 多词表达在日常语言中常见，但现有词典缺乏对其情感评分，因此需要扩展词典以支持更广泛的跨学科研究。

Method: 通过人工评分，扩展了NRC VAD Lexicon，增加了10k MWEs和25k单词的条目，并评估了MWEs的情感特征及其情感组合性。

Result: 新词典的评分具有高可信度，扩展后的词典可用于分析MWEs的情感强度和情感组合性。

Conclusion: NRC VAD Lexicon v2支持在自然语言处理、心理学、公共卫生、数字人文和社会科学等领域的广泛应用，并可免费获取。

Abstract: Factor analysis studies have shown that the primary dimensions of word meaning are Valence (V), Arousal (A), and Dominance (D). Existing lexicons such as the NRC VAD Lexicon, published in 2018, include VAD association ratings for words. Here, we present a complement to it, which has human ratings of valence, arousal, and dominance for 10k English Multiword Expressions (MWEs) and their constituent words. We also increase the coverage of unigrams, especially words that have become more common since 2018. In all, the new NRC VAD Lexicon v2 now has entries for 10k MWEs and 25k words, in addition to the entries in v1. We show that the associations are highly reliable. We use the lexicon to examine emotional characteristics of MWEs, including: 1. The degree to which MWEs (idioms, noun compounds, and verb particle constructions) exhibit strong emotionality; 2. The degree of emotional compositionality in MWEs. The lexicon enables a wide variety of research in NLP, Psychology, Public Health, Digital Humanities, and Social Sciences. The NRC VAD Lexicon v2 is freely available through the project webpage: http://saifmohammad.com/WebPages/nrc-vad.html

</details>


### [7] [Language-Independent Sentiment Labelling with Distant Supervision: A Case Study for English, Sepedi and Setswana](https://arxiv.org/abs/2511.19818)
*Koena Ronny Mabokela,Tim Schlippe,Mpho Raborife,Turgay Celik*

Main category: cs.CL

TL;DR: 本文提出了一种自动、语言无关的情感标注方法，利用带有情感的emojis和词汇进行标注，显著减少了人工标注的工作量。


<details>
  <summary>Details</summary>
Motivation: 由于人工标注文本数据耗时且昂贵，许多非洲语言因缺乏带标注的数字语言资源而被归为低资源语言，因此需要自动且高效的标注过程。

Method: 提出并分析了一种自动语言无关情感标注方法，利用情感承载的emojis和词汇进行标注。

Result: 实验表明，该方法对英语、Sepedi和茨瓦纳语（Setswana）推文的标注准确率分别为66%、69%和63%，平均只有34%的自动生成的标签需要修正。

Conclusion: 该方法有效地减少了人工标注的工作量，提高了标注效率，适用于低资源语言的情感标注。

Abstract: Sentiment analysis is a helpful task to automatically analyse opinions and emotions on various topics in areas such as AI for Social Good, AI in Education or marketing. While many of the sentiment analysis systems are developed for English, many African languages are classified as low-resource languages due to the lack of digital language resources like text labelled with corresponding sentiment classes. One reason for that is that manually labelling text data is time-consuming and expensive. Consequently, automatic and rapid processes are needed to reduce the manual effort as much as possible making the labelling process as efficient as possible. In this paper, we present and analyze an automatic language-independent sentiment labelling method that leverages information from sentiment-bearing emojis and words. Our experiments are conducted with tweets in the languages English, Sepedi and Setswana from SAfriSenti, a multilingual sentiment corpus for South African languages. We show that our sentiment labelling approach is able to label the English tweets with an accuracy of 66%, the Sepedi tweets with 69%, and the Setswana tweets with 63%, so that on average only 34% of the automatically generated labels remain to be corrected.

</details>


### [8] [Profile-LLM: Dynamic Profile Optimization for Realistic Personality Expression in LLMs](https://arxiv.org/abs/2511.19852)
*Shi-Wei Dai,Yan-Wei Shie,Tsung-Huan Yang,Lun-Wei Ku,Yung-Hui Li*

Main category: cs.CL

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Personalized Large Language Models (LLMs) have been shown to be an effective way to create more engaging and enjoyable user-AI interactions. While previous studies have explored using prompts to elicit specific personality traits in LLMs, they have not optimized these prompts to maximize personality expression. To address this limitation, we propose PersonaPulse: Dynamic Profile Optimization for Realistic Personality Expression in LLMs, a framework that leverages LLMs' inherent knowledge of personality traits to iteratively enhance role-play prompts while integrating a situational response benchmark as a scoring tool, ensuring a more realistic and contextually grounded evaluation to guide the optimization process. Quantitative evaluations demonstrate that the prompts generated by PersonaPulse outperform those of prior work, which were designed based on personality descriptions from psychological studies. Additionally, we explore the relationship between model size and personality modeling through extensive experiments. Finally, we find that, for certain personality traits, the extent of personality evocation can be partially controlled by pausing the optimization process. These findings underscore the importance of prompt optimization in shaping personality expression within LLMs, offering valuable insights for future research on adaptive AI interactions.

</details>


### [9] [A Systematic Analysis of Large Language Models with RAG-enabled Dynamic Prompting for Medical Error Detection and Correction](https://arxiv.org/abs/2511.19858)
*Farzad Ahmed,Joniel Augustine Jerome,Meliha Yetisgen,Özlem Uzuner*

Main category: cs.CL

TL;DR: 该论文评估了不同提示策略在医疗错误处理中的表现，发现检索增强的动态提示（RDP）优于零样本提示和静态提示。


<details>
  <summary>Details</summary>
Motivation: 临床文档中存在影响患者安全的错误，大型语言模型（LLMs）有潜力帮助检测与纠正这些错误，但其在不同提示策略下的行为仍不清楚。

Method: 使用MEDEC数据集，评估了九种指令调优的LLMs在零样本提示、随机范例静态提示（SPR）和检索增强动态提示（RDP）下的表现，并分析了准确性、召回率、假阳性率和错误修正的聚合分数。

Result: 零样本提示在检测任务中召回率低，SPR提高了召回率但增加了假阳性率。RDP在所有LLMs中降低了假阳性率，提高了错误句子检测的召回率，并生成了更准确的修正。

Conclusion: RDP在不同LLMs中表现优于零样本和SPR提示，使用检索范例提高了检测准确性，减少了假阳性，增强了医疗错误修正的可靠性。

Abstract: Objective: Clinical documentation contains factual, diagnostic, and management errors that can compromise patient safety. Large language models (LLMs) may help detect and correct such errors, but their behavior under different prompting strategies remains unclear. We evaluate zero-shot prompting, static prompting with random exemplars (SPR), and retrieval-augmented dynamic prompting (RDP) for three subtasks of medical error processing: error flag detection, error sentence detection, and error correction.
  Methods: Using the MEDEC dataset, we evaluated nine instruction-tuned LLMs (GPT, Claude, Gemini, and OpenAI o-series models). We measured performance using accuracy, recall, false-positive rate (FPR), and an aggregate score of ROUGE-1, BLEURT, and BERTScore for error correction. We also analyzed example outputs to identify failure modes and differences between LLM and clinician reasoning.
  Results: Zero-shot prompting showed low recall in both detection tasks, often missing abbreviation-heavy or atypical errors. SPR improved recall but increased FPR. Across all nine LLMs, RDP reduced FPR by about 15 percent, improved recall by 5 to 10 percent in error sentence detection, and generated more contextually accurate corrections.
  Conclusion: Across diverse LLMs, RDP outperforms zero-shot and SPR prompting. Using retrieved exemplars improves detection accuracy, reduces false positives, and enhances the reliability of medical error correction.

</details>


### [10] [$\text{R}^2\text{R}$: A Route-to-Rerank Post-Training Framework for Multi-Domain Decoder-Only Rerankers](https://arxiv.org/abs/2511.19987)
*Xinyu Wang,Hanwei Wu,Qingchen Hu,Zhenghan Tai,Jingrui Tian,Lei Ding,Jijun Chi,Hailin He,Tung Sum Thomas Kwok,Yufei Cui,Sicheng Lyu,Muzhi Li,Mingze Li,Xinyue Yu,Ling Zhou,Peng Lu*

Main category: cs.CL

TL;DR: 引入R2R框架，结合动态专家路由和两阶段训练策略EAG，以解决领域特定重排序中的表面形式过拟合和灾难性遗忘问题。


<details>
  <summary>Details</summary>
Motivation: 通用模型在高风险领域（如金融和法律）中无法捕捉领域特定的细微差别，而简单的微调会导致表面形式过拟合和灾难性遗忘。

Method: R2R框架结合动态专家路由和EAG策略，通过屏蔽最具预测性的表面线索，迫使重排序器学习领域不变的相关性模式，并使用轻量级潜在语义路由器激活领域专家。

Result: 在不同重排序器骨干和多个领域（法律、医疗和金融）的实验中，R2R始终优于通用和单领域微调的基线。

Conclusion: R2R是一种模型无关且模块化的领域专业化方法，具有强大的跨领域鲁棒性。

Abstract: Decoder-only rerankers are central to Retrieval-Augmented Generation (RAG). However, generalist models miss domain-specific nuances in high-stakes fields like finance and law, and naive fine-tuning causes surface-form overfitting and catastrophic forgetting. To address this challenge, we introduce R2R, a domain-aware framework that combines dynamic expert routing with a two-stage training strategy, Entity Abstraction for Generalization (EAG). EAG introduces a counter-shortcut mechanism by masking the most predictive surface cues, forcing the reranker to learn domain-invariant relevance patterns rather than memorizing dataset-specific entities. To efficiently activate domain experts, R2R employs a lightweight Latent Semantic Router that probes internal representations from the frozen backbone decoder to select the optimal LoRA expert per query. Extensive experiments across different reranker backbones and diverse domains (legal, medical, and financial) demonstrate that R2R consistently surpasses generalist and single-domain fine-tuned baselines. Our results confirm that R2R is a model-agnostic and modular approach to domain specialization with strong cross-domain robustness.

</details>


### [11] [Directional Optimization Asymmetry in Transformers: A Synthetic Stress Test](https://arxiv.org/abs/2511.19997)
*Mihir Sahasrabudhe*

Main category: cs.CL

TL;DR: 本文通过一个完全合成的、熵可控的基准测试，揭示了Transformer在训练中固有的方向性摩擦，即使在无语义先验、词频和语料库时间不对称的情况下，Transformer的逆映射任务仍比正向映射任务更难。


<details>
  <summary>Details</summary>
Motivation: 尽管Transformer在理论上具有反转不变性，但经验研究和最近的工作表明，自然语言处理中存在方向性失败。为了确定这些失败是源于语言统计还是架构本身，作者设计了一个干净的基准测试。

Method: 使用具有可调分支因子K的随机字符串映射，构建了具有零条件熵的前向任务和分析确定的熵下限的逆任务，并通过完全合成的熵控制基准测试来检验方向性学习。

Result: 即使是经过从头训练的GPT-2模型也表现出强大且可重复的方向性优化差距（例如，在K=5时差距为1.16 nats），这种差距远大于在相同数据上训练的MLP。预训练初始化和LoRA方法未能消除这一差距。

Conclusion: Transformer的训练中存在固有的方向性摩擦，这种摩擦即使在去除语言先验、词频和语料库时间不对称的情况下依然存在，表明逆映射任务对Transformer来说本质上更难。基准测试为分析现代序列模型中的方向性偏差提供了受控工具。

Abstract: Transformers are theoretically reversal-invariant: their function class does not prefer left-to-right over right-to-left mappings. Yet empirical studies on natural language repeatedly report a "reversal curse," and recent work on temporal asymmetry in LLMs suggests that real-world corpora carry their own arrow of time. This leaves an unresolved question: do directional failures stem from linguistic statistics, or from the architecture itself? We cut through this ambiguity with a fully synthetic, entropy-controlled benchmark designed as a clean-room stress test for directional learning. Using random string mappings with tunable branching factor K, we construct forward tasks with zero conditional entropy and inverse tasks with analytically determined entropy floors. Excess loss above these floors reveals that even scratch-trained GPT-2 models exhibit a strong, reproducible directional optimization gap (e.g., 1.16 nats at K=5), far larger than that of an MLP trained on the same data. Pre-trained initializations shift optimization behavior but do not eliminate this gap, while LoRA encounters a sharp capacity wall on high-entropy inverse mappings. Together, these results isolate a minimal, semantics-free signature of directional friction intrinsic to causal Transformer training-one that persists even when linguistic priors, token frequencies, and corpus-level temporal asymmetries are removed. Our benchmark provides a controlled instrument for dissecting directional biases in modern sequence models and motivates deeper mechanistic study of why inversion remains fundamentally harder for Transformers.

</details>


### [12] [Online-PVLM: Advancing Personalized VLMs with Online Concept Learning](https://arxiv.org/abs/2511.20056)
*Huiyu Bai,Runze Wang,Zhuoyun Du,Yiyang Zhao,Fengji Zhang,Haoyu Chen,Xiaoyong Zhu,Bo Zheng,Xuejiao Zhao*

Main category: cs.CL

TL;DR: 本文提出了一种新的框架Online-PVLM，利用双曲表示进行在线概念学习，以支持个性化视觉语言模型在测试时的实时适应。


<details>
  <summary>Details</summary>
Motivation: 个性化视觉语言模型在用户特定概念对齐交互方面表现出色，但现有方法需要为每个新概念学习单独的嵌入，无法在测试期间支持实时适应，尤其在大规模场景下效率低下。

Method: 提出了Online-PVLM框架，通过双曲表示实现测试时无需训练即可生成概念嵌入，并开发了一个包含1,292个概念和30K高质量实例的大规模基准OP-Eval来评估在线概念学习。

Result: 大量实验验证了该框架的先进性能，证明其在个性化和效率方面的优势。

Conclusion: Online-PVLM框架通过双曲表示和无需训练的方法，使得个性化视觉语言模型在大规模场景下更加可扩展和高效。

Abstract: Personalized Visual Language Models (VLMs) are gaining increasing attention for their formidable ability in user-specific concepts aligned interactions (e.g., identifying a user's bike). Existing methods typically require the learning of separate embeddings for each new concept, which fails to support real-time adaptation during testing. This limitation becomes particularly pronounced in large-scale scenarios, where efficient retrieval of concept embeddings is not achievable. To alleviate this gap, we propose Online-PVLM, a framework for online concept learning by leveraging hyperbolic representations. Our approach makes a train-free paradigm for concept embeddings generation at test time, making the use of personalized VLMs both scalable and efficient. In addition, we develop OP-Eval, a comprehensive and large-scale benchmark comprising 1,292 concepts and over 30K high-quality instances with diverse question types, designed to rigorously assess online concept learning in realistic scenarios. Extensive experiments demonstrate the state-of-the-art performance of our proposed framework. Our source code and dataset will be made available.

</details>


### [13] [MTA: A Merge-then-Adapt Framework for Personalized Large Language Model](https://arxiv.org/abs/2511.20072)
*Xiaopeng Li,Yuanjin Zheng,Wanyu Wang,wenlin zhang,Pengyue Jia,Yiqi Wang,Maolin Wang,Xuetao Wei,Xiangyu Zhao*

Main category: cs.CL

TL;DR: 提出一种用于个性化大型语言模型（PLLM）的Merge-then-Adapt（MTA）框架，解决了传统方法存储成本高和稀疏数据下性能不佳的问题。


<details>
  <summary>Details</summary>
Motivation: 个性化大型语言模型需要适应用户的特定偏好，但现有方法存在存储成本高和在数据稀疏情况下表现不佳的局限性。

Method: MTA框架包含三个阶段：构建共享Meta-LoRA Bank，引入Adaptive LoRA Fusion阶段进行动态个性化组合，以及LoRA Stacking for Few-Shot Personalization阶段，用于在少量数据下进行个性化。

Result: 在LaMP基准上的广泛实验表明，MTA在多个任务上优于现有的SOTA方法。

Conclusion: MTA框架提供了一种可扩展且灵活的个性化解决方案，显著降低了存储成本，并提高了在稀疏数据下的性能。

Abstract: Personalized Large Language Models (PLLMs) aim to align model outputs with individual user preferences, a crucial capability for user-centric applications. However, the prevalent approach of fine-tuning a separate module for each user faces two major limitations: (1) storage costs scale linearly with the number of users, rendering the method unscalable; and (2) fine-tuning a static model from scratch often yields suboptimal performance for users with sparse data. To address these challenges, we propose MTA, a Merge-then-Adapt framework for PLLMs. MTA comprises three key stages. First, we construct a shared Meta-LoRA Bank by selecting anchor users and pre-training meta-personalization traits within meta-LoRA modules. Second, to ensure scalability and enable dynamic personalization combination beyond static models, we introduce an Adaptive LoRA Fusion stage. This stage retrieves and dynamically merges the most relevant anchor meta-LoRAs to synthesize a user-specific one, thereby eliminating the need for user-specific storage and supporting more flexible personalization. Third, we propose a LoRA Stacking for Few-Shot Personalization stage, which applies an additional ultra-low-rank, lightweight LoRA module on top of the merged LoRA. Fine-tuning this module enables effective personalization under few-shot settings. Extensive experiments on the LaMP benchmark demonstrate that our approach outperforms existing SOTA methods across multiple tasks.

</details>


### [14] [More Bias, Less Bias: BiasPrompting for Enhanced Multiple-Choice Question Answering](https://arxiv.org/abs/2511.20086)
*Duc Anh Vu,Thong Nguyen,Cong-Duy Nguyen,Viet Anh Nguyen,Anh Tuan Luu*

Main category: cs.CL

TL;DR: 提出了一种名为BiasPrompting的新推理框架，旨在通过为所有可能的答案选项生成和评估推理，提高大型语言模型在多项选择题任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前方法在多项选择题任务中存在关键限制，答案选项通常没有上下文支持或解释，导致模型对所有可能答案的探索不完整，降低了推理能力。

Method: BiasPrompting由两个阶段组成：首先，推理生成阶段，模型为每个答案选项生成支持性推理；其次，推理引导的一致阶段，综合生成的推理以选择最合理的答案。

Result: 在五个广泛使用的多项选择题问答基准测试中，BiasPrompting展示了显著的改进，并提高了LLMs的推理能力。

Conclusion: BiasPrompting为应对复杂和具有挑战性的问题提供了坚实的基础，尤其是在现有方法表现不佳的情况下。

Abstract: With the advancement of large language models (LLMs), their performance on multiple-choice question (MCQ) tasks has improved significantly. However, existing approaches face key limitations: answer choices are typically presented to LLMs without contextual grounding or explanation. This absence of context can lead to incomplete exploration of all possible answers, ultimately degrading the models' reasoning capabilities. To address these challenges, we introduce BiasPrompting, a novel inference framework that guides LLMs to generate and critically evaluate reasoning across all plausible answer options before reaching a final prediction. It consists of two components: first, a reasoning generation stage, where the model is prompted to produce supportive reasonings for each answer option, and then, a reasoning-guided agreement stage, where the generated reasonings are synthesized to select the most plausible answer. Through comprehensive evaluations, BiasPrompting demonstrates significant improvements in five widely used multiple-choice question answering benchmarks. Our experiments showcase that BiasPrompting enhances the reasoning capabilities of LLMs and provides a strong foundation for tackling complex and challenging questions, particularly in settings where existing methods underperform.

</details>


### [15] [SSA: Sparse Sparse Attention by Aligning Full and Sparse Attention Outputs in Feature Space](https://arxiv.org/abs/2511.20102)
*Zhenyi Shen,Junru Lu,Lin Gui,Jiazheng Li,Yulan He,Di Yin,Xing Sun*

Main category: cs.CL

TL;DR: 提出SSA（Sparse Sparse Attention）框架，解决稀疏注意力中的梯度更新不足问题，实现高效的长上下文处理，并在多个基准上取得最优性能。


<details>
  <summary>Details</summary>
Motivation: 全注意力的二次复杂性限制了大型语言模型（LLM）高效处理长上下文。尽管稀疏注意力降低了成本，但常导致性能下降。现有方法在稀疏性上表现不佳，存在矛盾。

Method: 提出SSA，一种统一的训练框架，考虑稀疏和全注意力，强制每层的双向对齐，保持所有标记的梯度流，并鼓励稀疏注意力输出与全注意力对齐，从而增强稀疏性。

Result: SSA在稀疏和全注意力推理下，在多个常识基准上实现了最先进的性能。模型能够适应不同的稀疏预算，推理时灵活权衡计算和性能。

Conclusion: 原生稀疏注意力训练通过减轻注意力值在汇聚区域的过度分配，意外改善了长上下文的外推，SSA展现出最强外推能力。

Abstract: The quadratic complexity of full attention limits efficient long-context processing in large language models (LLMs). Sparse attention mitigates this cost by restricting each query to attend to a subset of previous tokens; however, training-free approaches often lead to severe performance degradation. Native sparse-attention methods (e.g., NSA, MoBA) alleviate this issue, yet exhibit a critical paradox: they produce lower attention sparsity than full-attention models, despite aiming to approximate full attention, which may constrain their effectiveness. We attribute this paradox to gradient update deficiency: low-ranked key-value pairs excluded during sparse training receive neither forward contribution nor backward gradients, and thus never learn proper suppression. To overcome this limitation, we propose SSA (Sparse Sparse Attention), a unified training framework that considers both sparse and full attention and enforces bidirectional alignment at every layer. This design preserves gradient flow to all tokens while explicitly encouraging sparse-attention outputs to align with their full-attention counterparts, thereby promoting stronger sparsity. As a result, SSA achieves state-of-the-art performance under both sparse and full attention inference across multiple commonsense benchmarks. Furthermore, SSA enables models to adapt smoothly to varying sparsity budgets; performance improves consistently as more tokens are allowed to attend, supporting flexible compute-performance trade-offs at inference time. Finally, we show that native sparse-attention training surprisingly improves long-context extrapolation by mitigating the over-allocation of attention values in sink areas, with SSA demonstrating the strongest extrapolation capability.

</details>


### [16] [EM2LDL: A Multilingual Speech Corpus for Mixed Emotion Recognition through Label Distribution Learning](https://arxiv.org/abs/2511.20106)
*Xingfeng Li,Xiaohan Shi,Junjie Li,Yongwei Li,Masashi Unoki,Tomoki Toda,Masato Akagi*

Main category: cs.CL

TL;DR: EM2LDL是一个新颖的多语言语音语料库，通过标签分布学习推进混合情感识别。


<details>
  <summary>Details</summary>
Motivation: 解决现有语料库语言多样性不足、单标签情感建模以及生态效度低的问题。

Method: 包含英语、普通话和粤语的表达性话语，并整合了来自在线平台的自然情感表达，在32个类别上进行细致的情感分布标注。

Result: 使用自监督学习模型进行实验，HuBERT-large-EN在性别、年龄和人格独立评估中表现最佳。

Conclusion: EM2LDL通过纳入语言多样性和生态效度，为开发适应性强、具有共情能力的系统提供了多功能测试平台，适用于情感计算中的心理健康监测和跨文化交际等应用。

Abstract: This study introduces EM2LDL, a novel multilingual speech corpus designed to advance mixed emotion recognition through label distribution learning. Addressing the limitations of predominantly monolingual and single-label emotion corpora \textcolor{black}{that restrict linguistic diversity, are unable to model mixed emotions, and lack ecological validity}, EM2LDL comprises expressive utterances in English, Mandarin, and Cantonese, capturing the intra-utterance code-switching prevalent in multilingual regions like Hong Kong and Macao. The corpus integrates spontaneous emotional expressions from online platforms, annotated with fine-grained emotion distributions across 32 categories. Experimental baselines using self-supervised learning models demonstrate robust performance in speaker-independent gender-, age-, and personality-based evaluations, with HuBERT-large-EN achieving optimal results. By incorporating linguistic diversity and ecological validity, EM2LDL enables the exploration of complex emotional dynamics in multilingual settings. This work provides a versatile testbed for developing adaptive, empathetic systems for applications in affective computing, including mental health monitoring and cross-cultural communication. The dataset, annotations, and baseline codes are publicly available at https://github.com/xingfengli/EM2LDL.

</details>


### [17] [Mispronunciation Detection and Diagnosis Without Model Training: A Retrieval-Based Approach](https://arxiv.org/abs/2511.20107)
*Huu Tuong Tu,Ha Viet Khanh,Tran Tien Dat,Vu Huan,Thien Van Luong,Nguyen Tien Cuong,Nguyen Thi Thu Trang*

Main category: cs.CL

TL;DR: 提出了一种无需训练的利用检索技术和预训练语音识别模型的发音错误检测与诊断框架。


<details>
  <summary>Details</summary>
Motivation: 发音错误检测与诊断对语言学习和言语治疗至关重要，传统方法复杂且需要大量训练。

Method: 利用检索技术和预训练ASR模型，避免音素建模或额外任务特定训练。

Result: 在L2-ARCTIC数据集上，该方法实现了69.60%的F1得分。

Conclusion: 该方法在避免模型训练复杂性的同时，实现了准确的发音错误检测和诊断。

Abstract: Mispronunciation Detection and Diagnosis (MDD) is crucial for language learning and speech therapy. Unlike conventional methods that require scoring models or training phoneme-level models, we propose a novel training-free framework that leverages retrieval techniques with a pretrained Automatic Speech Recognition model. Our method avoids phoneme-specific modeling or additional task-specific training, while still achieving accurate detection and diagnosis of pronunciation errors. Experiments on the L2-ARCTIC dataset show that our method achieves a superior F1 score of 69.60% while avoiding the complexity of model training.

</details>


### [18] ["When Data is Scarce, Prompt Smarter"... Approaches to Grammatical Error Correction in Low-Resource Settings](https://arxiv.org/abs/2511.20120)
*Somsubhra De,Harsh Kumar,Arun Prakash A*

Main category: cs.CL

TL;DR: 本文探索了基于提示学习的大语言模型在低资源印度语系语法纠错任务上的应用，发现即使简单提示策略也能显著超越传统微调方法。


<details>
  <summary>Details</summary>
Motivation: 由于印度语系语言资源稀缺、形态复杂，传统语法纠错方法进展有限，需要探索更有效的低资源解决方案。

Method: 采用GPT-4.1、Gemini-2.5和LLaMA-4等先进大模型，结合零样本/少样本提示策略，设计轻量级适配方案。

Result: 在共享任务中取得优异成绩：泰米尔语(GLEU:91.57)和印地语(85.69)第1，泰卢固语(85.22)第2，孟加拉语(92.86)第4，马拉雅拉姆语(92.97)第5。

Conclusion: 现代大模型具有强大的多语言泛化能力，提示学习方法能有效弥合多语言语法纠错任务中的资源差距。

Abstract: Grammatical error correction (GEC) is an important task in Natural Language Processing that aims to automatically detect and correct grammatical mistakes in text. While recent advances in transformer-based models and large annotated datasets have greatly improved GEC performance for high-resource languages such as English, the progress has not extended equally. For most Indic languages, GEC remains a challenging task due to limited resources, linguistic diversity and complex morphology. In this work, we explore prompting-based approaches using state-of-the-art large language models (LLMs), such as GPT-4.1, Gemini-2.5 and LLaMA-4, combined with few-shot strategy to adapt them to low-resource settings. We observe that even basic prompting strategies, such as zero-shot and few-shot approaches, enable these LLMs to substantially outperform fine-tuned Indic-language models like Sarvam-22B, thereby illustrating the exceptional multilingual generalization capabilities of contemporary LLMs for GEC. Our experiments show that carefully designed prompts and lightweight adaptation significantly enhance correction quality across multiple Indic languages. We achieved leading results in the shared task--ranking 1st in Tamil (GLEU: 91.57) and Hindi (GLEU: 85.69), 2nd in Telugu (GLEU: 85.22), 4th in Bangla (GLEU: 92.86), and 5th in Malayalam (GLEU: 92.97). These findings highlight the effectiveness of prompt-driven NLP techniques and underscore the potential of large-scale LLMs to bridge resource gaps in multilingual GEC.

</details>


### [19] [SEDA: A Self-Adapted Entity-Centric Data Augmentation for Boosting Gird-based Discontinuous NER Models](https://arxiv.org/abs/2511.20143)
*Wen-Fang Su,Hsiao-Wei Chou,Wen-Yang Lin*

Main category: cs.CL

TL;DR: 该论文提出了一种利用图像数据增强技术改进的网格标记方法，以更好地识别不连续的命名实体。


<details>
  <summary>Details</summary>
Motivation: 解决传统文本分割方法在处理跨句子不连续实体时的误分割和遗漏问题，提高命名实体识别的准确性。

Method: 将图像数据增强技术（如裁剪、缩放和填充）集成到基于网格的模型中，以增强对不连续实体的识别能力。

Result: 在CADEC, ShARe13, 和ShARe14数据集上的实验表明，该方法总体F1分数提高了1-2.5%，对不连续实体的F1分数提高了3.7-8.4%。

Conclusion: 图像数据增强技术结合网格标记方法显著提高了不连续实体的识别性能，验证了该方法的有效性。

Abstract: Named Entity Recognition (NER) is a critical task in natural language processing, yet it remains particularly challenging for discontinuous entities. The primary difficulty lies in text segmentation, as traditional methods often missegment or entirely miss cross-sentence discontinuous entities, significantly affecting recognition accuracy. Therefore, we aim to address the segmentation and omission issues associated with such entities. Recent studies have shown that grid-tagging methods are effective for information extraction due to their flexible tagging schemes and robust architectures. Building on this, we integrate image data augmentation techniques, such as cropping, scaling, and padding, into grid-based models to enhance their ability to recognize discontinuous entities and handle segmentation challenges. Experimental results demonstrate that traditional segmentation methods often fail to capture cross-sentence discontinuous entities, leading to decreased performance. In contrast, our augmented grid models achieve notable improvements. Evaluations on the CADEC, ShARe13, and ShARe14 datasets show F1 score gains of 1-2.5% overall and 3.7-8.4% for discontinuous entities, confirming the effectiveness of our approach.

</details>


### [20] [KyrgyzBERT: A Compact, Efficient Language Model for Kyrgyz NLP](https://arxiv.org/abs/2511.20182)
*Adilet Metinov,Gulida M. Kudakeeva,Gulnara D. Kabaeva*

Main category: cs.CL

TL;DR: 介绍KyrgyzBERT，首个公开的基于BERT的吉尔吉斯语单语语言模型，并构建了一个情感分析基准数据集kyrgyz-sst2。


<details>
  <summary>Details</summary>
Motivation: 吉尔吉斯语资源稀缺，缺乏基础NLP工具，需开发专门的语言模型以支持相关研究。

Method: 构建了3590万参数的KyrgyzBERT模型，并设计了一个适应吉尔吉斯语形态结构的自定义分词器。创建了kyrgyz-sst2情感分析基准数据集，通过翻译和手动标注斯坦福情感树库得到。

Result: 在kyrgyz-sst2数据集上微调的KyrgyzBERT模型实现了0.8280的F1分数，性能与五倍大的mBERT模型相当。

Conclusion: KyrgyzBERT为吉尔吉斯语NLP研究提供了有力工具，所有模型、数据和代码均已开源以支持未来研究。

Abstract: Kyrgyz remains a low-resource language with limited foundational NLP tools. To address this gap, we introduce KyrgyzBERT, the first publicly available monolingual BERT-based language model for Kyrgyz. The model has 35.9M parameters and uses a custom tokenizer designed for the language's morphological structure. To evaluate performance, we create kyrgyz-sst2, a sentiment analysis benchmark built by translating the Stanford Sentiment Treebank and manually annotating the full test set. KyrgyzBERT fine-tuned on this dataset achieves an F1-score of 0.8280, competitive with a fine-tuned mBERT model five times larger. All models, data, and code are released to support future research in Kyrgyz NLP.

</details>


### [21] [REFLEX: Self-Refining Explainable Fact-Checking via Disentangling Truth into Style and Substance](https://arxiv.org/abs/2511.20233)
*Chuyi Kong,Gao Wei,Jing Ma,Hongzhan Lin,Zhiyuan Fan*

Main category: cs.CL

TL;DR: 提出REFLEX，一个通过内部知识增强判决准确性和解释质量的自完善、即插即用的虚假信息核查系统。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的方法依赖外部知识，导致延迟和幻觉问题，影响实时性和可靠性。

Method: REFLEX将事实核查重构为角色扮演对话，并共同训练判决预测和解释生成，提取对比激活对以构建指导向量，自然解耦风格和内容。

Result: REFLEX在真实数据集上超越以往方法，仅用465个自完善训练样本实现最先进性能，解释性目标能有效引导非解释性模型，提升高达7.57%。

Conclusion: REFLEX通过内部知识引导核查过程，提高判决准确性和解释质量，展示了内部解释信号在增强事实推理中的双重作用。

Abstract: The prevalence of misinformation on social media threatens public trust, demanding automated fact-checking systems that provide accurate verdicts with interpretable explanations. However, existing large language model-based (LLM-based) approaches often rely heavily on external knowledge sources, introducing substantial latency and even hallucinations that undermine reliability, interpretability, and responsiveness, which is crucial for real-time use. To address these challenges, we propose REason-guided Fact-checking with Latent EXplanations REFLEX paradigm, a plug-and-play, self-refining paradigm that leverages the internal knowledge in backbone model to improve both verdict accuracy and explanation quality. REFLEX reformulates fact-checking as a role-play dialogue and jointly trains verdict prediction and explanation generation. It adaptively extracts contrastive activation pairs between the backbone model and its fine-tuned variant to construct steering vectors that disentangle truth into style and substance naturally. These activation-level signals guide inference and suppress noisy explanations, enabling more faithful and efficient reasoning. Experiments on real-world datasets show that REFLEX outperforms previous methods that steer toward a single truth direction and underscores the challenge traditional approaches face when handling the subtle, human-unknown truth in fact-checking tasks. Remarkably, with only 465 self-refined training samples, RELFEX achieves state-of-the-art performance. Furthermore, models trained with explanatory objectives can effectively guide those without them, yielding up to a 7.57% improvement, highlighting that internal explanation signals play a dual role in both interpreting and enhancing factual reasoning.

</details>


### [22] [Scaling LLM Speculative Decoding: Non-Autoregressive Forecasting in Large-Batch Scenarios](https://arxiv.org/abs/2511.20340)
*Luohe Shi,Zuchao Li,Lefei Zhang,Baoyuan Qi,Guoming Liu,Hai Zhao*

Main category: cs.CL

TL;DR: SpecFormer通过整合单向和双向注意力机制，提出了一种新的推测解码架构，能够在低验证资源和低调度成本下加速大规模语言模型的推理。


<details>
  <summary>Details</summary>
Motivation: 当前推测解码方法假设大量可用计算能力，并使用小型自回归语言模型生成复杂的草稿树。然而，批处理等技术在主流模型推理系统中压缩了可用空闲计算能力，使得低资源推测解码成为重要研究问题。

Method: 提出SpecFormer架构，结合自回归模型和非自回归模型的优点，通过集成单向和双向注意力机制，消除对大型前缀树的依赖，实现并行生成草稿序列。

Result: 在各种模型规模的实验中，SpecFormer展示了无损推测解码能力，并降低了训练需求和计算成本，在大批量情况下也实现了一致的加速效果。

Conclusion: SpecFormer为大规模语言模型推理提供了一种新的标准，通过降低资源需求和计算成本，提升了推测解码的效率。

Abstract: Speculative decoding accelerates LLM inference by utilizing otherwise idle computational resources during memory-to-chip data transfer. Current speculative decoding methods typically assume a considerable amount of available computing power, then generate a complex and massive draft tree using a small autoregressive language model to improve overall prediction accuracy. However, methods like batching have been widely applied in mainstream model inference systems as a superior alternative to speculative decoding, as they compress the available idle computing power. Therefore, performing speculative decoding with low verification resources and low scheduling costs has become an important research problem. We believe that more capable models that allow for parallel generation on draft sequences are what we truly need. Recognizing the fundamental nature of draft models to only generate sequences of limited length, we propose SpecFormer, a novel architecture that integrates unidirectional and bidirectional attention mechanisms. SpecFormer combines the autoregressive model's ability to extract information from the entire input sequence with the parallel generation benefits of non-autoregressive models. This design eliminates the reliance on large prefix trees and achieves consistent acceleration, even in large-batch scenarios. Through lossless speculative decoding experiments across models of various scales, we demonstrate that SpecFormer sets a new standard for scaling LLM inference with lower training demands and reduced computational costs.

</details>


### [23] [The Curious Case of Analogies: Investigating Analogical Reasoning in Large Language Models](https://arxiv.org/abs/2511.20344)
*Taewhoo Lee,Minju Song,Chanwoong Yoon,Jungwoo Park,Jaewoo Kang*

Main category: cs.CL

TL;DR: 该论文探讨了大型语言模型（LLMs）在类比推理方面的能力，发现其能够编码高级关系概念，但在应用到新情况时存在局限。


<details>
  <summary>Details</summary>
Motivation: 类比推理是人类认知的核心，是各种智力活动的重要基础。尽管先前的研究表明LLMs可以表示任务模式和表面概念，但其是否能编码高级关系概念并通过结构化比较在新情况下应用仍不明确。

Method: 使用比例和故事类比进行研究，通过分析属性信息和关系信息在模型中的传播，以及隐藏表示的战略性修补来考察LLMs的类比推理能力。

Result: 1. LLMs能够有效编码类比实体之间的基本关系，但在应用到新实体时存在困难。2. 在关键标记位置进行隐藏表示的修补可以在一定程度上促进信息传递。3. LLMs的成功类比推理依赖于类比情境之间的强结构对齐。

Conclusion: LLMs在编码和应用高级关系概念方面展现出新兴但有限的能力，揭示了与人类认知的异同。

Abstract: Analogical reasoning is at the core of human cognition, serving as an important foundation for a variety of intellectual activities. While prior work has shown that LLMs can represent task patterns and surface-level concepts, it remains unclear whether these models can encode high-level relational concepts and apply them to novel situations through structured comparisons. In this work, we explore this fundamental aspect using proportional and story analogies, and identify three key findings. First, LLMs effectively encode the underlying relationships between analogous entities; both attributive and relational information propagate through mid-upper layers in correct cases, whereas reasoning failures reflect missing relational information within these layers. Second, unlike humans, LLMs often struggle not only when relational information is missing, but also when attempting to apply it to new entities. In such cases, strategically patching hidden representations at critical token positions can facilitate information transfer to a certain extent. Lastly, successful analogical reasoning in LLMs is marked by strong structural alignment between analogous situations, whereas failures often reflect degraded or misplaced alignment. Overall, our findings reveal that LLMs exhibit emerging but limited capabilities in encoding and applying high-level relational concepts, highlighting both parallels and gaps with human cognition.

</details>


### [24] [BengaliFig: A Low-Resource Challenge for Figurative and Culturally Grounded Reasoning in Bengali](https://arxiv.org/abs/2511.20399)
*Abdullah Al Sefat*

Main category: cs.CL

TL;DR: 提出BengaliFig，一个针对孟加拉语的小型标注挑战集，旨在评估大型语言模型在低资源语境下的比喻和文化相关推理能力。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在多语言评测中表现出色，但在比喻和文化相关推理，尤其是在低资源语境下，尚未得到充分评估。

Method: 构建了一个包含435个来自孟加拉口头和文学传统的独特谜语的数据集，每个谜语在五个正交维度上进行了标注，并通过AI辅助流程自动转换为多选题格式。

Result: 在零样本和少样本思维链提示下评估了八个前沿大型语言模型，发现它们在比喻和文化特定推理方面存在持续弱点。

Conclusion: BengaliFig不仅为评估低资源文化语境下大型语言模型的稳健性提供了诊断工具，还推动了包容性和传统意识的自然语言处理评测的发展。

Abstract: Large language models excel on broad multilingual benchmarks but remain to be evaluated extensively in figurative and culturally grounded reasoning, especially in low-resource contexts. We present BengaliFig, a compact yet richly annotated challenge set that targets this gap in Bengali, a widely spoken low-resourced language. The dataset contains 435 unique riddles drawn from Bengali oral and literary traditions. Each item is annotated along five orthogonal dimensions capturing reasoning type, trap type, cultural depth, answer category, and difficulty, and is automatically converted to multiple-choice format through a constraint-aware, AI-assisted pipeline. We evaluate eight frontier LLMs from major providers under zero-shot and few-shot chain-of-thought prompting, revealing consistent weaknesses in metaphorical and culturally specific reasoning. BengaliFig thus contributes both a diagnostic probe for evaluating LLM robustness in low-resource cultural contexts and a step toward inclusive and heritage-aware NLP evaluation.

</details>


### [25] [A Task-Oriented Evaluation Framework for Text Normalization in Modern NLP Pipelines](https://arxiv.org/abs/2511.20409)
*Md Abdullah Al Kafi,Raka Moni,Sumit Kumar Banshal*

Main category: cs.CL

TL;DR: 本文提出了一种新的、面向任务的词干提取方法评估框架，该框架综合考虑词干提取的有效性、对下游任务的影响以及词干与原始词之间的语义相似性。


<details>
  <summary>Details</summary>
Motivation: 当前词干提取评估方法存在局限，不能充分捕捉过度词干提取造成的潜在危害，因此需要开发新的评估方法。

Method: 提出了一个新的评估框架，包括词干提取有效性得分（SES）、模型性能变化（MPD）和平均归一化编辑距离（ANLD）三个评估方面。

Result: 应用于比较孟加拉语（BNLTK）和英语（Snowball）词干提取器，发现孟加拉语词干提取器因过度词干提取导致下游性能下降，而英语词干提取器在保持意义的同时有效提升了下游性能。

Conclusion: 该研究提供了一个有价值的工具，可以区分潜在效率增益（高SES）和意义保持（低ANLD），从而帮助选择更可靠的词干提取器。

Abstract: Text normalization is an essential preprocessing step in many natural language processing (NLP) tasks, and stemming is one such normalization technique that reduces words to their base or root form. However, evaluating stemming methods is challenging because current evaluation approaches are limited and do not capture the potential harm caused by excessive stemming; therefore, it is essential to develop new approaches to evaluate stemming methods. To address this issue, this study propose a novel, task-oriented approach to evaluate stemming methods, which considers three aspects: (1) the utility of stemming using Stemming Effectiveness Score (SES), (2) the impact of stemming on downstream tasks using Model Performance Delta (MPD), and (3) the semantic similarity between stemmed and original words using Average Normalized Levenshtein Distance (ANLD), thus providing a comprehensive evaluation framework. We apply our evaluation framework to compare two stemmers for Bangla (BNLTK) and English (Snowball), and our results reveal a significant issue, prompting us to analyze their performance in detail. While the Bangla stemmer achieves the highest SES (1.67) due to effective word reduction (CR = 1.90), SES alone is insufficient because our proposed safety measure, ANLD, reveals that this high SES is due to harmful over-stemming (ANLD = 0.26), which correlates with the observed decrease in downstream performance.In contrast, the English stemmer achieves a moderate SES (1.31) with a safe meaning distance (ANLD = 0.14), allowing its word reduction to contribute positively to downstream performance; therefore, it is a more reliable stemmer. Our study provides a valuable tool for distinguishing between potential efficiency gains (high SES) and meaning preservation (low ANLD).

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [26] [Using Wearable Devices to Improve Chronic PainTreatment among Patients with Opioid Use Disorder](https://arxiv.org/abs/2511.19577)
*Abhay Goyal,Navin Kumar,Kimberly DiMeola,Rafael Trujillo,Soorya Ram Shimgekar,Christian Poellabauer,Pi Zonooz,Ermonda Gjoni-Markaj,Declan Barry,Lynn Madden*

Main category: cs.AI

TL;DR: 该论文旨在通过AI技术（包括机器学习和大型语言模型）分析穿戴设备数据，以识别慢性疼痛（CP）和阿片类药物使用障碍（OUD）患者的疼痛峰值及其临床相关性。研究发现机器学习在预测疼痛峰值方面表现较好，而LLMs在提供疼痛峰值洞察方面有限。


<details>
  <summary>Details</summary>
Motivation: 慢性疼痛和阿片类药物使用障碍是常见且相互关联的慢性疾病，目前缺乏基于证据的综合治疗方法。穿戴设备能监控复杂患者信息，有助于开发针对OUD和CP的治疗方法，但LLMs在分析穿戴设备数据以理解疼痛峰值方面尚未被探索。

Method: 研究采用了多种AI技术（包括机器学习和大型语言模型）分析穿戴设备数据，以识别与疼痛峰值相关的临床因素。

Result: 机器学习模型在预测疼痛峰值方面实现了较高准确率（>0.7），而LLMs在提供关于疼痛峰值的洞察方面表现有限。

Conclusion: 穿戴设备的实时监控结合先进的AI模型，可以促进疼痛峰值的早期检测，并支持个性化干预措施，有助于减轻阿片类药物复发风险、改善MOUD依从性，以及提升CP和OUD的综合护理。鉴于LLMs表现有限，研究强调了开发能在OUD/CP背景下提供可操作洞察的LLMs的必要性。

Abstract: Chronic pain (CP) and opioid use disorder (OUD) are common and interrelated chronic medical conditions. Currently, there is a paucity of evidence-based integrated treatments for CP and OUD among individuals receiving medication for opioid use disorder (MOUD). Wearable devices have the potential to monitor complex patient information and inform treatment development for persons with OUD and CP, including pain variability (e.g., exacerbations of pain or pain spikes) and clinical correlates (e.g., perceived stress). However, the application of large language models (LLMs) with wearable data for understanding pain spikes, remains unexplored. Consequently, the aim of this pilot study was to examine the clinical correlates of pain spikes using a range of AI approaches. We found that machine learning models achieved relatively high accuracy (>0.7) in predicting pain spikes, while LLMs were limited in providing insights on pain spikes. Real-time monitoring through wearable devices, combined with advanced AI models, could facilitate early detection of pain spikes and support personalized interventions that may help mitigate the risk of opioid relapse, improve adherence to MOUD, and enhance the integration of CP and OUD care. Given overall limited LLM performance, these findings highlight the need to develop LLMs which can provide actionable insights in the OUD/CP context.

</details>


### [27] [HeaRT: A Hierarchical Circuit Reasoning Tree-Based Agentic Framework for AMS Design Optimization](https://arxiv.org/abs/2511.19669)
*Souradip Poddar,Chia-Tung Ho,Ziming Wei,Weidong Cao,Haoxing Ren,David Z. Pan*

Main category: cs.AI

TL;DR: 提出HeaRT，一个用于自动化设计优化的基础推理引擎，具有高准确性和高效性。


<details>
  <summary>Details</summary>
Motivation: 传统AI驱动的AMS设计自动化算法受限于对高质量数据集的依赖，跨架构的迁移能力差，缺乏自适应机制。

Method: 提出了一种名为HeaRT的基础推理引擎，能够在自动化设计优化中实现智能和自适应的优化。

Result: HeaRT在40个电路的基准测试中，推理准确率超过97%，Pass@1性能超过98%，并且操作时间少于SOTA基线的一半。

Conclusion: HeaRT在多种优化方法中实现了更快的收敛，同时保留了之前的设计意图。

Abstract: Conventional AI-driven AMS design automation algorithms remain constrained by their reliance on high-quality datasets to capture underlying circuit behavior, coupled with poor transferability across architectures, and a lack of adaptive mechanisms. This work proposes HeaRT, a foundational reasoning engine for automation loops and a first step toward intelligent, adaptive, human-style design optimization. HeaRT consistently demonstrates reasoning accuracy >97% and Pass@1 performance >98% across our 40-circuit benchmark repository, even as circuit complexity increases, while operating at <0.5x real-time token budget of SOTA baselines. Our experiments show that HeaRT yields >3x faster convergence in both sizing and topology design adaptation tasks across diverse optimization approaches, while preserving prior design intent.

</details>


### [28] [FISCAL: Financial Synthetic Claim-document Augmented Learning for Efficient Fact-Checking](https://arxiv.org/abs/2511.19671)
*Rishab Sharma,Iman Saberi,Elham Alipour,Jie JW Wu,Fatemeh Fard*

Main category: cs.AI

TL;DR: 提出FISCAL框架和FISCAL-data数据集，用于金融事实核查，并训练轻量级验证器MiniCheck-FISCAL，其在准确性和效率上表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型在金融应用中存在幻觉现象和对大型模型的依赖，需要提高事实可靠性和计算效率。

Method: 提出FISCAL框架，生成用于金融事实核查的合成数据，并训练MiniCheck-FISCAL验证器。

Result: MiniCheck-FISCAL在多个数据集上表现优于同类模型，接近大型系统的准确性。

Conclusion: 特定领域的合成数据与高效微调结合，使轻量级模型在金融AI中实现先进准确性、鲁棒性和可扩展性。

Abstract: Financial applications of large language models (LLMs) require factual reliability and computational efficiency, yet current systems often hallucinate details and depend on prohibitively large models. We propose FISCAL (Financial Synthetic Claim-Document Augmented Learning), a modular framework for generating synthetic data tailored to financial fact-checking. Using FISCAL, we generate a dataset called FISCAL-data and use it to train MiniCheck-FISCAL, a lightweight verifier for numerical financial claims. MiniCheck-FISCAL outperforms its baseline, surpasses GPT-3.5 Turbo and other open-source peers of similar size, and approaches the accuracy of much larger systems (20x), such as Mixtral-8x22B and Command R+. On external datasets FinDVer and Fin-Fact, it rivals GPT-4o and Claude-3.5 while outperforming Gemini-1.5 Flash. These results show that domain-specific synthetic data, combined with efficient fine-tuning, enables compact models to achieve state-of-the-art accuracy, robustness, and scalability for practical financial AI. The dataset and scripts are available in the project repository (link provided in the paper).

</details>


### [29] [Scaling Item-to-Standard Alignment with Large Language Models: Accuracy, Limits, and Solutions](https://arxiv.org/abs/2511.19749)
*Farzan Karimi-Malekabadi,Pooya Razavi,Sonya Powers*

Main category: cs.AI

TL;DR: 本研究评估了大语言模型（LLMs）在教育评估项目与内容标准对齐过程中的加速作用，发现结合候选技能过滤策略的LLMs显著减少人工审核负担，同时保持对齐的准确性。


<details>
  <summary>Details</summary>
Motivation: 随着教育体系的发展，确保评估项目与内容标准对齐对于维护公平性和教学相关性至关重要。传统的人工对齐审核过程准确但缓慢且劳动强度大，尤其是在大型项目库中。因此，需要探索更高效的方法。

Method: 使用超过12,000个K-5年级的评估项目-技能对，测试了三种LLMs（GPT-3.5 Turbo, GPT-4o-mini, GPT-4o）在三个任务中的表现：识别不对齐项目、从完整标准集中选择正确技能、在分类前缩小候选列表。

Result: 研究发现，GPT-4o-mini在识别对齐状态方面表现良好，准确率约为83-94%；数学领域的表现优于阅读领域；预过滤候选技能显著提高了结果，正确技能出现在前五名建议中的时间超过95%。

Conclusion: 结合候选过滤策略的LLMs可以显著减少项目审核的人工负担，同时保持对齐准确性。建议开发混合流水线，将基于LLM的筛选与人工审核相结合，以应对模糊情况，为持续的项目验证和教学对齐提供可扩展的解决方案。

Abstract: As educational systems evolve, ensuring that assessment items remain aligned with content standards is essential for maintaining fairness and instructional relevance. Traditional human alignment reviews are accurate but slow and labor-intensive, especially across large item banks. This study examines whether Large Language Models (LLMs) can accelerate this process without sacrificing accuracy. Using over 12,000 item-skill pairs in grades K-5, we tested three LLMs (GPT-3.5 Turbo, GPT-4o-mini, and GPT-4o) across three tasks that mirror real-world challenges: identifying misaligned items, selecting the correct skill from the full set of standards, and narrowing candidate lists prior to classification. In Study 1, GPT-4o-mini correctly identified alignment status in approximately 83-94% of cases, including subtle misalignments. In Study 2, performance remained strong in mathematics but was lower for reading, where standards are more semantically overlapping. Study 3 demonstrated that pre-filtering candidate skills substantially improved results, with the correct skill appearing among the top five suggestions more than 95% of the time. These findings suggest that LLMs, particularly when paired with candidate filtering strategies, can significantly reduce the manual burden of item review while preserving alignment accuracy. We recommend the development of hybrid pipelines that combine LLM-based screening with human review in ambiguous cases, offering a scalable solution for ongoing item validation and instructional alignment.

</details>


### [30] [KOM: A Multi-Agent Artificial Intelligence System for Precision Management of Knee Osteoarthritis (KOA)](https://arxiv.org/abs/2511.19798)
*Weizhi Liu,Xi Chen,Zekun Jiang,Liang Zhao,Kunyuan Jiang,Ruisi Tang,Li Wang,Mingke You,Hanyu Zhou,Hongyu Chen,Qiankun Xiong,Yong Nie,Kang Li,Jian Li*

Main category: cs.AI

TL;DR: 开发了一个名为KOM的多智能体系统，以自动化膝关节骨性关节炎（KOA）的评估、风险预测和治疗方案制定。


<details>
  <summary>Details</summary>
Motivation: 个性化多学科的干预措施在资源有限的环境中难以实施，需要自动化系统来协助临床医生提高效率。

Method: 设计并实现KOM系统，通过多智能体协作，辅助临床医生进行KOA的评估、风险预测和个性化治疗方案生成。

Result: KOM在基准测试中表现优于一般大型语言模型，在与临床医生协作时能减少38.5%的诊断和规划时间，并提高治疗质量。

Conclusion: KOM系统能有效支持KOA的自动化管理，其模块化架构也为其他慢性病的AI辅助管理系统的开发提供了借鉴。

Abstract: Knee osteoarthritis (KOA) affects more than 600 million individuals globally and is associated with significant pain, functional impairment, and disability. While personalized multidisciplinary interventions have the potential to slow disease progression and enhance quality of life, they typically require substantial medical resources and expertise, making them difficult to implement in resource-limited settings. To address this challenge, we developed KOM, a multi-agent system designed to automate KOA evaluation, risk prediction, and treatment prescription. This system assists clinicians in performing essential tasks across the KOA care pathway and supports the generation of tailored management plans based on individual patient profiles, disease status, risk factors, and contraindications. In benchmark experiments, KOM demonstrated superior performance compared to several general-purpose large language models in imaging analysis and prescription generation. A randomized three-arm simulation study further revealed that collaboration between KOM and clinicians reduced total diagnostic and planning time by 38.5% and resulted in improved treatment quality compared to each approach used independently. These findings indicate that KOM could help facilitate automated KOA management and, when integrated into clinical workflows, has the potential to enhance care efficiency. The modular architecture of KOM may also offer valuable insights for developing AI-assisted management systems for other chronic conditions.

</details>


### [31] [A Unified Evaluation-Instructed Framework for Query-Dependent Prompt Optimization](https://arxiv.org/abs/2511.19829)
*Ke Chen,Yifeng Wang,Hassan Almosapeeh,Haohan Wang*

Main category: cs.AI

TL;DR: 提出了一种以性能为导向、系统化和全面的提示评估框架，并开发了无需执行的评估器和指标感知优化器，以实现稳定、可解释和模型无关的提示优化。


<details>
  <summary>Details</summary>
Motivation: 现有提示优化方法在复杂和动态用户场景中效果不佳，依赖于不稳定的文本反馈或黑盒奖励模型，导致优化信号弱且不可解释。同时，提示质量本身缺乏统一的系统定义，导致评估信号分散且不可靠。

Method: 建立了一个性能导向的提示评估框架，开发并微调了一个无需执行的评估器，直接从文本预测多维质量分数。该评估器指导一个指标感知优化器，以可解释、依赖于查询的方式诊断失败模式并重写提示。

Result: 该评估器在预测提示性能方面实现了最强的准确性，评价指导的优化在八个数据集和三个骨干模型上始终优于静态模板和依赖查询的基线。

Conclusion: 提出了一种统一的、基于指标的提示质量视角，并展示了评价指导的优化管道能够在各种任务中实现稳定、可解释和模型无关的改进。

Abstract: Most prompt-optimization methods refine a single static template, making them ineffective in complex and dynamic user scenarios. Existing query-dependent approaches rely on unstable textual feedback or black-box reward models, providing weak and uninterpretable optimization signals. More fundamentally, prompt quality itself lacks a unified, systematic definition, resulting in fragmented and unreliable evaluation signals. Our approach first establishes a performance-oriented, systematic, and comprehensive prompt evaluation framework. Furthermore, we develop and finetune an execution-free evaluator that predicts multi-dimensional quality scores directly from text. The evaluator then instructs a metric-aware optimizer that diagnoses failure modes and rewrites prompts in an interpretable, query-dependent manner. Our evaluator achieves the strongest accuracy in predicting prompt performance, and the evaluation-instructed optimization consistently surpass both static-template and query-dependent baselines across eight datasets and on three backbone models. Overall, we propose a unified, metric-grounded perspective on prompt quality, and demonstrated that our evaluation-instructed optimization pipeline delivers stable, interpretable, and model-agnostic improvements across diverse tasks.

</details>


### [32] [Reinforcement Learning with $ω$-Regular Objectives and Constraints](https://arxiv.org/abs/2511.19849)
*Dominik Wagner,Leon Witzman,Luke Ong*

Main category: cs.AI

TL;DR: 本文提出了一种结合ω-正则目标和显式约束的强化学习方法，以解决传统标量奖励在表达时序、条件和安全目标方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习使用标量奖励难以表达复杂目标，并可能导致奖励篡改。ω-正则目标可以精确描述丰富行为特性，但单标量性能度量无法揭示安全性能权衡。

Method: 结合ω-正则目标和显式约束，提出一种基于线性规划的模型强化学习算法，并将问题转化为有约束的极限平均问题。

Result: 算法在极限情况下能生成一个策略，最大化满足ω-正则目标的概率，同时遵守指定阈值内的ω-正则约束。

Conclusion: 该方法能有效分离安全要求和优化目标，提高强化学习在复杂目标下的性能表现和安全性。

Abstract: Reinforcement learning (RL) commonly relies on scalar rewards with limited ability to express temporal, conditional, or safety-critical goals, and can lead to reward hacking. Temporal logic expressible via the more general class of $ω$-regular objectives addresses this by precisely specifying rich behavioural properties. Even still, measuring performance by a single scalar (be it reward or satisfaction probability) masks safety-performance trade-offs that arise in settings with a tolerable level of risk.
  We address both limitations simultaneously by combining $ω$-regular objectives with explicit constraints, allowing safety requirements and optimisation targets to be treated separately. We develop a model-based RL algorithm based on linear programming, which in the limit produces a policy maximising the probability of satisfying an $ω$-regular objective while also adhering to $ω$-regular constraints within specified thresholds. Furthermore, we establish a translation to constrained limit-average problems with optimality-preserving guarantees.

</details>


### [33] [MicroSims: A Framework for AI-Generated, Scalable Educational Simulations with Universal Embedding and Adaptive Learning Support](https://arxiv.org/abs/2511.19864)
*Valerie Lockhart,Dan McCreary,Troy A. Peterson*

Main category: cs.AI

TL;DR: MicroSims是一个利用AI快速生成轻量级、可交互教育模拟的新框架，无需编程知识即可定制，能嵌入各种数字学习平台。


<details>
  <summary>Details</summary>
Motivation: 传统教育模拟创建需要大量资源和技术专长，存在成本高、技术复杂和平台依赖等障碍，限制了其广泛应用。

Method: MicroSims结合三种创新：(1)标准化设计模式实现AI辅助生成，(2)基于iframe的架构实现通用嵌入和安全沙箱，(3)透明可修改代码支持自定义和教学透明度。框架包含设计原则、技术架构、元数据标准和开发流程。

Result: 研究表明，交互式模拟比传统教学能提高30-40%的概念理解力。MicroSims扩展了这些优势，同时解决了成本、技术复杂性和平台依赖等持久障碍。

Conclusion: MicroSims对教育公平具有重要意义，可实现低成本智能互动教材，使全球教育工作者能按需创建定制化、符合课程标准的模拟。未来将发展为基于MicroSim基础的AI驱动自适应学习系统。

Abstract: Educational simulations have long been recognized as powerful tools for enhancing learning outcomes, yet their creation has traditionally required substantial resources and technical expertise. This paper introduces MicroSims a novel framework for creating lightweight, interactive educational simulations that can be rapidly generated using artificial intelligence, universally embedded across digital learning platforms, and easily customized without programming knowledge. MicroSims occupy a unique position at the intersection of three key innovations: (1) standardized design patterns that enable AI-assisted generation, (2) iframe-based architecture that provides universal embedding and sandboxed security, and (3) transparent, modifiable code that supports customization and pedagogical transparency. We present a comprehensive framework encompassing design principles, technical architecture, metadata standards, and development workflows. Drawing on empirical research from physics education studies and meta-analyses across STEM disciplines, we demonstrate that interactive simulations can improve conceptual understanding by up to 30-40\% compared to traditional instruction. MicroSims extend these benefits while addressing persistent barriers of cost, technical complexity, and platform dependence. This work has significant implications for educational equity, and low-cost intelligent interactive textbooks that enabling educators worldwide to create customized, curriculum-aligned simulations on demand. We discuss implementation considerations, present evidence of effectiveness, and outline future directions for AI-powered adaptive learning systems built on the MicroSim foundation.

</details>


### [34] [Simulated Self-Assessment in Large Language Models: A Psychometric Approach to AI Self-Efficacy](https://arxiv.org/abs/2511.19872)
*Daniel I Jackson,Emma L Jensen,Syed-Amad Hussain,Emre Sezgin*

Main category: cs.AI

TL;DR: 本文评估了大型语言模型（LLMs）在不同任务中的自我效能感，发现其自我评估与实际能力不匹配。


<details>
  <summary>Details</summary>
Motivation: 自我评估是可靠智能的关键方面，但对大型语言模型（LLMs）的评估主要集中在任务准确性上，缺乏对其自我评估能力的考察。

Method: 采用10项一般自我效能量表（GSES），在十种LLMs上模拟了自我评估，涵盖无任务、计算推理、社交推理和总结四个条件，并进行了重复管理和随机项目顺序的稳定性测试。

Result: GSES响应高度稳定，但不同条件下的自我效能水平显著不同，总体得分低于人类标准；所有模型在计算和社交问题上表现完美，但在总结任务上表现差异大；自我评估并未可靠地反映实际能力。

Conclusion: 心理测量提示为LLM的通信行为提供了结构化洞察，但未能提供校准的性能估计。

Abstract: Self-assessment is a key aspect of reliable intelligence, yet evaluations of large language models (LLMs) focus mainly on task accuracy. We adapted the 10-item General Self-Efficacy Scale (GSES) to elicit simulated self-assessments from ten LLMs across four conditions: no task, computational reasoning, social reasoning, and summarization. GSES responses were highly stable across repeated administrations and randomized item orders. However, models showed significantly different self-efficacy levels across conditions, with aggregate scores lower than human norms. All models achieved perfect accuracy on computational and social questions, whereas summarization performance varied widely. Self-assessment did not reliably reflect ability: several low-scoring models performed accurately, while some high-scoring models produced weaker summaries. Follow-up confidence prompts yielded modest, mostly downward revisions, suggesting mild overestimation in first-pass assessments. Qualitative analysis showed that higher self-efficacy corresponded to more assertive, anthropomorphic reasoning styles, whereas lower scores reflected cautious, de-anthropomorphized explanations. Psychometric prompting provides structured insight into LLM communication behavior but not calibrated performance estimates.

</details>


### [35] [RPM-MCTS: Knowledge-Retrieval as Process Reward Model with Monte Carlo Tree Search for Code Generation](https://arxiv.org/abs/2511.19895)
*Yuanyuan Lin,Xiangyu Ouyang,Teng Zhang,Kaixin Sui*

Main category: cs.AI

TL;DR: 提出RPM-MCTS方法，利用知识检索和蒙特卡洛树搜索来提升大语言模型代码生成能力。


<details>
  <summary>Details</summary>
Motivation: 树搜索方法在代码生成中因难以评估中间步骤和纠错，导致生成错误代码和计算成本增加。

Method: RPM-MCTS方法结合知识库检索和蒙特卡洛树搜索，评估中间步骤，利用相似性过滤去除冗余节点，并使用沙盒执行反馈纠错。

Result: 在四个代码生成基准测试中，RPM-MCTS优于现有方法，并减少约15%的标记消耗。

Conclusion: RPM-MCTS不仅提高了代码生成能力，还通过构建的数据微调基础模型，进一步增强了其能力。

Abstract: Tree search-based methods have made significant progress in enhancing the code generation capabilities of large language models. However, due to the difficulty in effectively evaluating intermediate algorithmic steps and the inability to locate and timely correct erroneous steps, these methods often generate incorrect code and incur increased computational costs. To tackle these problems, we propose RPM-MCTS, an effective method that utilizes Knowledge-Retrieval as Process Reward Model based on Monte Carlo Tree Search to evaluate intermediate algorithmic steps. By utilizing knowledge base retrieval, RPM-MCTS avoids the complex training of process reward models. During the expansion phase, similarity filtering is employed to remove redundant nodes, ensuring diversity in reasoning paths. Furthermore, our method utilizes sandbox execution feedback to locate erroneous algorithmic steps during generation, enabling timely and targeted corrections. Extensive experiments on four public code generation benchmarks demonstrate that RPM-MCTS outperforms current state-of-the-art methods while achieving an approximately 15% reduction in token consumption. Furthermore, full fine-tuning of the base model using the data constructed by RPM-MCTS significantly enhances its code capabilities.

</details>


### [36] [Semantic-KG: Using Knowledge Graphs to Construct Benchmarks for Measuring Semantic Similarity](https://arxiv.org/abs/2511.19925)
*Qiyao Wei,Edward Morrell,Lea Goetz,Mihaela van der Schaar*

Main category: cs.AI

TL;DR: 本文提出了一种利用知识图谱生成语义相似性基准数据集的新方法，以评估大型语言模型的输出。


<details>
  <summary>Details</summary>
Motivation: 当前语义相似性方法倾向于捕捉句法或词汇形式而非语义内容，并且现有基准存在生成成本高、主观性强、领域特定应用受限和等价定义不清的问题。

Method: 利用知识图谱生成语义相似或不相似的语句对，并将不相似对分为四个子类型，在四个不同领域生成基准数据集，比较传统自然语言处理分数和LLM-as-a-judge预测。

Result: 语义变异的子类型和基准领域影响语义相似性方法的性能，没有一种方法始终表现最佳。

Conclusion: 该研究对LLM-as-a-judge在检测文本语义内容时的使用具有重要启示。

Abstract: Evaluating the open-form textual responses generated by Large Language Models (LLMs) typically requires measuring the semantic similarity of the response to a (human generated) reference. However, there is evidence that current semantic similarity methods may capture syntactic or lexical forms over semantic content. While benchmarks exist for semantic equivalence, they often suffer from high generation costs due to reliance on subjective human judgment, limited availability for domain-specific applications, and unclear definitions of equivalence. This paper introduces a novel method for generating benchmarks to evaluate semantic similarity methods for LLM outputs, specifically addressing these limitations. Our approach leverages knowledge graphs (KGs) to generate pairs of natural-language statements that are semantically similar or dissimilar, with dissimilar pairs categorized into one of four sub-types. We generate benchmark datasets in four different domains (general knowledge, biomedicine, finance, biology), and conduct a comparative study of semantic similarity methods including traditional natural language processing scores and LLM-as-a-judge predictions. We observe that the sub-type of semantic variation, as well as the domain of the benchmark impact the performance of semantic similarity methods, with no method being consistently superior. Our results present important implications for the use of LLM-as-a-judge in detecting the semantic content of text. Code is available at https://github.com/QiyaoWei/semantic-kg and the dataset is available at https://huggingface.co/datasets/QiyaoWei/Semantic-KG.

</details>


### [37] [A System-Level Taxonomy of Failure Modes in Large Language Model Applications](https://arxiv.org/abs/2511.19933)
*Vaishali Vinay*

Main category: cs.AI

TL;DR: 本文提出了一个关于大型语言模型（LLMs）在生产环境中隐藏故障模式的系统级分类法，并指出了现有评估和监测实践的不足。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs被快速整合到各种工具和应用中，其在实际生产环境中的行为仍不明确，并且其故障模式与传统机器学习模型有根本的不同。

Method: 作者提出了一个包含十五种隐藏故障模式的分类法，包括多步推理漂移、潜在不一致、上下文边界退化、错误工具调用、版本漂移和成本驱动的性能崩溃。

Result: 分析了现有LLM评估方法在稳定性、可重复性、漂移或工作流程集成方面的不足，并探讨了部署LLMs的生产挑战，如可观察性限制、成本约束和更新引发的退化。

Conclusion: 通过将LLM可靠性视为系统工程问题而非纯粹模型中心问题，本文为未来的评估方法、AI系统稳健性和可靠的LLM部署研究提供了分析基础。

Abstract: Large language models (LLMs) are being rapidly integrated into decision-support tools, automation workflows, and AI-enabled software systems. However, their behavior in production environments remains poorly understood, and their failure patterns differ fundamentally from those of traditional machine learning models. This paper presents a system-level taxonomy of fifteen hidden failure modes that arise in real-world LLM applications, including multi-step reasoning drift, latent inconsistency, context-boundary degradation, incorrect tool invocation, version drift, and cost-driven performance collapse. Using this taxonomy, we analyze the growing gap in evaluation and monitoring practices: existing benchmarks measure knowledge or reasoning but provide little insight into stability, reproducibility, drift, or workflow integration. We further examine the production challenges associated with deploying LLMs - including observability limitations, cost constraints, and update-induced regressions - and outline high-level design principles for building reliable, maintainable, and cost-aware LLM systems. Finally, we outline high-level design principles for building reliable, maintainable, and cost-aware LLM-based systems. By framing LLM reliability as a system-engineering problem rather than a purely model-centric one, this work provides an analytical foundation for future research on evaluation methodology, AI system robustness, and dependable LLM deployment.

</details>


### [38] [Interactive AI NPCs Powered by LLMs: Technical Report for the CPDC Challenge 2025](https://arxiv.org/abs/2511.20200)
*Yitian Huang,Yuxuan Lei,Jianxun Lian,Hao Liao*

Main category: cs.AI

TL;DR: 提出了一个在CPDC 2025挑战赛中取得优异成绩的统一框架，包含上下文工程和GRPO训练。


<details>
  <summary>Details</summary>
Motivation: 解决小样本过拟合问题，提高工具调用稳定性和角色引导。

Method: 上下文工程（动态工具修剪和角色裁剪，参数归一化和功能合并）和GRPO训练。

Result: 在Task 2 API中获得第1名，在Task 1 API中获得第2名，在Task 3 API和GPU track中均获得第3名。

Conclusion: 该方法在提高工具调用稳定性、执行可靠性、角色扮演指导，以及减轻小样本过拟合方面表现出色。

Abstract: This report presents the solution and results of our team MSRA\_SC in the Commonsense Persona-Grounded Dialogue Challenge (CPDC 2025). We propose a simple yet effective framework that unifies improvements across both GPU Track and API Track. Our method centers on two key components. First, Context Engineering applies dynamic tool pruning and persona clipping for input compression, combined with post-processing techniques such as parameter normalization and function merging. Together with manually refined prompts, this design improves tool call stability, execution reliability, and role-playing guidance. Second, in the GPU Track, we further adopt GRPO training, replacing supervised fine-tuning with reinforcement learning directly optimized by reward signals. This mitigates small-sample overfitting and significantly enhances task-oriented dialogue performance. In the final evaluation, our team ranks 1st in Task 2 API, 2nd in Task 1 API, and 3rd in both Task 3 API and GPU track, demonstrating the effectiveness of our approach. Our code is publicly available at https://gitlab.aicrowd.com/nikoo_yu/cpdc-2025-winning-solution

</details>


### [39] [CostNav: A Navigation Benchmark for Cost-Aware Evaluation of Embodied Agents](https://arxiv.org/abs/2511.20216)
*Haebin Seong,Sungmin Kim,Minchan Kim,Yongjun Cho,Myunchul Joe,Suhwan Choi,Jaeyoon Jung,Jiyong Youn,Yoonshik Kim,Samwoo Seong,Yubeen Park,Youngjae Yu,Yunsung Lee*

Main category: cs.AI

TL;DR: 引入CostNav，首个专注于经济可行性的微导航测试平台，评估自主机器人在真实商业环境中的成本与收益。


<details>
  <summary>Details</summary>
Motivation: 现有导航基准忽视经济可行性，而这对自主投递机器人的商业部署至关重要。

Method: 提出CostNav模型，考虑硬件、培训、能源、维护成本和投递收入，通过行业标准参数进行成本-收入分析，并使用基于学习的方法在仿真环境中评估。

Result: 基准模型实现43.0%的SLA合规率，但每次运行亏损30.009美元，无法实现盈亏平衡，碰撞维护成本占总成本的99.7%。

Conclusion: CostNav揭示了导航任务成功指标与商业可行性之间的差距，为经济权衡提供了数据驱动的决策工具，并强调了避碰策略在优化中的重要性。

Abstract: Existing navigation benchmarks focus on task success metrics while overlooking economic viability -- critical for commercial deployment of autonomous delivery robots. We introduce \emph{CostNav}, a \textbf{Micro-Navigation Economic Testbed} that evaluates embodied agents through comprehensive cost-revenue analysis aligned with real-world business operations. CostNav models the complete economic lifecycle including hardware, training, energy, maintenance costs, and delivery revenue with service-level agreements, using industry-derived parameters. \textbf{To our knowledge, CostNav is the first work to quantitatively expose the gap between navigation research metrics and commercial viability}, revealing that optimizing for task success fundamentally differs from optimizing for economic deployment. Our cost model uses parameters derived from industry data sources (energy rates, delivery service pricing), and we project from a reduced-scale simulation to realistic deliveries. Under this projection, the baseline achieves 43.0\% SLA compliance but is \emph{not} commercially viable: yielding a loss of \$30.009 per run with no finite break-even point, because operating costs are dominated by collision-induced maintenance, which accounts for 99.7\% of per-run costs and highlights collision avoidance as a key optimization target. We demonstrate a learning-based on-device navigation baseline and establish a foundation for evaluating rule-based navigation, imitation learning, and cost-aware RL training. CostNav bridges the gap between navigation research and commercial deployment, enabling data-driven decisions about economic trade-offs across navigation paradigms.

</details>


### [40] [Active Inference in Discrete State Spaces from First Principles](https://arxiv.org/abs/2511.20321)
*Patrick Kenny*

Main category: cs.AI

TL;DR: 本文通过将主动推理与自由能原理解耦，澄清了主动推理的概念，展示了如何在离散状态空间中通过约束散度最小化问题实现主动推理。


<details>
  <summary>Details</summary>
Motivation: 旨在澄清主动推理的概念，并将其与自由能原理分开，展示如何在离散状态空间中实现主动推理。

Method: 通过将优化问题表述为约束散度最小化问题，使用标准的平均场方法进行求解，而不依赖预期自由能概念。

Result: 在建模感知时，提出的感知/动作散度准则与变分自由能一致；在建模动作时，与预期自由能功能存在熵正则化差异。

Conclusion: 主动推理可以通过不依赖预期自由能的方法实现，并且在感知和动作建模中，与变分自由能和预期自由能的关系有所不同。

Abstract: We seek to clarify the concept of active inference by disentangling it from the Free Energy Principle. We show how the optimizations that need to be carried out in order to implement active inference in discrete state spaces can be formulated as constrained divergence minimization problems which can be solved by standard mean field methods that do not appeal to the idea of expected free energy. When it is used to model perception, the perception/action divergence criterion that we propose coincides with variational free energy. When it is used to model action, it differs from an expected free energy functional by an entropy regularizer.

</details>


### [41] [VibraVerse: A Large-Scale Geometry-Acoustics Alignment Dataset for Physically-Consistent Multimodal Learning](https://arxiv.org/abs/2511.20422)
*Bo Pang,Chenxi Xu,Jierui Ren,Guoping Wang,Sheng Li*

Main category: cs.AI

TL;DR: VibraVerse是一个大型几何声学对齐数据集，通过CLASP对比学习框架，将3D几何、物理属性、模态参数和声音信号之间的因果关系显式地桥接起来，以实现物理一致性和可解释性的多模态学习。


<details>
  <summary>Details</summary>
Motivation: 当前多模态学习框架缺乏物理一致性，忽视了物体的几何、材料、振动模式与其声音之间的因果关系，因此需要建立能够体现物理定律和因果关系的数据集与模型。

Method: 引入VibraVerse数据集，包含3D模型及其物理属性，从几何和材料属性中计算模态参数，并通过CLASP框架实现跨模态对齐，确保物理结构和声音响应之间的因果一致性。

Result: 在VibraVerse上训练的模型在几何到声音预测、声音引导形状重建和跨模态表示学习等任务中表现出优越的准确性、可解释性和泛化能力。

Conclusion: VibraVerse为物理一致且可因果解释的多模态学习提供了基准，为声音引导的具身感知和对物理世界的深入理解奠定了基础。该数据集将开源。

Abstract: Understanding the physical world requires perceptual models grounded in physical laws rather than mere statistical correlations. However, existing multimodal learning frameworks, focused on vision and language, lack physical consistency and overlook the intrinsic causal relationships among an object's geometry, material, vibration modes, and the sounds it produces. We introduce VibraVerse, a large-scale geometry-acoustics alignment dataset that explicitly bridges the causal chain from 3D geometry -> physical attributes -> modal parameters -> acoustic signals. Each 3D model has explicit physical properties (density, Young's modulus, Poisson's ratio) and volumetric geometry, from which modal eigenfrequencies and eigenvectors are computed for impact sound synthesis under controlled excitations. To establish this coherence, we introduce CLASP, a contrastive learning framework for cross-modal alignment that preserves the causal correspondence between an object's physical structure and its acoustic response. This framework enforces physically consistent alignment across modalities, ensuring that every sample is coherent, traceable to the governing equations, and embedded within a unified representation space spanning shape, image, and sound. Built upon VibraVerse, we define a suite of benchmark tasks for geometry-to-sound prediction, sound-guided shape reconstruction, and cross-modal representation learning. Extensive validations on these tasks demonstrate that models trained on VibraVerse exhibit superior accuracy, interpretability, and generalization across modalities. These results establish VibraVerse as a benchmark for physically consistent and causally interpretable multimodal learning, providing a foundation for sound-guided embodied perception and a deeper understanding of the physical world. The dataset will be open-sourced.

</details>
