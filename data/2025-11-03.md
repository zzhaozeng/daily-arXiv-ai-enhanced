<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 38]
- [cs.AI](#cs.AI) [Total: 15]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Frame Semantic Patterns for Identifying Underreporting of Notifiable Events in Healthcare: The Case of Gender-Based Violence](https://arxiv.org/abs/2510.26969)
*Lívia Dutra,Arthur Lorenzi,Laís Berno,Franciany Campos,Karoline Biscardi,Kenneth Brown,Marcelo Viridiano,Frederico Belcavello,Ely Matos,Olívia Guaranha,Erik Santos,Sofia Reinach,Tiago Timponi Torrent*

Main category: cs.CL

TL;DR: 本文介绍了一种利用语义框架在医疗健康领域识别需报告事件的方法，应用于巴西电子病历中性别暴力（GBV）漏报问题。


<details>
  <summary>Details</summary>
Motivation: 解决医疗记录中性别暴力事件的漏报问题，提高公共健康监测的效率和准确性。

Method: 利用语义框架定义细粒度模式，并在非结构化数据（电子病历中的开放文本字段）中进行搜索。共定义并搜索了8种模式。

Result: 在2100万句的巴西葡萄牙语语料库中，该方法的精确度达到0.726，经语言学家手动评估确认其稳健性。

Conclusion: 该方法是一个透明、高效、低碳、与语言无关的流水线，易于适应其他健康监测背景，有助于自然语言处理在公共健康系统中的广泛、道德和可解释的使用。

Abstract: We introduce a methodology for the identification of notifiable events in the
domain of healthcare. The methodology harnesses semantic frames to define
fine-grained patterns and search them in unstructured data, namely, open-text
fields in e-medical records. We apply the methodology to the problem of
underreporting of gender-based violence (GBV) in e-medical records produced
during patients' visits to primary care units. A total of eight patterns are
defined and searched on a corpus of 21 million sentences in Brazilian
Portuguese extracted from e-SUS APS. The results are manually evaluated by
linguists and the precision of each pattern measured. Our findings reveal that
the methodology effectively identifies reports of violence with a precision of
0.726, confirming its robustness. Designed as a transparent, efficient,
low-carbon, and language-agnostic pipeline, the approach can be easily adapted
to other health surveillance contexts, contributing to the broader, ethical,
and explainable use of NLP in public health systems.

</details>


### [2] [Overview of the MEDIQA-OE 2025 Shared Task on Medical Order Extraction from Doctor-Patient Consultations](https://arxiv.org/abs/2510.26974)
*Jean-Philippe Corbeil,Asma Ben Abacha,Jerome Tremblay,Phillip Swazinna,Akila Jeeson Daniel,Miguel Del-Agua,Francois Beaulieu*

Main category: cs.CL

TL;DR: 本文介绍了MEDIQA-OE 2025共享任务，旨在从医患对话中提取医疗指令。


<details>
  <summary>Details</summary>
Motivation: 临床文档越来越多地使用自动语音识别和摘要，但将对话转化为可操作的医疗指令仍是一个未探索的领域，这可以显著减轻临床医生的文档负担并直接影响患者的后续护理。

Method: 介绍了MEDIQA-OE任务、数据集、最终排名和参与者的解决方案，参与者使用了多种方法，包括封闭和开放权重的大型语言模型（LLMs）。

Result: 六个团队参与了该任务，并实验了多种方法。

Conclusion: 该论文描述了MEDIQA-OE任务的目标、方法和参与者结果，为未来研究提供了基础。

Abstract: Clinical documentation increasingly uses automatic speech recognition and
summarization, yet converting conversations into actionable medical orders for
Electronic Health Records remains unexplored. A solution to this problem can
significantly reduce the documentation burden of clinicians and directly impact
downstream patient care. We introduce the MEDIQA-OE 2025 shared task, the first
challenge on extracting medical orders from doctor-patient conversations. Six
teams participated in the shared task and experimented with a broad range of
approaches, and both closed- and open-weight large language models (LLMs). In
this paper, we describe the MEDIQA-OE task, dataset, final leaderboard ranking,
and participants' solutions.

</details>


### [3] [Elastic Architecture Search for Efficient Language Models](https://arxiv.org/abs/2510.27037)
*Shang Wang*

Main category: cs.CL

TL;DR: 本文介绍了一种新的神经架构搜索（NAS）方法，即弹性语言模型（ELM），用于优化紧凑型语言模型。


<details>
  <summary>Details</summary>
Motivation: 大型预训练语言模型在自然语言理解（NLU）任务中至关重要，但其巨大的计算和存储需求引发了经济和环境问题。

Method: ELM通过引入包含高效Transformer块和动态模块的灵活搜索空间，扩展了现有的NAS方法，并引入了新的知识蒸馏损失。

Result: 在掩码语言建模和因果语言建模任务上的实验表明，ELM发现的模型显著优于现有方法。

Conclusion: ELM通过灵活的搜索空间和知识蒸馏损失，提高了搜索过程的效率和模型性能，为紧凑型语言模型提供了更优的解决方案。

Abstract: As large pre-trained language models become increasingly critical to natural
language understanding (NLU) tasks, their substantial computational and memory
requirements have raised significant economic and environmental concerns.
Addressing these challenges, this paper introduces the Elastic Language Model
(ELM), a novel neural architecture search (NAS) method optimized for compact
language models. ELM extends existing NAS approaches by introducing a flexible
search space with efficient transformer blocks and dynamic modules for
dimension and head number adjustment. These innovations enhance the efficiency
and flexibility of the search process, which facilitates more thorough and
effective exploration of model architectures. We also introduce novel knowledge
distillation losses that preserve the unique characteristics of each block, in
order to improve the discrimination between architectural choices during the
search process. Experiments on masked language modeling and causal language
modeling tasks demonstrate that models discovered by ELM significantly
outperform existing methods.

</details>


### [4] [Dataset Creation and Baseline Models for Sexism Detection in Hausa](https://arxiv.org/abs/2510.27038)
*Fatima Adam Muhammad,Shamsuddeen Muhammad Hassan,Isa Inuwa-Dutse*

Main category: cs.CL

TL;DR: 该论文介绍了首个通过社区参与、定性编码和数据增强构建的豪萨语性别歧视检测数据集，并比较了传统机器学习与多语言预训练模型在豪萨语性别歧视检测中的效果。


<details>
  <summary>Details</summary>
Motivation: 性别歧视通过刻板印象、偏见和歧视性规范加剧了性别不平等和社会排斥。在线平台助长了性别歧视的滋生，尤其在低资源语言中，由于语言资源有限和文化差异，性别歧视的表达和感知存在挑战。

Method: 研究通过社区参与、定性编码、数据增强构建数据集，并开展两阶段用户研究（n=66），调查母语者如何在日常语境中定义和表达性别歧视。进一步实验了传统机器学习分类器和预训练多语言语言模型，并评估了少样本学习在豪萨语性别歧视检测中的效果。

Result: 研究发现，尤其在涉及澄清性问题和习语表达时，捕捉文化差异具有挑战性，并揭示出许多假阳性情况。

Conclusion: 该研究突出了在豪萨语性别歧视检测中捕捉文化差异的挑战，为低资源语言的性别歧视检测提供了宝贵的数据集和方法参考。

Abstract: Sexism reinforces gender inequality and social exclusion by perpetuating
stereotypes, bias, and discriminatory norms. Noting how online platforms enable
various forms of sexism to thrive, there is a growing need for effective sexism
detection and mitigation strategies. While computational approaches to sexism
detection are widespread in high-resource languages, progress remains limited
in low-resource languages where limited linguistic resources and cultural
differences affect how sexism is expressed and perceived. This study introduces
the first Hausa sexism detection dataset, developed through community
engagement, qualitative coding, and data augmentation. For cultural nuances and
linguistic representation, we conducted a two-stage user study (n=66) involving
native speakers to explore how sexism is defined and articulated in everyday
discourse. We further experiment with both traditional machine learning
classifiers and pre-trained multilingual language models and evaluating the
effectiveness few-shot learning in detecting sexism in Hausa. Our findings
highlight challenges in capturing cultural nuance, particularly with
clarification-seeking and idiomatic expressions, and reveal a tendency for many
false positives in such cases.

</details>


### [5] [Quantitative Intertextuality from the Digital Humanities Perspective: A Survey](https://arxiv.org/abs/2510.27045)
*Siyu Duan*

Main category: cs.CL

TL;DR: 本文综述了定量互文性研究的进展，涵盖了数据、方法和应用，并展望了其在跨学科研究中的潜力。


<details>
  <summary>Details</summary>
Motivation: 互文性在数字人文研究中具有重要意义，近年来自然语言处理的发展使其进入定量研究时代。

Method: 综述了从统计到深度学习的方法，并回顾了多语言和主题的数据。

Result: 总结了这些方法在人文和社会科学研究中的应用及相关平台工具。

Conclusion: 随着计算机技术的进步，互文性研究将更加精确、多样化和大规模化，并有望在AI与人文学科的跨学科研究中得到更广泛应用。

Abstract: The connection between texts is referred to as intertextuality in literary
theory, which served as an important theoretical basis in many digital
humanities studies. Over the past decade, advancements in natural language
processing have ushered intertextuality studies into the quantitative age.
Large-scale intertextuality research based on cutting-edge methods has
continuously emerged. This paper provides a roadmap for quantitative
intertextuality studies, summarizing their data, methods, and applications.
Drawing on data from multiple languages and topics, this survey reviews methods
from statistics to deep learning. It also summarizes their applications in
humanities and social sciences research and the associated platform tools.
Driven by advances in computer technology, more precise, diverse, and
large-scale intertext studies can be anticipated. Intertextuality holds promise
for broader application in interdisciplinary research bridging AI and the
humanities.

</details>


### [6] [Recursive numeral systems are highly regular and easy to process](https://arxiv.org/abs/2510.27049)
*Ponrawee Prasertsom,Andrea Silvi,Jennifer Culbertson,Moa Johansson,Devdatt Dubhashi,Kenny Smith*

Main category: cs.CL

TL;DR: 本文提出，递归数字系统的优化不仅涉及词汇量和形态句法复杂度的平衡，还应考虑规律性。通过最小描述长度（MDL）方法，作者认为递归数字系统在规律性和处理复杂度方面是高效的。


<details>
  <summary>Details</summary>
Motivation: 先前的研究未能证明只有类似自然语言的系统能优化这种平衡，并且需要人为设定约束来排除非自然系统。本文旨在解决这个问题，通过引入规律性来更好地解释自然语言系统的优越性。

Method: 利用最小描述长度（MDL）方法，提出递归数字系统在规律性和处理复杂度方面的效率，并通过实验比较已证实自然系统和未被证实但可能的系统之间的差异。

Result: MDL方法在捕捉自然系统和非自然系统之间的关键差异方面表现更好，包括先前工作中提出的“最优”递归数字系统，并且先前文献中的人为约束自然地从规律性中推导出来。

Conclusion: 研究语言的最优性时，需要考虑形式集合的规律性，这为解释自然语言系统的优越性提供了新的视角。

Abstract: Previous work has argued that recursive numeral systems optimise the
trade-off between lexicon size and average morphosyntatic complexity (Deni\'c
and Szymanik, 2024). However, showing that only natural-language-like systems
optimise this tradeoff has proven elusive, and the existing solution has relied
on ad-hoc constraints to rule out unnatural systems (Yang and Regier, 2025).
Here, we argue that this issue arises because the proposed trade-off has
neglected regularity, a crucial aspect of complexity central to human grammars
in general. Drawing on the Minimum Description Length (MDL) approach, we
propose that recursive numeral systems are better viewed as efficient with
regard to their regularity and processing complexity. We show that our
MDL-based measures of regularity and processing complexity better capture the
key differences between attested, natural systems and unattested but possible
ones, including "optimal" recursive numeral systems from previous work, and
that the ad-hoc constraints from previous literature naturally follow from
regularity. Our approach highlights the need to incorporate regularity across
sets of forms in studies that attempt to measure and explain optimality in
language.

</details>


### [7] [VISTA Score: Verification In Sequential Turn-based Assessment](https://arxiv.org/abs/2510.27052)
*Ashley Lewis,Andrew Perrault,Eric Fosler-Lussier,Michael White*

Main category: cs.CL

TL;DR: 提出VISTA框架，通过逐句分解和验证来提高对话AI系统的真实性评估。


<details>
  <summary>Details</summary>
Motivation: 现有指标在评估多轮对话时存在局限，无法有效识别不可验证内容，导致幻觉问题严重。

Method: VISTA框架将每轮对话分解为原子性事实声明，并对照可信来源和对话历史进行验证，对不可验证的声明进行分类。

Result: 在八个大型语言模型和四个对话真实性基准测试中，VISTA显著提高了幻觉检测能力，优于FACTSCORE和LLM-as-Judge基线。

Conclusion: VISTA通过将真实性建模为对话的动态属性，为对话系统提供了更透明、更符合人类标准的真实性评估方法。

Abstract: Hallucination--defined here as generating statements unsupported or
contradicted by available evidence or conversational context--remains a major
obstacle to deploying conversational AI systems in settings that demand factual
reliability. Existing metrics either evaluate isolated responses or treat
unverifiable content as errors, limiting their use for multi-turn dialogue. We
introduce VISTA (Verification In Sequential Turn-based Assessment), a framework
for evaluating conversational factuality through claim-level verification and
sequential consistency tracking. VISTA decomposes each assistant turn into
atomic factual claims, verifies them against trusted sources and dialogue
history, and categorizes unverifiable statements (subjective, contradicted,
lacking evidence, or abstaining). Across eight large language models and four
dialogue factuality benchmarks (AIS, BEGIN, FAITHDIAL, and FADE), VISTA
substantially improves hallucination detection over FACTSCORE and LLM-as-Judge
baselines. Human evaluation confirms that VISTA's decomposition improves
annotator agreement and reveals inconsistencies in existing benchmarks. By
modeling factuality as a dynamic property of conversation, VISTA offers a more
transparent, human-aligned measure of truthfulness in dialogue systems.

</details>


### [8] [LLM-Centric RAG with Multi-Granular Indexing and Confidence Constraints](https://arxiv.org/abs/2510.27054)
*Xiaofan Guo,Yaxuan Luan,Yue Kang,Xiangchen Song,Jinxu Guo*

Main category: cs.CL

TL;DR: 提出一种结合多粒度记忆索引与不确定性估计的置信度控制方法，解决复杂知识环境下检索增强生成中的覆盖不足、结果不稳定和可靠性有限问题。


<details>
  <summary>Details</summary>
Motivation: 在复杂知识环境下，现有检索增强生成存在覆盖不足、结果不稳定和可靠性有限的问题，需要提升检索与生成的语义关联及生成过程的置信度控制。

Method: 构建分层记忆结构，将知识表示划分为不同粒度级别，实现局部到全局的动态索引和检索，并引入不确定性估计机制，在生成过程中显式约束和过滤低置信度路径，优化目标包括生成损失、熵约束和方差正则化。

Result: 实验结果显示，该方法在问答准确性、检索召回率、排序质量和事实一致性方面优于现有模型，表现出良好的稳定性和鲁棒性。

Conclusion: 该方法为检索增强生成提供了新的技术路径，并为提升大型模型在复杂环境中的可靠性和可控性提供了实践证据。

Abstract: This paper addresses the issues of insufficient coverage, unstable results,
and limited reliability in retrieval-augmented generation under complex
knowledge environments, and proposes a confidence control method that
integrates multi-granularity memory indexing with uncertainty estimation. The
method builds a hierarchical memory structure that divides knowledge
representations into different levels of granularity, enabling dynamic indexing
and retrieval from local details to global context, and thus establishing
closer semantic connections between retrieval and generation. On this basis, an
uncertainty estimation mechanism is introduced to explicitly constrain and
filter low-confidence paths during the generation process, allowing the model
to maintain information coverage while effectively suppressing noise and false
content. The overall optimization objective consists of generation loss,
entropy constraints, and variance regularization, forming a unified confidence
control framework. In the experiments, comprehensive sensitivity tests and
comparative analyses were designed, covering hyperparameters, environmental
conditions, and data structures, to verify the stability and robustness of the
proposed method across different scenarios. The results show that the method
achieves superior performance over existing models in QA accuracy, retrieval
recall, ranking quality, and factual consistency, demonstrating the
effectiveness of combining multi-granularity indexing with confidence control.
This study not only provides a new technical pathway for retrieval-augmented
generation but also offers practical evidence for improving the reliability and
controllability of large models in complex contexts.

</details>


### [9] [Detecting Data Contamination in LLMs via In-Context Learning](https://arxiv.org/abs/2510.27055)
*Michał Zawalski,Meriem Boubdir,Klaudia Bałazy,Besmira Nushi,Pablo Ribalta*

Main category: cs.CL

TL;DR: 提出了一种名为CoDeC的实用且准确的方法，用于检测和量化大型语言模型中的训练数据污染。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型存在训练数据污染的问题，需要一种有效的方法来检测和量化污染程度。

Method: 通过测量上下文学习对模型性能的影响，区分训练过程中记忆的数据和训练分布之外的数据。

Result: CoDeC生成了可解释的污染分数，能清楚区分已见和未见数据集，并在开放权重模型中揭示了强记忆证据。

Conclusion: CoDeC方法简单、自动化，且与模型和数据集无关，易于集成到基准评估中。

Abstract: We present Contamination Detection via Context (CoDeC), a practical and
accurate method to detect and quantify training data contamination in large
language models. CoDeC distinguishes between data memorized during training and
data outside the training distribution by measuring how in-context learning
affects model performance. We find that in-context examples typically boost
confidence for unseen datasets but may reduce it when the dataset was part of
training, due to disrupted memorization patterns. Experiments show that CoDeC
produces interpretable contamination scores that clearly separate seen and
unseen datasets, and reveals strong evidence of memorization in open-weight
models with undisclosed training corpora. The method is simple, automated, and
both model- and dataset-agnostic, making it easy to integrate with benchmark
evaluations.

</details>


### [10] [Contrastive Knowledge Transfer and Robust Optimization for Secure Alignment of Large Language Models](https://arxiv.org/abs/2510.27077)
*Jiasen Zheng,Huajun Zhang,Xu Yan,Ran Hao,Chong Peng*

Main category: cs.CL

TL;DR: 提出了一种结合对比蒸馏和抗噪训练的高效微调方法，以提升大规模语言模型的安全对齐和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决大规模语言模型在安全对齐和鲁棒性方面的局限性。

Method: 采用冻结主干模型，通过蒸馏将教师模型的知识边界传递给学生模型，并在训练中引入噪声扰动和鲁棒优化约束。

Result: 在知识转移、鲁棒性和整体安全性方面显著优于现有基线，并在多个关键指标上表现最佳。

Conclusion: 丰富了参数高效微调的理论体系，为构建更安全和可信的模型对齐机制提供了新方案。

Abstract: This paper addresses the limitations of large-scale language models in safety
alignment and robustness by proposing a fine-tuning method that combines
contrastive distillation with noise-robust training. The method freezes the
backbone model and transfers the knowledge boundaries of the teacher model to
the student model through distillation, thereby improving semantic consistency
and alignment accuracy. At the same time, noise perturbations and robust
optimization constraints are introduced during training to ensure that the
model maintains stable predictive outputs under noisy and uncertain inputs. The
overall framework consists of distillation loss, robustness loss, and a
regularization term, forming a unified optimization objective that balances
alignment ability with resistance to interference. To systematically validate
its effectiveness, the study designs experiments from multiple perspectives,
including distillation weight sensitivity, stability analysis under computation
budgets and mixed-precision environments, and the impact of data noise and
distribution shifts on model performance. Results show that the method
significantly outperforms existing baselines in knowledge transfer, robustness,
and overall safety, achieving the best performance across several key metrics.
This work not only enriches the theoretical system of parameter-efficient
fine-tuning but also provides a new solution for building safer and more
trustworthy alignment mechanisms.

</details>


### [11] [Characterizing Selective Refusal Bias in Large Language Models](https://arxiv.org/abs/2510.27087)
*Adel Khorramrouz,Sharon Levy*

Main category: cs.CL

TL;DR: 大型语言模型的防护措施可能会引入或反映新的偏见，导致对某些人口群体选择性地拒绝生成有害内容。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM防护措施中的选择性拒绝偏见，并分析其对不同人口群体的影响。

Method: 通过目标个体和交叉性人口群体的拒绝率、LLM回应类型和生成拒绝的长度来探索选择性拒绝偏见。

Result: 在性别、性取向、国籍和宗教属性上发现了选择性拒绝偏见的证据。

Conclusion: 强调了安全护栏需要在不同人口群体中实现更公平和稳健的性能。

Abstract: Safety guardrails in large language models(LLMs) are developed to prevent
malicious users from generating toxic content at a large scale. However, these
measures can inadvertently introduce or reflect new biases, as LLMs may refuse
to generate harmful content targeting some demographic groups and not others.
We explore this selective refusal bias in LLM guardrails through the lens of
refusal rates of targeted individual and intersectional demographic groups,
types of LLM responses, and length of generated refusals. Our results show
evidence of selective refusal bias across gender, sexual orientation,
nationality, and religion attributes. This leads us to investigate additional
safety implications via an indirect attack, where we target previously refused
groups. Our findings emphasize the need for more equitable and robust
performance in safety guardrails across demographic groups.

</details>


### [12] [Rating Roulette: Self-Inconsistency in LLM-As-A-Judge Frameworks](https://arxiv.org/abs/2510.27106)
*Rajarshi Haldar,Julia Hockenmaier*

Main category: cs.CL

TL;DR: 本文研究了大型语言模型（LLMs）在自然语言生成（NLG）评估中的可靠性，发现其在不同运行中的评分存在不一致性。


<details>
  <summary>Details</summary>
Motivation: 随着自然语言生成的广泛应用，如何准确评估生成内容变得困难。最近，使用LLMs进行评估成为一种趋势，因为它们比传统方法更接近人类偏好。

Method: 通过实验，作者展示了LLM评分者在不同运行中的低一致性，并量化了这种不一致性在不同NLG任务和基准中的表现。

Result: LLM评分者在不同运行中存在显著的评分差异，这种不一致性使得其评分在极端情况下几乎是任意的。

Conclusion: 尽管LLM评分者存在不一致性，但通过遵循适当的指导原则，它们仍然可以是有用的评估工具。

Abstract: As Natural Language Generation (NLG) continues to be widely adopted, properly
assessing it has become quite difficult. Lately, using large language models
(LLMs) for evaluating these generations has gained traction, as they tend to
align more closely with human preferences than conventional n-gram or
embedding-based metrics. In our experiments, we show that LLM judges have low
intra-rater reliability in their assigned scores across different runs. This
variance makes their ratings inconsistent, almost arbitrary in the worst case,
making it difficult to measure how good their judgments actually are. We
quantify this inconsistency across different NLG tasks and benchmarks and see
if judicious use of LLM judges can still be useful following proper guidelines.

</details>


### [13] [Probability Distributions Computed by Hard-Attention Transformers](https://arxiv.org/abs/2510.27118)
*Andy Yang,Anej Svete,Jiaoda Li,Anthony Widjaja Lin,Jonathan Rawski,Ryan Cotterell,David Chiang*

Main category: cs.CL

TL;DR: 论文分析了transformer语言模型在自回归和概率性生成字符串时的表达能力，指出与语言识别器不同的特性。


<details>
  <summary>Details</summary>
Motivation: 大多数关于transformer的表达能力的研究将其视为语言识别器，而不是实践中作为语言模型的用途，这促使作者研究其作为语言模型时的表达能力。

Method: 作者通过刻画transformer语言模型可以表达的概率分布，分析其在自回归和概率性条件下的表达能力。

Result: 研究表明，使transformer语言识别器自回归有时可以增加其表达能力，并且使其具有概率性可能会打破非概率情况下的等价性。

Conclusion: 论文的主要贡献在于揭示了transformer在作为语言模型时能够表达的功能。

Abstract: Most expressivity results for transformers treat them as language recognizers
(which accept or reject strings), and not as they are used in practice, as
language models (which generate strings autoregressively and
probabilistically). Here, we characterize the probability distributions that
transformer language models can express. We show that making transformer
language recognizers autoregressive can sometimes increase their expressivity,
and that making them probabilistic can break equivalences that hold in the
non-probabilistic case. Our overall contribution is to tease apart what
functions transformers are capable of expressing, in their most common use-case
as language models.

</details>


### [14] [Simple Additions, Substantial Gains: Expanding Scripts, Languages, and Lineage Coverage in URIEL+](https://arxiv.org/abs/2510.27183)
*Mason Shipton,York Hay Ng,Aditya Khan,Phuong Hanh Hoang,Xiang Lu,A. Seza Doğruöz,En-Shiun Annie Lee*

Main category: cs.CL

TL;DR: 本文通过引入脚本向量、整合Glottolog数据库和扩展谱系估算，扩展了URIEL+语言知识库，以解决数据稀疏性问题。


<details>
  <summary>Details</summary>
Motivation: 数据稀疏性限制了URIEL+在多语言迁移中的实用性，尤其是在支持低资源语言方面。

Method: 引入脚本向量表示7,488种语言的书写系统，整合Glottolog增加18,710种语言，并通过谱系传播扩展26,449种语言的估算。

Result: 脚本向量减少特征稀疏性14%，语言覆盖增加19,015种（1,007%），估算质量指标提升33%。

Conclusion: 这些改进使得URIEL+在多语言研究中更加完整和包容，尤其在低资源语言迁移任务中，性能提升可达6%。

Abstract: The URIEL+ linguistic knowledge base supports multilingual research by
encoding languages through geographic, genetic, and typological vectors.
However, data sparsity remains prevalent, in the form of missing feature types,
incomplete language entries, and limited genealogical coverage. This limits the
usefulness of URIEL+ in cross-lingual transfer, particularly for supporting
low-resource languages. To address this sparsity, this paper extends URIEL+
with three contributions: introducing script vectors to represent writing
system properties for 7,488 languages, integrating Glottolog to add 18,710
additional languages, and expanding lineage imputation for 26,449 languages by
propagating typological and script features across genealogies. These additions
reduce feature sparsity by 14% for script vectors, increase language coverage
by up to 19,015 languages (1,007%), and improve imputation quality metrics by
up to 33%. Our benchmark on cross-lingual transfer tasks (oriented around
low-resource languages) shows occasionally divergent performance compared to
URIEL+, with performance gains up to 6% in certain setups. Our advances make
URIEL+ more complete and inclusive for multilingual research.

</details>


### [15] [Identifying the Periodicity of Information in Natural Language](https://arxiv.org/abs/2510.27241)
*Yulin Ou,Yu Wang,Yang Xu,Hendrik Buschmeier*

Main category: cs.CL

TL;DR: 本文介绍了一种新方法AutoPeriod of Surprisal (APS)，用于检测自然语言信息密度中的周期性模式。


<details>
  <summary>Details</summary>
Motivation: 探讨自然语言在编码信息中表现出的周期性模式的程度。

Method: 引入APS方法，采用规范的周期性检测算法，识别单个文档惊讶序列中的显著周期。

Result: 发现相当部分的人类语言在信息中表现出强周期性模式，并发现新的周期，这些周期超出了典型文本结构单元的分布。

Conclusion: 语言中的信息周期性是结构化因素和在较长距离起作用的其他驱动因素共同作用的结果。

Abstract: Recent theoretical advancement of information density in natural language has
brought the following question on desk: To what degree does natural language
exhibit periodicity pattern in its encoded information? We address this
question by introducing a new method called AutoPeriod of Surprisal (APS). APS
adopts a canonical periodicity detection algorithm and is able to identify any
significant periods that exist in the surprisal sequence of a single document.
By applying the algorithm to a set of corpora, we have obtained the following
interesting results: Firstly, a considerable proportion of human language
demonstrates a strong pattern of periodicity in information; Secondly, new
periods that are outside the distributions of typical structural units in text
(e.g., sentence boundaries, elementary discourse units, etc.) are found and
further confirmed via harmonic regression modeling. We conclude that the
periodicity of information in language is a joint outcome from both structured
factors and other driving factors that take effect at longer distances. The
advantages of our periodicity detection method and its potentials in
LLM-generation detection are further discussed.

</details>


### [16] [Beyond a Million Tokens: Benchmarking and Enhancing Long-Term Memory in LLMs](https://arxiv.org/abs/2510.27246)
*Mohammad Tavakoli,Alireza Salemi,Carrie Ye,Mohamed Abdalla,Hamed Zamani,J Ross Mitchell*

Main category: cs.CL

TL;DR: 该论文介绍了一种用于评估大型语言模型在长期记忆和长上下文推理任务中表现的新框架和基准。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试在评估大型语言模型的长期记忆能力方面存在不足，例如缺乏叙事连贯性、领域狭窄和仅测试简单回忆任务。

Method: 提出了一种自动生成长而连贯、主题多样的对话及探测问题的新框架，并构建了BEAM基准。还提出了LIGHT框架，通过模拟人类认知增强模型性能，包括长期情景记忆、短期工作记忆和用于积累显著事实的便签。

Result: 在BEAM上的实验显示，即使在具有1M token上下文窗口的LLMs中，随着对话变长，其表现也不理想。而LIGHT框架在各种模型上持续提高性能，平均提高3.5%-12.69%。

Conclusion: LIGHT框架显著提升了大型语言模型在长期记忆和长上下文推理任务中的性能，且消融研究进一步证实了每个记忆组件的贡献。

Abstract: Evaluating the abilities of large language models (LLMs) for tasks that
require long-term memory and thus long-context reasoning, for example in
conversational settings, is hampered by the existing benchmarks, which often
lack narrative coherence, cover narrow domains, and only test simple
recall-oriented tasks. This paper introduces a comprehensive solution to these
challenges. First, we present a novel framework for automatically generating
long (up to 10M tokens), coherent, and topically diverse conversations,
accompanied by probing questions targeting a wide range of memory abilities.
From this, we construct BEAM, a new benchmark comprising 100 conversations and
2,000 validated questions. Second, to enhance model performance, we propose
LIGHT-a framework inspired by human cognition that equips LLMs with three
complementary memory systems: a long-term episodic memory, a short-term working
memory, and a scratchpad for accumulating salient facts. Our experiments on
BEAM reveal that even LLMs with 1M token context windows (with and without
retrieval-augmentation) struggle as dialogues lengthen. In contrast, LIGHT
consistently improves performance across various models, achieving an average
improvement of 3.5%-12.69% over the strongest baselines, depending on the
backbone LLM. An ablation study further confirms the contribution of each
memory component.

</details>


### [17] [Languages are Modalities: Cross-Lingual Alignment via Encoder Injection](https://arxiv.org/abs/2510.27254)
*Rajan Agarwal,Aarush Gupta*

Main category: cs.CL

TL;DR: LLINK方法通过将低资源语言作为模态，利用多语言编码器和轻量级对比投影器，在不改变分词器或重新训练解码器的情况下，显著提升大语言模型在非拉丁脚本上的性能。


<details>
  <summary>Details</summary>
Motivation: 当前指令微调的大语言模型在低资源、非拉丁脚本上表现不佳，主要由于分词器碎片化和跨语言耦合弱。

Method: LLINK通过将多语言编码器的句子嵌入与解码器的潜在嵌入空间对齐，并利用轻量级适配器和软槽扩展，实现语言模态的条件化。

Result: LLINK在双语检索上有显著提升，LLM-judged Q&A评估中优于基础模型81.3%，优于直接微调63.6%。

Conclusion: 将低资源语言视为模态，为轻量级大语言模型提供了更强的跨语言对齐实用路径，尽管在数字保真度上仍有不足。

Abstract: Instruction-tuned Large Language Models (LLMs) underperform on low resource,
non-Latin scripts due to tokenizer fragmentation and weak cross-lingual
coupling. We present LLINK (Latent Language Injection for Non-English
Knowledge), a compute efficient language-as-modality method that conditions an
instruction-tuned decoder without changing the tokenizer or retraining the
decoder. First, we align sentence embeddings from a frozen multilingual encoder
to the decoder's latent embedding space at a reserved position via a
lightweight contrastive projector. Second, the vector is expanded into K soft
slots and trained with minimal adapters so the frozen decoder consumes the
signal. LLINK substantially improves bilingual retrieval and achieves 81.3%
preference over the base model and 63.6% over direct fine-tuning in LLM-judged
Q&A evaluations. We further find that improvements can be attributed to reduced
tokenization inflation and a stronger cross lingual alignment, despite the
model having residual weaknesses in numeric fidelity. Treating low resource
languages as a modality offers a practical path to stronger cross-lingual
alignment in lightweight LLMs.

</details>


### [18] [MedCalc-Eval and MedCalc-Env: Advancing Medical Calculation Capabilities of Large Language Models](https://arxiv.org/abs/2510.27267)
*Kangkun Mao,Jinru Ding,Jiayuan Chen,Mouxiao Bian,Ruiyao Chen,Xinwei Peng,Sijie Ren,Linyang Li,Jie Xu*

Main category: cs.CL

TL;DR: 本文介绍了MedCalc-Eval，一个用于评估大型语言模型在医学计算能力方面的最大基准，包含700多项任务，涵盖方程型和规则型评分系统。


<details>
  <summary>Details</summary>
Motivation: 当前医学领域的大型语言模型大多在问答或描述性推理上评估，忽视了临床决策中重要的定量推理。现有数据集如MedCalc-Bench覆盖的计算任务少，且无法反映真实世界的计算场景。

Method: 引入了MedCalc-Eval基准，包含700多个任务，分为方程型（如Cockcroft-Gault、BMI、BSA）和规则型评分系统（如Apgar、Glasgow昏迷评分）。此外，开发了MedCalc-Env，一个基于InternBootcamp框架的强化学习环境，支持多步临床推理和规划。

Result: 在MedCalc-Eval上对Qwen2.5-32B模型进行微调，在数值敏感性、公式选择和推理鲁棒性方面取得了显著的进步，达到了最先进的结果。

Conclusion: 尽管取得了进展，仍存在单位转换、多条件逻辑和上下文理解的挑战。代码和数据集可在https://github.com/maokangkun/MedCalc-Eval获取。

Abstract: As large language models (LLMs) enter the medical domain, most benchmarks
evaluate them on question answering or descriptive reasoning, overlooking
quantitative reasoning critical to clinical decision-making. Existing datasets
like MedCalc-Bench cover few calculation tasks and fail to reflect real-world
computational scenarios.
  We introduce MedCalc-Eval, the largest benchmark for assessing LLMs' medical
calculation abilities, comprising 700+ tasks across two types: equation-based
(e.g., Cockcroft-Gault, BMI, BSA) and rule-based scoring systems (e.g., Apgar,
Glasgow Coma Scale). These tasks span diverse specialties including internal
medicine, surgery, pediatrics, and cardiology, offering a broader and more
challenging evaluation setting.
  To improve performance, we further develop MedCalc-Env, a reinforcement
learning environment built on the InternBootcamp framework, enabling multi-step
clinical reasoning and planning. Fine-tuning a Qwen2.5-32B model within this
environment achieves state-of-the-art results on MedCalc-Eval, with notable
gains in numerical sensitivity, formula selection, and reasoning robustness.
Remaining challenges include unit conversion, multi-condition logic, and
contextual understanding.
  Code and datasets are available at
https://github.com/maokangkun/MedCalc-Eval.

</details>


### [19] [Why Do Multilingual Reasoning Gaps Emerge in Reasoning Language Models?](https://arxiv.org/abs/2510.27269)
*Deokhyung Kang,Seonjeong Hwang,Daehui Kim,Hyounghun Kim,Gary Geunbae Lee*

Main category: cs.CL

TL;DR: 本文探讨了推理语言模型在多语言推理任务中的差距，并提出了一种选择性翻译策略以缩小这一差距。


<details>
  <summary>Details</summary>
Motivation: 推理语言模型在高资源语言中表现优于低资源语言，这种多语言推理差距的原因尚不明确。本文旨在探索并解决这一问题。

Method: 作者提出了一种名为Selective Translation的策略，通过检测理解失败并在需要时将多语言输入翻译成英文，从而减少多语言推理差距。

Result: 实验结果表明，Selective Translation策略有效地缩小了多语言推理差距，达到了接近完全翻译的性能，但仅对约20%的输入进行了翻译。

Conclusion: 理解失败是多语言推理差距的主要原因，可以通过检测和选择性缓解这一差距，这为更公平的多语言推理提供了一条有前景的路径。

Abstract: Reasoning language models (RLMs) achieve strong performance on complex
reasoning tasks, yet they still suffer from a multilingual reasoning gap,
performing better in high-resource languages than in low-resource ones. While
recent efforts have reduced this gap, its underlying causes remain largely
unexplored. In this paper, we address this by showing that the multilingual
reasoning gap largely stems from failures in language understanding-the model's
inability to represent the multilingual input meaning into the dominant
language (i.e., English) within its reasoning trace. This motivates us to
examine whether understanding failures can be detected, as this ability could
help mitigate the multilingual reasoning gap. To this end, we evaluate a range
of detection methods and find that understanding failures can indeed be
identified, with supervised approaches performing best. Building on this, we
propose Selective Translation, a simple yet effective strategy that translates
the multilingual input into English only when an understanding failure is
detected. Experimental results show that Selective Translation bridges the
multilingual reasoning gap, achieving near full-translation performance while
using translation for only about 20% of inputs. Together, our work demonstrates
that understanding failures are the primary cause of the multilingual reasoning
gap and can be detected and selectively mitigated, providing key insight into
its origin and a promising path toward more equitable multilingual reasoning.
Our code and data are publicly available at
https://github.com/deokhk/RLM_analysis.

</details>


### [20] [A Unified Representation Underlying the Judgment of Large Language Models](https://arxiv.org/abs/2510.27328)
*Yi-Long Lu,Jiajun Song,Wei Wang*

Main category: cs.CL

TL;DR: 本文探讨了人工智能判断是否依赖于专门模块或统一资源的问题，发现了大型语言模型中评估性判断的集中架构，即"情感-同意轴"（VAA）。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于理解判断在人工智能中是如何架构的，即它是依赖于多个专门模块还是一个统一的领域通用资源。

Method: 通过分析多种大型语言模型，并对这些模型进行直接干预，以观察和测量‘情感-同意轴’（VAA）的作用。

Result: 研究发现，VAA作为统一的控制信号，会引导生成过程构建与其评估状态一致的理由，甚至以牺牲事实准确性为代价。

Conclusion: 这种‘推理的从属’机制揭示了系统性偏见和幻觉的机制，表明促进连贯判断的架构可能会系统地削弱忠实的推理。

Abstract: A central architectural question for both biological and artificial
intelligence is whether judgment relies on specialized modules or a unified,
domain-general resource. While the discovery of decodable neural
representations for distinct concepts in Large Language Models (LLMs) has
suggested a modular architecture, whether these representations are truly
independent systems remains an open question. Here we provide evidence for a
convergent architecture. Across a range of LLMs, we find that diverse
evaluative judgments are computed along a dominant dimension, which we term the
Valence-Assent Axis (VAA). This axis jointly encodes subjective valence ("what
is good") and the model's assent to factual claims ("what is true"). Through
direct interventions, we show this unified representation creates a critical
dependency: the VAA functions as a control signal that steers the generative
process to construct a rationale consistent with its evaluative state, even at
the cost of factual accuracy. This mechanism, which we term the subordination
of reasoning, shifts the process of reasoning from impartial inference toward
goal-directed justification. Our discovery offers a mechanistic account for
systemic bias and hallucination, revealing how an architecture that promotes
coherent judgment can systematically undermine faithful reasoning.

</details>


### [21] [TransAlign: Machine Translation Encoders are Strong Word Aligners, Too](https://arxiv.org/abs/2510.27337)
*Benedikt Ebing,Christian Goldschmied,Goran Glavaš*

Main category: cs.CL

TL;DR: 本文提出了一种新的词对齐工具TransAlign，利用多语言机器翻译模型的编码器，显著提高了跨语言迁移任务中的标签投影性能。


<details>
  <summary>Details</summary>
Motivation: 在缺乏大规模训练数据的情况下，基于翻译的跨语言迁移策略（如translate-test和translate-train）需要标签投影，但现有的词对齐工具效果不佳。

Method: 提出TransAlign，一种利用大规模多语言机器翻译模型编码器的新词对齐方法。

Result: TransAlign在词对齐性能上表现优异，并在基于翻译的跨语言迁移任务中显著优于现有的词对齐和基于非词对齐的标签投影方法。

Conclusion: 利用多语言机器翻译模型的编码器进行词对齐，是一种有效的跨语言标签投影方法，能够显著提升跨语言迁移任务的性能。

Abstract: In the absence of sizable training data for most world languages and NLP
tasks, translation-based strategies such as translate-test -- evaluating on
noisy source language data translated from the target language -- and
translate-train -- training on noisy target language data translated from the
source language -- have been established as competitive approaches for
cross-lingual transfer (XLT). For token classification tasks, these strategies
require label projection: mapping the labels from each token in the original
sentence to its counterpart(s) in the translation. To this end, it is common to
leverage multilingual word aligners (WAs) derived from encoder language models
such as mBERT or LaBSE. Despite obvious associations between machine
translation (MT) and WA, research on extracting alignments with MT models is
largely limited to exploiting cross-attention in encoder-decoder architectures,
yielding poor WA results. In this work, in contrast, we propose TransAlign, a
novel word aligner that utilizes the encoder of a massively multilingual MT
model. We show that TransAlign not only achieves strong WA performance but
substantially outperforms popular WA and state-of-the-art non-WA-based label
projection methods in MT-based XLT for token classification.

</details>


### [22] [ThoughtProbe: Classifier-Guided LLM Thought Space Exploration via Probing Representations](https://arxiv.org/abs/2510.27355)
*Zijian Wang,Chang Xu*

Main category: cs.CL

TL;DR: ThoughtProbe是一个利用LLMs隐藏推理特征以改善推理性能的新框架。


<details>
  <summary>Details</summary>
Motivation: 以往的方法通过操控隐藏表示来引导LLM生成，而本框架则利用这些隐藏特征作为判别信号，指导树结构响应空间探索。

Method: 在每个节点扩展中，使用分类器作为评分和排序机制，通过优先选择高分候选者以高效分配计算资源。树扩展完成后，从所有分支收集答案，并通过分支聚合方法，通过聚合CoT得分找出最优答案。

Result: 实验结果表明，该框架的全面探索不仅覆盖了有效的推理链，还能有效识别它们，在多个算术推理基准上实现显著改进。

Conclusion: ThoughtProbe框架通过利用LLMs的隐藏推理特征，在推理任务中显著提高了性能。

Abstract: This paper introduces ThoughtProbe, a novel inference time framework that
leverages the hidden reasoning features of Large Language Models (LLMs) to
improve their reasoning performance. Unlike previous works that manipulate the
hidden representations to steer LLM generation, we harness them as
discriminative signals to guide the tree structured response space exploration.
In each node expansion, a classifier serves as a scoring and ranking mechanism
that efficiently allocates computational resources by prioritizing higher score
candidates for continuation. After completing the tree expansion, we collect
answers from all branches to form a candidate answer pool. We then propose a
branch aggregation method that marginalizes over all supporting branches by
aggregating their CoT scores, thereby identifying the optimal answer from the
pool. Experimental results show that our framework's comprehensive exploration
not only covers valid reasoning chains but also effectively identifies them,
achieving significant improvements across multiple arithmetic reasoning
benchmarks.

</details>


### [23] [Balancing Knowledge Updates: Toward Unified Modular Editing in LLMs](https://arxiv.org/abs/2510.27400)
*Jiahao Liu,Zijian Wang,Kuo Zhao,Dong Hu*

Main category: cs.CL

TL;DR: IntAttn-Edit是一种新的知识编辑方法，通过联合更新MLP和Attn模块来提高编辑效果。


<details>
  <summary>Details</summary>
Motivation: 现有知识编辑方法主要关注MLP模块，而忽视了Attn模块的作用，导致编辑效果受限。

Method: 提出IntAttn-Edit方法，将关联记忆范式扩展到MLP和Attn模块的联合更新，并引入知识平衡策略。

Result: 在标准基准测试中，IntAttn-Edit在编辑成功、泛化和知识保留方面优于现有方法。

Conclusion: Attn模块在知识存储和检索中起重要作用，平衡的更新策略有助于在不同设置下保持最优的编辑性能。

Abstract: Knowledge editing has emerged as an efficient approach for updating factual
knowledge in large language models (LLMs). It typically locates knowledge
storage modules and then modifies their parameters. However, most existing
methods focus on the weights of multilayer perceptron (MLP) modules, which are
often identified as the main repositories of factual information. Other
components, such as attention (Attn) modules, are often ignored during editing.
This imbalance can leave residual outdated knowledge and limit editing
effectiveness. We perform comprehensive knowledge localization experiments on
advanced LLMs and find that Attn modules play a substantial role in factual
knowledge storage and retrieval, especially in earlier layers. Based on these
insights, we propose IntAttn-Edit, a method that extends the associative memory
paradigm to jointly update both MLP and Attn modules. Our approach uses a
knowledge balancing strategy that allocates update magnitudes in proportion to
each module's measured contribution to knowledge storage. Experiments on
standard benchmarks show that IntAttn-Edit achieves higher edit success, better
generalization, and stronger knowledge preservation than prior methods. Further
analysis shows that the balancing strategy keeps editing performance within an
optimal range across diverse settings.

</details>


### [24] [Awal -- Community-Powered Language Technology for Tamazight](https://arxiv.org/abs/2510.27407)
*Alp Öktem,Farida Boudichat*

Main category: cs.CL

TL;DR: 本文介绍了Awal，一个为塔马齐特语（Tamazight）开发语言技术资源的社区驱动项目，旨在通过协作平台解决数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 解决塔马齐特语在数字空间中的代表性不足问题，并应对语言数据稀缺的挑战。

Method: 通过 awaldigital.org 平台，鼓励社区成员贡献翻译和语音数据，并进行18个月的社区参与分析。

Result: 社区贡献有限，仅有6,421个翻译对和3小时的语音数据，参与度集中在语言学家和活动家中。

Conclusion: 标准众包方法在复杂的社会语言环境中存在局限，需要改进方法以更好地支持资源稀缺语言的技术开发。

Abstract: This paper presents Awal, a community-powered initiative for developing
language technology resources for Tamazight. We provide a comprehensive review
of the NLP landscape for Tamazight, examining recent progress in computational
resources, and the emergence of community-driven approaches to address
persistent data scarcity. Launched in 2024, awaldigital.org platform addresses
the underrepresentation of Tamazight in digital spaces through a collaborative
platform enabling speakers to contribute translation and voice data. We analyze
18 months of community engagement, revealing significant barriers to
participation including limited confidence in written Tamazight and ongoing
standardization challenges. Despite widespread positive reception, actual data
contribution remained concentrated among linguists and activists. The modest
scale of community contributions -- 6,421 translation pairs and 3 hours of
speech data -- highlights the limitations of applying standard crowdsourcing
approaches to languages with complex sociolinguistic contexts. We are working
on improved open-source MT models using the collected data.

</details>


### [25] [VCORE: Variance-Controlled Optimization-based Reweighting for Chain-of-Thought Supervision](https://arxiv.org/abs/2510.27462)
*Xuan Gong,Senmiao Wang,Hanbo Huang,Ruoyu Sun,Shiyu Liang*

Main category: cs.CL

TL;DR: 提出了一种新的框架VCORE，通过优化理论视角对长链推理中的token进行自适应加权，提升大语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 标准交叉熵损失在长链推理中均等对待所有token，忽略了不同token在推理过程中的异质性贡献，导致监督分配不当和泛化能力弱。

Method: 引入了一种基于方差控制优化重加权（VCORE）的框架，将链式思维监督重构为约束优化问题，实现对token监督的有原则且自适应的分配。

Result: VCORE在数学和编码基准测试中，无论是在领域内还是领域外设置，均优于现有token加权方法，实现了显著的性能提升。

Conclusion: VCORE不仅提升了推理性能，还为后续强化学习提供了更有效的初始化，为增强LLM的推理能力奠定了更强基础。

Abstract: Supervised fine-tuning (SFT) on long chain-of-thought (CoT) trajectories has
emerged as a crucial technique for enhancing the reasoning abilities of large
language models (LLMs). However, the standard cross-entropy loss treats all
tokens equally, ignoring their heterogeneous contributions across a reasoning
trajectory. This uniform treatment leads to misallocated supervision and weak
generalization, especially in complex, long-form reasoning tasks. To address
this, we introduce \textbf{V}ariance-\textbf{C}ontrolled
\textbf{O}ptimization-based \textbf{RE}weighting (VCORE), a principled
framework that reformulates CoT supervision as a constrained optimization
problem. By adopting an optimization-theoretic perspective, VCORE enables a
principled and adaptive allocation of supervision across tokens, thereby
aligning the training objective more closely with the goal of robust reasoning
generalization. Empirical evaluations demonstrate that VCORE consistently
outperforms existing token reweighting methods. Across both in-domain and
out-of-domain settings, VCORE achieves substantial performance gains on
mathematical and coding benchmarks, using models from the Qwen3 series (4B, 8B,
32B) and LLaMA-3.1-8B-Instruct. Moreover, we show that VCORE serves as a more
effective initialization for subsequent reinforcement learning, establishing a
stronger foundation for advancing the reasoning capabilities of LLMs. The Code
will be released at https://github.com/coder-gx/VCORE.

</details>


### [26] [Diffuse Thinking: Exploring Diffusion Language Models as Efficient Thought Proposers for Reasoning](https://arxiv.org/abs/2510.27469)
*Chenyang Shao,Sijian Ren,Fengli Xu,Yong Li*

Main category: cs.CL

TL;DR: 本文提出了一个高效协作推理框架，利用扩散语言模型（DLMs）生成候选思维，并用大型语言模型（LLMs）评估其质量，以减轻自回归生成时的计算负担。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在推理能力上表现出众，但自回归生成模式导致推理性能在测试时间计算下扩展不佳，需要大量计算开销。相对地，扩散语言模型（DLMs）可以通过并行去噪高效地产生多样样本。

Method: 提出一种框架，利用DLMs生成候选思维，LLMs评估质量，从而实现高效的协作推理。

Result: 在多个复杂推理任务的基准测试中，该框架表现出强大的性能。

Conclusion: 该框架为未来研究提供了一个有希望的方向，即通过结合DLMs和LLMs，实现更高效的推理过程。

Abstract: In recent years, large language models (LLMs) have witnessed remarkable
advancements, with the test-time scaling law consistently enhancing the
reasoning capabilities. Through systematic evaluation and exploration of a
diverse spectrum of intermediate thoughts, LLMs demonstrate the potential to
generate deliberate reasoning steps, thereby substantially enhancing reasoning
accuracy. However, LLMs' autoregressive generation paradigm results in
reasoning performance scaling sub-optimally with test-time computation, often
requiring excessive computational overhead to propose thoughts while yielding
only marginal performance gains. In contrast, diffusion language models (DLMs)
can efficiently produce diverse samples through parallel denoising in a single
forward pass, inspiring us to leverage them for proposing intermediate
thoughts, thereby alleviating the computational burden associated with
autoregressive generation while maintaining quality. In this work, we propose
an efficient collaborative reasoning framework, leveraging DLMs to generate
candidate thoughts and LLMs to evaluate their quality. Experiments across
diverse benchmarks demonstrate that our framework achieves strong performance
in complex reasoning tasks, offering a promising direction for future research.
Our code is open-source at
https://anonymous.4open.science/r/Diffuse-Thinking-EC60.

</details>


### [27] [The aftermath of compounds: Investigating Compounds and their Semantic Representations](https://arxiv.org/abs/2510.27477)
*Swarang Joshi*

Main category: cs.CL

TL;DR: 本研究探讨了计算嵌入在处理英语复合词时与人类语义判断的一致性，比较了静态词向量（GloVe）和上下文嵌入（BERT）。


<details>
  <summary>Details</summary>
Motivation: 研究旨在理解计算嵌入如何捕捉复合词的语义，以及它们与人类的语义判断之间的对应关系。

Method: 使用了爱丁堡联想词库、英国国家语料库和可预测性（LaDEC）等关联强度、频率的测量，计算嵌入的LMD和ST指标，并通过斯皮尔曼相关和回归分析评估其与人类判断的关系。

Result: 结果表明，BERT嵌入在捕捉组合语义方面优于GloVe，且可预测性评分是语义透明度的强预测因子。

Conclusion: 这些发现推动了计算心理语言学的发展，阐明了复合词处理的影响因素，并提供了对基于嵌入的语义建模的见解。

Abstract: This study investigates how well computational embeddings align with human
semantic judgments in the processing of English compound words. We compare
static word vectors (GloVe) and contextualized embeddings (BERT) against human
ratings of lexeme meaning dominance (LMD) and semantic transparency (ST) drawn
from a psycholinguistic dataset. Using measures of association strength
(Edinburgh Associative Thesaurus), frequency (BNC), and predictability (LaDEC),
we compute embedding-derived LMD and ST metrics and assess their relationships
with human judgments via Spearmans correlation and regression analyses. Our
results show that BERT embeddings better capture compositional semantics than
GloVe, and that predictability ratings are strong predictors of semantic
transparency in both human and model data. These findings advance computational
psycholinguistics by clarifying the factors that drive compound word processing
and offering insights into embedding-based semantic modeling.

</details>


### [28] [Effect of Domain Generalization Techniques in Low Resource Systems](https://arxiv.org/abs/2510.27512)
*Mahi Aminu,Chisom Chibuike,Fatimo Adebanjo,Omokolade Awosanya,Samuel Oyeneye*

Main category: cs.CL

TL;DR: 该研究探讨了两种因果领域泛化技术，在低资源自然语言任务中提升模型对分布变化的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型通常假设训练和测试数据同分布，但现实场景中分布偏移普遍存在，尤其在低资源环境下。领域泛化方法通过学习跨领域的不变特征以增强模型鲁棒性。

Method: 研究采用两种因果领域泛化方法：1) 因果数据增强（CDA），通过生成反事实样本增强情感分类的鲁棒性；2) 不变因果表征学习（ICRL），使用DINER框架进行多语言情感分析。

Result: 两种方法均提升了对未见领域的鲁棒性：CDA在情感分类中实现跨领域准确率增益，ICRL在多语言情感分析中提升分布外性能，但不同语言间增益有差异。

Conclusion: 因果领域泛化方法在低资源自然语言任务中有效，CDA和ICRL分别在单语和多语环境下提升了模型在分布偏移下的泛化能力。

Abstract: Machine learning models typically assume that training and test data follow
the same distribution, an assumption that often fails in real-world scenarios
due to distribution shifts. This issue is especially pronounced in low-resource
settings, where data scarcity and limited domain diversity hinder robust
generalization. Domain generalization (DG) approaches address this challenge by
learning features that remain invariant across domains, often using causal
mechanisms to improve model robustness. In this study, we examine two distinct
causal DG techniques in low-resource natural language tasks. First, we
investigate a causal data augmentation (CDA) approach that automatically
generates counterfactual examples to improve robustness to spurious
correlations. We apply this method to sentiment classification on the
NaijaSenti Twitter corpus, expanding the training data with semantically
equivalent paraphrases to simulate controlled distribution shifts. Second, we
explore an invariant causal representation learning (ICRL) approach using the
DINER framework, originally proposed for debiasing aspect-based sentiment
analysis. We adapt DINER to a multilingual setting. Our findings demonstrate
that both approaches enhance robustness to unseen domains: counterfactual data
augmentation yields consistent cross-domain accuracy gains in sentiment
classification, while causal representation learning with DINER improves
out-of-distribution performance in multilingual sentiment analysis, albeit with
varying gains across languages.

</details>


### [29] [Detecting Prefix Bias in LLM-based Reward Models](https://arxiv.org/abs/2505.13487)
*Ashwin Kumar,Yuzi He,Aram H. Markosyan,Bobbie Chern,Imanol Arrieta-Ibarra*

Main category: cs.CL

TL;DR: 本文探讨了强化学习结合人类反馈（RLHF）在语言模型微调中的前缀偏差问题，提出检测和缓解该偏差的方法。


<details>
  <summary>Details</summary>
Motivation: 尽管已有许多公开的偏好数据集，但这些数据可能引入奖励模型中的偏见，尤其是前缀变化导致的系统性偏好偏移（即前缀偏差）尚未被充分研究。

Method: 引入新指标检测并评估前缀偏差，在多个开源偏好数据集和奖励模型架构上进行全面评估，并提出一种数据增强策略以缓解偏差。

Result: 在多个偏好模型和不同数据集上发现显著的前缀偏差，尤其是在种族和性别维度上；提出的数据增强方法被证明能有效降低这种偏差。

Conclusion: 强调了在设计公平、可靠的奖励模型时，需关注数据集偏差问题，并呼吁在AI公平性领域进行更深入的研究。

Abstract: Reinforcement Learning with Human Feedback (RLHF) has emerged as a key
paradigm for task-specific fine-tuning of language models using human
preference data. While numerous publicly available preference datasets provide
pairwise comparisons of responses, the potential for biases in the resulting
reward models remains underexplored. In this work, we introduce novel methods
to detect and evaluate prefix bias -- a systematic shift in model preferences
triggered by minor variations in query prefixes -- in LLM-based reward models
trained on such datasets. We leverage these metrics to reveal significant
biases in preference models across racial and gender dimensions. Our
comprehensive evaluation spans diverse open-source preference datasets and
reward model architectures, demonstrating susceptibility to this kind of bias
regardless of the underlying model architecture. Furthermore, we propose a data
augmentation strategy to mitigate these biases, showing its effectiveness in
reducing the impact of prefix bias. Our findings highlight the critical need
for bias-aware dataset design and evaluation in developing fair and reliable
reward models, contributing to the broader discourse on fairness in AI.

</details>


### [30] [BiSparse-AAS: Bilinear Sparse Attention and Adaptive Spans Framework for Scalable and Efficient Text Summarization](https://arxiv.org/abs/2510.27516)
*Desta Haileselassie Hagos,Legand L. Burge,Anietie Andy,Anis Yazidi,Vladimir Vlassov*

Main category: cs.CL

TL;DR: BiSparse-AAS是一种结合稀疏注意力、自适应跨度和双线性注意力的新框架，解决了Transformer在长文档摘要中的计算复杂性问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于Transformer的架构在文本摘要方面取得了进展，但其二次复杂度限制了长文档的可扩展性。

Method: 引入BiSparse-AAS，该框架结合稀疏注意力减少计算成本，自适应跨度动态调整注意力范围，以及双线性注意力建模复杂标记交互。

Result: BiSparse-AAS在抽取式和生成式摘要任务中表现优于现有最佳基线，在CNN/DailyMail和XSum数据集上分别实现了平均68.1%和52.6%的ROUGE改进。

Conclusion: BiSparse-AAS解决了效率、可扩展性和长序列建模问题，为现实世界的文本摘要应用提供了统一且实用的解决方案。

Abstract: Transformer-based architectures have advanced text summarization, yet their
quadratic complexity limits scalability on long documents. This paper
introduces BiSparse-AAS (Bilinear Sparse Attention with Adaptive Spans), a
novel framework that combines sparse attention, adaptive spans, and bilinear
attention to address these limitations. Sparse attention reduces computational
costs by focusing on the most relevant parts of the input, while adaptive spans
dynamically adjust the attention ranges. Bilinear attention complements both by
modeling complex token interactions within this refined context. BiSparse-AAS
consistently outperforms state-of-the-art baselines in both extractive and
abstractive summarization tasks, achieving average ROUGE improvements of about
68.1% on CNN/DailyMail and 52.6% on XSum, while maintaining strong performance
on OpenWebText and Gigaword datasets. By addressing efficiency, scalability,
and long-sequence modeling, BiSparse-AAS provides a unified, practical solution
for real-world text summarization applications.

</details>


### [31] [SQLSpace: A Representation Space for Text-to-SQL to Discover and Mitigate Robustness Gaps](https://arxiv.org/abs/2510.27532)
*Neha Srikanth,Victor Bursztyn,Puneet Mathur,Ani Nenkova*

Main category: cs.CL

TL;DR: SQLSpace是一种可解释性强、可推广且简洁的text-to-SQL示例表示方法，通过少量人工干预即可派生。


<details>
  <summary>Details</summary>
Motivation: 为了解决在text-to-SQL任务中，难以通过原始示例进行深入分析的问题，特别是在比较不同基准数据集、理解模型表现和通过有针对性的查询重写提升模型性能方面。

Method: 引入SQLSpace，一种新的表示方法，并应用于三个用例：比较基准数据集组成、细致理解模型表现，以及通过查询重写提升模型性能。

Result: SQLSpace成功揭示了基准数据集之间的组合差异，揭露了仅靠准确率无法看到的性能模式，并支持了查询成功的建模。

Conclusion: SQLSpace提供了一种有效的方式，使得text-to-SQL的分析更加深入和细致，有助于未来在这一领域的进一步研究和应用。

Abstract: We introduce SQLSpace, a human-interpretable, generalizable, compact
representation for text-to-SQL examples derived with minimal human
intervention. We demonstrate the utility of these representations in evaluation
with three use cases: (i) closely comparing and contrasting the composition of
popular text-to-SQL benchmarks to identify unique dimensions of examples they
evaluate, (ii) understanding model performance at a granular level beyond
overall accuracy scores, and (iii) improving model performance through targeted
query rewriting based on learned correctness estimation. We show that SQLSpace
enables analysis that would be difficult with raw examples alone: it reveals
compositional differences between benchmarks, exposes performance patterns
obscured by accuracy alone, and supports modeling of query success.

</details>


### [32] [Patient-Centered Summarization Framework for AI Clinical Summarization: A Mixed-Methods Design](https://arxiv.org/abs/2510.27535)
*Maria Lizarazo Jimenez,Ana Gabriela Claros,Kieran Green,David Toro-Tobon,Felipe Larios,Sheena Asthana,Camila Wenczenovicz,Kerly Guevara Maldonado,Luis Vilatuna-Andrango,Cristina Proano-Velez,Satya Sai Sri Bandi,Shubhangi Bagewadi,Megan E. Branda,Misk Al Zahidy,Saturnino Luz,Mirella Lapata,Juan P. Brito,Oscar J. Ponce-Ponte*

Main category: cs.CL

TL;DR: 提出患者中心摘要（PCS）新标准，开发框架并评估开源LLMs生成患者价值观摘要的能力。


<details>
  <summary>Details</summary>
Motivation: 当前临床摘要侧重患者生理信息，忽视其偏好、价值观和担忧，需实现以患者为中心的医疗。

Method: 采用混合方法：患者和医护人员访谈确定摘要内容结构；临床医生创建金标准PCS；使用五种开源LLMs进行零样本/少样本摘要生成，结合ROUGE-L、BERTScore和定性指标评估。

Result: 最佳零样本表现：Mistral-8B（ROUGE-L 0.189）和Llama-3.1-8B（BERTScore 0.673）；最佳少样本表现：Llama-3.1-8B（ROUGE-L 0.206/BERTScore 0.683）。模型在完整性和流畅性接近专家，正确性和患者中心性仍落后。

Conclusion: 当前开源LLMs尚未达到人类水平的PCS生成能力，但已展示出潜力，需进一步改进正确性和患者中心性。

Abstract: Large Language Models (LLMs) are increasingly demonstrating the potential to
reach human-level performance in generating clinical summaries from
patient-clinician conversations. However, these summaries often focus on
patients' biology rather than their preferences, values, wishes, and concerns.
To achieve patient-centered care, we propose a new standard for Artificial
Intelligence (AI) clinical summarization tasks: Patient-Centered Summaries
(PCS). Our objective was to develop a framework to generate PCS that capture
patient values and ensure clinical utility and to assess whether current
open-source LLMs can achieve human-level performance in this task. We used a
mixed-methods process. Two Patient and Public Involvement groups (10 patients
and 8 clinicians) in the United Kingdom participated in semi-structured
interviews exploring what personal and contextual information should be
included in clinical summaries and how it should be structured for clinical
use. Findings informed annotation guidelines used by eight clinicians to create
gold-standard PCS from 88 atrial fibrillation consultations. Sixteen
consultations were used to refine a prompt aligned with the guidelines. Five
open-source LLMs (Llama-3.2-3B, Llama-3.1-8B, Mistral-8B, Gemma-3-4B, and
Qwen3-8B) generated summaries for 72 consultations using zero-shot and few-shot
prompting, evaluated with ROUGE-L, BERTScore, and qualitative metrics. Patients
emphasized lifestyle routines, social support, recent stressors, and care
values. Clinicians sought concise functional, psychosocial, and emotional
context. The best zero-shot performance was achieved by Mistral-8B (ROUGE-L
0.189) and Llama-3.1-8B (BERTScore 0.673); the best few-shot by Llama-3.1-8B
(ROUGE-L 0.206, BERTScore 0.683). Completeness and fluency were similar between
experts and models, while correctness and patient-centeredness favored human
PCS.

</details>


### [33] [DialectalArabicMMLU: Benchmarking Dialectal Capabilities in Arabic and Multilingual Language Models](https://arxiv.org/abs/2510.27543)
*Malik H. Altakrori,Nizar Habash,Abdelhakim Freihat,Younes Samih,Kirill Chirkunov,Muhammed AbuOdeh,Radu Florian,Teresa Lynn,Preslav Nakov,Alham Fikri Aji*

Main category: cs.CL

TL;DR: 提出DialectalArabicMMLU，一个新的用于评估大型语言模型在阿拉伯方言上的性能的基准测试。


<details>
  <summary>Details</summary>
Motivation: 尽管现代标准阿拉伯语（MSA）在大型语言模型评估中取得了进展，但日常交流中广泛使用的方言却未被充分代表。因此，需要开发一个能够评估方言理解能力的基准。

Method: 通过手动翻译和适配，将3K个多选题-答案对扩展为五种主要方言（叙利亚、埃及、阿联酋、沙特和摩洛哥），形成包含15K个QA对的基准测试，涵盖32个学术和职业领域。

Result: 评估了19个开放权重的阿拉伯语和多种语言大型语言模型，发现模型在不同方言上的表现存在显著差异，揭示了方言泛化方面的持续差距。

Conclusion: DialectalArabicMMLU是首个统一的人工审核资源，用于测量阿拉伯语方言理解，推动更具包容性的评估和未来模型开发。

Abstract: We present DialectalArabicMMLU, a new benchmark for evaluating the
performance of large language models (LLMs) across Arabic dialects. While
recently developed Arabic and multilingual benchmarks have advanced LLM
evaluation for Modern Standard Arabic (MSA), dialectal varieties remain
underrepresented despite their prevalence in everyday communication.
DialectalArabicMMLU extends the MMLU-Redux framework through manual translation
and adaptation of 3K multiple-choice question-answer pairs into five major
dialects (Syrian, Egyptian, Emirati, Saudi, and Moroccan), yielding a total of
15K QA pairs across 32 academic and professional domains (22K QA pairs when
also including English and MSA). The benchmark enables systematic assessment of
LLM reasoning and comprehension beyond MSA, supporting both task-based and
linguistic analysis. We evaluate 19 open-weight Arabic and multilingual LLMs
(1B-13B parameters) and report substantial performance variation across
dialects, revealing persistent gaps in dialectal generalization.
DialectalArabicMMLU provides the first unified, human-curated resource for
measuring dialectal understanding in Arabic, thus promoting more inclusive
evaluation and future model development.

</details>


### [34] [Multilingual BERT language model for medical tasks: Evaluation on domain-specific adaptation and cross-linguality](https://arxiv.org/abs/2510.27552)
*Yinghao Luo,Lang Zhou,Amrish Jhingoer,Klaske Vliegenthart Jongbloed,Carlijn Jordans,Ben Werkhoven,Tom Seinen,Erik van Mulligen,Casper Rokx,Yunlei Li*

Main category: cs.CL

TL;DR: 该研究探讨了通过在特定领域语料库上进一步预训练多语言BERT模型，对低资源语言医疗NLP任务性能的影响。


<details>
  <summary>Details</summary>
Motivation: 多语言BERT在减少语言差距方面具有潜力，但在低资源语言的医疗NLP任务中仍探索不足。

Method: 通过在荷兰语、罗马尼亚语和西班牙语的临床和生物医学语料库上进一步预训练BERT模型，并在三个下游任务中微调，创建医疗领域模型。

Result: 领域自适应显著提升了任务性能；临床领域自适应模型表现优于通用生物医学领域模型，并观察到跨语言迁移能力的证据。

Conclusion: 该研究展示了在低资源语言环境下，领域自适应和跨语言能力在医疗NLP中的可行性，为开发多语言医疗NLP系统提供了指导。

Abstract: In multilingual healthcare applications, the availability of domain-specific
natural language processing(NLP) tools is limited, especially for low-resource
languages. Although multilingual bidirectional encoder representations from
transformers (BERT) offers a promising motivation to mitigate the language gap,
the medical NLP tasks in low-resource languages are still underexplored.
Therefore, this study investigates how further pre-training on domain-specific
corpora affects model performance on medical tasks, focusing on three
languages: Dutch, Romanian and Spanish. In terms of further pre-training, we
conducted four experiments to create medical domain models. Then, these models
were fine-tuned on three downstream tasks: Automated patient screening in Dutch
clinical notes, named entity recognition in Romanian and Spanish clinical
notes. Results show that domain adaptation significantly enhanced task
performance. Furthermore, further differentiation of domains, e.g. clinical and
general biomedical domains, resulted in diverse performances. The clinical
domain-adapted model outperformed the more general biomedical domain-adapted
model. Moreover, we observed evidence of cross-lingual transferability.
Moreover, we also conducted further investigations to explore potential reasons
contributing to these performance differences. These findings highlight the
feasibility of domain adaptation and cross-lingual ability in medical NLP.
Within the low-resource language settings, these findings can provide
meaningful guidance for developing multilingual medical NLP systems to mitigate
the lack of training data and thereby improve the model performance.

</details>


### [35] [Data-Efficient Domain Adaptation for LLM-based MT using Contrastive Preference Optimization](https://arxiv.org/abs/2510.27556)
*Inacio Vieira,Antonio Castaldo,James O'Doherty,Sheila Castilho*

Main category: cs.CL

TL;DR: 提出一种利用CPO模拟后编辑流程以实现数据高效领域适应的方法。


<details>
  <summary>Details</summary>
Motivation: LLMs需要适应特定领域的需求，而传统的SFT方法成本较高。

Method: 通过将基础模型的原始输出视为“被拒绝”的翻译，人类批准的翻译记忆条目作为“选中”的翻译，合成偏好对。

Result: 仅使用14.7k个偏好对，模型性能接近使用160k+样本训练的模型，表现出显著的数据效率。

Conclusion: 该方法在翻译任务中展示了高效性，并可推广到其他生成任务。

Abstract: LLMs often require adaptation to domain-specific requirements, a process that
can be expensive when relying solely on SFT. We present an empirical study on
applying CPO to simulate a post-editing workflow for data-efficient domain
adaptation. Our approach synthesizes preference pairs by treating the base
model's own raw output as the 'rejected' translation and the human-approved TM
entry as the 'chosen' one. This method provides direct feedback on the model's
current knowledge, guiding it to align with domain-specific standards.
Experiments in English-Brazilian Portuguese and English-Korean show that, by
using just 14.7k preference pairs, the model achieves performance close to that
of a model trained on 160k+ samples with SFT, demonstrating significant data
efficiency. Although we showcase its effectiveness in MT, this application of
CPO naturally generalizes to other generative tasks where a model's initial
drafts can serve as a contrastive signal against a golden reference.

</details>


### [36] [MARAG-R1: Beyond Single Retriever via Reinforcement-Learned Multi-Tool Agentic Retrieval](https://arxiv.org/abs/2510.27569)
*Qi Luo,Xiaonan Li,Yuxin Wang,Tingshuo Fan,Yuan Li,Xinchi Chen,Xipeng Qiu*

Main category: cs.CL

TL;DR: 提出了一种名为MARAG-R1的强化学习多工具检索增强生成框架，以解决现有RAG系统依赖单一检索器的问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型因静态预训练数据导致事实不准确，且现有RAG系统依赖单一检索器，限制了对外部信息的全面获取。

Method: 提出MARAG-R1，通过强化学习训练模型动态协调四种检索工具（语义搜索、关键词搜索、过滤和聚合），采用两阶段训练过程：监督微调和强化学习。

Result: 在全球问答、HotpotQA和2WikiMultiHopQA实验中，MARAG-R1显著优于强基线，并实现了最先进的性能。

Conclusion: MARAG-R1能够有效提升模型对外部信息的访问广度和精确度，改善语料库级推理任务的表现。

Abstract: Large Language Models (LLMs) excel at reasoning and generation but are
inherently limited by static pretraining data, resulting in factual
inaccuracies and weak adaptability to new information. Retrieval-Augmented
Generation (RAG) addresses this issue by grounding LLMs in external knowledge;
However, the effectiveness of RAG critically depends on whether the model can
adequately access relevant information. Existing RAG systems rely on a single
retriever with fixed top-k selection, restricting access to a narrow and static
subset of the corpus. As a result, this single-retriever paradigm has become
the primary bottleneck for comprehensive external information acquisition,
especially in tasks requiring corpus-level reasoning. To overcome this
limitation, we propose MARAG-R1, a reinforcement-learned multi-tool RAG
framework that enables LLMs to dynamically coordinate multiple retrieval
mechanisms for broader and more precise information access. MARAG-R1 equips the
model with four retrieval tools -- semantic search, keyword search, filtering,
and aggregation -- and learns both how and when to use them through a two-stage
training process: supervised fine-tuning followed by reinforcement learning.
This design allows the model to interleave reasoning and retrieval,
progressively gathering sufficient evidence for corpus-level synthesis.
Experiments on GlobalQA, HotpotQA, and 2WikiMultiHopQA demonstrate that
MARAG-R1 substantially outperforms strong baselines and achieves new
state-of-the-art results in corpus-level reasoning tasks.

</details>


### [37] [SpecAttn: Speculating Sparse Attention](https://arxiv.org/abs/2510.27641)
*Harsh Shah*

Main category: cs.CL

TL;DR: SpecAttn是一种无需训练的新方法，通过利用草稿模型在推测解码过程中已计算出的注意力权重，实现高效稀疏注意力，显著减少关键值缓存访问，同时保持输出质量。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在推理过程中由于自注意力机制的二次复杂性，面临显著的计算瓶颈，尤其是在上下文长度增加时。

Method: SpecAttn采用三种核心技术：基于KL散度的层对齐、GPU优化的无排序top-p标记选择算法，以及由预测引导的动态关键值缓存修剪。

Result: SpecAttn在PG-19数据集上实现了关键值缓存访问减少超过75%，而困惑度仅增加15.29%，显著优于现有稀疏注意力方法。

Conclusion: SpecAttn通过利用推测解码流程中的计算工作，实现了推测执行的增强，提供了近似验证，且性能退化较小。

Abstract: Large Language Models (LLMs) face significant computational bottlenecks
during inference due to the quadratic complexity of self-attention mechanisms,
particularly as context lengths increase. We introduce SpecAttn, a novel
training-free approach that seamlessly integrates with existing speculative
decoding techniques to enable efficient sparse attention in pre-trained
transformers. Our key insight is to exploit the attention weights already
computed by the draft model during speculative decoding to identify important
tokens for the target model, eliminating redundant computation while
maintaining output quality. SpecAttn employs three core techniques: KL
divergence-based layer alignment between draft and target models, a
GPU-optimized sorting-free algorithm for top-p token selection from draft
attention patterns, and dynamic key-value cache pruning guided by these
predictions. By leveraging the computational work already performed in standard
speculative decoding pipelines, SpecAttn achieves over 75% reduction in
key-value cache accesses with a mere 15.29% increase in perplexity on the PG-19
dataset, significantly outperforming existing sparse attention methods. Our
approach demonstrates that speculative execution can be enhanced to provide
approximate verification without significant performance degradation.

</details>


### [38] [Continuous Autoregressive Language Models](https://arxiv.org/abs/2510.27688)
*Chenze Shao,Darren Li,Fandong Meng,Jie Zhou*

Main category: cs.CL

TL;DR: 大型语言模型效率受限于逐令牌生成过程，CALM通过连续向量的预测提高每步生成的语义带宽，从而减少生成步骤。


<details>
  <summary>Details</summary>
Motivation: 当前LLM的生成过程效率受限于其顺序性，通过提高每步的语义带宽，可以显著减少计算成本，提高性能-计算比率。

Method: 引入连续自回归语言模型（CALM），利用高保真自编码器将K个令牌压缩为单个连续向量，并开发了一套无似然框架，以支持连续域中的训练、评估和控制采样。

Result: 实验表明，CALM在显著降低计算成本的同时，达到了强大的离散基线性能，并且每个生成步骤的语义带宽提高了K倍。

Conclusion: CALM通过连续向量预测提供了一种高效且可扩展的语言模型路径，为超高效语言模型的发展提供了新的方向。

Abstract: The efficiency of large language models (LLMs) is fundamentally limited by
their sequential, token-by-token generation process. We argue that overcoming
this bottleneck requires a new design axis for LLM scaling: increasing the
semantic bandwidth of each generative step. To this end, we introduce
Continuous Autoregressive Language Models (CALM), a paradigm shift from
discrete next-token prediction to continuous next-vector prediction. CALM uses
a high-fidelity autoencoder to compress a chunk of K tokens into a single
continuous vector, from which the original tokens can be reconstructed with
over 99.9\% accuracy. This allows us to model language as a sequence of
continuous vectors instead of discrete tokens, which reduces the number of
generative steps by a factor of K. The paradigm shift necessitates a new
modeling toolkit; therefore, we develop a comprehensive likelihood-free
framework that enables robust training, evaluation, and controllable sampling
in the continuous domain. Experiments show that CALM significantly improves the
performance-compute trade-off, achieving the performance of strong discrete
baselines at a significantly lower computational cost. More importantly, these
findings establish next-vector prediction as a powerful and scalable pathway
towards ultra-efficient language models. Code:
https://github.com/shaochenze/calm. Project:
https://shaochenze.github.io/blog/2025/CALM.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [39] [Cognition Envelopes for Bounded AI Reasoning in Autonomous UAS Operations](https://arxiv.org/abs/2510.26905)
*Pedro Antonio Alarcón Granadeno,Arturo Miguel Bernal Russell,Sofia Nelson,Demetrius Hernandez,Maureen Petterson,Michael Murphy,Walter J. Scheirer,Jane Cleland-Huang*

Main category: cs.AI

TL;DR: 该论文介绍了认知包络（Cognition Envelopes）的概念，旨在通过建立推理边界来约束AI生成的决策，以应对基础模型（如LLMs和VLMs）在信息物理系统中引入的错误。


<details>
  <summary>Details</summary>
Motivation: 随着信息物理系统越来越依赖基础模型（如LLMs和VLMs）来提升自主性，这些模型带来的新错误类型（如幻觉、过度概括和上下文错位）导致了不正确和有缺陷的决策。

Method: 引入认知包络的概念，通过建立推理边界来约束AI生成的决策，并补充使用元认知和传统安全包络。

Result: 提出了认知包络的实际指导原则和系统流程，用于其定义、验证和保证。

Conclusion: 认知包络是应对基础模型在信息物理系统中引入错误的有效方法，需要系统性的定义和验证流程以确保其有效性。

Abstract: Cyber-physical systems increasingly rely on Foundational Models such as Large
Language Models (LLMs) and Vision-Language Models (VLMs) to increase autonomy
through enhanced perception, inference, and planning. However, these models
also introduce new types of errors, such as hallucinations,
overgeneralizations, and context misalignments, resulting in incorrect and
flawed decisions. To address this, we introduce the concept of Cognition
Envelopes, designed to establish reasoning boundaries that constrain
AI-generated decisions while complementing the use of meta-cognition and
traditional safety envelopes. As with safety envelopes, Cognition Envelopes
require practical guidelines and systematic processes for their definition,
validation, and assurance.

</details>


### [40] [SUSTAINABLE Platform: Seamless Smart Farming Integration Towards Agronomy Automation](https://arxiv.org/abs/2510.26989)
*Agorakis Bompotas,Konstantinos Koutras,Nikitas Rigas Kalogeropoulos,Panagiotis Kechagias,Dimitra Gariza,Athanasios P. Kalogeras,Christos Alexakos*

Main category: cs.AI

TL;DR: SUSTAINABLE是一个智慧农业平台，通过整合IoT、AI、卫星成像和基于角色的任务编排，旨在实现高效、可追溯和可持续的农业，尤其是在地中海葡萄园中的应用。


<details>
  <summary>Details</summary>
Motivation: 全球农业部门正经历由日益增长的食品需求、气候变率和可持续实践需求驱动的变革。

Method: 整合IoT、AI、卫星成像和基于角色的任务编排，开发SUSTAINABLE平台。

Result: 介绍了SUSTAINABLE的关键功能，包括卫星指数集成、实时环境数据和针对地中海葡萄园的角色感知任务管理。

Conclusion: SUSTAINABLE平台为智慧农业提供了一个综合解决方案，通过技术创新实现可持续农业实践。

Abstract: The global agricultural sector is undergoing a transformative shift, driven
by increasing food demands, climate variability and the need for sustainable
practices. SUSTAINABLE is a smart farming platform designed to integrate IoT,
AI, satellite imaging, and role-based task orchestration to enable efficient,
traceable, and sustainable agriculture with a pilot usecase in viticulture.
This paper explores current smart agriculture solutions, presents a comparative
evaluation, and introduces SUSTAINABLE's key features, including satellite
index integration, real-time environmental data, and role-aware task management
tailored to Mediterranean vineyards.

</details>


### [41] [Causal Masking on Spatial Data: An Information-Theoretic Case for Learning Spatial Datasets with Unimodal Language Models](https://arxiv.org/abs/2510.27009)
*Jared Junkin,Samuel Nathanson*

Main category: cs.AI

TL;DR: 研究探讨了语言模型在具有空间或关系结构的领域中使用因果掩码的可行性，特别在国际象棋领域，发现即使使用因果掩码，基于空间棋盘状态的模型表现优于基于序列数据的模型。


<details>
  <summary>Details</summary>
Motivation: 因果掩码在非序列数据上的信息损失问题尚未直接研究，国际象棋领域提供了空间和序列两种表示方式，适合进行此研究。

Method: 在国际象棋数据集上，使用双向和因果自注意力机制，分别在空间（棋盘状态）和序列（移动步骤）数据上训练语言模型。

Result: 训练在空间棋盘状态的模型，即使使用因果掩码，始终比训练在序列数据上的模型具有更强的棋艺表现。

Conclusion: 将因果掩码应用于空间数据是训练空间数据的单模态LLMs的可行方法，在某些领域甚至优于序列化方法。

Abstract: Language models are traditionally designed around causal masking. In domains
with spatial or relational structure, causal masking is often viewed as
inappropriate, and sequential linearizations are instead used. Yet the question
of whether it is viable to accept the information loss introduced by causal
masking on nonsequential data has received little direct study, in part because
few domains offer both spatial and sequential representations of the same
dataset. In this work, we investigate this issue in the domain of chess, which
naturally supports both representations. We train language models with
bidirectional and causal self-attention mechanisms on both spatial
(board-based) and sequential (move-based) data. Our results show that models
trained on spatial board states - \textit{even with causal masking} -
consistently achieve stronger playing strength than models trained on
sequential data. While our experiments are conducted on chess, our results are
methodological and may have broader implications: applying causal masking to
spatial data is a viable procedure for training unimodal LLMs on spatial data,
and in some domains is even preferable to sequentialization.

</details>


### [42] [e1: Learning Adaptive Control of Reasoning Effort](https://arxiv.org/abs/2510.27042)
*Michael Kleinman,Matthew Trager,Alessandro Achille,Wei Xia,Stefano Soatto*

Main category: cs.AI

TL;DR: 该论文提出了一种名为Adaptive Effort Control的自适应强化学习方法，允许用户通过连续的努力参数在推理时动态调整AI模型的成本-准确性权衡。


<details>
  <summary>Details</summary>
Motivation: 提高AI模型的思考预算可以显著提升准确性，但不是所有问题都需要相同的推理量。用户需要在输出质量、延迟和成本之间进行权衡，因此需要细粒度地控制每次查询的思考量。现有方法需要用户预先设定token数量，这需要事先知道问题难度。

Method: 提出的方法Adaptive Effort Control训练模型使用用户指定的相对于当前平均思维链长度的token比例，无需数据集和阶段特定的调优。

Result: 该方法在不同模型规模（1.5B到32B参数）上实现了约3倍的思维链长度减少，同时维持或提升了性能。

Conclusion: 该方法通过用户指定的努力参数，动态调整成本-准确性权衡，自动学习根据任务难度分配资源，优于标准方法。

Abstract: Increasing the thinking budget of AI models can significantly improve
accuracy, but not all questions warrant the same amount of reasoning. Users may
prefer to allocate different amounts of reasoning effort depending on how they
value output quality versus latency and cost. To leverage this tradeoff
effectively, users need fine-grained control over the amount of thinking used
for a particular query, but few approaches enable such control. Existing
methods require users to specify the absolute number of desired tokens, but
this requires knowing the difficulty of the problem beforehand to appropriately
set the token budget for a query. To address these issues, we propose Adaptive
Effort Control, a self-adaptive reinforcement learning method that trains
models to use a user-specified fraction of tokens relative to the current
average chain-of-thought length for each query. This approach eliminates
dataset- and phase-specific tuning while producing better cost-accuracy
tradeoff curves compared to standard methods. Users can dynamically adjust the
cost-accuracy trade-off through a continuous effort parameter specified at
inference time. We observe that the model automatically learns to allocate
resources proportionally to the task difficulty and, across model scales
ranging from 1.5B to 32B parameters, our approach enables approximately 3x
reduction in chain-of-thought length while maintaining or improving performance
relative to the base model used for RL training.

</details>


### [43] [Fints: Efficient Inference-Time Personalization for LLMs with Fine-Grained Instance-Tailored Steering](https://arxiv.org/abs/2510.27206)
*Kounianhua Du,Jianxing Liu,Kangning Zhang,Wenxiang Jiao,Yuan Lu,Jiarui Jin,Weiwen Liu,Yong Yu,Weinan Zhang*

Main category: cs.AI

TL;DR: 提出了一种细粒度和实例定制的引导框架，通过动态生成样本级干扰向量并注入到模型的前向传递中，以实现个性化适应。


<details>
  <summary>Details</summary>
Motivation: 当前个性化方法在处理动态用户模式和高数据稀疏性场景时存在适应性低和数据效率低的问题。

Method: 提出了一个细粒度的引导组件，通过捕捉注意力和MLP层的激活信号，以及一个输入感知的聚合模块，将这些信号综合成上下文相关的增强。

Result: 在快速变化的环境和高数据稀疏性场景中，该方法显著提升了个性化性能，并在不同交互模式和上下文长度下保持鲁棒性。

Conclusion: 该方法具有高度灵活性和数据效率，且与现有方法正交，可作为插件组件与不同的个性化技术兼容。

Abstract: The rapid evolution of large language models (LLMs) has intensified the
demand for effective personalization techniques that can adapt model behavior
to individual user preferences. Despite the non-parametric methods utilizing
the in-context learning ability of LLMs, recent parametric adaptation methods,
including personalized parameter-efficient fine-tuning and reward modeling
emerge. However, these methods face limitations in handling dynamic user
patterns and high data sparsity scenarios, due to low adaptability and data
efficiency. To address these challenges, we propose a fine-grained and
instance-tailored steering framework that dynamically generates sample-level
interference vectors from user data and injects them into the model's forward
pass for personalized adaptation. Our approach introduces two key technical
innovations: a fine-grained steering component that captures nuanced signals by
hooking activations from attention and MLP layers, and an input-aware
aggregation module that synthesizes these signals into contextually relevant
enhancements. The method demonstrates high flexibility and data efficiency,
excelling in fast-changing distribution and high data sparsity scenarios. In
addition, the proposed method is orthogonal to existing methods and operates as
a plug-in component compatible with different personalization techniques.
Extensive experiments across diverse scenarios--including short-to-long text
generation, and web function calling--validate the effectiveness and
compatibility of our approach. Results show that our method significantly
enhances personalization performance in fast-shifting environments while
maintaining robustness across varying interaction modes and context lengths.
Implementation is available at https://github.com/KounianhuaDu/Fints.

</details>


### [44] [Reinforcement Learning for Long-Horizon Unordered Tasks: From Boolean to Coupled Reward Machines](https://arxiv.org/abs/2510.27329)
*Kristina Levina,Nikolaos Pappas,Athanasios Karapantelakis,Aneta Vulgarakis Feljan,Jendrik Seipp*

Main category: cs.AI

TL;DR: 本文介绍了三种奖励机器（RMs）的泛化形式，并提出了一种新的组合学习算法CoRM，以解决长时程问题中无序子任务的学习效率问题。


<details>
  <summary>Details</summary>
Motivation: 传统奖励机器在长时程、无序子任务问题中信息量呈指数增长，导致学习效率低下，因此需要新的方法来提高学习效率。

Method: 引入了三种RMs的泛化形式：Numeric RMs、Agenda RMs和Coupled RMs，并提出了一种新的组合学习算法Q-learning with coupled RMs (CoRM)。

Result: 实验表明，CoRM在具有无序子任务的长时程问题上，其扩展性优于现有的RM算法。

Conclusion: 通过引入新的泛化形式和组合学习算法，CoRM能够更高效地处理长时程、无序子任务的问题。

Abstract: Reward machines (RMs) inform reinforcement learning agents about the reward
structure of the environment. This is particularly advantageous for complex
non-Markovian tasks because agents with access to RMs can learn more
efficiently from fewer samples. However, learning with RMs is ill-suited for
long-horizon problems in which a set of subtasks can be executed in any order.
In such cases, the amount of information to learn increases exponentially with
the number of unordered subtasks. In this work, we address this limitation by
introducing three generalisations of RMs: (1) Numeric RMs allow users to
express complex tasks in a compact form. (2) In Agenda RMs, states are
associated with an agenda that tracks the remaining subtasks to complete. (3)
Coupled RMs have coupled states associated with each subtask in the agenda.
Furthermore, we introduce a new compositional learning algorithm that leverages
coupled RMs: Q-learning with coupled RMs (CoRM). Our experiments show that CoRM
scales better than state-of-the-art RM algorithms for long-horizon problems
with unordered subtasks.

</details>


### [45] [Discriminative Rule Learning for Outcome-Guided Process Model Discovery](https://arxiv.org/abs/2510.27343)
*Ali Norouzifar,Wil van der Aalst*

Main category: cs.AI

TL;DR: 该论文提出了一种基于控制流特征学习可解释判别规则的方法，以对业务过程执行日志中的理想和非理想行为进行分组，并在每组内分别进行过程发现，从而提高模型的解释性和适用性。


<details>
  <summary>Details</summary>
Motivation: 当前的过程发现方法通常不考虑执行结果的优劣，导致生成的模型在一致性检查和性能分析中表现不佳。因此，有必要开发一种更关注结果的过程发现方法，以区分和揭示理想和非理想行为之间的关键差异。

Method: 通过学习控制流特征上的可解释判别规则，将具有相似可取性特征的事件日志分组，然后在每组内部分别进行过程发现。

Result: 在多个真实事件日志上的评估表明，该方法能有效隔离和可视化关键过程模式，生成的模型更具解释性和适用性。

Conclusion: 该方法不仅提高了过程模型的可解释性，还能揭示驱动理想和非理想执行的关键因素，为过程改进提供了有力支持。

Abstract: Event logs extracted from information systems offer a rich foundation for
understanding and improving business processes. In many real-world
applications, it is possible to distinguish between desirable and undesirable
process executions, where desirable traces reflect efficient or compliant
behavior, and undesirable ones may involve inefficiencies, rule violations,
delays, or resource waste. This distinction presents an opportunity to guide
process discovery in a more outcome-aware manner. Discovering a single process
model without considering outcomes can yield representations poorly suited for
conformance checking and performance analysis, as they fail to capture critical
behavioral differences. Moreover, prioritizing one behavior over the other may
obscure structural distinctions vital for understanding process outcomes. By
learning interpretable discriminative rules over control-flow features, we
group traces with similar desirability profiles and apply process discovery
separately within each group. This results in focused and interpretable models
that reveal the drivers of both desirable and undesirable executions. The
approach is implemented as a publicly available tool and it is evaluated on
multiple real-life event logs, demonstrating its effectiveness in isolating and
visualizing critical process patterns.

</details>


### [46] [An In-depth Study of LLM Contributions to the Bin Packing Problem](https://arxiv.org/abs/2510.27353)
*Julien Herrmann,Guillaume Pallez*

Main category: cs.AI

TL;DR: 本文评估了大型语言模型（LLMs）在数学发现中的作用，特别是在在线装箱问题中的启发式生成。


<details>
  <summary>Details</summary>
Motivation: 最近的报告表明，基于LLM的遗传算法可以产生对在线装箱问题有新颖见解的启发式方法，这激发了本文的研究。

Method: 通过详细分析LLM生成的启发式方法，考察其行为和解释性，提出针对特定装箱问题的新算法类。

Result: 新算法更简单、高效、可解释和具有更强泛化能力，表明所考虑的问题实例相对简单。

Conclusion: LLMs在问题上的贡献被高估了，强调了评估LLM生成结果的科学价值时需进行严格的验证和上下文分析。

Abstract: Recent studies have suggested that Large Language Models (LLMs) could provide
interesting ideas contributing to mathematical discovery. This claim was
motivated by reports that LLM-based genetic algorithms produced heuristics
offering new insights into the online bin packing problem under uniform and
Weibull distributions. In this work, we reassess this claim through a detailed
analysis of the heuristics produced by LLMs, examining both their behavior and
interpretability. Despite being human-readable, these heuristics remain largely
opaque even to domain experts. Building on this analysis, we propose a new
class of algorithms tailored to these specific bin packing instances. The
derived algorithms are significantly simpler, more efficient, more
interpretable, and more generalizable, suggesting that the considered instances
are themselves relatively simple. We then discuss the limitations of the claim
regarding LLMs' contribution to this problem, which appears to rest on the
mistaken assumption that the instances had previously been studied. Our
findings instead emphasize the need for rigorous validation and
contextualization when assessing the scientific value of LLM-generated outputs.

</details>


### [47] [Realistic pedestrian-driver interaction modelling using multi-agent RL with human perceptual-motor constraints](https://arxiv.org/abs/2510.27383)
*Yueyang Wang,Mehmet Dogar,Gustav Markkula*

Main category: cs.AI

TL;DR: 提出了一个结合行人和驾驶员视觉与运动约束的多智能体强化学习框架，以更真实地建模道路使用者交互行为。


<details>
  <summary>Details</summary>
Motivation: 现有模型缺乏灵活性或忽略了行人和驾驶员在交互场景中的感知和行动机制，如感官和运动约束。

Method: 提出的多智能体强化学习框架整合了视觉和运动约束，使用真实世界的无信号人行横道数据集评估了四种模型变体。

Result: 结合视觉和运动约束的模型表现最佳，运动约束使动作更平滑，视觉约束使行为更谨慎和多样化。

Conclusion: 该框架通过建模人类约束参数为群体级分布，能有效模拟真实道路使用者交互，是建模行人和车辆交互的一种有前途的方法。

Abstract: Modelling pedestrian-driver interactions is critical for understanding human
road user behaviour and developing safe autonomous vehicle systems. Existing
approaches often rely on rule-based logic, game-theoretic models, or
'black-box' machine learning methods. However, these models typically lack
flexibility or overlook the underlying mechanisms, such as sensory and motor
constraints, which shape how pedestrians and drivers perceive and act in
interactive scenarios. In this study, we propose a multi-agent reinforcement
learning (RL) framework that integrates both visual and motor constraints of
pedestrian and driver agents. Using a real-world dataset from an unsignalised
pedestrian crossing, we evaluate four model variants, one without constraints,
two with either motor or visual constraints, and one with both, across
behavioural metrics of interaction realism. Results show that the combined
model with both visual and motor constraints performs best. Motor constraints
lead to smoother movements that resemble human speed adjustments during
crossing interactions. The addition of visual constraints introduces perceptual
uncertainty and field-of-view limitations, leading the agents to exhibit more
cautious and variable behaviour, such as less abrupt deceleration. In this
data-limited setting, our model outperforms a supervised behavioural cloning
model, demonstrating that our approach can be effective without large training
datasets. Finally, our framework accounts for individual differences by
modelling parameters controlling the human constraints as population-level
distributions, a perspective that has not been explored in previous work on
pedestrian-vehicle interaction modelling. Overall, our work demonstrates that
multi-agent RL with human constraints is a promising modelling approach for
simulating realistic road user interactions.

</details>


### [48] [DeepCompress: A Dual Reward Strategy for Dynamically Exploring and Compressing Reasoning Chains](https://arxiv.org/abs/2510.27419)
*Tian Liang,Wenxiang Jiao,Zhiwei He,Jiahao Xu,Haitao Mi,Dong Yu*

Main category: cs.AI

TL;DR: 本文介绍了一种名为DeepCompress的新框架，通过自适应长度奖励机制，提高大型推理模型（LRMs）的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）在处理简单和复杂问题时存在认知效率低的问题。现有的方法在提升效率时通常会牺牲准确性。

Method: DeepCompress采用自适应长度奖励机制，根据问题难度实时将问题分类为“简单”或“困难”，并相应地调整推理路径长度。

Result: 在具有挑战性的数学基准测试中，DeepCompress在准确性和标记效率方面始终优于基线方法。

Conclusion: DeepCompress通过双奖励策略，使模型能够自主调整推理路径长度，在提升效率的同时也提高了准确性。

Abstract: Large Reasoning Models (LRMs) have demonstrated impressive capabilities but
suffer from cognitive inefficiencies like ``overthinking'' simple problems and
``underthinking'' complex ones. While existing methods that use supervised
fine-tuning~(SFT) or reinforcement learning~(RL) with token-length rewards can
improve efficiency, they often do so at the cost of accuracy. This paper
introduces \textbf{DeepCompress}, a novel framework that simultaneously
enhances both the accuracy and efficiency of LRMs. We challenge the prevailing
approach of consistently favoring shorter reasoning paths, showing that longer
responses can contain a broader range of correct solutions for difficult
problems. DeepCompress employs an adaptive length reward mechanism that
dynamically classifies problems as ``Simple'' or ``Hard'' in real-time based on
the model's evolving capability. It encourages shorter, more efficient
reasoning for ``Simple'' problems while promoting longer, more exploratory
thought chains for ``Hard'' problems. This dual-reward strategy enables the
model to autonomously adjust its Chain-of-Thought (CoT) length, compressing
reasoning for well-mastered problems and extending it for those it finds
challenging. Experimental results on challenging mathematical benchmarks show
that DeepCompress consistently outperforms baseline methods, achieving superior
accuracy while significantly improving token efficiency.

</details>


### [49] [GeoFM: Enhancing Geometric Reasoning of MLLMs via Synthetic Data Generation through Formal Language](https://arxiv.org/abs/2510.27448)
*Yuhao Zhang,Dingxin Hu,Tinghao Yu,Hao Liu,Yiting Liu*

Main category: cs.AI

TL;DR: 本文提出了一种新方法GeoFM，通过形式语言生成高保真几何问题数据，以解决多模态大型语言模型在几何推理中的数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 多模态大型语言模型在几何推理方面由于高质量几何数据稀缺而面临挑战，现有合成数据方法生成的数据缺乏多样性或容易产生噪声。

Method: GeoFM利用形式语言探索度量空间内的条件组合，生成高保真的几何问题，并通过符号引擎确保其正确性。

Result: 实验结果显示，GeoFM生成的数据显著优于现有方法，其训练模型在MathVista和GeoQA几何问题解决任务上超越了GPT-4o和领先开源模型。

Conclusion: GeoFM提供了一种有效的几何数据合成方法，通过提高数据多样性和真实性，显著提升了多模态大型语言模型在几何推理任务中的性能。

Abstract: Multi-modal Large Language Models (MLLMs) have gained significant attention
in both academia and industry for their capabilities in handling multi-modal
tasks. However, these models face challenges in mathematical geometric
reasoning due to the scarcity of high-quality geometric data. To address this
issue, synthetic geometric data has become an essential strategy. Current
methods for generating synthetic geometric data involve rephrasing or expanding
existing problems and utilizing predefined rules and templates to create
geometric images and problems. However, these approaches often produce data
that lacks diversity or is prone to noise. Additionally, the geometric images
synthesized by existing methods tend to exhibit limited variation and deviate
significantly from authentic geometric diagrams. To overcome these limitations,
we propose GeoFM, a novel method for synthesizing geometric data. GeoFM uses
formal languages to explore combinations of conditions within metric space,
generating high-fidelity geometric problems that differ from the originals
while ensuring correctness through a symbolic engine. Experimental results show
that our synthetic data significantly outperforms existing methods. The model
trained with our data surpass the proprietary GPT-4o model by 18.7\% on
geometry problem-solving tasks in MathVista and by 16.5\% on GeoQA.
Additionally, it exceeds the performance of a leading open-source model by
5.7\% on MathVista and by 2.7\% on GeoQA.

</details>


### [50] [SIGMA: Search-Augmented On-Demand Knowledge Integration for Agentic Mathematical Reasoning](https://arxiv.org/abs/2510.27568)
*Ali Asgarov,Umid Suleymanov,Aadyant Khatri*

Main category: cs.AI

TL;DR: SIGMA是一个多智能体框架，通过按需检索和知识整合来提升数学推理的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 当前检索增强模型在解决数学推理问题时，往往依赖于单一的视角和固定的搜索策略，难以有效整合多源信息。

Method: SIGMA框架通过协调专门的智能体进行独立推理、有针对性的搜索，并通过一个协调机制综合结果。每个智能体生成假设性段落以优化检索，确保知识整合既敏感于上下文又计算高效。

Result: 在MATH500、AIME和GPQA等挑战性基准测试中，SIGMA始终优于现有的开源和闭源系统，性能提升了7.4%。

Conclusion: 多智能体、按需知识整合显著提升了推理的准确性和效率，为复杂的知识密集型问题求解提供了一个可扩展的方法。

Abstract: Solving mathematical reasoning problems requires not only accurate access to
relevant knowledge but also careful, multi-step thinking. However, current
retrieval-augmented models often rely on a single perspective, follow
inflexible search strategies, and struggle to effectively combine information
from multiple sources. We introduce SIGMA (Search-Augmented On-Demand Knowledge
Integration for AGentic Mathematical reAsoning), a unified framework that
orchestrates specialized agents to independently reason, perform targeted
searches, and synthesize findings through a moderator mechanism. Each agent
generates hypothetical passages to optimize retrieval for its analytic
perspective, ensuring knowledge integration is both context-sensitive and
computation-efficient. When evaluated on challenging benchmarks such as
MATH500, AIME, and PhD-level science QA GPQA, SIGMA consistently outperforms
both open- and closed-source systems, achieving an absolute performance
improvement of 7.4%. Our results demonstrate that multi-agent, on-demand
knowledge integration significantly enhances both reasoning accuracy and
efficiency, offering a scalable approach for complex, knowledge-intensive
problem-solving. We will release the code upon publication.

</details>


### [51] [VeriMoA: A Mixture-of-Agents Framework for Spec-to-HDL Generation](https://arxiv.org/abs/2510.27617)
*Heng Ping,Arijit Bhattacharjee,Peiyu Zhang,Shixuan Li,Wei Yang,Anzhe Cheng,Xiaole Zhang,Jesse Thomason,Ali Jannesari,Nesreen Ahmed,Paul Bogdan*

Main category: cs.AI

TL;DR: 提出了一种无需训练的多智能体框架VeriMoA，用于提高硬件描述语言（HDL）的生成质量。


<details>
  <summary>Details</summary>
Motivation: 自动化RTL设计能帮助满足日益增长的计算需求，但现有LLM在HDL生成上受限于知识覆盖和领域约束，多智能体架构存在噪声传播和推理空间受限问题。

Method: VeriMoA框架采用质量导向缓存机制和多路径生成策略，利用C++和Python作为中间表示，分解规范到HDL的转换过程。

Result: 在VerilogEval 2.0和RTLLM 2.0基准测试中，Pass@1指标提升15%-30%，小模型性能可匹配大模型及微调模型。

Conclusion: VeriMoA通过缓存和多路径策略有效提升了HDL生成质量，无需训练即可实现性能改进。

Abstract: Automation of Register Transfer Level (RTL) design can help developers meet
increasing computational demands. Large Language Models (LLMs) show promise for
Hardware Description Language (HDL) generation, but face challenges due to
limited parametric knowledge and domain-specific constraints. While prompt
engineering and fine-tuning have limitations in knowledge coverage and training
costs, multi-agent architectures offer a training-free paradigm to enhance
reasoning through collaborative generation. However, current multi-agent
approaches suffer from two critical deficiencies: susceptibility to noise
propagation and constrained reasoning space exploration. We propose VeriMoA, a
training-free mixture-of-agents (MoA) framework with two synergistic
innovations. First, a quality-guided caching mechanism to maintain all
intermediate HDL outputs and enables quality-based ranking and selection across
the entire generation process, encouraging knowledge accumulation over layers
of reasoning. Second, a multi-path generation strategy that leverages C++ and
Python as intermediate representations, decomposing specification-to-HDL
translation into two-stage processes that exploit LLM fluency in high-resource
languages while promoting solution diversity. Comprehensive experiments on
VerilogEval 2.0 and RTLLM 2.0 benchmarks demonstrate that VeriMoA achieves
15--30% improvements in Pass@1 across diverse LLM backbones, especially
enabling smaller models to match larger models and fine-tuned alternatives
without requiring costly training.

</details>


### [52] [Visual Backdoor Attacks on MLLM Embodied Decision Making via Contrastive Trigger Learning](https://arxiv.org/abs/2510.27623)
*Qiusi Zhan,Hyeonjeong Ha,Rui Yang,Sirui Xu,Hanyang Chen,Liang-Yan Gui,Yu-Xiong Wang,Huan Zhang,Heng Ji,Daniel Kang*

Main category: cs.AI

TL;DR: 本文介绍了BEAT，首个针对多模态大型语言模型（MLLMs）驱动的具身智能体的视觉后门攻击框架。


<details>
  <summary>Details</summary>
Motivation: 视觉驱动的具身智能体易受视觉后门攻击，攻击者通过环境中的物体作为触发器操控智能体行为，这种攻击面尚未被深入探索。

Method: BEAT通过构建涵盖多样场景、任务和触发器位置的数据集，并采用两阶段训练方案（监督微调SFT和对比触发学习CTL）实现后门植入。CTL将触发器识别建模为偏好学习，以明确加强决策边界。

Result: 在多种具身智能体基准测试和多模态大型语言模型上，BEAT实现了高达80%的攻击成功率，同时保持较高的正常任务性能，并在非分布触发器位置上可靠泛化。CTL在有限数据下提升后门激活准确率达39%。

Conclusion: BEAT揭示了MLLM驱动的具身智能体存在的重要安全风险，强调了在实际部署前需要稳健的防御机制。

Abstract: Multimodal large language models (MLLMs) have advanced embodied agents by
enabling direct perception, reasoning, and planning task-oriented actions from
visual inputs. However, such vision driven embodied agents open a new attack
surface: visual backdoor attacks, where the agent behaves normally until a
visual trigger appears in the scene, then persistently executes an
attacker-specified multi-step policy. We introduce BEAT, the first framework to
inject such visual backdoors into MLLM-based embodied agents using objects in
the environments as triggers. Unlike textual triggers, object triggers exhibit
wide variation across viewpoints and lighting, making them difficult to implant
reliably. BEAT addresses this challenge by (1) constructing a training set that
spans diverse scenes, tasks, and trigger placements to expose agents to trigger
variability, and (2) introducing a two-stage training scheme that first applies
supervised fine-tuning (SFT) and then our novel Contrastive Trigger Learning
(CTL). CTL formulates trigger discrimination as preference learning between
trigger-present and trigger-free inputs, explicitly sharpening the decision
boundaries to ensure precise backdoor activation. Across various embodied agent
benchmarks and MLLMs, BEAT achieves attack success rates up to 80%, while
maintaining strong benign task performance, and generalizes reliably to
out-of-distribution trigger placements. Notably, compared to naive SFT, CTL
boosts backdoor activation accuracy up to 39% under limited backdoor data.
These findings expose a critical yet unexplored security risk in MLLM-based
embodied agents, underscoring the need for robust defenses before real-world
deployment.

</details>


### [53] [Validity Is What You Need](https://arxiv.org/abs/2510.27628)
*Sebastian Benthall,Andrew Clark*

Main category: cs.AI

TL;DR: Agentic AI被定义为一种软件交付机制，类似于SaaS，能在复杂的商业环境中自主运行。与基础模型不同，Agentic AI的成功取决于终端用户和主要利益相关者的验证。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）的发展，Agentic AI引起了广泛关注。然而，当前对Agentic AI系统的验证方法不同于基础模型的评估方法，这促使作者提出对Agentic AI的新定义和验证方法。

Method: 作者提出了一种现实主义定义的Agentic AI，并强调其主要任务是应用，而不是基础模型。Agentic AI的成功在于通过终端用户和利益相关者的验证。

Result: 良好的验证措施可以使得在许多情况下，基础模型可以被更简单、快速和可解释的模型替代，这些模型能够处理核心逻辑。

Conclusion: 在Agentic AI中，有效性是至关重要的，LLM只是实现有效性的一种选择。

Abstract: While AI agents have long been discussed and studied in computer science,
today's Agentic AI systems are something new. We consider other definitions of
Agentic AI and propose a new realist definition. Agentic AI is a software
delivery mechanism, comparable to software as a service (SaaS), which puts an
application to work autonomously in a complex enterprise setting. Recent
advances in large language models (LLMs) as foundation models have driven
excitement in Agentic AI. We note, however, that Agentic AI systems are
primarily applications, not foundations, and so their success depends on
validation by end users and principal stakeholders. The tools and techniques
needed by the principal users to validate their applications are quite
different from the tools and techniques used to evaluate foundation models.
Ironically, with good validation measures in place, in many cases the
foundation models can be replaced with much simpler, faster, and more
interpretable models that handle core logic. When it comes to Agentic AI,
validity is what you need. LLMs are one option that might achieve it.

</details>
